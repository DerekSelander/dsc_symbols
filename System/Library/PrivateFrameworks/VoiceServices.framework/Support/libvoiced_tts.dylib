|| __DATA.__data __ZN11flatbuffers25flatbuffer_version_stringE
|| __DATA.__data __ZZN11flatbuffers4dataINS_6OffsetIN4siri6speech9schema_fb14WordTimingInfoEEENSt3__19allocatorIS6_EEEEPKT_RKNS7_6vectorISA_T0_EEE1t
|| __DATA.__data __ZZN11flatbuffers4dataINS_6OffsetIN4siri6speech9schema_fb20TextToSpeechRequest_16ContextInfoEntryEEENSt3__19allocatorIS7_EEEEPKT_RKNS8_6vectorISB_T0_EEE1t
|| __DATA.__data __ZZN11flatbuffers4dataINS_6OffsetIN4siri6speech9schema_fb34StartTextToSpeechStreamingRequest_16ContextInfoEntryEEENSt3__19allocatorIS7_EEEEPKT_RKNS8_6vectorISB_T0_EEE1t
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableAudioDescription
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableBeginTextToSpeechStreamingResponse
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableFinalTextToSpeechStreamingResponse
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutablePartialTextToSpeechStreamingResponse
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTTSRequestFeatureFlags
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechMeta
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRequestContext
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRequestExperiment
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechResource
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechResponse
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechVoice
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSMutableWordTimingInfo
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSTTSRequestFeatureFlags
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRequestContext
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRequestExperiment
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechResponse
|| __DATA.__objc_data _OBJC_CLASS_$_VSAudioMappedInfoAVSBAR
|| __DATA.__objc_data _OBJC_CLASS_$_VSAudioPlaybackServiceAVSBAR
|| __DATA.__objc_data _OBJC_CLASS_$_VSDurationEstimationTask
|| __DATA.__objc_data _OBJC_CLASS_$_VSMemoryMap
|| __DATA.__objc_data _OBJC_CLASS_$_VSOccasionalTimesObserver
|| __DATA.__objc_data _OBJC_CLASS_$_VSSiriInlineTTSStreamTask
|| __DATA.__objc_data _OBJC_CLASS_$_VSTextToPhonemesTask
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableAudioDescription
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableBeginTextToSpeechStreamingResponse
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableFinalTextToSpeechStreamingResponse
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutablePartialTextToSpeechStreamingResponse
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTTSRequestFeatureFlags
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechMeta
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRequestContext
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechResource
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechResponse
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRouterStreamingStreamingResponse
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechVoice
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSMutableWordTimingInfo
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSTTSRequestFeatureFlags
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRequestContext
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRequestExperiment
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRequest_ContextInfoEntry
|| __DATA.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechResponse
|| __DATA.__objc_data _OBJC_METACLASS_$_VSAudioMappedInfoAVSBAR
|| __DATA.__objc_data _OBJC_METACLASS_$_VSAudioPlaybackServiceAVSBAR
|| __DATA.__objc_data _OBJC_METACLASS_$_VSDurationEstimationTask
|| __DATA.__objc_data _OBJC_METACLASS_$_VSMemoryMap
|| __DATA.__objc_data _OBJC_METACLASS_$_VSOccasionalTimesObserver
|| __DATA.__objc_data _OBJC_METACLASS_$_VSSiriInlineTTSStreamTask
|| __DATA.__objc_data _OBJC_METACLASS_$_VSTextToPhonemesTask
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSAudioDescription._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSBeginTextToSpeechStreamingResponse._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSFinalTextToSpeechStreamingResponse._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSPartialTextToSpeechStreamingResponse._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSStartTextToSpeechStreamingRequest._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTTSRequestFeatureFlags._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechMeta._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRequest._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRequestContext._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRequestExperiment._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRequestMeta._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRequest_ContextInfoEntry._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechResource._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechResponse._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRouterStreamingStreamingRequest._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechRouterStreamingStreamingResponse._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSTextToSpeechVoice._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_OPTTSWordTimingInfo._storage
|| __DATA.__objc_ivar _OBJC_IVAR_$_VSAudioMappedInfoAVSBAR.sampleBuffer
|| __DATA.__objc_ivar _OBJC_IVAR_$_VSOccasionalTimesObserver._invalid
|| __DATA.__objc_ivar _OBJC_IVAR_$_VSOccasionalTimesObserver._timerQueue
|| __DATA.__objc_ivar _OBJC_IVAR_$_VSOccasionalTimesObserver._timerSource
|| __DATA_CONST.__const _VSAudioPlaybackAudioQueueUID
|| __DATA_CONST.__const _VSPreinstalledCacheLocation
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSAudioDescription
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSBeginTextToSpeechStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSFinalTextToSpeechStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSMutableStartTextToSpeechStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRequest
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRequestMeta
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSPartialTextToSpeechStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSStartTextToSpeechStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechMeta
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRequest
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRequestMeta
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechResource
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRouterStreamingStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechRouterStreamingStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSTextToSpeechVoice
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OPTTSWordTimingInfo
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_OspreyTTSService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSAudioMappedInfoAT
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSAudioPlaybackService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSAudioPlaybackServiceAT
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSAudioRouteInfo
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSCacheDeleteService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSCachingService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSDeviceTTSCore
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSDiagnosticService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSDownloadService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSHHManagementClient
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSHMHomeManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSInlineStreamService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSOspreyTTSCore
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSPostInstallService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSPrewarmService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSServerTTSClient
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSShortTermCache
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSiriInstrumentation
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSiriServerConfiguration
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechAudioPowerService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechCache
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechCacheAudio
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechPresynthesizedTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechServerTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechSpeakTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechSynthesisTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechTaskQueue
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSSpeechXPCHandler
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSStreamAudioData
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSStreamAudioMappedInfo
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSTimeoutCondition
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSVoiceBooster
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VSVoicePreviewTask
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSAudioDescription
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSBeginTextToSpeechStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSFinalTextToSpeechStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSMutableStartTextToSpeechStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRequest
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRequestExperiment
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRequestMeta
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSMutableTextToSpeechRouterStreamingStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSPartialTextToSpeechStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSStartTextToSpeechStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechMeta
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRequest
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRequestMeta
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechResource
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRouterStreamingStreamingRequest
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechRouterStreamingStreamingResponse
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSTextToSpeechVoice
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OPTTSWordTimingInfo
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_OspreyTTSService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSAudioMappedInfoAT
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSAudioPlaybackService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSAudioPlaybackServiceAT
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSAudioRouteInfo
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSCacheDeleteService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSCachingService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSDeviceTTSCore
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSDiagnosticService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSDownloadService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSHHManagementClient
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSHMHomeManager
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSInlineStreamService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSOspreyTTSCore
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSPostInstallService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSPrewarmService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSServerTTSClient
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSShortTermCache
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSiriInstrumentation
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSiriServerConfiguration
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechAudioPowerService
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechCache
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechCacheAudio
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechPresynthesizedTask
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechServerTask
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechSpeakTask
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechSynthesisTask
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechTaskQueue
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSSpeechXPCHandler
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSStreamAudioData
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSStreamAudioMappedInfo
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSTimeoutCondition
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSVoiceBooster
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VSVoicePreviewTask
__ AVFAudio: _AVAudioSessionCategoryPlayback
__ AVFAudio: _AVAudioSessionMediaServicesWereResetNotification
__ AVFAudio: _OBJC_CLASS_$_AVAudioPlayer
__ AVFAudio: _OBJC_CLASS_$_AVAudioSession
__ AVFoundation: _AVFileTypeCoreAudioFormat
__ AVFoundation: _OBJC_CLASS_$_AVSampleBufferAudioRenderer
__ AVFoundation: _OBJC_CLASS_$_AVSampleBufferRenderSynchronizer
__ AssistantServices: _OBJC_CLASS_$_AFAudioPowerUpdater
__ AssistantServices: _OBJC_CLASS_$_AFPowerContextClient
__ AudioToolbox: _AudioComponentFindNext
__ AudioToolbox: _AudioComponentInstanceDispose
__ AudioToolbox: _AudioComponentInstanceNew
__ AudioToolbox: _AudioConverterConvertComplexBuffer
__ AudioToolbox: _AudioConverterDispose
__ AudioToolbox: _AudioConverterNew
__ AudioToolbox: _AudioFileClose
__ AudioToolbox: _AudioFileCreateWithURL
__ AudioToolbox: _AudioFileGetProperty
__ AudioToolbox: _AudioFileOpenURL
__ AudioToolbox: _AudioFileReadPacketData
__ AudioToolbox: _AudioFileWriteBytes
__ AudioToolbox: _AudioQueueAddPropertyListener
__ AudioToolbox: _AudioQueueAllocateBuffer
__ AudioToolbox: _AudioQueueDispose
__ AudioToolbox: _AudioQueueEnqueueBuffer
__ AudioToolbox: _AudioQueueEnqueueSilence
__ AudioToolbox: _AudioQueueFlush
__ AudioToolbox: _AudioQueueFreeBuffer
__ AudioToolbox: _AudioQueueGetCurrentTime
__ AudioToolbox: _AudioQueueGetProperty
__ AudioToolbox: _AudioQueueNewOutputWithAudioSession
__ AudioToolbox: _AudioQueuePause
__ AudioToolbox: _AudioQueueRemovePropertyListener
__ AudioToolbox: _AudioQueueSetProperty
__ AudioToolbox: _AudioQueueStart
__ AudioToolbox: _AudioQueueStop
__ AudioToolbox: _AudioUnitInitialize
__ AudioToolbox: _AudioUnitProcess
__ AudioToolbox: _AudioUnitSetParameter
__ AudioToolbox: _AudioUnitSetProperty
__ CacheDelete: _CacheDeleteRegisterInfoCallbacks
__ CoreFoundation: _CFRelease
__ CoreFoundation: _CFRetain
__ CoreFoundation: _NSDefaultRunLoopMode
__ CoreFoundation: _OBJC_CLASS_$_NSArray
__ CoreFoundation: _OBJC_CLASS_$_NSCache
__ CoreFoundation: _OBJC_CLASS_$_NSConstantArray
__ CoreFoundation: _OBJC_CLASS_$_NSData
__ CoreFoundation: _OBJC_CLASS_$_NSDate
__ CoreFoundation: _OBJC_CLASS_$_NSDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSException
__ CoreFoundation: _OBJC_CLASS_$_NSMutableArray
__ CoreFoundation: _OBJC_CLASS_$_NSMutableData
__ CoreFoundation: _OBJC_CLASS_$_NSMutableDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSMutableOrderedSet
__ CoreFoundation: _OBJC_CLASS_$_NSMutableSet
__ CoreFoundation: _OBJC_CLASS_$_NSRunLoop
__ CoreFoundation: _OBJC_CLASS_$_NSSet
__ CoreFoundation: _OBJC_CLASS_$_NSTimer
__ CoreFoundation: _OBJC_CLASS_$_NSURL
__ CoreFoundation: _OBJC_EHTYPE_$_NSException
__ CoreFoundation: ___CFConstantStringClassReference
__ CoreFoundation: ___NSArray0__struct
__ CoreFoundation: ___NSDictionary0__struct
__ CoreFoundation: _kCFAllocatorDefault
__ CoreFoundation: _kCFAllocatorMalloc
__ CoreFoundation: _kCFBooleanTrue
__ CoreFoundation: _kCFRunLoopCommonModes
__ CoreKnowledge: _OBJC_CLASS_$_CKKnowledgeStore
__ CoreMedia: _CMAudioFormatDescriptionCreate
__ CoreMedia: _CMAudioSampleBufferCreateWithPacketDescriptions
__ CoreMedia: _CMBlockBufferCreateWithMemoryBlock
__ CoreMedia: _CMClockGetHostTimeClock
__ CoreMedia: _CMSampleBufferGetOutputDuration
__ CoreMedia: _CMSampleBufferGetOutputPresentationTimeStamp
__ CoreMedia: _CMSetAttachment
__ CoreMedia: _CMTimeAdd
__ CoreMedia: _CMTimeCompare
__ CoreMedia: _CMTimeGetSeconds
__ CoreMedia: _CMTimebaseAddTimerDispatchSource
__ CoreMedia: _CMTimebaseCreateWithSourceClock
__ CoreMedia: _CMTimebaseGetTimeClampedAboveAnchorTime
__ CoreMedia: _CMTimebaseRemoveTimerDispatchSource
__ CoreMedia: _CMTimebaseSetRate
__ CoreMedia: _CMTimebaseSetTime
__ CoreMedia: _CMTimebaseSetTimerDispatchSourceNextFireTime
__ CoreMedia: _FigCreateBlockBufferCopyingMemoryBlock
__ CoreMedia: _kCMSampleBufferAttachmentKey_EndOfSiriTTSUtterance
__ CoreMedia: _kCMTimeInvalid
__ CoreMedia: _kCMTimeZero
__ Foundation: _NSClassFromString
__ Foundation: _NSFileOwnerAccountName
__ Foundation: _NSLocalizedDescriptionKey
__ Foundation: _NSLocalizedFailureErrorKey
__ Foundation: _NSLocalizedFailureReasonErrorKey
__ Foundation: _NSOSStatusErrorDomain
__ Foundation: _NSObjectNotAvailableException
__ Foundation: _NSSearchPathForDirectoriesInDomains
__ Foundation: _OBJC_CLASS_$_NSBundle
__ Foundation: _OBJC_CLASS_$_NSCondition
__ Foundation: _OBJC_CLASS_$_NSConstantIntegerNumber
__ Foundation: _OBJC_CLASS_$_NSDateFormatter
__ Foundation: _OBJC_CLASS_$_NSError
__ Foundation: _OBJC_CLASS_$_NSFileHandle
__ Foundation: _OBJC_CLASS_$_NSFileManager
__ Foundation: _OBJC_CLASS_$_NSJSONSerialization
__ Foundation: _OBJC_CLASS_$_NSKeyedArchiver
__ Foundation: _OBJC_CLASS_$_NSKeyedUnarchiver
__ Foundation: _OBJC_CLASS_$_NSLock
__ Foundation: _OBJC_CLASS_$_NSNotificationCenter
__ Foundation: _OBJC_CLASS_$_NSNumber
__ Foundation: _OBJC_CLASS_$_NSOperation
__ Foundation: _OBJC_CLASS_$_NSString
__ Foundation: _OBJC_CLASS_$_NSURLSessionConfiguration
__ Foundation: _OBJC_CLASS_$_NSUUID
__ Foundation: _OBJC_CLASS_$_NSValue
__ Foundation: _OBJC_METACLASS_$_NSOperation
__ MediaExperience: _AVSystemController_PickedRouteAttribute
__ MediaExperience: _AVSystemController_RouteDescriptionKey_AVAudioRouteName
__ MediaExperience: _AVSystemController_RouteDescriptionKey_IsBTRoute
__ MediaExperience: _AVSystemController_RouteDescriptionKey_RouteSubtype
__ MediaExperience: _OBJC_CLASS_$_AVSystemController
__ MobileAsset: _ASSetAssetServerURLForAssetType
__ MobileAsset: _ASSetDefaultAssetServerURLForAssetType
__ MobileAsset: _MASetServerUrlOverride
__ Osprey: _OBJC_CLASS_$_OspreyChannel
__ Osprey: _OBJC_METACLASS_$_OspreyChannel
__ SAObjects: _OBJC_CLASS_$_SATTSSpeechSynthesisResource
__ SAObjects: _OBJC_CLASS_$_SATTSSpeechSynthesisStreamingBegin
__ SAObjects: _OBJC_CLASS_$_SATTSSpeechSynthesisStreamingChunk
__ SAObjects: _OBJC_CLASS_$_SATTSSpeechSynthesisStreamingEnd
__ SAObjects: _OBJC_CLASS_$_SATTSSpeechSynthesisVoice
__ SAObjects: _OBJC_CLASS_$_SAUIAudioDescription
__ SiriAnalytics: _OBJC_CLASS_$_AssistantSiriAnalytics
__ SiriInstrumentation: _OBJC_CLASS_$_SISchemaRequestLink
__ SiriInstrumentation: _OBJC_CLASS_$_SISchemaRequestLinkInfo
__ SiriInstrumentation: _OBJC_CLASS_$_SISchemaUUID
__ SiriInstrumentation: _OBJC_CLASS_$_SISchemaVoiceSettings
__ SiriInstrumentation: _OBJC_CLASS_$_SIUtilities
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSClientEvent
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSClientEventMetadata
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSClientSpeechContext
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSRequestReceived
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSRequestReceivedTier1
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSSpeechCancelled
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSSpeechEnded
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSSpeechFailed
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSSpeechStarted
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSVoiceContext
__ SiriInstrumentation: _OBJC_CLASS_$_TTSSchemaTTSVoiceFallbackOccurred
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPIPowerLogger
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPIProcessStartedEventContext
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPITtsRequestReceivedEventContext
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPITtsSpeechCancelledEventContext
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPITtsSpeechEndedEventContext
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPITtsSpeechFailedEventContext
__ SiriPowerInstrumentation: _OBJC_CLASS_$_SPITtsSpeechStartedOrChangedEventContext
__ VoiceServices: _OBJC_CLASS_$_VSAnalytics
__ VoiceServices: _OBJC_CLASS_$_VSAudioData
__ VoiceServices: _OBJC_CLASS_$_VSFeatureFlags
__ VoiceServices: _OBJC_CLASS_$_VSInstrumentMetrics
__ VoiceServices: _OBJC_CLASS_$_VSLocalizedString
__ VoiceServices: _OBJC_CLASS_$_VSMappedData
__ VoiceServices: _OBJC_CLASS_$_VSMobileAssetsManager
__ VoiceServices: _OBJC_CLASS_$_VSNeuralTTSUtils
__ VoiceServices: _OBJC_CLASS_$_VSOpusDecoder
__ VoiceServices: _OBJC_CLASS_$_VSOpusEncoder
__ VoiceServices: _OBJC_CLASS_$_VSPhonemeTool
__ VoiceServices: _OBJC_CLASS_$_VSPreferencesInterface
__ VoiceServices: _OBJC_CLASS_$_VSSpeechEngine
__ VoiceServices: _OBJC_CLASS_$_VSSpeechInternalSettings
__ VoiceServices: _OBJC_CLASS_$_VSSpeechSynthesizerPreference
__ VoiceServices: _OBJC_CLASS_$_VSSpeechWordTimingInfo
__ VoiceServices: _OBJC_CLASS_$_VSUtilities
__ VoiceServices: _OBJC_CLASS_$_VSVoiceAsset
__ VoiceServices: _OBJC_CLASS_$_VSVoiceAssetSelection
__ VoiceServices: _OBJC_CLASS_$_VSVoiceResourceAsset
__ VoiceServices: _OBJC_CLASS_$_VSVoiceSubscription
__ VoiceServices: _OBJC_CLASS_$_VSWordTimingService
__ VoiceServices: _VSAbsoluteTimeToSecond
__ VoiceServices: _VSAudioFormat48khzOpus
__ VoiceServices: _VSDefaultPitch
__ VoiceServices: _VSDefaultRate
__ VoiceServices: _VSDefaultVolume
__ VoiceServices: _VSGetLogDefault
__ VoiceServices: _VSGetLogEvent
__ VoiceServices: _VSLocalizedStringKeyNetworkStallRetryInterstitial
__ VoiceServices: _VSSpeechSynthesizerNotificationSynthesisDone
__ VoiceServices: _VSVoiceResourceAssetConfigPlist
__ libSystem.B.dylib: _XPC_ACTIVITY_CHECK_IN
__ libSystem.B.dylib: _XPC_ACTIVITY_POST_INSTALL
__ libSystem.B.dylib: __Block_object_dispose
__ libSystem.B.dylib: __NSConcreteGlobalBlock
__ libSystem.B.dylib: __NSConcreteStackBlock
__ libSystem.B.dylib: __Unwind_Resume
__ libSystem.B.dylib: ___assert_rtn
__ libSystem.B.dylib: ___error
__ libSystem.B.dylib: ___stack_chk_fail
__ libSystem.B.dylib: ___stack_chk_guard
__ libSystem.B.dylib: __dispatch_main_q
__ libSystem.B.dylib: __dispatch_source_type_timer
__ libSystem.B.dylib: __os_log_debug_impl
__ libSystem.B.dylib: __os_log_error_impl
__ libSystem.B.dylib: __os_log_fault_impl
__ libSystem.B.dylib: __os_log_impl
__ libSystem.B.dylib: __os_signpost_emit_with_name_impl
__ libSystem.B.dylib: _bzero
__ libSystem.B.dylib: _calloc
__ libSystem.B.dylib: _close
__ libSystem.B.dylib: _dispatch_assert_queue$V2
__ libSystem.B.dylib: _dispatch_async
__ libSystem.B.dylib: _dispatch_async_and_wait
__ libSystem.B.dylib: _dispatch_block_create
__ libSystem.B.dylib: _dispatch_get_global_queue
__ libSystem.B.dylib: _dispatch_once
__ libSystem.B.dylib: _dispatch_pthread_root_queue_create
__ libSystem.B.dylib: _dispatch_queue_attr_make_with_autorelease_frequency
__ libSystem.B.dylib: _dispatch_queue_attr_make_with_qos_class
__ libSystem.B.dylib: _dispatch_queue_create
__ libSystem.B.dylib: _dispatch_queue_create_with_target$V2
__ libSystem.B.dylib: _dispatch_resume
__ libSystem.B.dylib: _dispatch_semaphore_create
__ libSystem.B.dylib: _dispatch_semaphore_signal
__ libSystem.B.dylib: _dispatch_semaphore_wait
__ libSystem.B.dylib: _dispatch_source_create
__ libSystem.B.dylib: _dispatch_source_set_event_handler
__ libSystem.B.dylib: _dispatch_sync
__ libSystem.B.dylib: _dispatch_time
__ libSystem.B.dylib: _exit
__ libSystem.B.dylib: _fcntl
__ libSystem.B.dylib: _free
__ libSystem.B.dylib: _fstat
__ libSystem.B.dylib: _getpid
__ libSystem.B.dylib: _gettimeofday
__ libSystem.B.dylib: _kdebug_trace
__ libSystem.B.dylib: _mach_absolute_time
__ libSystem.B.dylib: _madvise
__ libSystem.B.dylib: _memcmp
__ libSystem.B.dylib: _memcpy
__ libSystem.B.dylib: _mmap
__ libSystem.B.dylib: _munmap
__ libSystem.B.dylib: _notify_post
__ libSystem.B.dylib: _open
__ libSystem.B.dylib: _os_log_type_enabled
__ libSystem.B.dylib: _os_signpost_enabled
__ libSystem.B.dylib: _os_signpost_id_generate
__ libSystem.B.dylib: _os_transaction_create
__ libSystem.B.dylib: _pthread_attr_getschedparam
__ libSystem.B.dylib: _pthread_attr_init
__ libSystem.B.dylib: _pthread_attr_setinheritsched
__ libSystem.B.dylib: _pthread_attr_setschedparam
__ libSystem.B.dylib: _pthread_attr_setschedpolicy
__ libSystem.B.dylib: _pthread_cond_broadcast
__ libSystem.B.dylib: _pthread_cond_destroy
__ libSystem.B.dylib: _pthread_cond_timedwait
__ libSystem.B.dylib: _pthread_mutex_destroy
__ libSystem.B.dylib: _pthread_mutex_init
__ libSystem.B.dylib: _pthread_mutex_lock
__ libSystem.B.dylib: _pthread_mutex_unlock
__ libSystem.B.dylib: _pthread_mutexattr_init
__ libSystem.B.dylib: _pthread_mutexattr_settype
__ libSystem.B.dylib: _strerror
__ libSystem.B.dylib: _strlen
__ libSystem.B.dylib: _xpc_activity_copy_criteria
__ libSystem.B.dylib: _xpc_activity_get_state
__ libSystem.B.dylib: _xpc_activity_register
__ libSystem.B.dylib: _xpc_activity_run
__ libSystem.B.dylib: _xpc_activity_set_criteria
__ libSystem.B.dylib: _xpc_activity_set_state
__ libSystem.B.dylib: _xpc_activity_should_defer
__ libSystem.B.dylib: _xpc_dictionary_create
__ libSystem.B.dylib: _xpc_dictionary_set_bool
__ libc++.1.dylib: __ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNSt11logic_errorC2EPKc
__ libc++.1.dylib: __ZNSt12length_errorD1Ev
__ libc++.1.dylib: __ZSt9terminatev
__ libc++.1.dylib: __ZTISt12length_error
__ libc++.1.dylib: __ZTVN10__cxxabiv117__class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv120__si_class_type_infoE
__ libc++.1.dylib: __ZTVSt12length_error
__ libc++.1.dylib: __ZdaPv
__ libc++.1.dylib: __ZdlPv
__ libc++.1.dylib: __Znam
__ libc++.1.dylib: __Znwm
__ libc++.1.dylib: ___cxa_allocate_exception
__ libc++.1.dylib: ___cxa_begin_catch
__ libc++.1.dylib: ___cxa_free_exception
__ libc++.1.dylib: ___cxa_throw
__ libc++.1.dylib: ___gxx_personality_v0
__ libobjc.A.dylib: _OBJC_CLASS_$_NSObject
__ libobjc.A.dylib: _OBJC_METACLASS_$_NSObject
__ libobjc.A.dylib: ___objc_personality_v0
__ libobjc.A.dylib: __objc_empty_cache
__ libobjc.A.dylib: _objc_alloc
__ libobjc.A.dylib: _objc_alloc_init
__ libobjc.A.dylib: _objc_autorelease
__ libobjc.A.dylib: _objc_autoreleasePoolPop
__ libobjc.A.dylib: _objc_autoreleasePoolPush
__ libobjc.A.dylib: _objc_autoreleaseReturnValue
__ libobjc.A.dylib: _objc_begin_catch
__ libobjc.A.dylib: _objc_claimAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_copyWeak
__ libobjc.A.dylib: _objc_destroyWeak
__ libobjc.A.dylib: _objc_end_catch
__ libobjc.A.dylib: _objc_enumerationMutation
__ libobjc.A.dylib: _objc_exception_throw
__ libobjc.A.dylib: _objc_initWeak
__ libobjc.A.dylib: _objc_loadWeakRetained
__ libobjc.A.dylib: _objc_msgSend
__ libobjc.A.dylib: _objc_msgSendSuper2
__ libobjc.A.dylib: _objc_opt_class
__ libobjc.A.dylib: _objc_opt_isKindOfClass
__ libobjc.A.dylib: _objc_opt_new
__ libobjc.A.dylib: _objc_opt_respondsToSelector
__ libobjc.A.dylib: _objc_release
__ libobjc.A.dylib: _objc_release_x1
__ libobjc.A.dylib: _objc_release_x19
__ libobjc.A.dylib: _objc_release_x20
__ libobjc.A.dylib: _objc_release_x21
__ libobjc.A.dylib: _objc_release_x22
__ libobjc.A.dylib: _objc_release_x23
__ libobjc.A.dylib: _objc_release_x24
__ libobjc.A.dylib: _objc_release_x25
__ libobjc.A.dylib: _objc_release_x26
__ libobjc.A.dylib: _objc_release_x27
__ libobjc.A.dylib: _objc_release_x28
__ libobjc.A.dylib: _objc_release_x8
__ libobjc.A.dylib: _objc_release_x9
__ libobjc.A.dylib: _objc_retain
__ libobjc.A.dylib: _objc_retainAutorelease
__ libobjc.A.dylib: _objc_retainAutoreleaseReturnValue
__ libobjc.A.dylib: _objc_retainAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_retainBlock
__ libobjc.A.dylib: _objc_retain_x1
__ libobjc.A.dylib: _objc_retain_x19
__ libobjc.A.dylib: _objc_retain_x2
__ libobjc.A.dylib: _objc_retain_x20
__ libobjc.A.dylib: _objc_retain_x21
__ libobjc.A.dylib: _objc_retain_x22
__ libobjc.A.dylib: _objc_retain_x23
__ libobjc.A.dylib: _objc_retain_x24
__ libobjc.A.dylib: _objc_retain_x25
__ libobjc.A.dylib: _objc_retain_x26
__ libobjc.A.dylib: _objc_retain_x27
__ libobjc.A.dylib: _objc_retain_x28
__ libobjc.A.dylib: _objc_retain_x3
__ libobjc.A.dylib: _objc_retain_x4
__ libobjc.A.dylib: _objc_retain_x7
__ libobjc.A.dylib: _objc_retain_x8
__ libobjc.A.dylib: _objc_setProperty_nonatomic_copy
__ libobjc.A.dylib: _objc_storeStrong
__ libobjc.A.dylib: _objc_storeWeak
__ libobjc.A.dylib: _objc_sync_enter
__ libobjc.A.dylib: _objc_sync_exit
__ libobjc.A.dylib: _objc_unsafeClaimAutoreleasedReturnValue
__ libtailspin.dylib: _tailspin_dump_output
VSSpeechSynthesisTask : VSSpeechSpeakTask <VSSpeechEagerProtocol>
 @property  VSSpeechSpeakTask *speakTask
 @property  BOOL readyForEagerTask
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSSpeechSynthesisTask initWithRequest:]
  -[VSSpeechSynthesisTask .cxx_destruct]
  -[VSSpeechSynthesisTask isSpeaking]
  -[VSSpeechSynthesisTask main]
  -[VSSpeechSynthesisTask reportFinish]
  -[VSSpeechSynthesisTask reportInstrumentMetrics]
  -[VSSpeechSynthesisTask reportSpeechStart]
  -[VSSpeechSynthesisTask setObserverForWordTimings:]
  -[VSSpeechSynthesisTask reportTimingInfo]
  -[VSSpeechSynthesisTask readyForEagerTask]
  -[VSSpeechSynthesisTask setSpeakTask:]
  -[VSSpeechSynthesisTask synthesize]
  -[VSSpeechSynthesisTask speakTask]
  -[VSSpeechSynthesisTask setReadyForEagerTask:]


VSAudioMappedInfoAVSBAR : NSObject <VSAudioMappedInfo>
 @property  {_NSRange=QQ} audioBytesRange
 @property  unsigned long packetCount
 @property  {_NSRange=QQ} packetDescriptionsRange
 @property  BOOL endOfSiriTTSUtterance
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSAudioMappedInfoAVSBAR setPacketCount:]
  -[VSAudioMappedInfoAVSBAR packetCount]
  -[VSAudioMappedInfoAVSBAR audioBytesRange]
  -[VSAudioMappedInfoAVSBAR setAudioBytesRange:]
  -[VSAudioMappedInfoAVSBAR packetDescriptionsRange]
  -[VSAudioMappedInfoAVSBAR setPacketDescriptionsRange:]
  -[VSAudioMappedInfoAVSBAR endOfSiriTTSUtterance]
  -[VSAudioMappedInfoAVSBAR setEndOfSiriTTSUtterance:]


VSAudioPlaybackServiceAVSBAR : NSObject <VSAudioPlaybackServiceProtocol, AFAudioPowerProviding>
 @property  {_opaque_pthread_mutex_t=q[56c]} audioQueueBufferLock
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd
 @property  AVSampleBufferAudioRenderer *renderer
 @property  AVSampleBufferRenderSynchronizer *synchronizer
 @property  NSObject<OS_dispatch_queue> *dataQueue
 @property  {_opaque_pthread_mutex_t=q[56c]} stateLock
 @property  long long state
 @property  {?=qiIq} mappedAudioQueuedTimeStamp
 @property  double rendererEnqueuedAudioDuration
 @property  NSString *outputRoute
 @property  VSMappedData *mappedData
 @property  NSMutableArray *enqueuedMappedAudioInfo
 @property  BOOL startedProvidingData
 @property  NSObject<OS_dispatch_semaphore> *noRemainTasks
 @property  unsigned int sessionID
 @property  BOOL discontinuedDuringPlayback
 @property  NSError *error
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSAudioPlaybackServiceAVSBAR sessionID]
  -[VSAudioPlaybackServiceAVSBAR error]
  -[VSAudioPlaybackServiceAVSBAR state]
  -[VSAudioPlaybackServiceAVSBAR pause]
  -[VSAudioPlaybackServiceAVSBAR dealloc]
  -[VSAudioPlaybackServiceAVSBAR setStateLock:]
  -[VSAudioPlaybackServiceAVSBAR .cxx_destruct]
  -[VSAudioPlaybackServiceAVSBAR didEndAccessPower]
  -[VSAudioPlaybackServiceAVSBAR setError:]
  -[VSAudioPlaybackServiceAVSBAR renderer]
  -[VSAudioPlaybackServiceAVSBAR setRenderer:]
  -[VSAudioPlaybackServiceAVSBAR stop]
  -[VSAudioPlaybackServiceAVSBAR stateLock]
  -[VSAudioPlaybackServiceAVSBAR willBeginAccessPower]
  -[VSAudioPlaybackServiceAVSBAR start]
  -[VSAudioPlaybackServiceAVSBAR getAveragePower:andPeakPower:]
  -[VSAudioPlaybackServiceAVSBAR setSessionID:]
  -[VSAudioPlaybackServiceAVSBAR setState:]
  -[VSAudioPlaybackServiceAVSBAR dataQueue]
  -[VSAudioPlaybackServiceAVSBAR setDataQueue:]
  -[VSAudioPlaybackServiceAVSBAR removeTimeObserver:]
  -[VSAudioPlaybackServiceAVSBAR duration:]
  -[VSAudioPlaybackServiceAVSBAR asbd]
  -[VSAudioPlaybackServiceAVSBAR setAsbd:]
  -[VSAudioPlaybackServiceAVSBAR handleMediaServerReset]
  -[VSAudioPlaybackServiceAVSBAR stopWaiting]
  -[VSAudioPlaybackServiceAVSBAR synchronizer]
  -[VSAudioPlaybackServiceAVSBAR setSynchronizer:]
  -[VSAudioPlaybackServiceAVSBAR _play]
  -[VSAudioPlaybackServiceAVSBAR mappedData]
  -[VSAudioPlaybackServiceAVSBAR audioPowerProvider]
  -[VSAudioPlaybackServiceAVSBAR initWithAudioSessionID:asbd:]
  -[VSAudioPlaybackServiceAVSBAR enqueue:packetCount:packetDescriptions:]
  -[VSAudioPlaybackServiceAVSBAR flushAndStop]
  -[VSAudioPlaybackServiceAVSBAR addBoundaryTimeObserverForTimes:usingBlock:]
  -[VSAudioPlaybackServiceAVSBAR discontinuedDuringPlayback]
  -[VSAudioPlaybackServiceAVSBAR createSampleBufferIdNeeded:]
  -[VSAudioPlaybackServiceAVSBAR createSampleBuffer:]
  -[VSAudioPlaybackServiceAVSBAR _startProvidingData]
  -[VSAudioPlaybackServiceAVSBAR createSilenceEndBuffer]
  -[VSAudioPlaybackServiceAVSBAR addEndOfDataAttachment]
  -[VSAudioPlaybackServiceAVSBAR provideMoreData]
  -[VSAudioPlaybackServiceAVSBAR freeAudioQueue]
  -[VSAudioPlaybackServiceAVSBAR audioQueueBufferLock]
  -[VSAudioPlaybackServiceAVSBAR setAudioQueueBufferLock:]
  -[VSAudioPlaybackServiceAVSBAR mappedAudioQueuedTimeStamp]
  -[VSAudioPlaybackServiceAVSBAR setMappedAudioQueuedTimeStamp:]
  -[VSAudioPlaybackServiceAVSBAR rendererEnqueuedAudioDuration]
  -[VSAudioPlaybackServiceAVSBAR setRendererEnqueuedAudioDuration:]
  -[VSAudioPlaybackServiceAVSBAR outputRoute]
  -[VSAudioPlaybackServiceAVSBAR setOutputRoute:]
  -[VSAudioPlaybackServiceAVSBAR setMappedData:]
  -[VSAudioPlaybackServiceAVSBAR enqueuedMappedAudioInfo]
  -[VSAudioPlaybackServiceAVSBAR setEnqueuedMappedAudioInfo:]
  -[VSAudioPlaybackServiceAVSBAR startedProvidingData]
  -[VSAudioPlaybackServiceAVSBAR setStartedProvidingData:]
  -[VSAudioPlaybackServiceAVSBAR noRemainTasks]
  -[VSAudioPlaybackServiceAVSBAR setNoRemainTasks:]


VSVoiceBooster : NSObject
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd
 @property  unsigned long pcmBufferSize
 @property  ^{OpaqueAudioConverter=} floatConverter
 @property  ^{OpaqueAudioConverter=} integerConverter
 @property  ^{OpaqueAudioComponentInstance=} voiceBoostUnit
 @property  {AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II} audioTimeStamp
 @property  float voiceBoostGainDecibels

  // instance methods
  -[VSVoiceBooster dealloc]
  -[VSVoiceBooster initialize]
  -[VSVoiceBooster processData:]
  -[VSVoiceBooster audioTimeStamp]
  -[VSVoiceBooster asbd]
  -[VSVoiceBooster setAsbd:]
  -[VSVoiceBooster pcmBufferSize]
  -[VSVoiceBooster setPcmBufferSize:]
  -[VSVoiceBooster uninitialize]
  -[VSVoiceBooster initWithStreamDescription:pcmBufferSize:]
  -[VSVoiceBooster setVoiceBoostGainDecibels:]
  -[VSVoiceBooster voiceBoostGainDecibels]
  -[VSVoiceBooster floatConverter]
  -[VSVoiceBooster setFloatConverter:]
  -[VSVoiceBooster integerConverter]
  -[VSVoiceBooster setIntegerConverter:]
  -[VSVoiceBooster voiceBoostUnit]
  -[VSVoiceBooster setVoiceBoostUnit:]
  -[VSVoiceBooster setAudioTimeStamp:]


VSDurationEstimationTask : NSOperation <VSSpeechTaskProtocol>
 @property  VSDeviceTTSCore *deviceCore
 @property  VSSpeechRequest *request
 @property  NSError *error
 @property  double estimatedDuration
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VSDurationEstimationTask shortTermCachedEngines]
  +[VSDurationEstimationTask shortTermCachedEngineForVoice:voiceResource:]

  // instance methods
  -[VSDurationEstimationTask initWithRequest:]
  -[VSDurationEstimationTask setRequest:]
  -[VSDurationEstimationTask suspend]
  -[VSDurationEstimationTask delegate]
  -[VSDurationEstimationTask error]
  -[VSDurationEstimationTask .cxx_destruct]
  -[VSDurationEstimationTask setError:]
  -[VSDurationEstimationTask resume]
  -[VSDurationEstimationTask main]
  -[VSDurationEstimationTask request]
  -[VSDurationEstimationTask cancel]
  -[VSDurationEstimationTask init]
  -[VSDurationEstimationTask estimatedDuration]
  -[VSDurationEstimationTask instrumentMetrics]
  -[VSDurationEstimationTask setInstrumentMetrics:]
  -[VSDurationEstimationTask taskHash]
  -[VSDurationEstimationTask deviceCore]
  -[VSDurationEstimationTask setDeviceCore:]


VSHMHomeManager : NSObject
  // class methods
  +[VSHMHomeManager sharedInstance]
  +[VSHMHomeManager init]

  // instance methods
  -[VSHMHomeManager transferPreinstallErrorMessagesOfLanguage:voiceName:forAccessoryID:]


VSSpeechSpeakTask : NSOperation <VSSpeechSpeakableProtocol>
 @property  NSObject<OS_dispatch_semaphore> *neuralPlaybackSemaphore
 @property  VSSpeechRequest *request
 @property  NSArray *timingInfos
 @property  <VSSpeechServiceDelegate> *delegate
 @property  VSSpeechEngine *engine
 @property  VSVoiceBooster *voiceBooster
 @property  VSAudioPlaybackService *playbackService
 @property  VSVoiceAssetSelection *voiceSelection
 @property  VSVoiceResourceAsset *voiceResource
 @property  VSCachingService *cachingService
 @property  VSPrewarmService *prewarmService
 @property  BOOL synthesisHasIssue
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  VSSiriInstrumentation *siriInstrumentation
 @property  <VSSpeechCacheItem> *speechCache
 @property  NSArray *phonemes
 @property  VSAudioData *compressedAudio
 @property  VSStreamAudioData *streamAudio
 @property  NSError *error
 @property  NSObject<OS_dispatch_queue> *taskAuxiliaryQueue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSSpeechSpeakTask initWithRequest:]
  -[VSSpeechSpeakTask setDelegate:]
  -[VSSpeechSpeakTask setRequest:]
  -[VSSpeechSpeakTask setEngine:]
  -[VSSpeechSpeakTask suspend]
  -[VSSpeechSpeakTask delegate]
  -[VSSpeechSpeakTask error]
  -[VSSpeechSpeakTask engine]
  -[VSSpeechSpeakTask .cxx_destruct]
  -[VSSpeechSpeakTask setError:]
  -[VSSpeechSpeakTask resume]
  -[VSSpeechSpeakTask isSpeaking]
  -[VSSpeechSpeakTask main]
  -[VSSpeechSpeakTask request]
  -[VSSpeechSpeakTask cancel]
  -[VSSpeechSpeakTask init]
  -[VSSpeechSpeakTask resumePlayback]
  -[VSSpeechSpeakTask pausePlayback]
  -[VSSpeechSpeakTask phonemes]
  -[VSSpeechSpeakTask setPhonemes:]
  -[VSSpeechSpeakTask timingInfos]
  -[VSSpeechSpeakTask instrumentMetrics]
  -[VSSpeechSpeakTask setInstrumentMetrics:]
  -[VSSpeechSpeakTask voiceResource]
  -[VSSpeechSpeakTask setVoiceResource:]
  -[VSSpeechSpeakTask taskHash]
  -[VSSpeechSpeakTask reportFinish]
  -[VSSpeechSpeakTask reportInstrumentMetrics]
  -[VSSpeechSpeakTask reportSpeechStart]
  -[VSSpeechSpeakTask setObserverForWordTimings:]
  -[VSSpeechSpeakTask reportTimingInfo]
  -[VSSpeechSpeakTask setSiriInstrumentation:]
  -[VSSpeechSpeakTask audioPowerProvider]
  -[VSSpeechSpeakTask taskAuxiliaryQueue]
  -[VSSpeechSpeakTask synthesizeAndSpeak]
  -[VSSpeechSpeakTask setTimingInfos:]
  -[VSSpeechSpeakTask voiceBooster]
  -[VSSpeechSpeakTask setVoiceBooster:]
  -[VSSpeechSpeakTask playbackService]
  -[VSSpeechSpeakTask setPlaybackService:]
  -[VSSpeechSpeakTask voiceSelection]
  -[VSSpeechSpeakTask setVoiceSelection:]
  -[VSSpeechSpeakTask cachingService]
  -[VSSpeechSpeakTask setCachingService:]
  -[VSSpeechSpeakTask prewarmService]
  -[VSSpeechSpeakTask setPrewarmService:]
  -[VSSpeechSpeakTask synthesisHasIssue]
  -[VSSpeechSpeakTask setSynthesisHasIssue:]
  -[VSSpeechSpeakTask siriInstrumentation]
  -[VSSpeechSpeakTask speechCache]
  -[VSSpeechSpeakTask setSpeechCache:]
  -[VSSpeechSpeakTask compressedAudio]
  -[VSSpeechSpeakTask setCompressedAudio:]
  -[VSSpeechSpeakTask streamAudio]
  -[VSSpeechSpeakTask setStreamAudio:]
  -[VSSpeechSpeakTask setTaskAuxiliaryQueue:]
  -[VSSpeechSpeakTask neuralPlaybackSemaphore]
  -[VSSpeechSpeakTask setNeuralPlaybackSemaphore:]
  -[VSSpeechSpeakTask prepareForSynthesis]
  -[VSSpeechSpeakTask speakCachedAudio]
  -[VSSpeechSpeakTask startPlaybackServiceWithAudioSessionID:]
  -[VSSpeechSpeakTask waitUntilAudioFinished]
  -[VSSpeechSpeakTask fetchVoiceResource]
  -[VSSpeechSpeakTask fetchVoiceAsset]
  -[VSSpeechSpeakTask _fetchVoiceAsset_NoRetry]
  -[VSSpeechSpeakTask logFinish]
  -[VSSpeechSpeakTask enqueueCache]


VSSpeechServerTask : NSOperation <VSDeviceTTSCoreDelegate, VSOspreyTTSCoreDelegate, VSSpeechSpeakableProtocol, VSSpeechEagerProtocol>
 @property  BOOL shouldSpeak
 @property  BOOL isNeuralFallbackCondition
 @property  VSSpeechRequest *request
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  NSError *error
 @property  VSAudioPlaybackService *playbackService
 @property  NSArray *wordTimingInfo
 @property  {_opaque_pthread_cond_t=q[40c]} timeoutCondition
 @property  double deviceTTSWaitTime
 @property  BOOL readyForEagerTask
 @property  VSSpeechServerTask *speakTask
 @property  VSDeviceTTSCore *synthesisCore
 @property  BOOL useServerResponse
 @property  BOOL useDeviceSynthesis
 @property  BOOL speechStartReported
 @property  BOOL isEagerCache
 @property  {_opaque_pthread_mutex_t=q[56c]} racingMutex
 @property  VSAudioData *serverAudio
 @property  NSArray *deferredTTSTimingInfo
 @property  VSSiriInstrumentation *siriInstrumentation
 @property  VSSpeechInternalSettings *internalSettings
 @property  VSOspreyTTSCore *ospreyCore
 @property  VSCachingService *cachingService
 @property  VSSiriServerConfiguration *serverTTSConfig
 @property  <VSSpeechServiceDelegate> *delegate
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSSpeechServerTask setDelegate:]
  -[VSSpeechServerTask setRequest:]
  -[VSSpeechServerTask suspend]
  -[VSSpeechServerTask delegate]
  -[VSSpeechServerTask error]
  -[VSSpeechServerTask dealloc]
  -[VSSpeechServerTask .cxx_destruct]
  -[VSSpeechServerTask setDeviceTTSWaitTime:]
  -[VSSpeechServerTask setError:]
  -[VSSpeechServerTask resume]
  -[VSSpeechServerTask deviceTTSWaitTime]
  -[VSSpeechServerTask isSpeaking]
  -[VSSpeechServerTask main]
  -[VSSpeechServerTask request]
  -[VSSpeechServerTask cancel]
  -[VSSpeechServerTask init]
  -[VSSpeechServerTask shouldSpeak]
  -[VSSpeechServerTask voiceKey]
  -[VSSpeechServerTask isNeuralFallbackCondition]
  -[VSSpeechServerTask instrumentMetrics]
  -[VSSpeechServerTask setInstrumentMetrics:]
  -[VSSpeechServerTask taskHash]
  -[VSSpeechServerTask reportFinish]
  -[VSSpeechServerTask reportInstrumentMetrics]
  -[VSSpeechServerTask reportSpeechStart]
  -[VSSpeechServerTask setObserverForWordTimings:]
  -[VSSpeechServerTask reportTimingInfo]
  -[VSSpeechServerTask setSiriInstrumentation:]
  -[VSSpeechServerTask audioPowerProvider]
  -[VSSpeechServerTask readyForEagerTask]
  -[VSSpeechServerTask setSpeakTask:]
  -[VSSpeechServerTask speakTask]
  -[VSSpeechServerTask setReadyForEagerTask:]
  -[VSSpeechServerTask playbackService]
  -[VSSpeechServerTask setPlaybackService:]
  -[VSSpeechServerTask cachingService]
  -[VSSpeechServerTask setCachingService:]
  -[VSSpeechServerTask siriInstrumentation]
  -[VSSpeechServerTask synthesisCore:didReceiveAudio:]
  -[VSSpeechServerTask synthesisCore:didReceiveWordTimingInfo:]
  -[VSSpeechServerTask ospreyCore:didReceiveAudio:wordTimingInfo:]
  -[VSSpeechServerTask ospreyCore:didFinishWithError:]
  -[VSSpeechServerTask initWithRequest:shouldSpeak:]
  -[VSSpeechServerTask handleServerResponse:timingInfo:]
  -[VSSpeechServerTask speakRetryPhrase]
  -[VSSpeechServerTask fallbackToDeviceSynthesis]
  -[VSSpeechServerTask shouldRelyOnServerTTS]
  -[VSSpeechServerTask shouldDeferDeviceTTS]
  -[VSSpeechServerTask handleDeviceSynthesis:timingInfo:]
  -[VSSpeechServerTask enqueueAudioData:]
  -[VSSpeechServerTask eagerTaskHashForRequest:]
  -[VSSpeechServerTask proceedWithSpeechCache:]
  -[VSSpeechServerTask broadcastTimeoutCondition]
  -[VSSpeechServerTask proceedWithServerTTS]
  -[VSSpeechServerTask writeAudioIfNeeded:]
  -[VSSpeechServerTask setShouldSpeak:]
  -[VSSpeechServerTask setIsNeuralFallbackCondition:]
  -[VSSpeechServerTask wordTimingInfo]
  -[VSSpeechServerTask setWordTimingInfo:]
  -[VSSpeechServerTask timeoutCondition]
  -[VSSpeechServerTask setTimeoutCondition:]
  -[VSSpeechServerTask synthesisCore]
  -[VSSpeechServerTask setSynthesisCore:]
  -[VSSpeechServerTask useServerResponse]
  -[VSSpeechServerTask setUseServerResponse:]
  -[VSSpeechServerTask useDeviceSynthesis]
  -[VSSpeechServerTask setUseDeviceSynthesis:]
  -[VSSpeechServerTask speechStartReported]
  -[VSSpeechServerTask setSpeechStartReported:]
  -[VSSpeechServerTask isEagerCache]
  -[VSSpeechServerTask setIsEagerCache:]
  -[VSSpeechServerTask racingMutex]
  -[VSSpeechServerTask setRacingMutex:]
  -[VSSpeechServerTask serverAudio]
  -[VSSpeechServerTask setServerAudio:]
  -[VSSpeechServerTask deferredTTSTimingInfo]
  -[VSSpeechServerTask setDeferredTTSTimingInfo:]
  -[VSSpeechServerTask internalSettings]
  -[VSSpeechServerTask setInternalSettings:]
  -[VSSpeechServerTask ospreyCore]
  -[VSSpeechServerTask setOspreyCore:]
  -[VSSpeechServerTask serverTTSConfig]
  -[VSSpeechServerTask setServerTTSConfig:]


VSSpeechXPCHandler : NSObject <VSSpeechXPCServiceProtocol, VSSpeechServiceDelegate>
 @property  NSString *connectionIdentifier
 @property  VSHHManagementClient *hubManagementClient
 @property  VSHMHomeManager *homeManager
 @property  NSObject<OS_dispatch_queue> *audioPowerUpdateQueue
 @property  AFAudioPowerUpdater *audioPowerUpdater
 @property  NSObject<OS_os_transaction> *synthesizerTransaction
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VSSpeechXPCHandler isSiriClientBundleIdentifier:]

  // instance methods
  -[VSSpeechXPCHandler _delegate]
  -[VSSpeechXPCHandler endAudioPowerUpdate]
  -[VSSpeechXPCHandler startSynthesisRequest:]
  -[VSSpeechXPCHandler killDaemon]
  -[VSSpeechXPCHandler cachePresynthesizedAudioRequest:]
  -[VSSpeechXPCHandler initWithConnection:]
  -[VSSpeechXPCHandler setSynthesizerTransaction:]
  -[VSSpeechXPCHandler setHubManagementClient:]
  -[VSSpeechXPCHandler getVoiceInfoForLanguageCode:name:footprint:gender:type:reply:]
  -[VSSpeechXPCHandler preprocessRequestBeforeSynthesis:]
  -[VSSpeechXPCHandler audioRequest:didReportInstrumentMetrics:error:]
  -[VSSpeechXPCHandler estimateDurationWithRequest:reply:]
  -[VSSpeechXPCHandler queryPhaticCapabilityWithRequest:reply:]
  -[VSSpeechXPCHandler audioPowerUpdater]
  -[VSSpeechXPCHandler startVoicePreviewRequest:reply:]
  -[VSSpeechXPCHandler setAudioPowerUpdater:]
  -[VSSpeechXPCHandler stopPresynthesizedAudioRequest:]
  -[VSSpeechXPCHandler audioRequestDidStart:]
  -[VSSpeechXPCHandler getSubscribedVoiceAssetsWithClientID:forAccessoryID:reply:]
  -[VSSpeechXPCHandler getSpeechIsActiveForConnectionReply:]
  -[VSSpeechXPCHandler speechRequest:didStartWithMark:forRange:]
  -[VSSpeechXPCHandler dealloc]
  -[VSSpeechXPCHandler stopVoicePreview]
  -[VSSpeechXPCHandler .cxx_destruct]
  -[VSSpeechXPCHandler startPhonemesRequest:phonemeSystem:reply:]
  -[VSSpeechXPCHandler performLanguageFallBackIfNeededWithRequest:]
  -[VSSpeechXPCHandler speechRequest:didStopWithSuccess:phonemesSpoken:error:]
  -[VSSpeechXPCHandler getLocalVoicesForLanguage:reply:]
  -[VSSpeechXPCHandler getVoiceNamesForLanguage:reply:]
  -[VSSpeechXPCHandler speechRequest:didReportInstrumentMetrics:]
  -[VSSpeechXPCHandler setSubscribedVoiceAssets:withClientID:forAccessoryID:]
  -[VSSpeechXPCHandler connectionIdentifier]
  -[VSSpeechXPCHandler homeManager]
  -[VSSpeechXPCHandler stopSpeechRequest:atMark:]
  -[VSSpeechXPCHandler audioPowerUpdateQueue]
  -[VSSpeechXPCHandler audioRequest:didStopAtEnd:error:]
  -[VSSpeechXPCHandler getSpeechIsActiveReply:]
  -[VSSpeechXPCHandler speechRequest:didReceiveTimingInfo:]
  -[VSSpeechXPCHandler setHomeManager:]
  -[VSSpeechXPCHandler speechRequestDidPause:]
  -[VSSpeechXPCHandler getVoiceResourceForLanguage:reply:]
  -[VSSpeechXPCHandler getAllVoiceSubscriptionsWithReply:]
  -[VSSpeechXPCHandler setAudioPowerUpdateQueue:]
  -[VSSpeechXPCHandler speechRequestDidContinue:]
  -[VSSpeechXPCHandler getFootprintsForVoiceName:languageCode:reply:]
  -[VSSpeechXPCHandler previewRequestDidStartPlaying:]
  -[VSSpeechXPCHandler getLocalVoiceResourcesReply:]
  -[VSSpeechXPCHandler startSpeechRequest:reply:]
  -[VSSpeechXPCHandler invalidate]
  -[VSSpeechXPCHandler pauseSpeechRequest:atMark:]
  -[VSSpeechXPCHandler hubManagementClient]
  -[VSSpeechXPCHandler invokeDaemon:]
  -[VSSpeechXPCHandler synthesisRequest:didGenerateAudioChunk:]
  -[VSSpeechXPCHandler triggerCellularDownloadedVoiceAssets:withClientID:]
  -[VSSpeechXPCHandler cleanUnusedAssets:]
  -[VSSpeechXPCHandler continueSpeechRequest:]
  -[VSSpeechXPCHandler setConnectionIdentifier:]
  -[VSSpeechXPCHandler synthesisRequest:didFinishWithInstrumentMetrics:error:]
  -[VSSpeechXPCHandler isSpeaking]
  -[VSSpeechXPCHandler startPresynthesizedAudioRequest:]
  -[VSSpeechXPCHandler synthesizerTransaction]
  -[VSSpeechXPCHandler synthesisRequest:didReceiveTimingInfo:]
  -[VSSpeechXPCHandler updateWithConnectionIdentifier:keepActive:]
  -[VSSpeechXPCHandler speechRequestDidStart:]
  -[VSSpeechXPCHandler beginAudioPowerUpdateWithReply:]
  -[VSSpeechXPCHandler prewarmIfNeededWithRequest:reply:]
  -[VSSpeechXPCHandler forwardStreamObject:]


VSOspreyTTSCore : NSOperation
 @property  VSServerTTSClient *serverTTSClient
 @property  VSSiriServerConfiguration *serverConfig
 @property  VSSpeechInternalSettings *internalSettings
 @property  double bufferDurationLimit
 @property  VSTimeoutCondition *timeoutCondition
 @property  BOOL didReceiveAudio
 @property  NSCondition *didReceiveAudioCondition
 @property  NSObject<OS_dispatch_queue> *delegateCallbackQueue
 @property  VSSpeechRequest *request
 @property  <VSOspreyTTSCoreDelegate> *delegate
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  NSError *error
 @property  VSVoiceAsset *voice
 @property  VSVoiceResourceAsset *voiceResource

  // instance methods
  -[VSOspreyTTSCore initWithRequest:]
  -[VSOspreyTTSCore setVoice:]
  -[VSOspreyTTSCore setDelegate:]
  -[VSOspreyTTSCore delegate]
  -[VSOspreyTTSCore error]
  -[VSOspreyTTSCore voice]
  -[VSOspreyTTSCore .cxx_destruct]
  -[VSOspreyTTSCore setError:]
  -[VSOspreyTTSCore timeout]
  -[VSOspreyTTSCore serverConfig]
  -[VSOspreyTTSCore delegateCallbackQueue]
  -[VSOspreyTTSCore setServerConfig:]
  -[VSOspreyTTSCore main]
  -[VSOspreyTTSCore request]
  -[VSOspreyTTSCore cancel]
  -[VSOspreyTTSCore instrumentMetrics]
  -[VSOspreyTTSCore setInstrumentMetrics:]
  -[VSOspreyTTSCore voiceResource]
  -[VSOspreyTTSCore setVoiceResource:]
  -[VSOspreyTTSCore timeoutCondition]
  -[VSOspreyTTSCore setTimeoutCondition:]
  -[VSOspreyTTSCore internalSettings]
  -[VSOspreyTTSCore setInternalSettings:]
  -[VSOspreyTTSCore setDidReceiveAudio:]
  -[VSOspreyTTSCore performRoundTripOspreyTTS]
  -[VSOspreyTTSCore performStreamingOspreyTTS]
  -[VSOspreyTTSCore waitUntilFinishedIfAudioReceivedWithin:]
  -[VSOspreyTTSCore serverTTSClient]
  -[VSOspreyTTSCore setServerTTSClient:]
  -[VSOspreyTTSCore bufferDurationLimit]
  -[VSOspreyTTSCore setBufferDurationLimit:]
  -[VSOspreyTTSCore didReceiveAudio]
  -[VSOspreyTTSCore didReceiveAudioCondition]
  -[VSOspreyTTSCore setDidReceiveAudioCondition:]
  -[VSOspreyTTSCore setDelegateCallbackQueue:]


VSPostInstallService : NSObject
  // instance methods
  -[VSPostInstallService resetMobileAssetDefaults]
  -[VSPostInstallService clearSynthesisCache]
  -[VSPostInstallService registerPostInstallActivity]


VSVoicePreviewTask : NSObject <AVAudioPlayerDelegate, AFAudioPowerProviding>
 @property  AVAudioPlayer *previewPlayer
 @property  @? completion
 @property  NSURL *currentPreviewURL
 @property  NSObject<OS_dispatch_queue> *speakingQueue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VSVoicePreviewTask sharedInstance]
  +[VSVoicePreviewTask stopVoicePreview]
  +[VSVoicePreviewTask audioPowerProvider]
  +[VSVoicePreviewTask previewAudioURLForLanguage:voiceName:previewType:]
  +[VSVoicePreviewTask startVoicePreviewForLanguageCode:voiceName:previewType:startedPlaying:completion:]

  // instance methods
  -[VSVoicePreviewTask completion]
  -[VSVoicePreviewTask setCompletion:]
  -[VSVoicePreviewTask stopVoicePreview]
  -[VSVoicePreviewTask .cxx_destruct]
  -[VSVoicePreviewTask didEndAccessPower]
  -[VSVoicePreviewTask willBeginAccessPower]
  -[VSVoicePreviewTask getAveragePower:andPeakPower:]
  -[VSVoicePreviewTask audioPlayerDidFinishPlaying:successfully:]
  -[VSVoicePreviewTask startVoicePreviewWithURL:startedPlaying:completion:]
  -[VSVoicePreviewTask previewPlayer]
  -[VSVoicePreviewTask setPreviewPlayer:]
  -[VSVoicePreviewTask currentPreviewURL]
  -[VSVoicePreviewTask setCurrentPreviewURL:]
  -[VSVoicePreviewTask speakingQueue]
  -[VSVoicePreviewTask setSpeakingQueue:]


VSSpeechCacheAudio : NSObject <VSSpeechCacheItem>
 @property  NSString *key
 @property  NSData *audioData
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd
 @property  long long packetCount
 @property  NSData *packetDescriptions
 @property  long long magicVersion
 @property  NSArray *timingInfos
 @property  NSString *voiceKey
 @property  NSString *voiceResourceKey
 @property  VSAudioData *audio
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSSpeechCacheAudio serializedData]
  -[VSSpeechCacheAudio .cxx_destruct]
  -[VSSpeechCacheAudio key]
  -[VSSpeechCacheAudio setKey:]
  -[VSSpeechCacheAudio audio]
  -[VSSpeechCacheAudio packetDescriptions]
  -[VSSpeechCacheAudio setPacketCount:]
  -[VSSpeechCacheAudio initWithKey:data:]
  -[VSSpeechCacheAudio packetCount]
  -[VSSpeechCacheAudio setPacketDescriptions:]
  -[VSSpeechCacheAudio asbd]
  -[VSSpeechCacheAudio setAsbd:]
  -[VSSpeechCacheAudio audioData]
  -[VSSpeechCacheAudio timingInfos]
  -[VSSpeechCacheAudio setAudioData:]
  -[VSSpeechCacheAudio voiceKey]
  -[VSSpeechCacheAudio initWithKey:audio:wordTimingInfo:voiceKey:voiceResourceKey:]
  -[VSSpeechCacheAudio magicVersion]
  -[VSSpeechCacheAudio voiceResourceKey]


VSSpeechCache : NSObject
 @property  NSString *dirPath
 @property  NSString *preinstalledCacheDir

  // class methods
  +[VSSpeechCache defaultCacheStore]

  // instance methods
  -[VSSpeechCache setDirPath:]
  -[VSSpeechCache dirPath]
  -[VSSpeechCache cleanCache]
  -[VSSpeechCache isPreinstalledCacheAvailableForRequest:]
  -[VSSpeechCache .cxx_destruct]
  -[VSSpeechCache preinstalledCacheForText:language:name:]
  -[VSSpeechCache deleteCache]
  -[VSSpeechCache cacheDataForKey:]
  -[VSSpeechCache totalCacheSize]
  -[VSSpeechCache addCache:]
  -[VSSpeechCache preinstalledCacheDir]
  -[VSSpeechCache setPreinstalledCacheDir:]
  -[VSSpeechCache initWithStorePath:]


OPTTSTTSRequestFeatureFlags : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  BOOL fe_feature
 @property  BOOL fe_feature_only

  // instance methods
  -[OPTTSTTSRequestFeatureFlags .cxx_destruct]
  -[OPTTSTTSRequestFeatureFlags copyWithZone:]
  -[OPTTSTTSRequestFeatureFlags fe_feature]
  -[OPTTSTTSRequestFeatureFlags fe_feature_only]
  -[OPTTSTTSRequestFeatureFlags flatbuffData]
  -[OPTTSTTSRequestFeatureFlags initWithFlatbuffData:]
  -[OPTTSTTSRequestFeatureFlags initAndVerifyWithFlatbuffData:]
  -[OPTTSTTSRequestFeatureFlags initWithFlatbuffData:root:]
  -[OPTTSTTSRequestFeatureFlags initWithFlatbuffData:root:verify:]
  -[OPTTSTTSRequestFeatureFlags addObjectToBuffer:]


OPTTSTextToSpeechVoice : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *language
 @property  NSString *gender
 @property  NSString *name
 @property  NSString *version
 @property  NSString *quality
 @property  NSString *type

  // instance methods
  -[OPTTSTextToSpeechVoice quality]
  -[OPTTSTextToSpeechVoice type]
  -[OPTTSTextToSpeechVoice gender]
  -[OPTTSTextToSpeechVoice .cxx_destruct]
  -[OPTTSTextToSpeechVoice version]
  -[OPTTSTextToSpeechVoice copyWithZone:]
  -[OPTTSTextToSpeechVoice language]
  -[OPTTSTextToSpeechVoice name]
  -[OPTTSTextToSpeechVoice flatbuffData]
  -[OPTTSTextToSpeechVoice initWithFlatbuffData:]
  -[OPTTSTextToSpeechVoice initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechVoice initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechVoice initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechVoice addObjectToBuffer:]
  -[OPTTSTextToSpeechVoice vs_voice]


OPTTSTextToSpeechResource : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *language
 @property  NSString *version

  // instance methods
  -[OPTTSTextToSpeechResource .cxx_destruct]
  -[OPTTSTextToSpeechResource version]
  -[OPTTSTextToSpeechResource copyWithZone:]
  -[OPTTSTextToSpeechResource language]
  -[OPTTSTextToSpeechResource flatbuffData]
  -[OPTTSTextToSpeechResource initWithFlatbuffData:]
  -[OPTTSTextToSpeechResource initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechResource initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechResource initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechResource addObjectToBuffer:]
  -[OPTTSTextToSpeechResource vs_voiceResource]


OPTTSTextToSpeechMeta : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  OPTTSTextToSpeechVoice *voice
 @property  OPTTSTextToSpeechResource *resource

  // instance methods
  -[OPTTSTextToSpeechMeta voice]
  -[OPTTSTextToSpeechMeta .cxx_destruct]
  -[OPTTSTextToSpeechMeta resource]
  -[OPTTSTextToSpeechMeta copyWithZone:]
  -[OPTTSTextToSpeechMeta flatbuffData]
  -[OPTTSTextToSpeechMeta initWithFlatbuffData:]
  -[OPTTSTextToSpeechMeta initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechMeta initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechMeta initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechMeta addObjectToBuffer:]


OPTTSTextToSpeechRequestMeta : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  long long channel_type
 @property  NSString *app_id

  // instance methods
  -[OPTTSTextToSpeechRequestMeta .cxx_destruct]
  -[OPTTSTextToSpeechRequestMeta copyWithZone:]
  -[OPTTSTextToSpeechRequestMeta channel_type]
  -[OPTTSTextToSpeechRequestMeta app_id]
  -[OPTTSTextToSpeechRequestMeta flatbuffData]
  -[OPTTSTextToSpeechRequestMeta initWithFlatbuffData:]
  -[OPTTSTextToSpeechRequestMeta initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRequestMeta initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRequestMeta initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRequestMeta addObjectToBuffer:]


OPTTSTextToSpeechRequestContext : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSArray *context_info
 @property  NSString *dialog_identifier

  // instance methods
  -[OPTTSTextToSpeechRequestContext .cxx_destruct]
  -[OPTTSTextToSpeechRequestContext copyWithZone:]
  -[OPTTSTextToSpeechRequestContext context_info]
  -[OPTTSTextToSpeechRequestContext dialog_identifier]
  -[OPTTSTextToSpeechRequestContext flatbuffData]
  -[OPTTSTextToSpeechRequestContext initWithFlatbuffData:]
  -[OPTTSTextToSpeechRequestContext initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRequestContext initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRequestContext initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRequestContext addObjectToBuffer:]


OPTTSTextToSpeechRequestExperiment : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *experiment_identifier

  // instance methods
  -[OPTTSTextToSpeechRequestExperiment .cxx_destruct]
  -[OPTTSTextToSpeechRequestExperiment copyWithZone:]
  -[OPTTSTextToSpeechRequestExperiment experiment_identifier]
  -[OPTTSTextToSpeechRequestExperiment flatbuffData]
  -[OPTTSTextToSpeechRequestExperiment initWithFlatbuffData:]
  -[OPTTSTextToSpeechRequestExperiment initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRequestExperiment initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRequestExperiment initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRequestExperiment addObjectToBuffer:]


OPTTSTextToSpeechRequest : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  NSString *language
 @property  NSString *gender
 @property  NSString *text
 @property  long long audio_type
 @property  BOOL enable_word_timing_info
 @property  NSString *voice_name
 @property  NSArray *context_info
 @property  long long preferred_voice_type
 @property  OPTTSTextToSpeechRequestMeta *meta_info
 @property  OPTTSTextToSpeechRequestContext *context
 @property  OPTTSTextToSpeechRequestExperiment *experiment
 @property  OPTTSTTSRequestFeatureFlags *feature_flags

  // instance methods
  -[OPTTSTextToSpeechRequest experiment]
  -[OPTTSTextToSpeechRequest text]
  -[OPTTSTextToSpeechRequest gender]
  -[OPTTSTextToSpeechRequest .cxx_destruct]
  -[OPTTSTextToSpeechRequest copyWithZone:]
  -[OPTTSTextToSpeechRequest language]
  -[OPTTSTextToSpeechRequest context]
  -[OPTTSTextToSpeechRequest context_info]
  -[OPTTSTextToSpeechRequest speech_id]
  -[OPTTSTextToSpeechRequest session_id]
  -[OPTTSTextToSpeechRequest audio_type]
  -[OPTTSTextToSpeechRequest enable_word_timing_info]
  -[OPTTSTextToSpeechRequest voice_name]
  -[OPTTSTextToSpeechRequest preferred_voice_type]
  -[OPTTSTextToSpeechRequest meta_info]
  -[OPTTSTextToSpeechRequest feature_flags]
  -[OPTTSTextToSpeechRequest flatbuffData]
  -[OPTTSTextToSpeechRequest initWithFlatbuffData:]
  -[OPTTSTextToSpeechRequest initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRequest initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRequest initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRequest addObjectToBuffer:]


OPTTSTextToSpeechRequest_ContextInfoEntry : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *key
 @property  NSString *value

  // instance methods
  -[OPTTSTextToSpeechRequest_ContextInfoEntry .cxx_destruct]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry copyWithZone:]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry key]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry value]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry flatbuffData]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry initWithFlatbuffData:]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRequest_ContextInfoEntry addObjectToBuffer:]


OPTTSAudioDescription : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  double sample_rate
 @property  unsigned int format_id
 @property  unsigned int format_flags
 @property  unsigned int bytes_per_packet
 @property  unsigned int frames_per_packet
 @property  unsigned int bytes_per_frame
 @property  unsigned int channels_per_frame
 @property  unsigned int bits_per_channel
 @property  unsigned int reserved

  // instance methods
  -[OPTTSAudioDescription .cxx_destruct]
  -[OPTTSAudioDescription copyWithZone:]
  -[OPTTSAudioDescription reserved]
  -[OPTTSAudioDescription sample_rate]
  -[OPTTSAudioDescription format_id]
  -[OPTTSAudioDescription format_flags]
  -[OPTTSAudioDescription bytes_per_packet]
  -[OPTTSAudioDescription frames_per_packet]
  -[OPTTSAudioDescription bytes_per_frame]
  -[OPTTSAudioDescription channels_per_frame]
  -[OPTTSAudioDescription bits_per_channel]
  -[OPTTSAudioDescription flatbuffData]
  -[OPTTSAudioDescription initWithFlatbuffData:]
  -[OPTTSAudioDescription initAndVerifyWithFlatbuffData:]
  -[OPTTSAudioDescription initWithFlatbuffData:root:]
  -[OPTTSAudioDescription initWithFlatbuffData:root:verify:]
  -[OPTTSAudioDescription addObjectToBuffer:]
  -[OPTTSAudioDescription audioStreamBasicDescription]


OPTTSWordTimingInfo : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *word
 @property  unsigned int sample_idx
 @property  unsigned int offset
 @property  unsigned int length
 @property  float timestamp

  // class methods
  +[OPTTSWordTimingInfo vs_wordTimingInfos:withText:]

  // instance methods
  -[OPTTSWordTimingInfo length]
  -[OPTTSWordTimingInfo .cxx_destruct]
  -[OPTTSWordTimingInfo copyWithZone:]
  -[OPTTSWordTimingInfo timestamp]
  -[OPTTSWordTimingInfo offset]
  -[OPTTSWordTimingInfo word]
  -[OPTTSWordTimingInfo sample_idx]
  -[OPTTSWordTimingInfo flatbuffData]
  -[OPTTSWordTimingInfo initWithFlatbuffData:]
  -[OPTTSWordTimingInfo initAndVerifyWithFlatbuffData:]
  -[OPTTSWordTimingInfo initWithFlatbuffData:root:]
  -[OPTTSWordTimingInfo initWithFlatbuffData:root:verify:]
  -[OPTTSWordTimingInfo addObjectToBuffer:]


OPTTSTextToSpeechResponse : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  long long audio_type
 @property  int sample_rate
 @property  NSData *audio
 @property  OPTTSAudioDescription *decoder_description
 @property  OPTTSAudioDescription *playback_description
 @property  NSArray *word_timing_info
 @property  OPTTSTextToSpeechMeta *meta_info

  // instance methods
  -[OPTTSTextToSpeechResponse .cxx_destruct]
  -[OPTTSTextToSpeechResponse copyWithZone:]
  -[OPTTSTextToSpeechResponse audio]
  -[OPTTSTextToSpeechResponse sample_rate]
  -[OPTTSTextToSpeechResponse speech_id]
  -[OPTTSTextToSpeechResponse session_id]
  -[OPTTSTextToSpeechResponse audio_type]
  -[OPTTSTextToSpeechResponse meta_info]
  -[OPTTSTextToSpeechResponse error_code]
  -[OPTTSTextToSpeechResponse error_str]
  -[OPTTSTextToSpeechResponse decoder_description]
  -[OPTTSTextToSpeechResponse playback_description]
  -[OPTTSTextToSpeechResponse audio:]
  -[OPTTSTextToSpeechResponse word_timing_info]
  -[OPTTSTextToSpeechResponse flatbuffData]
  -[OPTTSTextToSpeechResponse initWithFlatbuffData:]
  -[OPTTSTextToSpeechResponse initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechResponse initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechResponse initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechResponse addObjectToBuffer:]


OPTTSStartTextToSpeechStreamingRequest : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  NSString *stream_id
 @property  NSString *language
 @property  NSString *gender
 @property  NSString *text
 @property  long long audio_type
 @property  BOOL enable_word_timing_info
 @property  NSString *voice_name
 @property  NSArray *context_info
 @property  long long preferred_voice_type
 @property  OPTTSTextToSpeechRequestMeta *meta_info
 @property  OPTTSTextToSpeechRequestContext *context
 @property  OPTTSTextToSpeechRequestExperiment *experiment
 @property  OPTTSTTSRequestFeatureFlags *feature_flags

  // instance methods
  -[OPTTSStartTextToSpeechStreamingRequest experiment]
  -[OPTTSStartTextToSpeechStreamingRequest text]
  -[OPTTSStartTextToSpeechStreamingRequest gender]
  -[OPTTSStartTextToSpeechStreamingRequest .cxx_destruct]
  -[OPTTSStartTextToSpeechStreamingRequest copyWithZone:]
  -[OPTTSStartTextToSpeechStreamingRequest language]
  -[OPTTSStartTextToSpeechStreamingRequest context]
  -[OPTTSStartTextToSpeechStreamingRequest context_info]
  -[OPTTSStartTextToSpeechStreamingRequest speech_id]
  -[OPTTSStartTextToSpeechStreamingRequest session_id]
  -[OPTTSStartTextToSpeechStreamingRequest audio_type]
  -[OPTTSStartTextToSpeechStreamingRequest enable_word_timing_info]
  -[OPTTSStartTextToSpeechStreamingRequest voice_name]
  -[OPTTSStartTextToSpeechStreamingRequest preferred_voice_type]
  -[OPTTSStartTextToSpeechStreamingRequest meta_info]
  -[OPTTSStartTextToSpeechStreamingRequest feature_flags]
  -[OPTTSStartTextToSpeechStreamingRequest stream_id]
  -[OPTTSStartTextToSpeechStreamingRequest flatbuffData]
  -[OPTTSStartTextToSpeechStreamingRequest initWithFlatbuffData:]
  -[OPTTSStartTextToSpeechStreamingRequest initAndVerifyWithFlatbuffData:]
  -[OPTTSStartTextToSpeechStreamingRequest initWithFlatbuffData:root:]
  -[OPTTSStartTextToSpeechStreamingRequest initWithFlatbuffData:root:verify:]
  -[OPTTSStartTextToSpeechStreamingRequest addObjectToBuffer:]


OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *key
 @property  NSString *value

  // instance methods
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry .cxx_destruct]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry copyWithZone:]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry key]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry value]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry flatbuffData]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry initWithFlatbuffData:]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry initAndVerifyWithFlatbuffData:]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry initWithFlatbuffData:root:]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry initWithFlatbuffData:root:verify:]
  -[OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry addObjectToBuffer:]


OPTTSBeginTextToSpeechStreamingResponse : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  NSString *stream_id
 @property  long long audio_type
 @property  OPTTSAudioDescription *decoder_description
 @property  OPTTSAudioDescription *playback_description
 @property  OPTTSTextToSpeechMeta *meta_info
 @property  float streaming_playback_buffer_size_in_seconds

  // instance methods
  -[OPTTSBeginTextToSpeechStreamingResponse .cxx_destruct]
  -[OPTTSBeginTextToSpeechStreamingResponse copyWithZone:]
  -[OPTTSBeginTextToSpeechStreamingResponse speech_id]
  -[OPTTSBeginTextToSpeechStreamingResponse session_id]
  -[OPTTSBeginTextToSpeechStreamingResponse audio_type]
  -[OPTTSBeginTextToSpeechStreamingResponse meta_info]
  -[OPTTSBeginTextToSpeechStreamingResponse stream_id]
  -[OPTTSBeginTextToSpeechStreamingResponse error_code]
  -[OPTTSBeginTextToSpeechStreamingResponse error_str]
  -[OPTTSBeginTextToSpeechStreamingResponse decoder_description]
  -[OPTTSBeginTextToSpeechStreamingResponse playback_description]
  -[OPTTSBeginTextToSpeechStreamingResponse streaming_playback_buffer_size_in_seconds]
  -[OPTTSBeginTextToSpeechStreamingResponse flatbuffData]
  -[OPTTSBeginTextToSpeechStreamingResponse initWithFlatbuffData:]
  -[OPTTSBeginTextToSpeechStreamingResponse initAndVerifyWithFlatbuffData:]
  -[OPTTSBeginTextToSpeechStreamingResponse initWithFlatbuffData:root:]
  -[OPTTSBeginTextToSpeechStreamingResponse initWithFlatbuffData:root:verify:]
  -[OPTTSBeginTextToSpeechStreamingResponse addObjectToBuffer:]


OPTTSPartialTextToSpeechStreamingResponse : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  NSString *stream_id
 @property  int current_pkt_number
 @property  NSData *audio
 @property  NSArray *word_timing_info

  // instance methods
  -[OPTTSPartialTextToSpeechStreamingResponse .cxx_destruct]
  -[OPTTSPartialTextToSpeechStreamingResponse copyWithZone:]
  -[OPTTSPartialTextToSpeechStreamingResponse audio]
  -[OPTTSPartialTextToSpeechStreamingResponse speech_id]
  -[OPTTSPartialTextToSpeechStreamingResponse session_id]
  -[OPTTSPartialTextToSpeechStreamingResponse stream_id]
  -[OPTTSPartialTextToSpeechStreamingResponse error_code]
  -[OPTTSPartialTextToSpeechStreamingResponse error_str]
  -[OPTTSPartialTextToSpeechStreamingResponse current_pkt_number]
  -[OPTTSPartialTextToSpeechStreamingResponse audio:]
  -[OPTTSPartialTextToSpeechStreamingResponse word_timing_info]
  -[OPTTSPartialTextToSpeechStreamingResponse flatbuffData]
  -[OPTTSPartialTextToSpeechStreamingResponse initWithFlatbuffData:]
  -[OPTTSPartialTextToSpeechStreamingResponse initAndVerifyWithFlatbuffData:]
  -[OPTTSPartialTextToSpeechStreamingResponse initWithFlatbuffData:root:]
  -[OPTTSPartialTextToSpeechStreamingResponse initWithFlatbuffData:root:verify:]
  -[OPTTSPartialTextToSpeechStreamingResponse addObjectToBuffer:]


OPTTSFinalTextToSpeechStreamingResponse : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  NSString *stream_id
 @property  int total_pkt_number

  // instance methods
  -[OPTTSFinalTextToSpeechStreamingResponse .cxx_destruct]
  -[OPTTSFinalTextToSpeechStreamingResponse copyWithZone:]
  -[OPTTSFinalTextToSpeechStreamingResponse speech_id]
  -[OPTTSFinalTextToSpeechStreamingResponse session_id]
  -[OPTTSFinalTextToSpeechStreamingResponse stream_id]
  -[OPTTSFinalTextToSpeechStreamingResponse error_code]
  -[OPTTSFinalTextToSpeechStreamingResponse error_str]
  -[OPTTSFinalTextToSpeechStreamingResponse total_pkt_number]
  -[OPTTSFinalTextToSpeechStreamingResponse flatbuffData]
  -[OPTTSFinalTextToSpeechStreamingResponse initWithFlatbuffData:]
  -[OPTTSFinalTextToSpeechStreamingResponse initAndVerifyWithFlatbuffData:]
  -[OPTTSFinalTextToSpeechStreamingResponse initWithFlatbuffData:root:]
  -[OPTTSFinalTextToSpeechStreamingResponse initWithFlatbuffData:root:verify:]
  -[OPTTSFinalTextToSpeechStreamingResponse addObjectToBuffer:]


OPTTSTextToSpeechRouterStreamingStreamingRequest : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  long long content_type
 @property  OPTTSStartTextToSpeechStreamingRequest *contentAsOPTTSStartTextToSpeechStreamingRequest

  // instance methods
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest .cxx_destruct]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest copyWithZone:]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest content_type]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest contentAsOPTTSStartTextToSpeechStreamingRequest]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest flatbuffData]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest initWithFlatbuffData:]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRouterStreamingStreamingRequest addObjectToBuffer:]


OPTTSTextToSpeechRouterStreamingStreamingResponse : NSObject <FLTBFBufferAccessor, NSCopying>
 @property  long long content_type
 @property  OPTTSBeginTextToSpeechStreamingResponse *contentAsOPTTSBeginTextToSpeechStreamingResponse
 @property  OPTTSPartialTextToSpeechStreamingResponse *contentAsOPTTSPartialTextToSpeechStreamingResponse
 @property  OPTTSFinalTextToSpeechStreamingResponse *contentAsOPTTSFinalTextToSpeechStreamingResponse

  // instance methods
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse .cxx_destruct]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse copyWithZone:]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse content_type]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse contentAsOPTTSBeginTextToSpeechStreamingResponse]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse contentAsOPTTSPartialTextToSpeechStreamingResponse]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse contentAsOPTTSFinalTextToSpeechStreamingResponse]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse flatbuffData]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse initWithFlatbuffData:]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse initAndVerifyWithFlatbuffData:]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse initWithFlatbuffData:root:]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse initWithFlatbuffData:root:verify:]
  -[OPTTSTextToSpeechRouterStreamingStreamingResponse addObjectToBuffer:]


VSHHManagementClient : NSObject
  // class methods
  +[VSHHManagementClient sharedInstance]

  // instance methods
  -[VSHHManagementClient cleanUnknownAccessoriesPreferences]
  -[VSHHManagementClient isExistingAccessoryId:]


VSAudioMappedInfoAT : NSObject <VSAudioMappedInfo>
 @property  {_NSRange=QQ} audioBytesRange
 @property  unsigned long packetCount
 @property  {_NSRange=QQ} packetDescriptionsRange
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSAudioMappedInfoAT setPacketCount:]
  -[VSAudioMappedInfoAT packetCount]
  -[VSAudioMappedInfoAT audioBytesRange]
  -[VSAudioMappedInfoAT setAudioBytesRange:]
  -[VSAudioMappedInfoAT packetDescriptionsRange]
  -[VSAudioMappedInfoAT setPacketDescriptionsRange:]


VSOccasionalTimesObserver : NSObject
 @property  ^{OpaqueCMTimebase=} timebase

  // instance methods
  -[VSOccasionalTimesObserver _resetNextFireTime]
  -[VSOccasionalTimesObserver dealloc]
  -[VSOccasionalTimesObserver .cxx_destruct]
  -[VSOccasionalTimesObserver initWithTimebase:times:queue:block:]
  -[VSOccasionalTimesObserver invalidate]
  -[VSOccasionalTimesObserver timebase]
  -[VSOccasionalTimesObserver _reallyInvalidate]


VSAudioPlaybackServiceAT : NSObject <VSAudioPlaybackServiceProtocol, AFAudioPowerProviding>
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd
 @property  ^{OpaqueAudioQueue=} audioQueue
 @property  ^{OpaqueCMTimebase=} timebase
 @property  long long state
 @property  {_opaque_pthread_mutex_t=q[56c]} waitForStateChangeMutex
 @property  {_opaque_pthread_cond_t=q[40c]} stateChangeCondition
 @property  double enqueuedSampleCount
 @property  {AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II} audioStartTimeStamp
 @property  NSDate *audioQueueStartDate
 @property  NSDate *audioQueueFutureEndDate
 @property  VSMappedData *mappedData
 @property  NSMutableArray *enqueuedMappedAudioInfo
 @property  unsigned long playingBufferCount
 @property  NSCondition *dequeueCondition
 @property  unsigned int sessionID
 @property  BOOL discontinuedDuringPlayback
 @property  NSError *error
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSAudioPlaybackServiceAT sessionID]
  -[VSAudioPlaybackServiceAT error]
  -[VSAudioPlaybackServiceAT state]
  -[VSAudioPlaybackServiceAT pause]
  -[VSAudioPlaybackServiceAT dealloc]
  -[VSAudioPlaybackServiceAT .cxx_destruct]
  -[VSAudioPlaybackServiceAT didEndAccessPower]
  -[VSAudioPlaybackServiceAT setError:]
  -[VSAudioPlaybackServiceAT stop]
  -[VSAudioPlaybackServiceAT willBeginAccessPower]
  -[VSAudioPlaybackServiceAT start]
  -[VSAudioPlaybackServiceAT getAveragePower:andPeakPower:]
  -[VSAudioPlaybackServiceAT setSessionID:]
  -[VSAudioPlaybackServiceAT setState:]
  -[VSAudioPlaybackServiceAT removeTimeObserver:]
  -[VSAudioPlaybackServiceAT timebase]
  -[VSAudioPlaybackServiceAT asbd]
  -[VSAudioPlaybackServiceAT setAsbd:]
  -[VSAudioPlaybackServiceAT handleMediaServerReset]
  -[VSAudioPlaybackServiceAT audioQueue]
  -[VSAudioPlaybackServiceAT mappedData]
  -[VSAudioPlaybackServiceAT setAudioQueue:]
  -[VSAudioPlaybackServiceAT audioPowerProvider]
  -[VSAudioPlaybackServiceAT initWithAudioSessionID:asbd:]
  -[VSAudioPlaybackServiceAT enqueue:packetCount:packetDescriptions:]
  -[VSAudioPlaybackServiceAT flushAndStop]
  -[VSAudioPlaybackServiceAT addBoundaryTimeObserverForTimes:usingBlock:]
  -[VSAudioPlaybackServiceAT discontinuedDuringPlayback]
  -[VSAudioPlaybackServiceAT setMappedData:]
  -[VSAudioPlaybackServiceAT enqueuedMappedAudioInfo]
  -[VSAudioPlaybackServiceAT setEnqueuedMappedAudioInfo:]
  -[VSAudioPlaybackServiceAT signalQueueRunningStateChange]
  -[VSAudioPlaybackServiceAT dequeueAvailableMappedAudio]
  -[VSAudioPlaybackServiceAT _enqueueAudioBytesLength:audioBytes:packetCount:packetDescriptions:]
  -[VSAudioPlaybackServiceAT waitForAudioQueueStop]
  -[VSAudioPlaybackServiceAT isAudioQueueStalled]
  -[VSAudioPlaybackServiceAT isAudioQueueRunning]
  -[VSAudioPlaybackServiceAT setTimebase:]
  -[VSAudioPlaybackServiceAT waitForStateChangeMutex]
  -[VSAudioPlaybackServiceAT setWaitForStateChangeMutex:]
  -[VSAudioPlaybackServiceAT stateChangeCondition]
  -[VSAudioPlaybackServiceAT setStateChangeCondition:]
  -[VSAudioPlaybackServiceAT enqueuedSampleCount]
  -[VSAudioPlaybackServiceAT setEnqueuedSampleCount:]
  -[VSAudioPlaybackServiceAT audioStartTimeStamp]
  -[VSAudioPlaybackServiceAT setAudioStartTimeStamp:]
  -[VSAudioPlaybackServiceAT audioQueueStartDate]
  -[VSAudioPlaybackServiceAT setAudioQueueStartDate:]
  -[VSAudioPlaybackServiceAT audioQueueFutureEndDate]
  -[VSAudioPlaybackServiceAT setAudioQueueFutureEndDate:]
  -[VSAudioPlaybackServiceAT playingBufferCount]
  -[VSAudioPlaybackServiceAT setPlayingBufferCount:]
  -[VSAudioPlaybackServiceAT dequeueCondition]
  -[VSAudioPlaybackServiceAT setDequeueCondition:]


VSAudioRouteInfo : NSObject
 @property  NSDictionary *routeInfo

  // instance methods
  -[VSAudioRouteInfo routeInfo]
  -[VSAudioRouteInfo .cxx_destruct]
  -[VSAudioRouteInfo isAppleProduct]
  -[VSAudioRouteInfo initWithRouteAttributes:]
  -[VSAudioRouteInfo audioRouteName]
  -[VSAudioRouteInfo isBluetoothRoute]


VSAudioPlaybackService : NSObject
 @property  <VSAudioPlaybackServiceProtocol><AFAudioPowerProviding> *implementation
 @property  unsigned long playbackIntervalId
 @property  id timingObserver
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd
 @property  VSAudioRouteInfo *outputRouteInfo
 @property  BOOL discontinuedDuringPlayback
 @property  NSError *error

  // class methods
  +[VSAudioPlaybackService durationOfAudioDataLength:withAudioDescription:]
  +[VSAudioPlaybackService bytesOfDuration:withAudioDescription:]

  // instance methods
  -[VSAudioPlaybackService implementation]
  -[VSAudioPlaybackService error]
  -[VSAudioPlaybackService pause]
  -[VSAudioPlaybackService .cxx_destruct]
  -[VSAudioPlaybackService didEndAccessPower]
  -[VSAudioPlaybackService stop]
  -[VSAudioPlaybackService setImplementation:]
  -[VSAudioPlaybackService willBeginAccessPower]
  -[VSAudioPlaybackService start]
  -[VSAudioPlaybackService getAveragePower:andPeakPower:]
  -[VSAudioPlaybackService asbd]
  -[VSAudioPlaybackService audioPowerProvider]
  -[VSAudioPlaybackService enqueue:packetCount:packetDescriptions:]
  -[VSAudioPlaybackService flushAndStop]
  -[VSAudioPlaybackService discontinuedDuringPlayback]
  -[VSAudioPlaybackService initWithAudioSessionID:asbd:useAVSBAR:]
  -[VSAudioPlaybackService setTimingObserver:]
  -[VSAudioPlaybackService setBoundaryTimeObserverForTimingInfos:usingBlock:]
  -[VSAudioPlaybackService outputRouteInfo]
  -[VSAudioPlaybackService playbackIntervalId]
  -[VSAudioPlaybackService setPlaybackIntervalId:]
  -[VSAudioPlaybackService timingObserver]


VSDeviceTTSCore : NSOperation
 @property  VSCachingService *cachingService
 @property  VSPrewarmService *prewarmService
 @property  VSVoiceAssetSelection *selectedVoice
 @property  VSVoiceResourceAsset *selectedVoiceResource
 @property  VSVoiceBooster *voiceBooster
 @property  VSSpeechRequest *request
 @property  <VSDeviceTTSCoreDelegate> *delegate
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  NSError *error
 @property  VSAudioData *compressedAudio
 @property  VSStreamAudioData *streamAudio
 @property  VSSpeechEngine *engine

  // instance methods
  -[VSDeviceTTSCore initWithRequest:]
  -[VSDeviceTTSCore setDelegate:]
  -[VSDeviceTTSCore setEngine:]
  -[VSDeviceTTSCore delegate]
  -[VSDeviceTTSCore error]
  -[VSDeviceTTSCore engine]
  -[VSDeviceTTSCore .cxx_destruct]
  -[VSDeviceTTSCore setError:]
  -[VSDeviceTTSCore main]
  -[VSDeviceTTSCore request]
  -[VSDeviceTTSCore cancel]
  -[VSDeviceTTSCore instrumentMetrics]
  -[VSDeviceTTSCore setInstrumentMetrics:]
  -[VSDeviceTTSCore taskHash]
  -[VSDeviceTTSCore voiceBooster]
  -[VSDeviceTTSCore setVoiceBooster:]
  -[VSDeviceTTSCore cachingService]
  -[VSDeviceTTSCore setCachingService:]
  -[VSDeviceTTSCore prewarmService]
  -[VSDeviceTTSCore setPrewarmService:]
  -[VSDeviceTTSCore compressedAudio]
  -[VSDeviceTTSCore streamAudio]
  -[VSDeviceTTSCore selectedVoice]
  -[VSDeviceTTSCore selectedVoiceResource]
  -[VSDeviceTTSCore getCacheForHash:]
  -[VSDeviceTTSCore voiceSelectionWithRequest:error:]
  -[VSDeviceTTSCore voiceSelection_noRetry_WithRequest:error:]
  -[VSDeviceTTSCore prepareForSynthesis]
  -[VSDeviceTTSCore reportProcessingWordTimingInfo:]
  -[VSDeviceTTSCore reportWordTimingInfo:]
  -[VSDeviceTTSCore reportAudio:]
  -[VSDeviceTTSCore setSelectedVoice:]
  -[VSDeviceTTSCore setSelectedVoiceResource:]


VSCacheDeleteService : NSObject
  // class methods
  +[VSCacheDeleteService sharedService]

  // instance methods
  -[VSCacheDeleteService totalSizeOfAssets:]
  -[VSCacheDeleteService purgeableAssetsWithInfo:urgency:]
  -[VSCacheDeleteService purgeImpl:urgency:]
  -[VSCacheDeleteService purgeable:urgency:]
  -[VSCacheDeleteService purge:urgency:]
  -[VSCacheDeleteService registerCacheDelete]
  -[VSCacheDeleteService periodic:urgency:]


VSTimeoutCondition : NSObject
 @property  NSCondition *refreshTimeoutCondition
 @property  BOOL shouldStop
 @property  double timeoutValue

  // instance methods
  -[VSTimeoutCondition refresh]
  -[VSTimeoutCondition .cxx_destruct]
  -[VSTimeoutCondition stop]
  -[VSTimeoutCondition wait]
  -[VSTimeoutCondition shouldStop]
  -[VSTimeoutCondition setShouldStop:]
  -[VSTimeoutCondition timeoutValue]
  -[VSTimeoutCondition setTimeoutValue:]
  -[VSTimeoutCondition initWithTimeoutValue:]
  -[VSTimeoutCondition _waitForTimeInterval:]
  -[VSTimeoutCondition refreshTimeoutCondition]
  -[VSTimeoutCondition setRefreshTimeoutCondition:]


VSDownloadService : NSObject
 @property  VSMobileAssetsManager *assetsManager
 @property  VSSiriServerConfiguration *serverConfig
 @property  VSPreferencesInterface *preferenceInterface
 @property  NSLock *updateLock
 @property  unsigned long type

  // class methods
  +[VSDownloadService downloadQueue]
  +[VSDownloadService inProgressDownloadVoiceKeys]
  +[VSDownloadService addInProgressDownloadVoiceKey:]
  +[VSDownloadService removeInProgressDownloadVoiceKey:]

  // instance methods
  -[VSDownloadService type]
  -[VSDownloadService .cxx_destruct]
  -[VSDownloadService initWithType:]
  -[VSDownloadService serverConfig]
  -[VSDownloadService updateLock]
  -[VSDownloadService setServerConfig:]
  -[VSDownloadService initWithType:assetsManager:]
  -[VSDownloadService updateVoicesAndVoiceResources]
  -[VSDownloadService updateVoiceIfNeeded:]
  -[VSDownloadService updateTrialVoiceResourceWithLanguage:]
  -[VSDownloadService cancelDownloadForAssets:]
  -[VSDownloadService assetsManager]
  -[VSDownloadService setAssetsManager:]
  -[VSDownloadService preferenceInterface]
  -[VSDownloadService setPreferenceInterface:]
  -[VSDownloadService setUpdateLock:]


OspreyTTSService : OspreyChannel
 @property  NSString *deviceID

  // class methods
  +[OspreyTTSService sharedInstance]
  +[OspreyTTSService ospreyServiceEndpointURL]

  // instance methods
  -[OspreyTTSService deviceID]
  -[OspreyTTSService setDeviceID:]
  -[OspreyTTSService .cxx_destruct]
  -[OspreyTTSService init]
  -[OspreyTTSService roundTripTTS:responseHandler:]
  -[OspreyTTSService streamTTS:beginHandler:chunkHandler:endHandler:completion:]


VSDiagnosticService : NSObject
 @property  NSString *audioDumpPath
 @property  NSDictionary *audioDumpFileAttributes

  // class methods
  +[VSDiagnosticService defaultService]

  // instance methods
  -[VSDiagnosticService dumpCompressedAudio:forRequest:]
  -[VSDiagnosticService initWithDirectory:]
  -[VSDiagnosticService audioDumpFileAttributes]
  -[VSDiagnosticService totalDiagnosticFileSize]
  -[VSDiagnosticService .cxx_destruct]
  -[VSDiagnosticService setAudioDumpPath:]
  -[VSDiagnosticService removeOldFiles]
  -[VSDiagnosticService dumpInstrumentMetrics:withTimestamp:]
  -[VSDiagnosticService createDirectoryIfNeeded]
  -[VSDiagnosticService removeDirectory]
  -[VSDiagnosticService audioDumpPath]
  -[VSDiagnosticService setAudioDumpFileAttributes:]
  -[VSDiagnosticService dumpStreamAudio:forRequest:]
  -[VSDiagnosticService collectTailspin:]


VSSiriServerConfiguration : NSObject
 @property  CKKnowledgeStore *knowledgeStore
 @property  BOOL shouldDelayVoiceUpdate
 @property  NSArray *allowedAppID

  // class methods
  +[VSSiriServerConfiguration defaultConfig]

  // instance methods
  -[VSSiriServerConfiguration .cxx_destruct]
  -[VSSiriServerConfiguration setKnowledgeStore:]
  -[VSSiriServerConfiguration init]
  -[VSSiriServerConfiguration knowledgeStore]
  -[VSSiriServerConfiguration experimentIdentifier]
  -[VSSiriServerConfiguration dictForKey:]
  -[VSSiriServerConfiguration configForAppId:key:]
  -[VSSiriServerConfiguration timeoutForAppId:]
  -[VSSiriServerConfiguration deviceWaitTimeForAppId:]
  -[VSSiriServerConfiguration shouldDelayVoiceUpdate]
  -[VSSiriServerConfiguration allowedAppID]


VSShortTermCache : NSObject
 @property  NSCache *cache
 @property  NSMutableDictionary *cacheTimer

  // class methods
  +[VSShortTermCache sharedInstance]

  // instance methods
  -[VSShortTermCache setCache:]
  -[VSShortTermCache removeAllObjects]
  -[VSShortTermCache cache]
  -[VSShortTermCache .cxx_destruct]
  -[VSShortTermCache removeObjectForKey:]
  -[VSShortTermCache objectForKey:]
  -[VSShortTermCache init]
  -[VSShortTermCache timeToLiveTimerFired:]
  -[VSShortTermCache setObject:forKey:timeToLive:]
  -[VSShortTermCache cacheTimer]
  -[VSShortTermCache setCacheTimer:]


VSSiriInlineTTSStreamTask : NSOperation <VSDeviceTTSCoreDelegate, VSSpeechSpeakableProtocol>
 @property  VSSpeechRequest *request
 @property  NSString *streamID
 @property  SATTSSpeechSynthesisResource *streamingResource
 @property  SATTSSpeechSynthesisVoice *streamingVoice
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  VSDeviceTTSCore *deviceTTSCore
 @property  VSAudioPlaybackService *playbackServices
 @property  NSError *error
 @property  NSCondition *refreshTimeoutCondition
 @property  VSAudioData *serverAudio
 @property  NSMutableArray *finalTimingInfo
 @property  double bufferDurationLimit
 @property  double timeoutValue
 @property  NSDate *playbackBeginDate
 @property  VSSiriInstrumentation *siriInstrumentation
 @property  <VSSpeechServiceDelegate> *delegate
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSSiriInlineTTSStreamTask setDelegate:]
  -[VSSiriInlineTTSStreamTask setRequest:]
  -[VSSiriInlineTTSStreamTask suspend]
  -[VSSiriInlineTTSStreamTask delegate]
  -[VSSiriInlineTTSStreamTask error]
  -[VSSiriInlineTTSStreamTask streamID]
  -[VSSiriInlineTTSStreamTask dealloc]
  -[VSSiriInlineTTSStreamTask .cxx_destruct]
  -[VSSiriInlineTTSStreamTask setError:]
  -[VSSiriInlineTTSStreamTask resume]
  -[VSSiriInlineTTSStreamTask isSpeaking]
  -[VSSiriInlineTTSStreamTask main]
  -[VSSiriInlineTTSStreamTask request]
  -[VSSiriInlineTTSStreamTask cancel]
  -[VSSiriInlineTTSStreamTask init]
  -[VSSiriInlineTTSStreamTask startPlayback]
  -[VSSiriInlineTTSStreamTask setStreamID:]
  -[VSSiriInlineTTSStreamTask timeoutValue]
  -[VSSiriInlineTTSStreamTask setTimeoutValue:]
  -[VSSiriInlineTTSStreamTask voiceKey]
  -[VSSiriInlineTTSStreamTask instrumentMetrics]
  -[VSSiriInlineTTSStreamTask setInstrumentMetrics:]
  -[VSSiriInlineTTSStreamTask taskHash]
  -[VSSiriInlineTTSStreamTask reportFinish]
  -[VSSiriInlineTTSStreamTask reportInstrumentMetrics]
  -[VSSiriInlineTTSStreamTask reportSpeechStart]
  -[VSSiriInlineTTSStreamTask reportTimingInfo]
  -[VSSiriInlineTTSStreamTask setSiriInstrumentation:]
  -[VSSiriInlineTTSStreamTask audioPowerProvider]
  -[VSSiriInlineTTSStreamTask siriInstrumentation]
  -[VSSiriInlineTTSStreamTask synthesisCore:didReceiveAudio:]
  -[VSSiriInlineTTSStreamTask synthesisCore:didReceiveProcessingWordTimingInfo:]
  -[VSSiriInlineTTSStreamTask synthesisCore:didReceiveWordTimingInfo:]
  -[VSSiriInlineTTSStreamTask serverAudio]
  -[VSSiriInlineTTSStreamTask setServerAudio:]
  -[VSSiriInlineTTSStreamTask bufferDurationLimit]
  -[VSSiriInlineTTSStreamTask setBufferDurationLimit:]
  -[VSSiriInlineTTSStreamTask refreshTimeoutCondition]
  -[VSSiriInlineTTSStreamTask setRefreshTimeoutCondition:]
  -[VSSiriInlineTTSStreamTask handleStreamNotification:]
  -[VSSiriInlineTTSStreamTask initWithRequest:withStreamID:]
  -[VSSiriInlineTTSStreamTask handleBegin:]
  -[VSSiriInlineTTSStreamTask handleChunk:]
  -[VSSiriInlineTTSStreamTask handleEnd:]
  -[VSSiriInlineTTSStreamTask waitForNewData:]
  -[VSSiriInlineTTSStreamTask signalNewDataWithError:]
  -[VSSiriInlineTTSStreamTask streamingResource]
  -[VSSiriInlineTTSStreamTask setStreamingResource:]
  -[VSSiriInlineTTSStreamTask streamingVoice]
  -[VSSiriInlineTTSStreamTask setStreamingVoice:]
  -[VSSiriInlineTTSStreamTask deviceTTSCore]
  -[VSSiriInlineTTSStreamTask setDeviceTTSCore:]
  -[VSSiriInlineTTSStreamTask playbackServices]
  -[VSSiriInlineTTSStreamTask setPlaybackServices:]
  -[VSSiriInlineTTSStreamTask finalTimingInfo]
  -[VSSiriInlineTTSStreamTask setFinalTimingInfo:]
  -[VSSiriInlineTTSStreamTask playbackBeginDate]
  -[VSSiriInlineTTSStreamTask setPlaybackBeginDate:]


VSSpeechPresynthesizedTask : NSOperation <VSSpeechSpeakableProtocol>
 @property  VSPresynthesizedAudioRequest *request
 @property  <VSSpeechServiceDelegate> *delegate
 @property  VSAudioPlaybackService *playbackService
 @property  VSInstrumentMetrics *instrumentMetrics
 @property  NSMutableData *audioData
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd
 @property  NSError *error
 @property  VSSiriInstrumentation *siriInstrumentation
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VSSpeechPresynthesizedTask initWithRequest:]
  -[VSSpeechPresynthesizedTask setDelegate:]
  -[VSSpeechPresynthesizedTask suspend]
  -[VSSpeechPresynthesizedTask delegate]
  -[VSSpeechPresynthesizedTask error]
  -[VSSpeechPresynthesizedTask .cxx_destruct]
  -[VSSpeechPresynthesizedTask setError:]
  -[VSSpeechPresynthesizedTask resume]
  -[VSSpeechPresynthesizedTask isSpeaking]
  -[VSSpeechPresynthesizedTask main]
  -[VSSpeechPresynthesizedTask request]
  -[VSSpeechPresynthesizedTask cancel]
  -[VSSpeechPresynthesizedTask init]
  -[VSSpeechPresynthesizedTask asbd]
  -[VSSpeechPresynthesizedTask setAsbd:]
  -[VSSpeechPresynthesizedTask audioData]
  -[VSSpeechPresynthesizedTask setAudioData:]
  -[VSSpeechPresynthesizedTask instrumentMetrics]
  -[VSSpeechPresynthesizedTask setInstrumentMetrics:]
  -[VSSpeechPresynthesizedTask taskHash]
  -[VSSpeechPresynthesizedTask reportFinish]
  -[VSSpeechPresynthesizedTask reportInstrumentMetrics]
  -[VSSpeechPresynthesizedTask reportSpeechStart]
  -[VSSpeechPresynthesizedTask reportTimingInfo]
  -[VSSpeechPresynthesizedTask setSiriInstrumentation:]
  -[VSSpeechPresynthesizedTask audioPowerProvider]
  -[VSSpeechPresynthesizedTask playbackService]
  -[VSSpeechPresynthesizedTask setPlaybackService:]
  -[VSSpeechPresynthesizedTask siriInstrumentation]


VSSpeechAudioPowerService : NSObject <AFAudioPowerProviding>
 @property  <AFAudioPowerProviding> *previousProvider
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VSSpeechAudioPowerService sharedServices]

  // instance methods
  -[VSSpeechAudioPowerService .cxx_destruct]
  -[VSSpeechAudioPowerService didEndAccessPower]
  -[VSSpeechAudioPowerService willBeginAccessPower]
  -[VSSpeechAudioPowerService getAveragePower:andPeakPower:]
  -[VSSpeechAudioPowerService getCurrentAudioPowerProvider]
  -[VSSpeechAudioPowerService previousProvider]
  -[VSSpeechAudioPowerService setPreviousProvider:]


VSInlineStreamService : NSObject
 @property  NSMutableDictionary *queuedNotification
 @property  NSMutableSet *ongoingNotifications
 @property  NSMutableArray *streamRequestQueue
 @property  {_opaque_pthread_mutex_t=q[56c]} lock
 @property  {_opaque_pthread_mutexattr_t=q[8c]} recursiveLockAttr
 @property  NSObject<OS_dispatch_queue> *notifyQueue

  // class methods
  +[VSInlineStreamService sharedService]

  // instance methods
  -[VSInlineStreamService notifyQueue]
  -[VSInlineStreamService setNotifyQueue:]
  -[VSInlineStreamService dealloc]
  -[VSInlineStreamService .cxx_destruct]
  -[VSInlineStreamService setLock:]
  -[VSInlineStreamService lock]
  -[VSInlineStreamService init]
  -[VSInlineStreamService addInlineStreamRequest:]
  -[VSInlineStreamService popInlineStreamRequestForSpeakRequest:]
  -[VSInlineStreamService hasInlineStreamRequestForSpeakRequest:]
  -[VSInlineStreamService enqueueStreamId:withObject:]
  -[VSInlineStreamService startStreamingWithId:]
  -[VSInlineStreamService removeStreamId:]
  -[VSInlineStreamService queuedNotification]
  -[VSInlineStreamService setQueuedNotification:]
  -[VSInlineStreamService ongoingNotifications]
  -[VSInlineStreamService setOngoingNotifications:]
  -[VSInlineStreamService streamRequestQueue]
  -[VSInlineStreamService setStreamRequestQueue:]
  -[VSInlineStreamService recursiveLockAttr]
  -[VSInlineStreamService setRecursiveLockAttr:]


OPTTSMutableTTSRequestFeatureFlags : OPTTSTTSRequestFeatureFlags
 @property  BOOL fe_feature
 @property  BOOL fe_feature_only

  // instance methods
  -[OPTTSMutableTTSRequestFeatureFlags copyWithZone:]
  -[OPTTSMutableTTSRequestFeatureFlags init]
  -[OPTTSMutableTTSRequestFeatureFlags fe_feature]
  -[OPTTSMutableTTSRequestFeatureFlags setFe_feature:]
  -[OPTTSMutableTTSRequestFeatureFlags fe_feature_only]
  -[OPTTSMutableTTSRequestFeatureFlags setFe_feature_only:]


OPTTSMutableTextToSpeechVoice : OPTTSTextToSpeechVoice
 @property  NSString *language
 @property  NSString *gender
 @property  NSString *name
 @property  NSString *version
 @property  NSString *quality
 @property  NSString *type

  // instance methods
  -[OPTTSMutableTextToSpeechVoice setQuality:]
  -[OPTTSMutableTextToSpeechVoice quality]
  -[OPTTSMutableTextToSpeechVoice setLanguage:]
  -[OPTTSMutableTextToSpeechVoice type]
  -[OPTTSMutableTextToSpeechVoice gender]
  -[OPTTSMutableTextToSpeechVoice setType:]
  -[OPTTSMutableTextToSpeechVoice version]
  -[OPTTSMutableTextToSpeechVoice setName:]
  -[OPTTSMutableTextToSpeechVoice copyWithZone:]
  -[OPTTSMutableTextToSpeechVoice setGender:]
  -[OPTTSMutableTextToSpeechVoice language]
  -[OPTTSMutableTextToSpeechVoice name]
  -[OPTTSMutableTextToSpeechVoice setVersion:]
  -[OPTTSMutableTextToSpeechVoice init]


OPTTSMutableTextToSpeechResource : OPTTSTextToSpeechResource
 @property  NSString *language
 @property  NSString *version

  // instance methods
  -[OPTTSMutableTextToSpeechResource setLanguage:]
  -[OPTTSMutableTextToSpeechResource version]
  -[OPTTSMutableTextToSpeechResource copyWithZone:]
  -[OPTTSMutableTextToSpeechResource language]
  -[OPTTSMutableTextToSpeechResource setVersion:]
  -[OPTTSMutableTextToSpeechResource init]


OPTTSMutableTextToSpeechMeta : OPTTSTextToSpeechMeta
 @property  OPTTSTextToSpeechVoice *voice
 @property  OPTTSTextToSpeechResource *resource

  // instance methods
  -[OPTTSMutableTextToSpeechMeta setVoice:]
  -[OPTTSMutableTextToSpeechMeta voice]
  -[OPTTSMutableTextToSpeechMeta resource]
  -[OPTTSMutableTextToSpeechMeta copyWithZone:]
  -[OPTTSMutableTextToSpeechMeta init]
  -[OPTTSMutableTextToSpeechMeta setResource:]


OPTTSMutableTextToSpeechRequestMeta : OPTTSTextToSpeechRequestMeta
 @property  long long channel_type
 @property  NSString *app_id

  // instance methods
  -[OPTTSMutableTextToSpeechRequestMeta copyWithZone:]
  -[OPTTSMutableTextToSpeechRequestMeta init]
  -[OPTTSMutableTextToSpeechRequestMeta channel_type]
  -[OPTTSMutableTextToSpeechRequestMeta setChannel_type:]
  -[OPTTSMutableTextToSpeechRequestMeta app_id]
  -[OPTTSMutableTextToSpeechRequestMeta setApp_id:]


OPTTSMutableTextToSpeechRequestContext : OPTTSTextToSpeechRequestContext
 @property  NSArray *context_info
 @property  NSString *dialog_identifier

  // instance methods
  -[OPTTSMutableTextToSpeechRequestContext copyWithZone:]
  -[OPTTSMutableTextToSpeechRequestContext init]
  -[OPTTSMutableTextToSpeechRequestContext context_info]
  -[OPTTSMutableTextToSpeechRequestContext setContext_info:]
  -[OPTTSMutableTextToSpeechRequestContext dialog_identifier]
  -[OPTTSMutableTextToSpeechRequestContext setDialog_identifier:]


OPTTSMutableTextToSpeechRequestExperiment : OPTTSTextToSpeechRequestExperiment
 @property  NSString *experiment_identifier

  // instance methods
  -[OPTTSMutableTextToSpeechRequestExperiment copyWithZone:]
  -[OPTTSMutableTextToSpeechRequestExperiment init]
  -[OPTTSMutableTextToSpeechRequestExperiment experiment_identifier]
  -[OPTTSMutableTextToSpeechRequestExperiment setExperiment_identifier:]


OPTTSMutableTextToSpeechRequest : OPTTSTextToSpeechRequest
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  NSString *language
 @property  NSString *gender
 @property  NSString *text
 @property  long long audio_type
 @property  BOOL enable_word_timing_info
 @property  NSString *voice_name
 @property  NSArray *context_info
 @property  long long preferred_voice_type
 @property  OPTTSTextToSpeechRequestMeta *meta_info
 @property  OPTTSTextToSpeechRequestContext *context
 @property  OPTTSTextToSpeechRequestExperiment *experiment
 @property  OPTTSTTSRequestFeatureFlags *feature_flags

  // class methods
  +[OPTTSMutableTextToSpeechRequest genderStringFromGender:]
  +[OPTTSMutableTextToSpeechRequest requestFromVSRequest:]

  // instance methods
  -[OPTTSMutableTextToSpeechRequest experiment]
  -[OPTTSMutableTextToSpeechRequest text]
  -[OPTTSMutableTextToSpeechRequest setLanguage:]
  -[OPTTSMutableTextToSpeechRequest setExperiment:]
  -[OPTTSMutableTextToSpeechRequest gender]
  -[OPTTSMutableTextToSpeechRequest setContext:]
  -[OPTTSMutableTextToSpeechRequest copyWithZone:]
  -[OPTTSMutableTextToSpeechRequest setGender:]
  -[OPTTSMutableTextToSpeechRequest language]
  -[OPTTSMutableTextToSpeechRequest context]
  -[OPTTSMutableTextToSpeechRequest init]
  -[OPTTSMutableTextToSpeechRequest setText:]
  -[OPTTSMutableTextToSpeechRequest context_info]
  -[OPTTSMutableTextToSpeechRequest setContext_info:]
  -[OPTTSMutableTextToSpeechRequest speech_id]
  -[OPTTSMutableTextToSpeechRequest setSpeech_id:]
  -[OPTTSMutableTextToSpeechRequest session_id]
  -[OPTTSMutableTextToSpeechRequest setSession_id:]
  -[OPTTSMutableTextToSpeechRequest audio_type]
  -[OPTTSMutableTextToSpeechRequest setAudio_type:]
  -[OPTTSMutableTextToSpeechRequest enable_word_timing_info]
  -[OPTTSMutableTextToSpeechRequest setEnable_word_timing_info:]
  -[OPTTSMutableTextToSpeechRequest voice_name]
  -[OPTTSMutableTextToSpeechRequest setVoice_name:]
  -[OPTTSMutableTextToSpeechRequest preferred_voice_type]
  -[OPTTSMutableTextToSpeechRequest setPreferred_voice_type:]
  -[OPTTSMutableTextToSpeechRequest meta_info]
  -[OPTTSMutableTextToSpeechRequest setMeta_info:]
  -[OPTTSMutableTextToSpeechRequest feature_flags]
  -[OPTTSMutableTextToSpeechRequest setFeature_flags:]


OPTTSMutableTextToSpeechRequest_ContextInfoEntry : OPTTSTextToSpeechRequest_ContextInfoEntry
 @property  NSString *key
 @property  NSString *value

  // instance methods
  -[OPTTSMutableTextToSpeechRequest_ContextInfoEntry setValue:]
  -[OPTTSMutableTextToSpeechRequest_ContextInfoEntry copyWithZone:]
  -[OPTTSMutableTextToSpeechRequest_ContextInfoEntry key]
  -[OPTTSMutableTextToSpeechRequest_ContextInfoEntry value]
  -[OPTTSMutableTextToSpeechRequest_ContextInfoEntry setKey:]
  -[OPTTSMutableTextToSpeechRequest_ContextInfoEntry init]


OPTTSMutableAudioDescription : OPTTSAudioDescription
 @property  double sample_rate
 @property  unsigned int format_id
 @property  unsigned int format_flags
 @property  unsigned int bytes_per_packet
 @property  unsigned int frames_per_packet
 @property  unsigned int bytes_per_frame
 @property  unsigned int channels_per_frame
 @property  unsigned int bits_per_channel
 @property  unsigned int reserved

  // instance methods
  -[OPTTSMutableAudioDescription setReserved:]
  -[OPTTSMutableAudioDescription copyWithZone:]
  -[OPTTSMutableAudioDescription reserved]
  -[OPTTSMutableAudioDescription init]
  -[OPTTSMutableAudioDescription sample_rate]
  -[OPTTSMutableAudioDescription setSample_rate:]
  -[OPTTSMutableAudioDescription format_id]
  -[OPTTSMutableAudioDescription setFormat_id:]
  -[OPTTSMutableAudioDescription format_flags]
  -[OPTTSMutableAudioDescription setFormat_flags:]
  -[OPTTSMutableAudioDescription bytes_per_packet]
  -[OPTTSMutableAudioDescription setBytes_per_packet:]
  -[OPTTSMutableAudioDescription frames_per_packet]
  -[OPTTSMutableAudioDescription setFrames_per_packet:]
  -[OPTTSMutableAudioDescription bytes_per_frame]
  -[OPTTSMutableAudioDescription setBytes_per_frame:]
  -[OPTTSMutableAudioDescription channels_per_frame]
  -[OPTTSMutableAudioDescription setChannels_per_frame:]
  -[OPTTSMutableAudioDescription bits_per_channel]
  -[OPTTSMutableAudioDescription setBits_per_channel:]


OPTTSMutableWordTimingInfo : OPTTSWordTimingInfo
 @property  NSString *word
 @property  unsigned int sample_idx
 @property  unsigned int offset
 @property  unsigned int length
 @property  float timestamp

  // instance methods
  -[OPTTSMutableWordTimingInfo setTimestamp:]
  -[OPTTSMutableWordTimingInfo length]
  -[OPTTSMutableWordTimingInfo setLength:]
  -[OPTTSMutableWordTimingInfo copyWithZone:]
  -[OPTTSMutableWordTimingInfo timestamp]
  -[OPTTSMutableWordTimingInfo offset]
  -[OPTTSMutableWordTimingInfo setOffset:]
  -[OPTTSMutableWordTimingInfo init]
  -[OPTTSMutableWordTimingInfo word]
  -[OPTTSMutableWordTimingInfo setWord:]
  -[OPTTSMutableWordTimingInfo sample_idx]
  -[OPTTSMutableWordTimingInfo setSample_idx:]


OPTTSMutableTextToSpeechResponse : OPTTSTextToSpeechResponse
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  long long audio_type
 @property  int sample_rate
 @property  NSData *audio
 @property  OPTTSAudioDescription *decoder_description
 @property  OPTTSAudioDescription *playback_description
 @property  NSArray *word_timing_info
 @property  OPTTSTextToSpeechMeta *meta_info

  // instance methods
  -[OPTTSMutableTextToSpeechResponse copyWithZone:]
  -[OPTTSMutableTextToSpeechResponse init]
  -[OPTTSMutableTextToSpeechResponse audio]
  -[OPTTSMutableTextToSpeechResponse sample_rate]
  -[OPTTSMutableTextToSpeechResponse setSample_rate:]
  -[OPTTSMutableTextToSpeechResponse speech_id]
  -[OPTTSMutableTextToSpeechResponse setSpeech_id:]
  -[OPTTSMutableTextToSpeechResponse session_id]
  -[OPTTSMutableTextToSpeechResponse setSession_id:]
  -[OPTTSMutableTextToSpeechResponse audio_type]
  -[OPTTSMutableTextToSpeechResponse setAudio_type:]
  -[OPTTSMutableTextToSpeechResponse meta_info]
  -[OPTTSMutableTextToSpeechResponse setMeta_info:]
  -[OPTTSMutableTextToSpeechResponse error_code]
  -[OPTTSMutableTextToSpeechResponse setError_code:]
  -[OPTTSMutableTextToSpeechResponse error_str]
  -[OPTTSMutableTextToSpeechResponse setError_str:]
  -[OPTTSMutableTextToSpeechResponse decoder_description]
  -[OPTTSMutableTextToSpeechResponse setDecoder_description:]
  -[OPTTSMutableTextToSpeechResponse playback_description]
  -[OPTTSMutableTextToSpeechResponse setPlayback_description:]
  -[OPTTSMutableTextToSpeechResponse setAudio:]
  -[OPTTSMutableTextToSpeechResponse audio:]
  -[OPTTSMutableTextToSpeechResponse word_timing_info]
  -[OPTTSMutableTextToSpeechResponse setWord_timing_info:]


OPTTSMutableStartTextToSpeechStreamingRequest : OPTTSStartTextToSpeechStreamingRequest
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  NSString *stream_id
 @property  NSString *language
 @property  NSString *gender
 @property  NSString *text
 @property  long long audio_type
 @property  BOOL enable_word_timing_info
 @property  NSString *voice_name
 @property  NSArray *context_info
 @property  long long preferred_voice_type
 @property  OPTTSTextToSpeechRequestMeta *meta_info
 @property  OPTTSTextToSpeechRequestContext *context
 @property  OPTTSTextToSpeechRequestExperiment *experiment
 @property  OPTTSTTSRequestFeatureFlags *feature_flags

  // instance methods
  -[OPTTSMutableStartTextToSpeechStreamingRequest experiment]
  -[OPTTSMutableStartTextToSpeechStreamingRequest text]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setLanguage:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setExperiment:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest gender]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setContext:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest copyWithZone:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setGender:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest language]
  -[OPTTSMutableStartTextToSpeechStreamingRequest context]
  -[OPTTSMutableStartTextToSpeechStreamingRequest init]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setText:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest context_info]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setContext_info:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest speech_id]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setSpeech_id:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest session_id]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setSession_id:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest audio_type]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setAudio_type:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest enable_word_timing_info]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setEnable_word_timing_info:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest voice_name]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setVoice_name:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest preferred_voice_type]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setPreferred_voice_type:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest meta_info]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setMeta_info:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest feature_flags]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setFeature_flags:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest stream_id]
  -[OPTTSMutableStartTextToSpeechStreamingRequest setStream_id:]


OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry : OPTTSStartTextToSpeechStreamingRequest_ContextInfoEntry
 @property  NSString *key
 @property  NSString *value

  // instance methods
  -[OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry setValue:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry copyWithZone:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry key]
  -[OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry value]
  -[OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry setKey:]
  -[OPTTSMutableStartTextToSpeechStreamingRequest_ContextInfoEntry init]


OPTTSMutableBeginTextToSpeechStreamingResponse : OPTTSBeginTextToSpeechStreamingResponse
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  NSString *stream_id
 @property  long long audio_type
 @property  OPTTSAudioDescription *decoder_description
 @property  OPTTSAudioDescription *playback_description
 @property  OPTTSTextToSpeechMeta *meta_info
 @property  float streaming_playback_buffer_size_in_seconds

  // instance methods
  -[OPTTSMutableBeginTextToSpeechStreamingResponse copyWithZone:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse init]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse speech_id]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setSpeech_id:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse session_id]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setSession_id:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse audio_type]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setAudio_type:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse meta_info]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setMeta_info:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse stream_id]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setStream_id:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse error_code]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setError_code:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse error_str]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setError_str:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse decoder_description]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setDecoder_description:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse playback_description]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setPlayback_description:]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse streaming_playback_buffer_size_in_seconds]
  -[OPTTSMutableBeginTextToSpeechStreamingResponse setStreaming_playback_buffer_size_in_seconds:]


OPTTSMutablePartialTextToSpeechStreamingResponse : OPTTSPartialTextToSpeechStreamingResponse
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  NSString *stream_id
 @property  int current_pkt_number
 @property  NSData *audio
 @property  NSArray *word_timing_info

  // instance methods
  -[OPTTSMutablePartialTextToSpeechStreamingResponse copyWithZone:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse init]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse audio]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse speech_id]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setSpeech_id:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse session_id]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setSession_id:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse stream_id]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setStream_id:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse error_code]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setError_code:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse error_str]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setError_str:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse current_pkt_number]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setCurrent_pkt_number:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setAudio:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse audio:]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse word_timing_info]
  -[OPTTSMutablePartialTextToSpeechStreamingResponse setWord_timing_info:]


OPTTSMutableFinalTextToSpeechStreamingResponse : OPTTSFinalTextToSpeechStreamingResponse
 @property  NSString *speech_id
 @property  NSString *session_id
 @property  int error_code
 @property  NSString *error_str
 @property  NSString *stream_id
 @property  int total_pkt_number

  // instance methods
  -[OPTTSMutableFinalTextToSpeechStreamingResponse copyWithZone:]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse init]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse speech_id]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse setSpeech_id:]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse session_id]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse setSession_id:]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse stream_id]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse setStream_id:]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse error_code]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse setError_code:]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse error_str]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse setError_str:]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse total_pkt_number]
  -[OPTTSMutableFinalTextToSpeechStreamingResponse setTotal_pkt_number:]


OPTTSMutableTextToSpeechRouterStreamingStreamingRequest : OPTTSTextToSpeechRouterStreamingStreamingRequest
 @property  long long content_type
 @property  OPTTSStartTextToSpeechStreamingRequest *contentAsOPTTSStartTextToSpeechStreamingRequest

  // instance methods
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingRequest copyWithZone:]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingRequest init]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingRequest content_type]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingRequest setContent_type:]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingRequest contentAsOPTTSStartTextToSpeechStreamingRequest]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingRequest setContentAsOPTTSStartTextToSpeechStreamingRequest:]


OPTTSMutableTextToSpeechRouterStreamingStreamingResponse : OPTTSTextToSpeechRouterStreamingStreamingResponse
 @property  long long content_type
 @property  OPTTSBeginTextToSpeechStreamingResponse *contentAsOPTTSBeginTextToSpeechStreamingResponse
 @property  OPTTSPartialTextToSpeechStreamingResponse *contentAsOPTTSPartialTextToSpeechStreamingResponse
 @property  OPTTSFinalTextToSpeechStreamingResponse *contentAsOPTTSFinalTextToSpeechStreamingResponse

  // instance methods
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse copyWithZone:]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse init]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse content_type]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse setContent_type:]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse contentAsOPTTSBeginTextToSpeechStreamingResponse]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse setContentAsOPTTSBeginTextToSpeechStreamingResponse:]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse contentAsOPTTSPartialTextToSpeechStreamingResponse]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse setContentAsOPTTSPartialTextToSpeechStreamingResponse:]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse contentAsOPTTSFinalTextToSpeechStreamingResponse]
  -[OPTTSMutableTextToSpeechRouterStreamingStreamingResponse setContentAsOPTTSFinalTextToSpeechStreamingResponse:]


VSPrewarmService : NSObject
 @property  VSSpeechEngine *cachedEngine
 @property  VSVoiceResourceAsset *loadedResources
 @property  NSObject<OS_dispatch_queue> *prewarmQueue
 @property  long long activeSessionCount

  // class methods
  +[VSPrewarmService sharedService]

  // instance methods
  -[VSPrewarmService .cxx_destruct]
  -[VSPrewarmService init]
  -[VSPrewarmService prewarmQueue]
  -[VSPrewarmService setPrewarmQueue:]
  -[VSPrewarmService handleVoiceSelectionPurge:]
  -[VSPrewarmService setActiveSessionCount:]
  -[VSPrewarmService prewarmWithRequest:]
  -[VSPrewarmService _cachedEngineForVoice:resources:]
  -[VSPrewarmService cachedEngineForVoice:resources:]
  -[VSPrewarmService _engineForVoice:resources:]
  -[VSPrewarmService loadEngineForVoice:resources:]
  -[VSPrewarmService unloadCachedEngineWithVoice:]
  -[VSPrewarmService _loadVoiceResources:forEngine:]
  -[VSPrewarmService unloadEngine]
  -[VSPrewarmService waitUntilPrewarmFinish]
  -[VSPrewarmService activeSessionCount]
  -[VSPrewarmService cachedEngine]
  -[VSPrewarmService setCachedEngine:]
  -[VSPrewarmService loadedResources]
  -[VSPrewarmService setLoadedResources:]


VSServerTTSClient : NSObject
  // class methods
  +[VSServerTTSClient shouldUseServerTTSForRequest:]

  // instance methods
  -[VSServerTTSClient ospreyStartSynthesisRequest:responseHandler:completion:]
  -[VSServerTTSClient ospreyStartStreamingRequest:dataHandler:metaInfoHandler:completion:]


VSCachingService : NSObject
 @property  NSLock *threadLock
 @property  NSMutableArray *inMemoryCaches
 @property  VSSpeechCache *cacheStore
 @property  VSShortTermCache *shortTermCache
 @property  NSObject<OS_dispatch_queue> *cachingQueue

  // class methods
  +[VSCachingService standardService]

  // instance methods
  -[VSCachingService .cxx_destruct]
  -[VSCachingService initWithCache:shortTermMemory:]
  -[VSCachingService compressAudio:]
  -[VSCachingService compressStreamAudio:]
  -[VSCachingService enqueueCacheWithHash:audio:timingInfo:voiceKey:voiceResourceKey:completion:]
  -[VSCachingService enqueueCacheWithHash:streamAudio:timingInfo:voiceKey:voiceResourceKey:completion:]
  -[VSCachingService _enqueueCacheWithHash:audioObject:timingInfo:voiceKey:voiceResourceKey:completion:]
  -[VSCachingService inMemoryCacheForHash:]
  -[VSCachingService _inMemoryCacheForHash:]
  -[VSCachingService onDiskCacheForHash:]
  -[VSCachingService _onDiskCacheForHash:]
  -[VSCachingService fetchCacheForTask:]
  -[VSCachingService enqueueShortTermCacheWithHash:audio:timingInfo:voiceKey:voiceResourceKey:completion:]
  -[VSCachingService shortTermCacheForHash:]
  -[VSCachingService popShortTermCacheForHash:]
  -[VSCachingService threadLock]
  -[VSCachingService setThreadLock:]
  -[VSCachingService inMemoryCaches]
  -[VSCachingService setInMemoryCaches:]
  -[VSCachingService cacheStore]
  -[VSCachingService setCacheStore:]
  -[VSCachingService shortTermCache]
  -[VSCachingService setShortTermCache:]
  -[VSCachingService cachingQueue]
  -[VSCachingService setCachingQueue:]


VSSiriInstrumentation : NSObject
 @property  NSUUID *siriRequestId
 @property  NSUUID *ttsId
 @property  NSUUID *contextId

  // class methods
  +[VSSiriInstrumentation outputRouteFromRouteInfo:]
  +[VSSiriInstrumentation schemaVoiceTypeFromType:]
  +[VSSiriInstrumentation instrumentPowerEvent:ttsId:]
  +[VSSiriInstrumentation schemaVoiceGenderFromGender:]
  +[VSSiriInstrumentation schemaFootprintFromFootprint:]
  +[VSSiriInstrumentation synthesisSourceFromSource:]
  +[VSSiriInstrumentation sharedPowerLogger]
  +[VSSiriInstrumentation instrumentVoicedProcessStartedPowerEvent]

  // instance methods
  -[VSSiriInstrumentation setContextId:]
  -[VSSiriInstrumentation contextId]
  -[VSSiriInstrumentation .cxx_destruct]
  -[VSSiriInstrumentation siriRequestId]
  -[VSSiriInstrumentation setSiriRequestId:]
  -[VSSiriInstrumentation setTtsId:]
  -[VSSiriInstrumentation ttsId]
  -[VSSiriInstrumentation initWithSiriRequestId:]
  -[VSSiriInstrumentation makeRequestLinkEvent]
  -[VSSiriInstrumentation instrumentRequestReceivedWithText:requestedVoiceType:requestedVoiceFootprint:isPrivate:]
  -[VSSiriInstrumentation instrumentSpeechStartedWithSource:customerPerceivedLatency:audioOutputRoute:voiceType:voiceFootprint:voiceVersion:resourceVersion:isWhisper:]
  -[VSSiriInstrumentation instrumentSpeechEndedWithAudioDuration:synthesisLatency:realTimeFactor:promptCount:errorCode:]
  -[VSSiriInstrumentation instrumentSpeechFailedWithErrorCodes:]
  -[VSSiriInstrumentation instrumentSpeechCancelled]
  -[VSSiriInstrumentation instrumentVoiceFallbackOccurredWithVoice:resource:]


VSStreamAudioMappedInfo : NSObject
 @property  {_NSRange=QQ} audioBytesRange
 @property  unsigned long packetCount
 @property  {_NSRange=QQ} packetDescriptionsRange

  // instance methods
  -[VSStreamAudioMappedInfo setPacketCount:]
  -[VSStreamAudioMappedInfo packetCount]
  -[VSStreamAudioMappedInfo audioBytesRange]
  -[VSStreamAudioMappedInfo setAudioBytesRange:]
  -[VSStreamAudioMappedInfo packetDescriptionsRange]
  -[VSStreamAudioMappedInfo setPacketDescriptionsRange:]


VSStreamAudioData : NSObject
 @property  VSMappedData *mappedData
 @property  NSMutableArray *mappedAudioInfo
 @property  {AudioStreamBasicDescription=dIIIIIIII} asbd

  // instance methods
  -[VSStreamAudioData .cxx_destruct]
  -[VSStreamAudioData duration]
  -[VSStreamAudioData asbd]
  -[VSStreamAudioData mappedData]
  -[VSStreamAudioData setMappedData:]
  -[VSStreamAudioData initWithASBD:]
  -[VSStreamAudioData appendAudioData:packetCount:packetDescriptions:]
  -[VSStreamAudioData enumerateAudioWithBlock:]
  -[VSStreamAudioData writeWaveToFilePath:]
  -[VSStreamAudioData mappedAudioInfo]
  -[VSStreamAudioData setMappedAudioInfo:]


VSSpeechTaskQueue : NSObject
 @property  NSMutableArray *eagerTasks
 @property  NSMutableArray *speakTasks
 @property  NSOperation<VSSpeechTaskProtocol> *currentTask
 @property  {_opaque_pthread_mutex_t=q[56c]} threadMutex
 @property  {_opaque_pthread_mutexattr_t=q[8c]} threadMutexAttr
 @property  NSObject<OS_dispatch_queue> *speakingQueue
 @property  VSSpeechRequest *lastSynthesisRequest
 @property  unsigned long lastSynthesisRequestCreatedTimeStamp

  // class methods
  +[VSSpeechTaskQueue mainDeviceQueue]
  +[VSSpeechTaskQueue parallelQueueWithIdentifier:]
  +[VSSpeechTaskQueue cancelTasksWithDelegate:]

  // instance methods
  -[VSSpeechTaskQueue cancelTask:]
  -[VSSpeechTaskQueue setCurrentTask:]
  -[VSSpeechTaskQueue addTask:]
  -[VSSpeechTaskQueue .cxx_destruct]
  -[VSSpeechTaskQueue currentTask]
  -[VSSpeechTaskQueue init]
  -[VSSpeechTaskQueue speakingQueue]
  -[VSSpeechTaskQueue setSpeakingQueue:]
  -[VSSpeechTaskQueue spinNextTask]
  -[VSSpeechTaskQueue createdTimestampWithTask:]
  -[VSSpeechTaskQueue taskWithCreatedTimeStamp:]
  -[VSSpeechTaskQueue tasksWithDelegate:]
  -[VSSpeechTaskQueue suspendCurrentTask]
  -[VSSpeechTaskQueue resumeCurrentTask]
  -[VSSpeechTaskQueue eagerTasks]
  -[VSSpeechTaskQueue setEagerTasks:]
  -[VSSpeechTaskQueue speakTasks]
  -[VSSpeechTaskQueue setSpeakTasks:]
  -[VSSpeechTaskQueue threadMutex]
  -[VSSpeechTaskQueue setThreadMutex:]
  -[VSSpeechTaskQueue threadMutexAttr]
  -[VSSpeechTaskQueue setThreadMutexAttr:]
  -[VSSpeechTaskQueue lastSynthesisRequest]
  -[VSSpeechTaskQueue setLastSynthesisRequest:]
  -[VSSpeechTaskQueue lastSynthesisRequestCreatedTimeStamp]
  -[VSSpeechTaskQueue setLastSynthesisRequestCreatedTimeStamp:]


VSTextToPhonemesTask : VSSpeechSpeakTask
 @property  long long phonemeSystem
 @property  @? reply

  // instance methods
  -[VSTextToPhonemesTask reply]
  -[VSTextToPhonemesTask setReply:]
  -[VSTextToPhonemesTask .cxx_destruct]
  -[VSTextToPhonemesTask isSpeaking]
  -[VSTextToPhonemesTask main]
  -[VSTextToPhonemesTask phonemeSystem]
  -[VSTextToPhonemesTask setPhonemeSystem:]


VSMemoryMap : NSObject
 @property  NSString *filePath
 @property  unsigned long fileSize
 @property  ^v mappedData
 @property  int fd

  // instance methods
  -[VSMemoryMap fd]
  -[VSMemoryMap fileSize]
  -[VSMemoryMap filePath]
  -[VSMemoryMap dealloc]
  -[VSMemoryMap .cxx_destruct]
  -[VSMemoryMap initWithFilePath:]
  -[VSMemoryMap mappedData]
  -[VSMemoryMap mmap]
  -[VSMemoryMap madvise]


SAUIAudioDescription(VSAceObjectUtility)
	// instance methods
	-[SAUIAudioDescription(VSAceObjectUtility) vsDescription]

SATTSSpeechSynthesisResource(VSAceObjectUtility)
	// instance methods
	-[SATTSSpeechSynthesisResource(VSAceObjectUtility) vsDescription]

SATTSSpeechSynthesisVoice(VSAceObjectUtility)
	// instance methods
	-[SATTSSpeechSynthesisVoice(VSAceObjectUtility) vsDescription]

VSVoiceAsset(SpeechService)
	// instance methods
	-[VSVoiceAsset(SpeechService) gainDecibelWithVolume:]

VSAudioData(SAUIAudioData)
	// class methods
	+[VSAudioData(SAUIAudioData) audioDataFromFile:error:]
	+[VSAudioData(SAUIAudioData) audioDataFromSAUIAudioData:]
	+[VSAudioData(SAUIAudioData) audioDataFromPresynthesisRequest:]
	+[VSAudioData(SAUIAudioData) pcmAudioDataFromOpusAudio:]
	+[VSAudioData(SAUIAudioData) audioDataWithASBD:rawData:]
	+[VSAudioData(SAUIAudioData) asbdFromDescription:]

	// instance methods
	-[VSAudioData(SAUIAudioData) populateWithPCMData:]
	-[VSAudioData(SAUIAudioData) populateWithOpusData:]
	-[VSAudioData(SAUIAudioData) populatePCMDataWithSiriOpusSData:withOpusASBD:]
	-[VSAudioData(SAUIAudioData) writeToFilePath:]

01 00 0400 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFAudioPowerUpdater 
01 00 0400 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFPowerContextClient 
01 00 1700 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVAudioPlayer 
01 00 1700 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVAudioSession 
01 00 0800 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVSampleBufferAudioRenderer 
01 00 0800 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVSampleBufferRenderSynchronizer 
01 00 1300 /System/Library/PrivateFrameworks/MediaExperience.framework/MediaExperience: AVSystemController 
01 00 0f00 /System/Library/PrivateFrameworks/SiriAnalytics.framework/SiriAnalytics: AssistantSiriAnalytics 
01 00 0200 /System/Library/PrivateFrameworks/CoreKnowledge.framework/CoreKnowledge: CKKnowledgeStore 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSArray 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSBundle 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSCache 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSCondition 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSConstantArray 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantIntegerNumber 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSData 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDate 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSDateFormatter 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDictionary 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSError 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSException 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileHandle 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileManager 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSJSONSerialization 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedArchiver 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedUnarchiver 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSLock 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableArray 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableData 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableDictionary 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableOrderedSet 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableSet 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSNotificationCenter 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumber 
01 00 1400 /usr/lib/libobjc.A.dylib: NSObject 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSOperation 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSRunLoop 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSSet 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSString 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSTimer 
01 00 0900 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSURL 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSURLSessionConfiguration 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSUUID 
01 00 0a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSValue 
01 00 0d00 /System/Library/PrivateFrameworks/Osprey.framework/Osprey: OspreyChannel 
01 00 0300 /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects: SATTSSpeechSynthesisResource 
01 00 0300 /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects: SATTSSpeechSynthesisStreamingBegin 
01 00 0300 /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects: SATTSSpeechSynthesisStreamingChunk 
01 00 0300 /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects: SATTSSpeechSynthesisStreamingEnd 
01 00 0300 /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects: SATTSSpeechSynthesisVoice 
01 00 0300 /System/Library/PrivateFrameworks/SAObjects.framework/SAObjects: SAUIAudioDescription 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: SISchemaRequestLink 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: SISchemaRequestLinkInfo 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: SISchemaUUID 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: SISchemaVoiceSettings 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: SIUtilities 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPIPowerLogger 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPIProcessStartedEventContext 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPITtsRequestReceivedEventContext 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPITtsSpeechCancelledEventContext 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPITtsSpeechEndedEventContext 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPITtsSpeechFailedEventContext 
01 00 1100 /System/Library/PrivateFrameworks/SiriPowerInstrumentation.framework/SiriPowerInstrumentation: SPITtsSpeechStartedOrChangedEventContext 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSClientEvent 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSClientEventMetadata 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSClientSpeechContext 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSRequestReceived 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSRequestReceivedTier1 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSSpeechCancelled 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSSpeechEnded 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSSpeechFailed 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSSpeechStarted 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSVoiceContext 
01 00 1000 /System/Library/PrivateFrameworks/SiriInstrumentation.framework/SiriInstrumentation: TTSSchemaTTSVoiceFallbackOccurred 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSAnalytics 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSAudioData 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSFeatureFlags 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSInstrumentMetrics 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSLocalizedString 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSMappedData 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSMobileAssetsManager 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSNeuralTTSUtils 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSOpusDecoder 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSOpusEncoder 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSPhonemeTool 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSPreferencesInterface 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSSpeechEngine 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSSpeechInternalSettings 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSSpeechSynthesizerPreference 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSSpeechWordTimingInfo 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSUtilities 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSVoiceAsset 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSVoiceAssetSelection 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSVoiceResourceAsset 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSVoiceSubscription 
01 00 0c00 /System/Library/PrivateFrameworks/VoiceServices.framework/VoiceServices: VSWordTimingService 
