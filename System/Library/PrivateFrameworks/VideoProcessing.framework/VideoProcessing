|| __DATA.__data _VCPSceneProcessing_ForceFullScanKey
|| __DATA.__data _VCPTurboProcessing_QualityOfServiceKey
|| __DATA.__objc_data _OBJC_CLASS_$_VCPCallerIdentificationResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPCaptureAnalysisSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPContentAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPDeviceInformation
|| __DATA.__objc_data _OBJC_CLASS_$_VCPDownloadManager
|| __DATA.__objc_data _OBJC_CLASS_$_VCPEffectsAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceAnchor
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceGeometry
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeKitAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageConverter
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageDescriptor
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageManager
|| __DATA.__objc_data _OBJC_CLASS_$_VCPInMemoryAVAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPInterAssetAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPInternetReachability
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMediaAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMetaTrackDecoder
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieCurationResults
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieHighlightResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPhotoAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPhotosAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPreAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPriorityAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPProtoAssetAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPProtoLivePhotoEffectsRecipe
|| __DATA.__objc_data _OBJC_CLASS_$_VCPRealTimeAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPSceneTaxonomy
|| __DATA.__objc_data _OBJC_CLASS_$_VCPTimeMeasurement
|| __DATA.__objc_data _OBJC_CLASS_$_VCPURLAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoChatAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoKeyFrameResult
|| __DATA_CONST.__const _HomeKitAnalysisServiceName
|| __DATA_CONST.__const _MediaAnalysisActivityLevelResultsKey
|| __DATA_CONST.__const _MediaAnalysisAdjustedFingerprintKey
|| __DATA_CONST.__const _MediaAnalysisAnalysisTypesKey
|| __DATA_CONST.__const _MediaAnalysisApplauseResultsKey
|| __DATA_CONST.__const _MediaAnalysisBabbleResultsKey
|| __DATA_CONST.__const _MediaAnalysisBlurResultsKey
|| __DATA_CONST.__const _MediaAnalysisCameraMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisCheeringResultsKey
|| __DATA_CONST.__const _MediaAnalysisClassificationResultsKey
|| __DATA_CONST.__const _MediaAnalysisCompositionResultsKey
|| __DATA_CONST.__const _MediaAnalysisDateAnalyzedKey
|| __DATA_CONST.__const _MediaAnalysisDateModifiedKey
|| __DATA_CONST.__const _MediaAnalysisDistanceResultsKey
|| __DATA_CONST.__const _MediaAnalysisDomain
|| __DATA_CONST.__const _MediaAnalysisExposureResultsKey
|| __DATA_CONST.__const _MediaAnalysisFacePrintResultsKey
|| __DATA_CONST.__const _MediaAnalysisFaceResultsKey
|| __DATA_CONST.__const _MediaAnalysisFeatureVectorResultsKey
|| __DATA_CONST.__const _MediaAnalysisFineSubjectMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisFlagsKey
|| __DATA_CONST.__const _MediaAnalysisHumanActionResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanPoseInternalResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanPoseResultsKey
|| __DATA_CONST.__const _MediaAnalysisInterestingnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisObjectsResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisRecommendResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisSharpnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisJunkResultsKey
|| __DATA_CONST.__const _MediaAnalysisKeyFrameResourceResultsKey
|| __DATA_CONST.__const _MediaAnalysisLaughterResultsKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoEffectsResultsKey
|| __DATA_CONST.__const _MediaAnalysisLoudnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisMasterFingerprintKey
|| __DATA_CONST.__const _MediaAnalysisMovieHighlightResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovieSummaryResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovingObjectResultsKey
|| __DATA_CONST.__const _MediaAnalysisMusicResultsKey
|| __DATA_CONST.__const _MediaAnalysisObstructionResultsKey
|| __DATA_CONST.__const _MediaAnalysisOrientationResultsKey
|| __DATA_CONST.__const _MediaAnalysisPetsFaceResultsKey
|| __DATA_CONST.__const _MediaAnalysisPetsResultsKey
|| __DATA_CONST.__const _MediaAnalysisPhotosServiceName
|| __DATA_CONST.__const _MediaAnalysisPreEncodeResultsKey
|| __DATA_CONST.__const _MediaAnalysisQualityKey
|| __DATA_CONST.__const _MediaAnalysisQualityResultsKey
|| __DATA_CONST.__const _MediaAnalysisRealTimeServiceName
|| __DATA_CONST.__const _MediaAnalysisResultAttributesKey
|| __DATA_CONST.__const _MediaAnalysisResultBestPlaybackCropAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDistanceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDominantLineAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDuplicateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDurationKey
|| __DATA_CONST.__const _MediaAnalysisResultEnergyAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePoseYawAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePositionAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePrintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceQualityAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFeatureVectorAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFlagsKey
|| __DATA_CONST.__const _MediaAnalysisResultFlashAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionScoreAbsoluteAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionScoreRelativeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanKeypointsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanScoreAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultIndexAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultJunkAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultJunkConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameContentScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameExposureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameFaceQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameGlobalQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFramePenaltyScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameScoreAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameSharpnessScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTextureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTimeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTimestampKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameVisualPleasingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsGatingDescriptionsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsMatchingScenesAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsRecipeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLongExposureSuggestionStateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLoopSuggestionStateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultMovingObjectsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultNeighborAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultNeighborDateModifiedAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultOrientationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticAllScoresKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticFailureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticHarmoniousColorScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticImmersivenessScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticInterestingSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticIntrusiveObjectPresenceScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticLivelyColorScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticLowKeyLightingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticNoiseScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticOverallScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantCameraTiltScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantCompositionScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantLightingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantPatternScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantPerspectiveScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantPostProcessingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantReflectionsScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticPleasantSymmetryScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticSharplyFocusedSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticTastefullyBlurredScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticWellChosenBackgroundScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticWellFramedSubjectKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticWellTimedShotScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultPHAestheticsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPHClassificationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPHSaliencyAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPHSalientAcceptableCropKey
|| __DATA_CONST.__const _MediaAnalysisResultPHSalientPreferredCropKey
|| __DATA_CONST.__const _MediaAnalysisResultPHSceneprintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPeakAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPetsBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPetsConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPreEncodeDataAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultQualityKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSceneprintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSceneprintDistanceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSharpnessAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSharpnessFacesAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultShotTypeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSlowMoFlickerAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultStartKey
|| __DATA_CONST.__const _MediaAnalysisResultStillTimeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSummaryTimerangeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultTextureAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultUnderExposeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultVanishingPointAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultVanishingPointConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultsKey
|| __DATA_CONST.__const _MediaAnalysisSaliencyResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneChangeResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneprintResultsKey
|| __DATA_CONST.__const _MediaAnalysisServiceName
|| __DATA_CONST.__const _MediaAnalysisShotTypeResultsKey
|| __DATA_CONST.__const _MediaAnalysisStatsFlagsKey
|| __DATA_CONST.__const _MediaAnalysisSubjectMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisSubtleMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisSyncPointKey
|| __DATA_CONST.__const _MediaAnalysisTrackingResultsKey
|| __DATA_CONST.__const _MediaAnalysisUtteranceResultsKey
|| __DATA_CONST.__const _MediaAnalysisVersionKey
|| __DATA_CONST.__const _MediaAnalysisVoiceResultsKey
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowInnerUp
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowOuterUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowOuterUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekPuff
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekSquintLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekSquintRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeBlinkLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeBlinkRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookInLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookInRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookOutLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookOutRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeSquintLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeSquintRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeWideLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeWideRight
|| __DATA_CONST.__const _VCPBlendShapeLocationJawForward
|| __DATA_CONST.__const _VCPBlendShapeLocationJawLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationJawOpen
|| __DATA_CONST.__const _VCPBlendShapeLocationJawRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthClose
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthDimpleLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthDimpleRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFrownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFrownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFunnel
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLowerDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLowerDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPressLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPressRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPucker
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRollLower
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRollUpper
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthShrugLower
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthShrugUpper
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthSmileLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthSmileRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthStretchLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthStretchRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthUpperUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthUpperUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationNoseSneerLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationNoseSneerRight
|| __DATA_CONST.__const _VCPCaptureAnalysisAggregatedSubjectMotionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisDispatchQueuePropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisDurationKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceAnchorResultKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceBoundsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceResultsKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceRollAnglesPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFlagsKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFocalLengthInPixelsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFrameHeightPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFrameWidthPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisInterestingnessScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObstructionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisQualityKey
|| __DATA_CONST.__const _VCPCaptureAnalysisRegionsOfInterestResultKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSceneChangeScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSharpnessScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisStartKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSubjectMotionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisTrackingScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisTurboModePropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisVoiceResultsKey
|| __DATA_CONST.__const _VCPContentTypeKey
|| __DATA_CONST.__const _VCPFaceMetadataArrayKey
|| __DATA_CONST.__const _VCPFaceRectangleKey
|| __DATA_CONST.__const _VCPFaceRollKey
|| __DATA_CONST.__const _VCPPhotoLibrariesDefaultsKey
|| __DATA_CONST.__const _VCPPriorityScoreKey
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFingerprint
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPLogManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMediaAnalyzer
|| __TEXT.__const _MediaAnalysisBlacklistAgeOutInterval
|| __TEXT.__const _MediaAnalysisBlacklistThreshold
|| __TEXT.__const _MediaAnalysisChangedVersion17
|| __TEXT.__const _MediaAnalysisChangedVersion3
|| __TEXT.__const _MediaAnalysisChangedVersion6
|| __TEXT.__const _MediaAnalysisChangedVersion7
|| __TEXT.__const _MediaAnalysisDeleteRetainInterval
|| __TEXT.__const _MediaAnalysisDistanceUnknown
|| __TEXT.__const _MediaAnalysisFlagsCameraAll
|| __TEXT.__const _MediaAnalysisQualityUnknown
|| __TEXT.__const _MediaAnalysisVersion
|| __TEXT.__const _VCPLogToOSLogType
|| __TEXT.__const _VCPMAFullAnalysisTypesImage
|| __TEXT.__const _VCPMAFullAnalysisTypesLivePhoto
|| __TEXT.__const _VCPMAFullAnalysisTypesMovie
|| __TEXT.__const _VCPMAFullAnalysisTypesThumbnail
|| __TEXT.__const _VCPPhotosMediaAnalysisTaskID
|| __TEXT.__const _VCPPhotosSceneAnalysisTaskID
|| __TEXT.__const _VCPPhotosSceneProcessingVersion
|| __TEXT.__text _MediaAnalysisConvertAnalysisToOriginalTime
|| __TEXT.__text _MediaAnalysisFlagsForTypes
|| __TEXT.__text _MediaAnalysisLogLevel
|| __TEXT.__text _MediaAnalysisPostProcessSlowmoResults
|| __TEXT.__text _MediaAnalysisPurgeResources
|| __TEXT.__text _MediaAnalysisResultsKeyToType
|| __TEXT.__text _MediaAnalysisResultsKeysForAnalysisTypes
|| __TEXT.__text _MediaAnalysisResultsTypeToKey
|| __TEXT.__text _MediaAnalysisResultsUpdatedSince
|| __TEXT.__text _MediaAnalysisStripInternalResultsFromAnalysis
|| __TEXT.__text _MediaAnalysisStripKeyframeResourceResultsFromAnalysis
|| __TEXT.__text _MediaAnalysisStripOutdatedAnalysis
|| __TEXT.__text _MediaAnalysisTypeDescription
|| __TEXT.__text _MediaAnalysisTypeShortDescription
|| __TEXT.__text _MediaAnalysisTypesUpdatedSince
|| __TEXT.__text _VCPCodecGetProperties
|| __TEXT.__text _VCPCodecGetProperty
|| __TEXT.__text _VCPCompressionSessionCompleteFrames
|| __TEXT.__text _VCPCompressionSessionCopyProperty
|| __TEXT.__text _VCPCompressionSessionCopySupportedPropertyDictionary
|| __TEXT.__text _VCPCompressionSessionCreate
|| __TEXT.__text _VCPCompressionSessionEncodeFrame
|| __TEXT.__text _VCPCompressionSessionGetPixelBufferPool
|| __TEXT.__text _VCPCompressionSessionGetTypeID
|| __TEXT.__text _VCPCompressionSessionInvalidate
|| __TEXT.__text _VCPCompressionSessionSetProperty
|| __TEXT.__text _VCPDecompressionSessionCopyBlackPixelBuffer
|| __TEXT.__text _VCPDecompressionSessionCopyProperty
|| __TEXT.__text _VCPDecompressionSessionCopySerializableProperties
|| __TEXT.__text _VCPDecompressionSessionCopySupportedPropertyDictionary
|| __TEXT.__text _VCPDecompressionSessionCreate
|| __TEXT.__text _VCPDecompressionSessionDecodeFrame
|| __TEXT.__text _VCPDecompressionSessionFinishDelayedFrames
|| __TEXT.__text _VCPDecompressionSessionGetTypeID
|| __TEXT.__text _VCPDecompressionSessionInvalidate
|| __TEXT.__text _VCPDecompressionSessionSetProperties
|| __TEXT.__text _VCPDecompressionSessionSetProperty
|| __TEXT.__text _VCPDecompressionSessionWaitForAsynchronousFrames
|| __TEXT.__text _VCPJunkLabelFromSceneClassificationID
|| __TEXT.__text _VCPParseConfigurationRecordAndCreateParameterSets
|| __TEXT.__text _VCPParseParameterSetsAndCreateConfigurationRecord
|| __TEXT.__text _VCPPerformance_RecordMeasurement
|| __TEXT.__text _VCPPerformance_ReportSummary
|| __TEXT.__text _VCPProcessingStatusDescription
|| __TEXT.__text _VCPProcessingStatusShortDescription
|| __TEXT.__text _VCPReadCodecConfigParams
|| __TEXT.__text _VCPReadDecMaxFrameFormat
|| __TEXT.__text _VCPReadEncMaxFrameFormat
|| __TEXT.__text _VCPReadFrameSliceHeader
|| __TEXT.__text _VCPReadHEVCSliceHeader
|| __TEXT.__text _VCPSessionCopyProperty
|| __TEXT.__text _VCPSessionCreate
|| __TEXT.__text _VCPSessionCreateDefaultBufferProperties
|| __TEXT.__text _VCPSessionExecute
|| __TEXT.__text _VCPSessionGetTypeID
|| __TEXT.__text _VCPSessionSetProperty
|| __TEXT.__text _VCPSignPostLog
|| __TEXT.__text _VCPTaskIDDescription
|| __TEXT.__text _VCPVersionForTask
|| __TEXT.__text _VPModuleInitialize
__ AVFoundation: _AVFileTypeAVCI
__ AVFoundation: _AVFileTypeHEIC
__ AVFoundation: _AVFileTypeHEIF
__ AVFoundation: _AVFileTypeMPEG4
__ AVFoundation: _AVFormatIDKey
__ AVFoundation: _AVLinearPCMBitDepthKey
__ AVFoundation: _AVLinearPCMIsBigEndianKey
__ AVFoundation: _AVLinearPCMIsFloatKey
__ AVFoundation: _AVLinearPCMIsNonInterleaved
__ AVFoundation: _AVMediaTypeAudio
__ AVFoundation: _AVMediaTypeMetadata
__ AVFoundation: _AVMediaTypeVideo
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataDetectedFace
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataVideoOrientation
__ AVFoundation: _AVNumberOfChannelsKey
__ AVFoundation: _AVSampleRateKey
__ AVFoundation: _OBJC_CLASS_$_AVAsset
__ AVFoundation: _OBJC_CLASS_$_AVAssetImageGenerator
__ AVFoundation: _OBJC_CLASS_$_AVAssetReader
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderOutputMetadataAdaptor
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderSampleReferenceOutput
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderTrackOutput
__ AVFoundation: _OBJC_CLASS_$_AVAssetTrack
__ AVFoundation: _OBJC_CLASS_$_AVAudioFormat
__ AVFoundation: _OBJC_CLASS_$_AVAudioPCMBuffer
__ AVFoundation: _OBJC_CLASS_$_AVMetadataItem
__ AVFoundation: _OBJC_CLASS_$_AVMutableComposition
__ AVFoundation: _OBJC_CLASS_$_AVTimedMetadataGroup
__ AVFoundation: _OBJC_CLASS_$_AVURLAsset
__ AVFoundation: _OBJC_METACLASS_$_AVURLAsset
__ Accelerate: _sgetrf_
__ Accelerate: _sgetri_
__ Accelerate: _vDSP_create_fftsetup
__ Accelerate: _vDSP_ctoz
__ Accelerate: _vDSP_deq22
__ Accelerate: _vDSP_destroy_fftsetup
__ Accelerate: _vDSP_dotpr
__ Accelerate: _vDSP_f3x3
__ Accelerate: _vDSP_f5x5
__ Accelerate: _vDSP_fft2d_zrip
__ Accelerate: _vDSP_imgfir
__ Accelerate: _vDSP_maxmgv
__ Accelerate: _vDSP_mmul
__ Accelerate: _vDSP_mtrans
__ Accelerate: _vDSP_sve
__ Accelerate: _vDSP_svesq
__ Accelerate: _vDSP_vabs
__ Accelerate: _vDSP_vadd
__ Accelerate: _vDSP_vclr
__ Accelerate: _vDSP_vfill
__ Accelerate: _vDSP_vfltu8
__ Accelerate: _vDSP_vsadd
__ Accelerate: _vDSP_vsdiv
__ Accelerate: _vDSP_vsmul
__ Accelerate: _vDSP_vsorti
__ Accelerate: _vDSP_vsub
__ Accelerate: _vDSP_ztoc
__ Accelerate: _vDSP_zvcmul
__ Accelerate: _vDSP_zvmags
__ Accelerate: _vImageScale_ARGB8888
__ AppleCVA: _kCVAFaceKit_DetectedFacesArray
__ AudioToolbox: _AudioComponentFindNext
__ AudioToolbox: _AudioComponentInstanceDispose
__ AudioToolbox: _AudioComponentInstanceNew
__ AudioToolbox: _AudioUnitAddPropertyListener
__ AudioToolbox: _AudioUnitGetProperty
__ AudioToolbox: _AudioUnitInitialize
__ AudioToolbox: _AudioUnitProcessMultiple
__ AudioToolbox: _AudioUnitReset
__ AudioToolbox: _AudioUnitSetProperty
__ AutoLoop: _autoloopSettingsDestroy
__ AutoLoop: _autoloopSettingsSetDisableStabilizationGPU
__ AutoLoop: _autoloopSettingsSetGating
__ AutoLoop: _autoloopSettingsSetOptimizeForMemoryUse
__ AutoLoop: _createAutoLoopSettingsForAsset
__ AutoLoop: _createBundleDefaultGatingClassifierURL
__ AutoLoop: _getGatingResult
__ AutoLoop: _liveAnalysisResultDestroy
__ AutoLoop: _liveAnalysisResultToDictionary
__ AutoLoop: _runLiveAnalysisPipeline
__ CoreAnalytics: _AnalyticsSendEventLazy
__ CoreAppleCVA: __ZN3cva12VecLibLapackIfE5ormqrENS_4math8MULTSIDEENS2_5TRANSEiiiPfiS5_S5_iS5_i
__ CoreAppleCVA: __ZN3cva6VecLibIfE4gemmEbbiiifPKfiS3_ifPfi
__ CoreAppleCVA: __ZN3cva6vecLib5geqrfIfEEviiPT_iS3_S3_iPi
__ CoreAppleCVA: __ZN3cva6vecLib5gesvdIfEEvcciiPKT_iPS2_S5_iS5_iS5_iPi
__ CoreAppleCVA: __ZN3cva6vecLib5trtrsIfEEvccciiPKT_iPS2_iPi
__ CoreData: _NSOverwriteMergePolicy
__ CoreData: _OBJC_CLASS_$_NSEntityDescription
__ CoreData: _OBJC_CLASS_$_NSFetchRequest
__ CoreData: _OBJC_CLASS_$_NSManagedObject
__ CoreData: _OBJC_CLASS_$_NSManagedObjectModel
__ CoreData: _OBJC_CLASS_$_NSPersistentContainer
__ CoreData: _OBJC_CLASS_$_NSPersistentStoreDescription
__ CoreData: _OBJC_METACLASS_$_NSManagedObject
__ CoreFoundation: _CFAllocatorAllocate
__ CoreFoundation: _CFAllocatorDeallocate
__ CoreFoundation: _CFArrayAppendValue
__ CoreFoundation: _CFArrayCreate
__ CoreFoundation: _CFArrayCreateCopy
__ CoreFoundation: _CFArrayCreateMutable
__ CoreFoundation: _CFArrayGetCount
__ CoreFoundation: _CFArrayGetTypeID
__ CoreFoundation: _CFArrayGetValueAtIndex
__ CoreFoundation: _CFArrayInsertValueAtIndex
__ CoreFoundation: _CFArrayRemoveValueAtIndex
__ CoreFoundation: _CFBooleanGetTypeID
__ CoreFoundation: _CFBooleanGetValue
__ CoreFoundation: _CFDataAppendBytes
__ CoreFoundation: _CFDataCreate
__ CoreFoundation: _CFDataCreateMutable
__ CoreFoundation: _CFDataCreateWithBytesNoCopy
__ CoreFoundation: _CFDataGetBytePtr
__ CoreFoundation: _CFDataGetLength
__ CoreFoundation: _CFDataGetMutableBytePtr
__ CoreFoundation: _CFDataGetTypeID
__ CoreFoundation: _CFDataIncreaseLength
__ CoreFoundation: _CFDataSetLength
__ CoreFoundation: _CFDictionaryAddValue
__ CoreFoundation: _CFDictionaryApplyFunction
__ CoreFoundation: _CFDictionaryContainsKey
__ CoreFoundation: _CFDictionaryCreate
__ CoreFoundation: _CFDictionaryCreateMutable
__ CoreFoundation: _CFDictionaryCreateMutableCopy
__ CoreFoundation: _CFDictionaryGetCount
__ CoreFoundation: _CFDictionaryGetTypeID
__ CoreFoundation: _CFDictionaryGetValue
__ CoreFoundation: _CFDictionaryGetValueIfPresent
__ CoreFoundation: _CFDictionaryRemoveValue
__ CoreFoundation: _CFDictionarySetValue
__ CoreFoundation: _CFEqual
__ CoreFoundation: _CFGetTypeID
__ CoreFoundation: _CFLog
__ CoreFoundation: _CFNumberCreate
__ CoreFoundation: _CFNumberGetType
__ CoreFoundation: _CFNumberGetTypeID
__ CoreFoundation: _CFNumberGetValue
__ CoreFoundation: _CFPreferencesCopyAppValue
__ CoreFoundation: _CFPreferencesGetAppBooleanValue
__ CoreFoundation: _CFPreferencesGetAppIntegerValue
__ CoreFoundation: _CFRelease
__ CoreFoundation: _CFRetain
__ CoreFoundation: _CFSetAddValue
__ CoreFoundation: _CFSetContainsValue
__ CoreFoundation: _CFSetCreateMutable
__ CoreFoundation: _CFStringAppendFormat
__ CoreFoundation: _CFStringCompare
__ CoreFoundation: _CFStringCreateCopy
__ CoreFoundation: _CFStringCreateMutable
__ CoreFoundation: _CFStringCreateWithCString
__ CoreFoundation: _CFStringCreateWithFormat
__ CoreFoundation: _CFStringGetCString
__ CoreFoundation: _CFStringGetTypeID
__ CoreFoundation: _NSRangeException
__ CoreFoundation: _NSURLContentModificationDateKey
__ CoreFoundation: _NSURLTypeIdentifierKey
__ CoreFoundation: _OBJC_CLASS_$_NSArray
__ CoreFoundation: _OBJC_CLASS_$_NSData
__ CoreFoundation: _OBJC_CLASS_$_NSDate
__ CoreFoundation: _OBJC_CLASS_$_NSDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSException
__ CoreFoundation: _OBJC_CLASS_$_NSLocale
__ CoreFoundation: _OBJC_CLASS_$_NSMutableArray
__ CoreFoundation: _OBJC_CLASS_$_NSMutableData
__ CoreFoundation: _OBJC_CLASS_$_NSMutableDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSMutableSet
__ CoreFoundation: _OBJC_CLASS_$_NSSet
__ CoreFoundation: _OBJC_CLASS_$_NSURL
__ CoreFoundation: _OBJC_EHTYPE_$_NSException
__ CoreFoundation: __CFRuntimeCreateInstance
__ CoreFoundation: __CFRuntimeRegisterClass
__ CoreFoundation: ___CFConstantStringClassReference
__ CoreFoundation: ___NSDictionary0__
__ CoreFoundation: _kCFAllocatorDefault
__ CoreFoundation: _kCFAllocatorNull
__ CoreFoundation: _kCFBooleanFalse
__ CoreFoundation: _kCFBooleanTrue
__ CoreFoundation: _kCFTypeArrayCallBacks
__ CoreFoundation: _kCFTypeDictionaryKeyCallBacks
__ CoreFoundation: _kCFTypeDictionaryValueCallBacks
__ CoreFoundation: _kCFTypeSetCallBacks
__ CoreGraphics: _CGAffineTransformConcat
__ CoreGraphics: _CGAffineTransformIdentity
__ CoreGraphics: _CGAffineTransformMakeScale
__ CoreGraphics: _CGBitmapContextCreate
__ CoreGraphics: _CGColorSpaceCreateDeviceRGB
__ CoreGraphics: _CGContextConcatCTM
__ CoreGraphics: _CGContextDrawImage
__ CoreGraphics: _CGImageGetHeight
__ CoreGraphics: _CGImageGetProperty
__ CoreGraphics: _CGImageGetWidth
__ CoreGraphics: _CGPointZero
__ CoreGraphics: _CGRectApplyAffineTransform
__ CoreGraphics: _CGRectGetMaxX
__ CoreGraphics: _CGRectGetMaxY
__ CoreGraphics: _CGRectGetMidX
__ CoreGraphics: _CGRectGetMidY
__ CoreGraphics: _CGRectGetMinX
__ CoreGraphics: _CGRectGetMinY
__ CoreGraphics: _CGRectIntersection
__ CoreGraphics: _CGRectIntersectsRect
__ CoreGraphics: _CGRectIsEmpty
__ CoreGraphics: _CGRectIsNull
__ CoreGraphics: _CGRectMakeWithDictionaryRepresentation
__ CoreGraphics: _CGRectNull
__ CoreGraphics: _CGRectUnion
__ CoreGraphics: _CGRectZero
__ CoreGraphics: _CGSizeZero
__ CoreGraphics: _kCGImagePropertyIOSurface
__ CoreMedia: _CMAudioFormatDescriptionGetStreamBasicDescription
__ CoreMedia: _CMBaseObjectGetDerivedStorage
__ CoreMedia: _CMBaseObjectGetVTable
__ CoreMedia: _CMBlockBufferAccessDataBytes
__ CoreMedia: _CMBlockBufferAppendMemoryBlock
__ CoreMedia: _CMBlockBufferCopyDataBytes
__ CoreMedia: _CMBlockBufferCreateWithBufferReference
__ CoreMedia: _CMBlockBufferCreateWithMemoryBlock
__ CoreMedia: _CMBlockBufferGetDataLength
__ CoreMedia: _CMBlockBufferGetDataPointer
__ CoreMedia: _CMBlockBufferReplaceDataBytes
__ CoreMedia: _CMDerivedObjectCreate
__ CoreMedia: _CMFormatDescriptionGetExtension
__ CoreMedia: _CMFormatDescriptionGetMediaSubType
__ CoreMedia: _CMGetAttachment
__ CoreMedia: _CMMetadataFormatDescriptionGetIdentifiers
__ CoreMedia: _CMSampleBufferCreate
__ CoreMedia: _CMSampleBufferCreateCopyWithNewTiming
__ CoreMedia: _CMSampleBufferGetDataBuffer
__ CoreMedia: _CMSampleBufferGetDuration
__ CoreMedia: _CMSampleBufferGetFormatDescription
__ CoreMedia: _CMSampleBufferGetImageBuffer
__ CoreMedia: _CMSampleBufferGetNumSamples
__ CoreMedia: _CMSampleBufferGetOutputDuration
__ CoreMedia: _CMSampleBufferGetOutputPresentationTimeStamp
__ CoreMedia: _CMSampleBufferGetPresentationTimeStamp
__ CoreMedia: _CMSampleBufferGetSampleAttachmentsArray
__ CoreMedia: _CMSampleBufferGetSampleSize
__ CoreMedia: _CMSampleBufferGetSampleTimingInfo
__ CoreMedia: _CMTimeAdd
__ CoreMedia: _CMTimeCompare
__ CoreMedia: _CMTimeConvertScale
__ CoreMedia: _CMTimeCopyAsDictionary
__ CoreMedia: _CMTimeGetSeconds
__ CoreMedia: _CMTimeMake
__ CoreMedia: _CMTimeMakeFromDictionary
__ CoreMedia: _CMTimeMakeWithEpoch
__ CoreMedia: _CMTimeMakeWithSeconds
__ CoreMedia: _CMTimeMultiplyByFloat64
__ CoreMedia: _CMTimeMultiplyByRatio
__ CoreMedia: _CMTimeRangeContainsTime
__ CoreMedia: _CMTimeRangeContainsTimeRange
__ CoreMedia: _CMTimeRangeCopyAsDictionary
__ CoreMedia: _CMTimeRangeEqual
__ CoreMedia: _CMTimeRangeFromTimeToTime
__ CoreMedia: _CMTimeRangeGetEnd
__ CoreMedia: _CMTimeRangeGetIntersection
__ CoreMedia: _CMTimeRangeGetUnion
__ CoreMedia: _CMTimeRangeMake
__ CoreMedia: _CMTimeRangeMakeFromDictionary
__ CoreMedia: _CMTimeSubtract
__ CoreMedia: _CMVideoFormatDescriptionCreateFromH264ParameterSets
__ CoreMedia: _CMVideoFormatDescriptionGetDimensions
__ CoreMedia: _FigBlockBufferRelease
__ CoreMedia: _FigFormatDescriptionRelease
__ CoreMedia: _FigLivePhotoMetadataComputeDeserializationSize
__ CoreMedia: _FigLivePhotoMetadataDeserializeIntoBuffer
__ CoreMedia: _FigSampleBufferRelease
__ CoreMedia: _FigSampleBufferRetain
__ CoreMedia: _FigSignalErrorAt
__ CoreMedia: _FigThreadGetMachThreadPriorityValue
__ CoreMedia: _FigThreadRunOnce
__ CoreMedia: _kCMFormatDescriptionExtension_FormatName
__ CoreMedia: _kCMFormatDescriptionExtension_SampleDescriptionExtensionAtoms
__ CoreMedia: _kCMSampleAttachmentKey_DependsOnOthers
__ CoreMedia: _kCMSampleAttachmentKey_EarlierDisplayTimesAllowed
__ CoreMedia: _kCMSampleAttachmentKey_IsDependedOnByOthers
__ CoreMedia: _kCMSampleAttachmentKey_NotSync
__ CoreMedia: _kCMSampleAttachmentKey_PartialSync
__ CoreMedia: _kCMTimeIndefinite
__ CoreMedia: _kCMTimeInvalid
__ CoreMedia: _kCMTimeNegativeInfinity
__ CoreMedia: _kCMTimePositiveInfinity
__ CoreMedia: _kCMTimeRangeInvalid
__ CoreMedia: _kCMTimeRangeZero
__ CoreMedia: _kCMTimeZero
__ CoreMedia: _kFigCaptureSampleBufferAttachmentKey_MetadataDictionary
__ CoreMedia: _kFigCaptureStreamMetadata_AEAverage
__ CoreMedia: _kFigCaptureStreamMetadata_AGC
__ CoreMedia: _kFigCaptureStreamMetadata_AWBBGain
__ CoreMedia: _kFigCaptureStreamMetadata_AWBGGain
__ CoreMedia: _kFigCaptureStreamMetadata_AWBRGain
__ CoreMedia: _kFigCaptureStreamMetadata_ExposureTime
__ CoreMedia: _kFigCaptureStreamMetadata_NormalizedSNR
__ CoreMedia: _kFigCaptureStreamMetadata_ispDGain
__ CoreMedia: _kFigCaptureStreamMetadata_sensorDGain
__ CoreMedia: _kFigFaceDetectionMetadataArray
__ CoreMedia: _kFigFaceDetectionMetadata_FaceID
__ CoreMedia: _kFigFaceDetectionMetadata_Rect
__ CoreMedia: _kFigFaceDetectionMetadata_Roll
__ CoreMedia: _kFigFaceDetectionMetadata_Yaw
__ CoreMedia: _kFigMetadataDataType_QuickTimeMetadataLivePhotoInfo
__ CoreMedia: _kFigMetadataIdentifier_QuickTimeMetadataLivePhotoInfo
__ CoreMedia: _kFigMetadataIdentifier_QuickTimeMetadataStillImageTime
__ CoreServices: _UTTypeConformsTo
__ CoreServices: _kUTTypeImage
__ CoreServices: _kUTTypeJPEG
__ CoreServices: _kUTTypeMovie
__ CoreServices: _kUTTypeVideo
__ CoreVideo: _CVBufferGetAttachment
__ CoreVideo: _CVBufferGetAttachments
__ CoreVideo: _CVBufferPropagateAttachments
__ CoreVideo: _CVBufferSetAttachment
__ CoreVideo: _CVBufferSetAttachments
__ CoreVideo: _CVColorPrimariesGetIntegerCodePointForString
__ CoreVideo: _CVColorPrimariesGetStringForIntegerCodePoint
__ CoreVideo: _CVPixelBufferCreate
__ CoreVideo: _CVPixelBufferCreateResolvedAttributesDictionary
__ CoreVideo: _CVPixelBufferCreateWithIOSurface
__ CoreVideo: _CVPixelBufferGetBaseAddress
__ CoreVideo: _CVPixelBufferGetBaseAddressOfPlane
__ CoreVideo: _CVPixelBufferGetBytesPerRow
__ CoreVideo: _CVPixelBufferGetBytesPerRowOfPlane
__ CoreVideo: _CVPixelBufferGetDataSize
__ CoreVideo: _CVPixelBufferGetExtendedPixels
__ CoreVideo: _CVPixelBufferGetHeight
__ CoreVideo: _CVPixelBufferGetHeightOfPlane
__ CoreVideo: _CVPixelBufferGetIOSurface
__ CoreVideo: _CVPixelBufferGetPixelFormatType
__ CoreVideo: _CVPixelBufferGetPlaneCount
__ CoreVideo: _CVPixelBufferGetWidth
__ CoreVideo: _CVPixelBufferGetWidthOfPlane
__ CoreVideo: _CVPixelBufferIsCompatibleWithAttributes
__ CoreVideo: _CVPixelBufferIsPlanar
__ CoreVideo: _CVPixelBufferLockBaseAddress
__ CoreVideo: _CVPixelBufferPoolCreate
__ CoreVideo: _CVPixelBufferPoolCreatePixelBuffer
__ CoreVideo: _CVPixelBufferPoolGetPixelBufferAttributes
__ CoreVideo: _CVPixelBufferPoolRelease
__ CoreVideo: _CVPixelBufferPoolRetain
__ CoreVideo: _CVPixelBufferPoolSetMaxBufferAge
__ CoreVideo: _CVPixelBufferRelease
__ CoreVideo: _CVPixelBufferRetain
__ CoreVideo: _CVPixelBufferUnlockBaseAddress
__ CoreVideo: _CVTransferFunctionGetIntegerCodePointForString
__ CoreVideo: _CVTransferFunctionGetStringForIntegerCodePoint
__ CoreVideo: _CVYCbCrMatrixGetIntegerCodePointForString
__ CoreVideo: _CVYCbCrMatrixGetStringForIntegerCodePoint
__ CoreVideo: _kCVImageBufferChromaLocationBottomFieldKey
__ CoreVideo: _kCVImageBufferChromaLocationTopFieldKey
__ CoreVideo: _kCVImageBufferChromaLocation_Bottom
__ CoreVideo: _kCVImageBufferChromaLocation_BottomLeft
__ CoreVideo: _kCVImageBufferChromaLocation_Center
__ CoreVideo: _kCVImageBufferChromaLocation_Left
__ CoreVideo: _kCVImageBufferChromaLocation_Top
__ CoreVideo: _kCVImageBufferChromaLocation_TopLeft
__ CoreVideo: _kCVImageBufferCleanApertureHeightKey
__ CoreVideo: _kCVImageBufferCleanApertureHorizontalOffsetKey
__ CoreVideo: _kCVImageBufferCleanApertureKey
__ CoreVideo: _kCVImageBufferCleanApertureVerticalOffsetKey
__ CoreVideo: _kCVImageBufferCleanApertureWidthKey
__ CoreVideo: _kCVImageBufferColorPrimariesKey
__ CoreVideo: _kCVImageBufferColorPrimaries_EBU_3213
__ CoreVideo: _kCVImageBufferColorPrimaries_ITU_R_709_2
__ CoreVideo: _kCVImageBufferColorPrimaries_SMPTE_C
__ CoreVideo: _kCVImageBufferPixelAspectRatioHorizontalSpacingKey
__ CoreVideo: _kCVImageBufferPixelAspectRatioKey
__ CoreVideo: _kCVImageBufferPixelAspectRatioVerticalSpacingKey
__ CoreVideo: _kCVImageBufferTransferFunctionKey
__ CoreVideo: _kCVImageBufferTransferFunction_ITU_R_709_2
__ CoreVideo: _kCVImageBufferTransferFunction_SMPTE_240M_1995
__ CoreVideo: _kCVImageBufferTransferFunction_UseGamma
__ CoreVideo: _kCVImageBufferYCbCrMatrixKey
__ CoreVideo: _kCVImageBufferYCbCrMatrix_ITU_R_601_4
__ CoreVideo: _kCVImageBufferYCbCrMatrix_ITU_R_709_2
__ CoreVideo: _kCVImageBufferYCbCrMatrix_SMPTE_240M_1995
__ CoreVideo: _kCVPixelBufferBytesPerRowAlignmentKey
__ CoreVideo: _kCVPixelBufferCacheModeKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsBottomKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsLeftKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsRightKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsTopKey
__ CoreVideo: _kCVPixelBufferHeightKey
__ CoreVideo: _kCVPixelBufferIOSurfacePropertiesKey
__ CoreVideo: _kCVPixelBufferPixelFormatTypeKey
__ CoreVideo: _kCVPixelBufferPlaneAlignmentKey
__ CoreVideo: _kCVPixelBufferPoolMinimumBufferCountKey
__ CoreVideo: _kCVPixelBufferWidthKey
__ Espresso: _espresso_create_context
__ Espresso: _espresso_create_plan
__ Espresso: _espresso_network_bind_buffer
__ Espresso: _espresso_network_select_configuration
__ Espresso: _espresso_plan_add_network
__ Espresso: _espresso_plan_build
__ Espresso: _espresso_plan_build_clean
__ Espresso: _espresso_plan_destroy
__ Espresso: _espresso_plan_execute_sync
__ Espresso: _espresso_plan_get_phase
__ Foundation: _NSClassFromString
__ Foundation: _NSLocalizedDescriptionKey
__ Foundation: _NSOSStatusErrorDomain
__ Foundation: _NSPointFromString
__ Foundation: _NSRectFromString
__ Foundation: _NSStringFromClass
__ Foundation: _NSStringFromPoint
__ Foundation: _NSStringFromRect
__ Foundation: _NSTemporaryDirectory
__ Foundation: _OBJC_CLASS_$_NSBundle
__ Foundation: _OBJC_CLASS_$_NSCompoundPredicate
__ Foundation: _OBJC_CLASS_$_NSDateFormatter
__ Foundation: _OBJC_CLASS_$_NSError
__ Foundation: _OBJC_CLASS_$_NSFileManager
__ Foundation: _OBJC_CLASS_$_NSKeyedArchiver
__ Foundation: _OBJC_CLASS_$_NSKeyedUnarchiver
__ Foundation: _OBJC_CLASS_$_NSLock
__ Foundation: _OBJC_CLASS_$_NSMutableString
__ Foundation: _OBJC_CLASS_$_NSMutableURLRequest
__ Foundation: _OBJC_CLASS_$_NSNumber
__ Foundation: _OBJC_CLASS_$_NSOperation
__ Foundation: _OBJC_CLASS_$_NSPredicate
__ Foundation: _OBJC_CLASS_$_NSPropertyListSerialization
__ Foundation: _OBJC_CLASS_$_NSSortDescriptor
__ Foundation: _OBJC_CLASS_$_NSString
__ Foundation: _OBJC_CLASS_$_NSURLSession
__ Foundation: _OBJC_CLASS_$_NSURLSessionConfiguration
__ Foundation: _OBJC_CLASS_$_NSUUID
__ Foundation: _OBJC_CLASS_$_NSXPCConnection
__ Foundation: _OBJC_CLASS_$_NSXPCInterface
__ Foundation: _OBJC_METACLASS_$_NSOperation
__ IOKit: _IOObjectRelease
__ IOKit: _IORegistryEntryCreateCFProperty
__ IOKit: _IORegistryEntryFromPath
__ IOKit: _IORegistryEntrySearchCFProperty
__ IOKit: _IOServiceGetMatchingService
__ IOKit: _IOServiceMatching
__ IOKit: _kIOMasterPortDefault
__ IOSurface: _IOSurfaceAcceleratorCreate
__ IOSurface: _IOSurfaceAcceleratorSetCustomFilter
__ IOSurface: _IOSurfaceAcceleratorTransformSurface
__ IOSurface: _IOSurfaceCreate
__ IOSurface: _IOSurfaceGetAddressFormatOfPlane
__ IOSurface: _IOSurfaceGetAllocSize
__ IOSurface: _IOSurfaceGetBaseAddress
__ IOSurface: _IOSurfaceGetBaseAddressOfCompressedTileDataRegionOfPlane
__ IOSurface: _IOSurfaceGetBaseAddressOfCompressedTileHeaderRegionOfPlane
__ IOSurface: _IOSurfaceGetBaseAddressOfPlane
__ IOSurface: _IOSurfaceGetBytesPerRowOfPlane
__ IOSurface: _IOSurfaceGetCompressedTileHeightOfPlane
__ IOSurface: _IOSurfaceGetCompressedTileWidthOfPlane
__ IOSurface: _IOSurfaceGetCompressionTypeOfPlane
__ IOSurface: _IOSurfaceGetHeight
__ IOSurface: _IOSurfaceGetHeightInCompressedTilesOfPlane
__ IOSurface: _IOSurfaceGetHeightOfPlane
__ IOSurface: _IOSurfaceGetHorizontalPixelOffsetWithinCompressedTileArrayOfPlane
__ IOSurface: _IOSurfaceGetID
__ IOSurface: _IOSurfaceGetPixelFormat
__ IOSurface: _IOSurfaceGetPlaneCount
__ IOSurface: _IOSurfaceGetTileFormat
__ IOSurface: _IOSurfaceGetVerticalPixelOffsetWithinCompressedTileArrayOfPlane
__ IOSurface: _IOSurfaceGetWidth
__ IOSurface: _IOSurfaceGetWidthInCompressedTilesOfPlane
__ IOSurface: _IOSurfaceGetWidthOfPlane
__ IOSurface: _IOSurfaceIsTiled
__ IOSurface: _IOSurfaceLock
__ IOSurface: _IOSurfaceLookup
__ IOSurface: _IOSurfaceSetValue
__ IOSurface: _IOSurfaceUnlock
__ IOSurface: _kIOSurfaceAcceleratorUseCustomFilter
__ IOSurface: _kIOSurfaceAddressFormat
__ IOSurface: _kIOSurfaceAllocSize
__ IOSurface: _kIOSurfaceBufferTileFormat
__ IOSurface: _kIOSurfaceBufferTileMode
__ IOSurface: _kIOSurfaceBytesPerElement
__ IOSurface: _kIOSurfaceBytesPerRow
__ IOSurface: _kIOSurfaceCacheMode
__ IOSurface: _kIOSurfaceHeight
__ IOSurface: _kIOSurfaceIsGlobal
__ IOSurface: _kIOSurfaceName
__ IOSurface: _kIOSurfacePixelFormat
__ IOSurface: _kIOSurfacePlaneBytesPerCompressedTileHeader
__ IOSurface: _kIOSurfacePlaneBytesPerElement
__ IOSurface: _kIOSurfacePlaneBytesPerRow
__ IOSurface: _kIOSurfacePlaneBytesPerRowOfCompressedTileHeaderGroups
__ IOSurface: _kIOSurfacePlaneCompressedTileDataRegionOffset
__ IOSurface: _kIOSurfacePlaneCompressedTileHeaderRegionOffset
__ IOSurface: _kIOSurfacePlaneCompressedTileHeight
__ IOSurface: _kIOSurfacePlaneCompressedTileWidth
__ IOSurface: _kIOSurfacePlaneCompressionType
__ IOSurface: _kIOSurfacePlaneHTPCPredictionSelector
__ IOSurface: _kIOSurfacePlaneHTPCVerticalHeaderGroupingMode
__ IOSurface: _kIOSurfacePlaneHeight
__ IOSurface: _kIOSurfacePlaneHeightInCompressedTiles
__ IOSurface: _kIOSurfacePlaneHorizontalPixelOffsetWithinCompressedTileArray
__ IOSurface: _kIOSurfacePlaneInfo
__ IOSurface: _kIOSurfacePlaneOffset
__ IOSurface: _kIOSurfacePlaneSize
__ IOSurface: _kIOSurfacePlaneVerticalPixelOffsetWithinCompressedTileArray
__ IOSurface: _kIOSurfacePlaneWidth
__ IOSurface: _kIOSurfacePlaneWidthInCompressedTiles
__ IOSurface: _kIOSurfaceWidth
__ ImageIO: _CGImageSourceCopyPropertiesAtIndex
__ ImageIO: _CGImageSourceCreateImageAtIndex
__ ImageIO: _CGImageSourceCreateWithData
__ ImageIO: _CGImageSourceCreateWithURL
__ ImageIO: _kCGImagePropertyExifAuxDictionary
__ ImageIO: _kCGImagePropertyExifAuxROIRegionFaceType
__ ImageIO: _kCGImagePropertyExifAuxROIRegionHeight
__ ImageIO: _kCGImagePropertyExifAuxROIRegionList
__ ImageIO: _kCGImagePropertyExifAuxROIRegionType
__ ImageIO: _kCGImagePropertyExifAuxROIRegionWidth
__ ImageIO: _kCGImagePropertyExifAuxROIRegionX
__ ImageIO: _kCGImagePropertyExifAuxROIRegionY
__ ImageIO: _kCGImagePropertyExifDictionary
__ ImageIO: _kCGImagePropertyExifExposureTime
__ ImageIO: _kCGImagePropertyExifFlash
__ ImageIO: _kCGImagePropertyMakerAppleDictionary
__ ImageIO: _kCGImagePropertyOrientation
__ ImageIO: _kCGImagePropertyPixelHeight
__ ImageIO: _kCGImagePropertyPixelWidth
__ ImageIO: _kCGImageSourceShouldCache
__ ImageIO: _kCGImageSourceSubsampleFactor
__ ImageIO: _kCGImageSourceUseHardwareAcceleration
__ MediaToolbox: _FigPhotoDecompressionContainerCreateDictionaryDescription
__ MediaToolbox: _FigPhotoDecompressionContainerCreateImageForIndex
__ MediaToolbox: _FigPhotoDecompressionSessionCreate
__ MediaToolbox: _FigPhotoDecompressionSessionCreateContainer
__ MediaToolbox: _FigPhotoDecompressionSessionDiscardCachedBuffers
__ MediaToolbox: _kFigPhotoDecompressionContainerDescription_PrimaryImageIndex
__ MediaToolbox: _kFigPhotoDecompressionOption_ApplyTransform
__ MediaToolbox: _kFigPhotoDecompressionOption_MaxPixelSize
__ MediaToolbox: _kFigPhotoDecompressionOption_OutputPixelFormat
__ Metal: _MTLCreateSystemDefaultDevice
__ MetalPerformanceShaders: _MPSSetHeapCacheDuration
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNBinaryConvolution
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNConvolution
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNConvolutionDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNDepthWiseConvolutionDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNFullyConnected
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNPoolingMax
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImage
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImageDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSTemporaryImage
__ OpenGLES: _OBJC_CLASS_$_EAGLContext
__ OpenGLES: _glActiveTexture
__ OpenGLES: _glBindFramebuffer
__ OpenGLES: _glBindTexture
__ OpenGLES: _glFinish
__ OpenGLES: _glFramebufferTexture2D
__ OpenGLES: _glGenTextures
__ OpenGLES: _glGetUniformLocation
__ OpenGLES: _glTexParameteri
__ OpenGLES: _glUniform1i
__ OpenGLES: _glUseProgram
__ OpenGLES: _glViewport
__ Photos: _OBJC_CLASS_$_PHAsset
__ Photos: _OBJC_CLASS_$_PHAssetResource
__ Photos: _OBJC_CLASS_$_PHAssetResourceManager
__ Photos: _OBJC_CLASS_$_PHAssetResourceRequestOptions
__ Photos: _OBJC_CLASS_$_PHFace
__ Photos: _OBJC_CLASS_$_PHFetchOptions
__ Photos: _OBJC_CLASS_$_PHPhotoLibrary
__ Photos: _OBJC_CLASS_$_PHSceneClassification
__ Photos: _PHAssetPropertySetSceneAnalysis
__ PhotosFormats: _OBJC_CLASS_$_PFSlowMotionConfiguration
__ PhotosFormats: _OBJC_CLASS_$_PFVideoAVObjectBuilder
__ PhotosFormats: _OBJC_CLASS_$_PFVideoAdjustments
__ ProtocolBuffer: _OBJC_CLASS_$_PBCodable
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._bytes
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._error
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._length
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._pos
__ ProtocolBuffer: _OBJC_METACLASS_$_PBCodable
__ ProtocolBuffer: _PBDataWriterWriteBOOLField
__ ProtocolBuffer: _PBDataWriterWriteDataField
__ ProtocolBuffer: _PBDataWriterWriteDoubleField
__ ProtocolBuffer: _PBDataWriterWriteFloatField
__ ProtocolBuffer: _PBDataWriterWriteInt32Field
__ ProtocolBuffer: _PBDataWriterWriteInt64Field
__ ProtocolBuffer: _PBDataWriterWriteStringField
__ ProtocolBuffer: _PBDataWriterWriteSubmessage
__ ProtocolBuffer: _PBDataWriterWriteUint32Field
__ ProtocolBuffer: _PBDataWriterWriteUint64Field
__ ProtocolBuffer: _PBReaderPlaceMark
__ ProtocolBuffer: _PBReaderReadData
__ ProtocolBuffer: _PBReaderReadString
__ ProtocolBuffer: _PBReaderRecallMark
__ ProtocolBuffer: _PBReaderSkipValueWithTag
__ ProtocolBuffer: _PBRepeatedFloatAdd
__ ProtocolBuffer: _PBRepeatedFloatClear
__ ProtocolBuffer: _PBRepeatedFloatCopy
__ ProtocolBuffer: _PBRepeatedFloatHash
__ ProtocolBuffer: _PBRepeatedFloatIsEqual
__ ProtocolBuffer: _PBRepeatedFloatNSArray
__ ProtocolBuffer: _PBRepeatedFloatSet
__ SoundAnalysis: _OBJC_CLASS_$_SNAudioStreamAnalyzer
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectSoundRequest
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectionResult
__ SoundAnalysis: _SNSoundIdentifierApplause
__ SoundAnalysis: _SNSoundIdentifierBabble
__ SoundAnalysis: _SNSoundIdentifierCheering
__ SoundAnalysis: _SNSoundIdentifierLaughter
__ SoundAnalysis: _SNSoundIdentifierMusic
__ SoundAnalysis: _SNSoundIdentifierSpeech
__ SystemConfiguration: _SCNetworkReachabilityCreateWithAddress
__ SystemConfiguration: _SCNetworkReachabilityGetFlags
__ SystemConfiguration: _SCNetworkReachabilitySetCallback
__ SystemConfiguration: _SCNetworkReachabilitySetDispatchQueue
__ TelephonyUtilities: _OBJC_CLASS_$_TUCallCenter
__ VideoToolbox: _VTCompressionSessionCompleteFrames
__ VideoToolbox: _VTCompressionSessionCreate
__ VideoToolbox: _VTCompressionSessionEncodeFrame
__ VideoToolbox: _VTCompressionSessionGetPixelBufferPool
__ VideoToolbox: _VTCompressionSessionInvalidate
__ VideoToolbox: _VTCompressionSessionPrepareToEncodeFrames
__ VideoToolbox: _VTCompressionSessionSetProperty
__ VideoToolbox: _VTDecompressionSessionCanAcceptFormatDescription
__ VideoToolbox: _VTDecompressionSessionCopyBlackPixelBuffer
__ VideoToolbox: _VTDecompressionSessionCopyProperty
__ VideoToolbox: _VTDecompressionSessionCopySerializableProperties
__ VideoToolbox: _VTDecompressionSessionCopySupportedPropertyDictionary
__ VideoToolbox: _VTDecompressionSessionCreate
__ VideoToolbox: _VTDecompressionSessionDecodeFrame
__ VideoToolbox: _VTDecompressionSessionFinishDelayedFrames
__ VideoToolbox: _VTDecompressionSessionInvalidate
__ VideoToolbox: _VTDecompressionSessionSetProperties
__ VideoToolbox: _VTDecompressionSessionSetProperty
__ VideoToolbox: _VTDecompressionSessionWaitForAsynchronousFrames
__ VideoToolbox: _VTEncoderSessionCreateVideoFormatDescription
__ VideoToolbox: _VTEncoderSessionDequeueDecodeTimeStamp
__ VideoToolbox: _VTEncoderSessionEmitEncodedFrame
__ VideoToolbox: _VTEncoderSessionEnqueuePresentationTimeStamp
__ VideoToolbox: _VTEncoderSessionSetPixelBufferAttributes
__ VideoToolbox: _VTImageRotationSessionCreate
__ VideoToolbox: _VTImageRotationSessionTransferImage
__ VideoToolbox: _VTPixelTransferSessionCreate
__ VideoToolbox: _VTPixelTransferSessionTransferImage
__ VideoToolbox: _VTRegisterVideoEncoderWithInfo
__ VideoToolbox: _VTSelectAndCreateVideoEncoderInstance
__ VideoToolbox: _VTSessionCopyProperty
__ VideoToolbox: _VTSessionCopySupportedPropertyDictionary
__ VideoToolbox: _VTSessionSetProperty
__ VideoToolbox: _VTVideoEncoderGetCMBaseObject
__ VideoToolbox: _VTVideoEncoderGetClassID
__ VideoToolbox: _kVTCompressionPropertyKey_AllowFrameReordering
__ VideoToolbox: _kVTCompressionPropertyKey_AllowTemporalCompression
__ VideoToolbox: _kVTCompressionPropertyKey_AverageBitRate
__ VideoToolbox: _kVTCompressionPropertyKey_AverageDataRate
__ VideoToolbox: _kVTCompressionPropertyKey_ColorPrimaries
__ VideoToolbox: _kVTCompressionPropertyKey_ConnectionID
__ VideoToolbox: _kVTCompressionPropertyKey_DataRateLimits
__ VideoToolbox: _kVTCompressionPropertyKey_Depth
__ VideoToolbox: _kVTCompressionPropertyKey_EnsureTIJacinto4Compatibility
__ VideoToolbox: _kVTCompressionPropertyKey_ExpectedFrameRate
__ VideoToolbox: _kVTCompressionPropertyKey_FigThreadPriority
__ VideoToolbox: _kVTCompressionPropertyKey_H264EntropyMode
__ VideoToolbox: _kVTCompressionPropertyKey_MaxKeyFrameInterval
__ VideoToolbox: _kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration
__ VideoToolbox: _kVTCompressionPropertyKey_MaximizePowerEfficiency
__ VideoToolbox: _kVTCompressionPropertyKey_MinNumRepeatedFramesToEncode
__ VideoToolbox: _kVTCompressionPropertyKey_NegotiationDetails
__ VideoToolbox: _kVTCompressionPropertyKey_NumberOfPendingFrames
__ VideoToolbox: _kVTCompressionPropertyKey_NumberOfSubFrameSections
__ VideoToolbox: _kVTCompressionPropertyKey_PixelAspectRatio
__ VideoToolbox: _kVTCompressionPropertyKey_PrioritizeEncodingSpeedOverQuality
__ VideoToolbox: _kVTCompressionPropertyKey_Priority
__ VideoToolbox: _kVTCompressionPropertyKey_ProfileLevel
__ VideoToolbox: _kVTCompressionPropertyKey_RealTime
__ VideoToolbox: _kVTCompressionPropertyKey_SourceFrameCount
__ VideoToolbox: _kVTCompressionPropertyKey_TransferFunction
__ VideoToolbox: _kVTCompressionPropertyKey_Usage
__ VideoToolbox: _kVTCompressionPropertyKey_YCbCrMatrix
__ VideoToolbox: _kVTDecompressionPropertyKey_ActiveVideoResolution
__ VideoToolbox: _kVTDecompressionPropertyKey_ExtraInLoopChromaFilter
__ VideoToolbox: _kVTDecompressionPropertyKey_PixelBufferPool
__ VideoToolbox: _kVTDecompressionPropertyKey_VideoResolutionAdaptationType
__ VideoToolbox: _kVTDecompressionResolutionKey_Height
__ VideoToolbox: _kVTDecompressionResolutionKey_Width
__ VideoToolbox: _kVTEncodeFrameOptionKey_AcknowledgedTokens
__ VideoToolbox: _kVTEncodeFrameOptionKey_AverageBurstyErrorLength
__ VideoToolbox: _kVTEncodeFrameOptionKey_FECNumBitsAdded
__ VideoToolbox: _kVTEncodeFrameOptionKey_FirstMbInDuplicateSlices
__ VideoToolbox: _kVTEncodeFrameOptionKey_FirstMbInRecvSlices
__ VideoToolbox: _kVTEncodeFrameOptionKey_FirstMbInSkipSlices
__ VideoToolbox: _kVTEncodeFrameOptionKey_ForceKeyFrame
__ VideoToolbox: _kVTEncodeFrameOptionKey_ForceRefresh
__ VideoToolbox: _kVTEncodeFrameOptionKey_LimitFrameSize
__ VideoToolbox: _kVTEncodeFrameOptionKey_PacketErrorRate
__ VideoToolbox: _kVTEncodeFrameOptionKey_PacketHeaderBitsAdded
__ VideoToolbox: _kVTEncodeFrameOptionKey_RepeatedFrame
__ VideoToolbox: _kVTEncodeFrameOptionKey_RoundTripDelay
__ VideoToolbox: _kVTEncodeFrameOptionKey_SectionID
__ VideoToolbox: _kVTEncodeFrameOptionKey_SectionOffsets
__ VideoToolbox: _kVTEncodeFrameOptionKey_VisibleRectangle
__ VideoToolbox: _kVTH264EntropyMode_CABAC
__ VideoToolbox: _kVTImageBufferVisibleRectangleKey
__ VideoToolbox: _kVTPixelTransferPropertyKey_ScalingMode
__ VideoToolbox: _kVTProfileLevel_H264_High_AutoLevel
__ VideoToolbox: _kVTSampleAttachmentKey_EncodedFrameAvgQP
__ VideoToolbox: _kVTSampleAttachmentKey_FECGroupID
__ VideoToolbox: _kVTSampleAttachmentKey_FECLastFrameInGroup
__ VideoToolbox: _kVTSampleAttachmentKey_FECLevelOfProtection
__ VideoToolbox: _kVTSampleAttachmentKey_PadByteCount
__ VideoToolbox: _kVTSampleAttachmentKey_ReferenceWasRefreshed
__ VideoToolbox: _kVTSampleAttachmentKey_RequireAcknowledgementToken
__ VideoToolbox: _kVTScalingMode_CropSourceToCleanAperture
__ VideoToolbox: _kVTVideoDecoderSpecification_Usage
__ VideoToolbox: _kVTVideoEncoderSpecification_CMSession
__ VideoToolbox: _kVTVideoEncoderSpecification_RequireHardwareAcceleratedVideoEncoder
__ VideoToolbox: _kVTVideoEncoder_Hide
__ VideoToolbox: _kVTVideoEncoder_IsHardwareAccelerated
__ VideoToolbox: _kVTVideoEncoder_Rating
__ Vision: _OBJC_CLASS_$_VNClassifyImageAestheticsRequest
__ Vision: _OBJC_CLASS_$_VNClassifyJunkImageRequest
__ Vision: _OBJC_CLASS_$_VNClustererBuilder
__ Vision: _OBJC_CLASS_$_VNClustererBuilderOptions
__ Vision: _OBJC_CLASS_$_VNCreateFaceprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateImageprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateSceneprintRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceCaptureQualityRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceRectanglesRequest
__ Vision: _OBJC_CLASS_$_VNFaceprint
__ Vision: _OBJC_CLASS_$_VNGenerateAttentionBasedSaliencyImageRequest
__ Vision: _OBJC_CLASS_$_VNIdentifyJunkRequest
__ Vision: _OBJC_CLASS_$_VNImageRequestHandler
__ Vision: _OBJC_CLASS_$_VNImageprint
__ Vision: _OBJC_CLASS_$_VNProcessingDevice
__ Vision: _OBJC_CLASS_$_VNSceneClassificationRequest
__ Vision: _OBJC_CLASS_$_VNSceneObservation
__ Vision: _OBJC_CLASS_$_VNSceneprint
__ Vision: _VNClusteringAlgorithm_Greedy
__ libMobileGestalt.dylib: _MGCopyAnswer
__ libMobileGestalt.dylib: _MGGetBoolAnswer
__ libMobileGestalt.dylib: _MGGetStringAnswer
__ libSystem.B.dylib: _CC_MD5_Final
__ libSystem.B.dylib: _CC_MD5_Init
__ libSystem.B.dylib: _CC_MD5_Update
__ libSystem.B.dylib: __Block_copy
__ libSystem.B.dylib: __Block_object_assign
__ libSystem.B.dylib: __Block_object_dispose
__ libSystem.B.dylib: __Block_release
__ libSystem.B.dylib: __NSConcreteGlobalBlock
__ libSystem.B.dylib: __NSConcreteStackBlock
__ libSystem.B.dylib: __Unwind_Resume
__ libSystem.B.dylib: ___chkstk_darwin
__ libSystem.B.dylib: ___cxa_atexit
__ libSystem.B.dylib: ___error
__ libSystem.B.dylib: ___fpclassifyd
__ libSystem.B.dylib: ___memcpy_chk
__ libSystem.B.dylib: ___sincos_stret
__ libSystem.B.dylib: ___sincosf_stret
__ libSystem.B.dylib: ___snprintf_chk
__ libSystem.B.dylib: ___stack_chk_fail
__ libSystem.B.dylib: ___stack_chk_guard
__ libSystem.B.dylib: ___stderrp
__ libSystem.B.dylib: ___stdoutp
__ libSystem.B.dylib: ___strlcpy_chk
__ libSystem.B.dylib: __dispatch_main_q
__ libSystem.B.dylib: __os_log_default
__ libSystem.B.dylib: __os_log_error_impl
__ libSystem.B.dylib: __os_log_impl
__ libSystem.B.dylib: __os_signpost_emit_with_name_impl
__ libSystem.B.dylib: _abort
__ libSystem.B.dylib: _acosf
__ libSystem.B.dylib: _asinf
__ libSystem.B.dylib: _atan2
__ libSystem.B.dylib: _atan2f
__ libSystem.B.dylib: _atanf
__ libSystem.B.dylib: _atof
__ libSystem.B.dylib: _atoi
__ libSystem.B.dylib: _atol
__ libSystem.B.dylib: _bzero
__ libSystem.B.dylib: _calloc
__ libSystem.B.dylib: _cos
__ libSystem.B.dylib: _cosf
__ libSystem.B.dylib: _dispatch_apply
__ libSystem.B.dylib: _dispatch_async
__ libSystem.B.dylib: _dispatch_get_global_queue
__ libSystem.B.dylib: _dispatch_group_async
__ libSystem.B.dylib: _dispatch_group_async_f
__ libSystem.B.dylib: _dispatch_group_create
__ libSystem.B.dylib: _dispatch_group_enter
__ libSystem.B.dylib: _dispatch_group_leave
__ libSystem.B.dylib: _dispatch_group_wait
__ libSystem.B.dylib: _dispatch_once
__ libSystem.B.dylib: _dispatch_once_f
__ libSystem.B.dylib: _dispatch_queue_create
__ libSystem.B.dylib: _dispatch_release
__ libSystem.B.dylib: _dispatch_semaphore_create
__ libSystem.B.dylib: _dispatch_semaphore_signal
__ libSystem.B.dylib: _dispatch_semaphore_wait
__ libSystem.B.dylib: _dispatch_sync
__ libSystem.B.dylib: _dispatch_time
__ libSystem.B.dylib: _dlopen
__ libSystem.B.dylib: _erff
__ libSystem.B.dylib: _exit
__ libSystem.B.dylib: _exp
__ libSystem.B.dylib: _exp2
__ libSystem.B.dylib: _exp2f
__ libSystem.B.dylib: _expf
__ libSystem.B.dylib: _fclose
__ libSystem.B.dylib: _fflush
__ libSystem.B.dylib: _fgets
__ libSystem.B.dylib: _fmod
__ libSystem.B.dylib: _fmodf
__ libSystem.B.dylib: _fopen
__ libSystem.B.dylib: _fprintf
__ libSystem.B.dylib: _fputc
__ libSystem.B.dylib: _fread
__ libSystem.B.dylib: _free
__ libSystem.B.dylib: _fscanf
__ libSystem.B.dylib: _fseek
__ libSystem.B.dylib: _ftell
__ libSystem.B.dylib: _fwrite
__ libSystem.B.dylib: _hypotf
__ libSystem.B.dylib: _kdebug_trace
__ libSystem.B.dylib: _log
__ libSystem.B.dylib: _log10
__ libSystem.B.dylib: _log10f
__ libSystem.B.dylib: _log2
__ libSystem.B.dylib: _log2f
__ libSystem.B.dylib: _logf
__ libSystem.B.dylib: _mach_absolute_time
__ libSystem.B.dylib: _mach_task_self_
__ libSystem.B.dylib: _mach_timebase_info
__ libSystem.B.dylib: _malloc
__ libSystem.B.dylib: _matrix_identity_float4x4
__ libSystem.B.dylib: _memcmp
__ libSystem.B.dylib: _memcpy
__ libSystem.B.dylib: _memmove
__ libSystem.B.dylib: _memset
__ libSystem.B.dylib: _memset_pattern16
__ libSystem.B.dylib: _memset_pattern4
__ libSystem.B.dylib: _notify_post
__ libSystem.B.dylib: _notify_register_dispatch
__ libSystem.B.dylib: _os_log_create
__ libSystem.B.dylib: _os_log_type_enabled
__ libSystem.B.dylib: _os_signpost_enabled
__ libSystem.B.dylib: _os_signpost_id_generate
__ libSystem.B.dylib: _posix_memalign
__ libSystem.B.dylib: _pow
__ libSystem.B.dylib: _powf
__ libSystem.B.dylib: _printf
__ libSystem.B.dylib: _pthread_attr_destroy
__ libSystem.B.dylib: _pthread_attr_init
__ libSystem.B.dylib: _pthread_attr_setdetachstate
__ libSystem.B.dylib: _pthread_cond_broadcast
__ libSystem.B.dylib: _pthread_cond_destroy
__ libSystem.B.dylib: _pthread_cond_init
__ libSystem.B.dylib: _pthread_cond_signal
__ libSystem.B.dylib: _pthread_cond_wait
__ libSystem.B.dylib: _pthread_create
__ libSystem.B.dylib: _pthread_join
__ libSystem.B.dylib: _pthread_mach_thread_np
__ libSystem.B.dylib: _pthread_mutex_destroy
__ libSystem.B.dylib: _pthread_mutex_init
__ libSystem.B.dylib: _pthread_mutex_lock
__ libSystem.B.dylib: _pthread_mutex_unlock
__ libSystem.B.dylib: _pthread_once
__ libSystem.B.dylib: _pthread_setname_np
__ libSystem.B.dylib: _puts
__ libSystem.B.dylib: _qsort
__ libSystem.B.dylib: _sandbox_extension_consume
__ libSystem.B.dylib: _sandbox_extension_release
__ libSystem.B.dylib: _semaphore_create
__ libSystem.B.dylib: _semaphore_destroy
__ libSystem.B.dylib: _semaphore_signal
__ libSystem.B.dylib: _semaphore_wait
__ libSystem.B.dylib: _setpriority
__ libSystem.B.dylib: _sin
__ libSystem.B.dylib: _sinf
__ libSystem.B.dylib: _snprintf
__ libSystem.B.dylib: _sscanf
__ libSystem.B.dylib: _strchr
__ libSystem.B.dylib: _strcmp
__ libSystem.B.dylib: _strdup
__ libSystem.B.dylib: _strlcpy
__ libSystem.B.dylib: _strlen
__ libSystem.B.dylib: _strncmp
__ libSystem.B.dylib: _strncpy
__ libSystem.B.dylib: _strnlen
__ libSystem.B.dylib: _strsep
__ libSystem.B.dylib: _strstr
__ libSystem.B.dylib: _strtod
__ libSystem.B.dylib: _strtoimax
__ libSystem.B.dylib: _strtok
__ libSystem.B.dylib: _strtok_r
__ libSystem.B.dylib: _strtol
__ libSystem.B.dylib: _strtoll
__ libSystem.B.dylib: _sysctlbyname
__ libSystem.B.dylib: _syslog
__ libSystem.B.dylib: _tan
__ libSystem.B.dylib: _thread_info
__ libSystem.B.dylib: _thread_policy_set
__ libSystem.B.dylib: dyld_stub_binder
__ libc++.1.dylib: __ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info
__ libc++.1.dylib: __ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNKSt3__121__basic_string_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNKSt3__16locale9use_facetERNS0_2idE
__ libc++.1.dylib: __ZNKSt3__18ios_base6getlocEv
__ libc++.1.dylib: __ZNKSt9exception4whatEv
__ libc++.1.dylib: __ZNSt11logic_errorC2EPKc
__ libc++.1.dylib: __ZNSt12length_errorD1Ev
__ libc++.1.dylib: __ZNSt13exception_ptrC1ERKS_
__ libc++.1.dylib: __ZNSt13exception_ptrD1Ev
__ libc++.1.dylib: __ZNSt3__111__call_onceERVmPvPFvS2_E
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6resizeEmc
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE9push_backEc
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC1ERKS5_
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE3putEc
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE5flushEv
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE6sentryC1ERS3_
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE6sentryD1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED0Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEb
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEd
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEi
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEl
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEm
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE4syncEv
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE5imbueERKNS_6localeE
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE5uflowEv
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE6setbufEPcl
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE6xsgetnEPcl
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE6xsputnEPKcl
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE9showmanycEv
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEEC2Ev
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt3__117__assoc_sub_state10__sub_waitERNS_11unique_lockINS_5mutexEEE
__ libc++.1.dylib: __ZNSt3__118condition_variable10notify_allEv
__ libc++.1.dylib: __ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE
__ libc++.1.dylib: __ZNSt3__118condition_variableD1Ev
__ libc++.1.dylib: __ZNSt3__119__shared_weak_count14__release_weakEv
__ libc++.1.dylib: __ZNSt3__119__shared_weak_count4lockEv
__ libc++.1.dylib: __ZNSt3__119__shared_weak_countD2Ev
__ libc++.1.dylib: __ZNSt3__120__throw_system_errorEiPKc
__ libc++.1.dylib: __ZNSt3__14cerrE
__ libc++.1.dylib: __ZNSt3__14coutE
__ libc++.1.dylib: __ZNSt3__15ctypeIcE2idE
__ libc++.1.dylib: __ZNSt3__15mutex4lockEv
__ libc++.1.dylib: __ZNSt3__15mutex6unlockEv
__ libc++.1.dylib: __ZNSt3__15mutexD1Ev
__ libc++.1.dylib: __ZNSt3__16futureIvED1Ev
__ libc++.1.dylib: __ZNSt3__16localeD1Ev
__ libc++.1.dylib: __ZNSt3__18ios_base33__set_badbit_and_consider_rethrowEv
__ libc++.1.dylib: __ZNSt3__18ios_base4initEPv
__ libc++.1.dylib: __ZNSt3__18ios_base5clearEj
__ libc++.1.dylib: __ZNSt3__19basic_iosIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt9exceptionD2Ev
__ libc++.1.dylib: __ZSt13set_terminatePFvvE
__ libc++.1.dylib: __ZSt17rethrow_exceptionSt13exception_ptr
__ libc++.1.dylib: __ZSt7nothrow
__ libc++.1.dylib: __ZSt9terminatev
__ libc++.1.dylib: __ZTINSt3__113basic_ostreamIcNS_11char_traitsIcEEEE
__ libc++.1.dylib: __ZTINSt3__115basic_streambufIcNS_11char_traitsIcEEEE
__ libc++.1.dylib: __ZTIi
__ libc++.1.dylib: __ZTVN10__cxxabiv117__class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv120__si_class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv121__vmi_class_type_infoE
__ libc++.1.dylib: __ZTVSt12length_error
__ libc++.1.dylib: __ZTv0_n24_NSt3__113basic_ostreamIcNS_11char_traitsIcEEED0Ev
__ libc++.1.dylib: __ZTv0_n24_NSt3__113basic_ostreamIcNS_11char_traitsIcEEED1Ev
__ libc++.1.dylib: __ZdaPv
__ libc++.1.dylib: __ZdaPvRKSt9nothrow_t
__ libc++.1.dylib: __ZdlPv
__ libc++.1.dylib: __ZdlPvRKSt9nothrow_t
__ libc++.1.dylib: __Znam
__ libc++.1.dylib: __ZnamRKSt9nothrow_t
__ libc++.1.dylib: __Znwm
__ libc++.1.dylib: __ZnwmRKSt9nothrow_t
__ libc++.1.dylib: ___cxa_allocate_exception
__ libc++.1.dylib: ___cxa_begin_catch
__ libc++.1.dylib: ___cxa_end_catch
__ libc++.1.dylib: ___cxa_free_exception
__ libc++.1.dylib: ___cxa_guard_abort
__ libc++.1.dylib: ___cxa_guard_acquire
__ libc++.1.dylib: ___cxa_guard_release
__ libc++.1.dylib: ___cxa_pure_virtual
__ libc++.1.dylib: ___cxa_rethrow
__ libc++.1.dylib: ___cxa_throw
__ libc++.1.dylib: ___gxx_personality_v0
__ libobjc.A.dylib: _OBJC_CLASS_$_NSObject
__ libobjc.A.dylib: _OBJC_METACLASS_$_NSObject
__ libobjc.A.dylib: ___objc_personality_v0
__ libobjc.A.dylib: __objc_empty_cache
__ libobjc.A.dylib: _objc_alloc
__ libobjc.A.dylib: _objc_autorelease
__ libobjc.A.dylib: _objc_autoreleasePoolPop
__ libobjc.A.dylib: _objc_autoreleasePoolPush
__ libobjc.A.dylib: _objc_autoreleaseReturnValue
__ libobjc.A.dylib: _objc_begin_catch
__ libobjc.A.dylib: _objc_copyStruct
__ libobjc.A.dylib: _objc_copyWeak
__ libobjc.A.dylib: _objc_destroyWeak
__ libobjc.A.dylib: _objc_end_catch
__ libobjc.A.dylib: _objc_enumerationMutation
__ libobjc.A.dylib: _objc_exception_throw
__ libobjc.A.dylib: _objc_getClass
__ libobjc.A.dylib: _objc_getProperty
__ libobjc.A.dylib: _objc_initWeak
__ libobjc.A.dylib: _objc_loadWeakRetained
__ libobjc.A.dylib: _objc_msgSend
__ libobjc.A.dylib: _objc_msgSendSuper2
__ libobjc.A.dylib: _objc_opt_class
__ libobjc.A.dylib: _objc_opt_isKindOfClass
__ libobjc.A.dylib: _objc_opt_respondsToSelector
__ libobjc.A.dylib: _objc_release
__ libobjc.A.dylib: _objc_retain
__ libobjc.A.dylib: _objc_retainAutorelease
__ libobjc.A.dylib: _objc_retainAutoreleaseReturnValue
__ libobjc.A.dylib: _objc_retainAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_retainBlock
__ libobjc.A.dylib: _objc_setProperty_atomic
__ libobjc.A.dylib: _objc_setProperty_nonatomic_copy
__ libobjc.A.dylib: _objc_storeStrong
__ libobjc.A.dylib: _objc_storeWeak
__ libobjc.A.dylib: _objc_sync_enter
__ libobjc.A.dylib: _objc_sync_exit
__ libobjc.A.dylib: _objc_unsafeClaimAutoreleasedReturnValue
__ libsqlite3.dylib: _sqlite3_bind_double
__ libsqlite3.dylib: _sqlite3_bind_int
__ libsqlite3.dylib: _sqlite3_bind_int64
__ libsqlite3.dylib: _sqlite3_bind_null
__ libsqlite3.dylib: _sqlite3_bind_text
__ libsqlite3.dylib: _sqlite3_close
__ libsqlite3.dylib: _sqlite3_column_blob
__ libsqlite3.dylib: _sqlite3_column_bytes
__ libsqlite3.dylib: _sqlite3_column_double
__ libsqlite3.dylib: _sqlite3_column_int
__ libsqlite3.dylib: _sqlite3_column_int64
__ libsqlite3.dylib: _sqlite3_column_text
__ libsqlite3.dylib: _sqlite3_column_type
__ libsqlite3.dylib: _sqlite3_finalize
__ libsqlite3.dylib: _sqlite3_open
__ libsqlite3.dylib: _sqlite3_prepare_v2
__ libsqlite3.dylib: _sqlite3_step
VCPAudioAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPAudioAnalyzer dealloc]
  -[VCPAudioAnalyzer .cxx_destruct]
  -[VCPAudioAnalyzer processSampleBuffer:]
  -[VCPAudioAnalyzer processAudioSamples:timestamp:]
  -[VCPAudioAnalyzer finalizeAnalysisAtTime:]
  -[VCPAudioAnalyzer audioFormatRequirements]
  -[VCPAudioAnalyzer setupWithSample:]
  -[VCPAudioAnalyzer voiceDetections]
  -[VCPAudioAnalyzer initWithAnalysisTypes:forStreaming:]
  -[VCPAudioAnalyzer analyzeAsset:cancel:results:]
  -[VCPAudioAnalyzer analyzeSampleBuffer:]


VCPSoundDetector : NSObject /usr/lib/libc++.1.dylib <SNResultsObserving>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPSoundDetector .cxx_destruct]
  -[VCPSoundDetector results]
  -[VCPSoundDetector request:didProduceResult:]
  -[VCPSoundDetector finalizeAnalysisAtTime:]
  -[VCPSoundDetector addDetectionFromTime:toTime:confidence:]
  -[VCPSoundDetector initWithTrackStart:threshold:resultsKey:]


VCPAudioClassifier : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPAudioClassifier .cxx_destruct]
  -[VCPAudioClassifier results]
  -[VCPAudioClassifier initWithTypes:]
  -[VCPAudioClassifier setupWithSample:andSampleBatchSize:]
  -[VCPAudioClassifier processAudioSamples:timestamp:]
  -[VCPAudioClassifier finalizeAnalysisAtTime:]


VCPImageHumanPoseAnalyzer : VCPImageAnalyzer
 @property  BOOL trackingMode

  // class methods
  +[VCPImageHumanPoseAnalyzer sharedModel:]
  +[VCPImageHumanPoseAnalyzer saveKeypoints]

  // instance methods
  -[VCPImageHumanPoseAnalyzer init]
  -[VCPImageHumanPoseAnalyzer dealloc]
  -[VCPImageHumanPoseAnalyzer .cxx_destruct]
  -[VCPImageHumanPoseAnalyzer trackingMode]
  -[VCPImageHumanPoseAnalyzer setTrackingMode:]
  -[VCPImageHumanPoseAnalyzer createModelWithHeight:srcWidth:]
  -[VCPImageHumanPoseAnalyzer parsePersons:width:height:]
  -[VCPImageHumanPoseAnalyzer processPersons:width:height:]
  -[VCPImageHumanPoseAnalyzer copyImage:toData:withChannels:]
  -[VCPImageHumanPoseAnalyzer createInput:withBuffer:modelInputHeight:modelInputWidth:]
  -[VCPImageHumanPoseAnalyzer generateHumanPose:]
  -[VCPImageHumanPoseAnalyzer initWithKeypointsOption:aspectRatio:lightweight:]
  -[VCPImageHumanPoseAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPProtoLivePhotoKeyFrameResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  double timestamp
 @property  float qualityScoreForLivePhoto
 @property  float visualPleasingScore
 @property  float overallFaceQualityScore
 @property  float exposureScore
 @property  float penaltyScore
 @property  float textureScore
 @property  float sharpness
 @property  NSMutableArray *faceResults
 @property  BOOL hasGlobalQualityScore
 @property  float globalQualityScore
 @property  BOOL hasContentScore
 @property  float contentScore

  // class methods
  +[VCPProtoLivePhotoKeyFrameResult faceResultsType]
  +[VCPProtoLivePhotoKeyFrameResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameResult .cxx_destruct]
  -[VCPProtoLivePhotoKeyFrameResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameResult timestamp]
  -[VCPProtoLivePhotoKeyFrameResult setTimestamp:]
  -[VCPProtoLivePhotoKeyFrameResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameResult sharpness]
  -[VCPProtoLivePhotoKeyFrameResult setSharpness:]
  -[VCPProtoLivePhotoKeyFrameResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameResult exposureScore]
  -[VCPProtoLivePhotoKeyFrameResult setExposureScore:]
  -[VCPProtoLivePhotoKeyFrameResult setContentScore:]
  -[VCPProtoLivePhotoKeyFrameResult contentScore]
  -[VCPProtoLivePhotoKeyFrameResult addFaceResults:]
  -[VCPProtoLivePhotoKeyFrameResult faceResultsCount]
  -[VCPProtoLivePhotoKeyFrameResult clearFaceResults]
  -[VCPProtoLivePhotoKeyFrameResult faceResultsAtIndex:]
  -[VCPProtoLivePhotoKeyFrameResult setGlobalQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult setHasGlobalQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult hasGlobalQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult setHasContentScore:]
  -[VCPProtoLivePhotoKeyFrameResult hasContentScore]
  -[VCPProtoLivePhotoKeyFrameResult qualityScoreForLivePhoto]
  -[VCPProtoLivePhotoKeyFrameResult setQualityScoreForLivePhoto:]
  -[VCPProtoLivePhotoKeyFrameResult visualPleasingScore]
  -[VCPProtoLivePhotoKeyFrameResult setVisualPleasingScore:]
  -[VCPProtoLivePhotoKeyFrameResult overallFaceQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult setOverallFaceQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult penaltyScore]
  -[VCPProtoLivePhotoKeyFrameResult setPenaltyScore:]
  -[VCPProtoLivePhotoKeyFrameResult textureScore]
  -[VCPProtoLivePhotoKeyFrameResult setTextureScore:]
  -[VCPProtoLivePhotoKeyFrameResult faceResults]
  -[VCPProtoLivePhotoKeyFrameResult setFaceResults:]
  -[VCPProtoLivePhotoKeyFrameResult globalQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult exportToLegacyDictionary]


VCPBlurAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPBlurAnalyzer computeSharpnessScore:forObjects:inImage:]
  -[VCPBlurAnalyzer computeRegionSharpness:width:height:stride:]


VCPBoundingBox : NSObject /usr/lib/libc++.1.dylib
 @property  float minX
 @property  float maxX
 @property  float minY
 @property  float maxY
 @property  float confidence
 @property  float flag

  // instance methods
  -[VCPBoundingBox confidence]
  -[VCPBoundingBox setConfidence:]
  -[VCPBoundingBox setFlag:]
  -[VCPBoundingBox setMaxX:]
  -[VCPBoundingBox maxX]
  -[VCPBoundingBox area]
  -[VCPBoundingBox minX]
  -[VCPBoundingBox setMinX:]
  -[VCPBoundingBox minY]
  -[VCPBoundingBox setMinY:]
  -[VCPBoundingBox maxY]
  -[VCPBoundingBox setMaxY:]
  -[VCPBoundingBox flag]
  -[VCPBoundingBox initWithXYAndSize:y:width:height:confidence:]
  -[VCPBoundingBox intersect:]
  -[VCPBoundingBox union:]
  -[VCPBoundingBox initWithCenterAndSize:y:width:height:confidence:]
  -[VCPBoundingBox computeIntersectionOverUnion:]
  -[VCPBoundingBox getCGRectWithClipWidth:height:]


VCPProtoMovieBabbleResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieBabbleResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieBabbleResult isEqual:]
  -[VCPProtoMovieBabbleResult copyWithZone:]
  -[VCPProtoMovieBabbleResult .cxx_destruct]
  -[VCPProtoMovieBabbleResult dictionaryRepresentation]
  -[VCPProtoMovieBabbleResult confidence]
  -[VCPProtoMovieBabbleResult writeTo:]
  -[VCPProtoMovieBabbleResult mergeFrom:]
  -[VCPProtoMovieBabbleResult readFrom:]
  -[VCPProtoMovieBabbleResult copyTo:]
  -[VCPProtoMovieBabbleResult setConfidence:]
  -[VCPProtoMovieBabbleResult setTimeRange:]
  -[VCPProtoMovieBabbleResult timeRange]
  -[VCPProtoMovieBabbleResult exportToLegacyDictionary]


VCPCNNBlock : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *inputSize
 @property  NSMutableArray *outputSize
 @property  VCPCNNData *input
 @property  VCPCNNData *output
 @property  VCPCNNMetalContext *context
 @property  BOOL generateOutput

  // instance methods
  -[VCPCNNBlock .cxx_destruct]
  -[VCPCNNBlock context]
  -[VCPCNNBlock input]
  -[VCPCNNBlock inputSize]
  -[VCPCNNBlock setInputSize:]
  -[VCPCNNBlock setOutputSize:]
  -[VCPCNNBlock outputSize]
  -[VCPCNNBlock setInput:]
  -[VCPCNNBlock useGPU]
  -[VCPCNNBlock output]
  -[VCPCNNBlock setOutput:]
  -[VCPCNNBlock forward]
  -[VCPCNNBlock generateOutput]
  -[VCPCNNBlock setGenerateOutput:]
  -[VCPCNNBlock supportGPU]
  -[VCPCNNBlock constructBlock:context:]
  -[VCPCNNBlock readFromDisk:quantFactor:]


VCPCNNBlurAnalyzer : VCPImageAnalyzer
 @property  BOOL sdof

  // class methods
  +[VCPCNNBlurAnalyzer analyzer]

  // instance methods
  -[VCPCNNBlurAnalyzer _copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:]
  -[VCPCNNBlurAnalyzer sdof]
  -[VCPCNNBlurAnalyzer calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:]
  -[VCPCNNBlurAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzer getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzer computeSharpnessScore:textureness:contrast:imgWidth:cancel:]
  -[VCPCNNBlurAnalyzer setSdof:]
  -[VCPCNNBlurAnalyzer scaleRegion:ofImage:toData:withWidth:andHeight:]
  -[VCPCNNBlurAnalyzer computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:]


VCPCNNBlurAnalyzerEspresso : VCPCNNBlurAnalyzer
  // class methods
  +[VCPCNNBlurAnalyzerEspresso sharedModel:]

  // instance methods
  -[VCPCNNBlurAnalyzerEspresso init]
  -[VCPCNNBlurAnalyzerEspresso dealloc]
  -[VCPCNNBlurAnalyzerEspresso .cxx_destruct]
  -[VCPCNNBlurAnalyzerEspresso prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzerEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzerEspresso computeSharpnessScore:textureness:contrast:imgWidth:cancel:]


VCPCNNBlurAnalyzerMPS : VCPCNNBlurAnalyzer
  // instance methods
  -[VCPCNNBlurAnalyzerMPS init]
  -[VCPCNNBlurAnalyzerMPS .cxx_destruct]
  -[VCPCNNBlurAnalyzerMPS prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzerMPS getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzerMPS computeSharpnessScore:textureness:contrast:imgWidth:cancel:]


VCPCNNConvBlock : VCPCNNBlock
  // class methods
  +[VCPCNNConvBlock convBlockClass:]
  +[VCPCNNConvBlock convBlockWithFilterSize:filterNum:chunk:reLU:padding:]
  +[VCPCNNConvBlock convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]

  // instance methods
  -[VCPCNNConvBlock .cxx_destruct]
  -[VCPCNNConvBlock useGPU]
  -[VCPCNNConvBlock supportGPU]
  -[VCPCNNConvBlock initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]
  -[VCPCNNConvBlock constructBlock:context:]


VCPCNNConvBlockBinary : VCPCNNBlock
  // instance methods
  -[VCPCNNConvBlockBinary dealloc]
  -[VCPCNNConvBlockBinary .cxx_destruct]
  -[VCPCNNConvBlockBinary useGPU]
  -[VCPCNNConvBlockBinary forward]
  -[VCPCNNConvBlockBinary supportGPU]
  -[VCPCNNConvBlockBinary constructBlock:context:]
  -[VCPCNNConvBlockBinary readFromDisk:quantFactor:]
  -[VCPCNNConvBlockBinary fillConvWeightsGPU]
  -[VCPCNNConvBlockBinary gpuForward]
  -[VCPCNNConvBlockBinary initWithParameters:filterNum:convType:reLU:padding:]


VCPCNNConvBlockGPU : VCPCNNConvBlock
  // instance methods
  -[VCPCNNConvBlockGPU dealloc]
  -[VCPCNNConvBlockGPU .cxx_destruct]
  -[VCPCNNConvBlockGPU forward]
  -[VCPCNNConvBlockGPU releaseBatchNormMemory]
  -[VCPCNNConvBlockGPU readFromDisk:quantFactor:]
  -[VCPCNNConvBlockGPU readBatchNormParam:quantFactor:]
  -[VCPCNNConvBlockGPU fillConvWeightsGPU]
  -[VCPCNNConvBlockGPU gpuForward]


VCPCNNConvBlockScalar : VCPCNNConvBlock
  // instance methods
  -[VCPCNNConvBlockScalar forward]
  -[VCPCNNConvBlockScalar readFromDisk:quantFactor:]


VCPCNNConvBlockVector : VCPCNNConvBlock
  // class methods
  +[VCPCNNConvBlockVector isFilterSizeSupported:]

  // instance methods
  -[VCPCNNConvBlockVector forward]
  -[VCPCNNConvBlockVector initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]
  -[VCPCNNConvBlockVector readFromDisk:quantFactor:]
  -[VCPCNNConvBlockVector straightForwardForChunkFour]
  -[VCPCNNConvBlockVector chunkFourForward]


VCPCNNData : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *size
 @property  ^f data
 @property  BOOL isInputOutput
 @property  MPSImage *mpsImg
 @property  VCPCNNMetalContext *context

  // class methods
  +[VCPCNNData cnnDataWithGPUContext:]
  +[VCPCNNData cnnData]
  +[VCPCNNData cnnDataClass]
  +[VCPCNNData cnnDataWithPlane:height:width:context:]

  // instance methods
  -[VCPCNNData init]
  -[VCPCNNData dealloc]
  -[VCPCNNData .cxx_destruct]
  -[VCPCNNData data]
  -[VCPCNNData size]
  -[VCPCNNData setData:]
  -[VCPCNNData context]
  -[VCPCNNData setContext:]
  -[VCPCNNData setSize:]
  -[VCPCNNData normalization]
  -[VCPCNNData allocBuffers:]
  -[VCPCNNData reallocGPUTemporalBuffers]
  -[VCPCNNData mpsImg]
  -[VCPCNNData readFromDisk:quantFactor:]
  -[VCPCNNData initWithGPUContext:]
  -[VCPCNNData initWithParameters:height:width:context:]
  -[VCPCNNData bufferAllocCPU]
  -[VCPCNNData randInit]
  -[VCPCNNData convertCPUData2GPU]
  -[VCPCNNData convertGPUData2CPU]
  -[VCPCNNData copyImage:withChunk:]
  -[VCPCNNData softmax]
  -[VCPCNNData isInputOutput]
  -[VCPCNNData setIsInputOutput:]
  -[VCPCNNData setMpsImg:]


VCPCNNDataGPU : VCPCNNData
  // instance methods
  -[VCPCNNDataGPU allocBuffers:]
  -[VCPCNNDataGPU reallocGPUTemporalBuffers]
  -[VCPCNNDataGPU convertCPUData2GPU]
  -[VCPCNNDataGPU convertGPUData2CPU]
  -[VCPCNNDataGPU bufferAllocGPU]


VCPCNNEspressoContext : NSObject /usr/lib/libc++.1.dylib
 @property  ^v espressoContext

  // class methods
  +[VCPCNNEspressoContext supportGPU]
  +[VCPCNNEspressoContext sharedEspressoContext]

  // instance methods
  -[VCPCNNEspressoContext espressoContext]
  -[VCPCNNEspressoContext initNewContext]


VCPCNNFaceLandmarkDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNFaceLandmarkDetector detector]

  // instance methods
  -[VCPCNNFaceLandmarkDetector .cxx_destruct]
  -[VCPCNNFaceLandmarkDetector landmarks]
  -[VCPCNNFaceLandmarkDetector getInputBuffer]
  -[VCPCNNFaceLandmarkDetector computeLandmarks:]
  -[VCPCNNFaceLandmarkDetector analyzeFrame:withFaceBounds:]


VCPCNNFaceLandmarkDetectorEspresso : VCPCNNFaceLandmarkDetector
  // class methods
  +[VCPCNNFaceLandmarkDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNFaceLandmarkDetectorEspresso init]
  -[VCPCNNFaceLandmarkDetectorEspresso dealloc]
  -[VCPCNNFaceLandmarkDetectorEspresso .cxx_destruct]
  -[VCPCNNFaceLandmarkDetectorEspresso getInputBuffer]
  -[VCPCNNFaceLandmarkDetectorEspresso computeLandmarks:]


VCPCNNFaceLandmarkDetectorMPS : VCPCNNFaceLandmarkDetector
  // instance methods
  -[VCPCNNFaceLandmarkDetectorMPS init]
  -[VCPCNNFaceLandmarkDetectorMPS .cxx_destruct]
  -[VCPCNNFaceLandmarkDetectorMPS getInputBuffer]
  -[VCPCNNFaceLandmarkDetectorMPS computeLandmarks:]


VCPCNNFlattenBlock : VCPCNNBlock
  // instance methods
  -[VCPCNNFlattenBlock initWithParameters:]
  -[VCPCNNFlattenBlock forward]
  -[VCPCNNFlattenBlock constructBlock:context:]


VCPCNNFullConnectionBlock : VCPCNNBlock
  // class methods
  +[VCPCNNFullConnectionBlock fcBlockWithNumNeurons:NeuronType:]

  // instance methods
  -[VCPCNNFullConnectionBlock dealloc]
  -[VCPCNNFullConnectionBlock useGPU]
  -[VCPCNNFullConnectionBlock supportGPU]
  -[VCPCNNFullConnectionBlock constructBlock:context:]
  -[VCPCNNFullConnectionBlock readFromDisk:quantFactor:]
  -[VCPCNNFullConnectionBlock initWithParameters:NeuronType:]
  -[VCPCNNFullConnectionBlock readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:]
  -[VCPCNNFullConnectionBlock loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNFastGestureRecognitionEspresso : VCPCNNFastGestureRecognition
  // instance methods
  -[VCPCNNFastGestureRecognitionEspresso init]
  -[VCPCNNFastGestureRecognitionEspresso dealloc]
  -[VCPCNNFastGestureRecognitionEspresso .cxx_destruct]
  -[VCPCNNFastGestureRecognitionEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNFastGestureRecognitionEspresso createModel:srcWidth:]
  -[VCPCNNFastGestureRecognitionEspresso getDetectionScore:]
  -[VCPCNNFastGestureRecognitionEspresso planDestroy]


VCPCNNFullConnectionBlockGPU : VCPCNNFullConnectionBlock
  // instance methods
  -[VCPCNNFullConnectionBlockGPU .cxx_destruct]
  -[VCPCNNFullConnectionBlockGPU forward]
  -[VCPCNNFullConnectionBlockGPU convVCPNeuronTypeToMPS:]
  -[VCPCNNFullConnectionBlockGPU shuffleWeights:fromSrc:inputChannels:inputHeight:inputWidth:outputChannels:]
  -[VCPCNNFullConnectionBlockGPU setupMPS]
  -[VCPCNNFullConnectionBlockGPU loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNFullConnectionBlockScalar : VCPCNNFullConnectionBlock
  // instance methods
  -[VCPCNNFullConnectionBlockScalar forward]
  -[VCPCNNFullConnectionBlockScalar loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNGazeAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNGazeAnalysis sharedModel:]

  // instance methods
  -[VCPCNNGazeAnalysis init]
  -[VCPCNNGazeAnalysis dealloc]
  -[VCPCNNGazeAnalysis .cxx_destruct]
  -[VCPCNNGazeAnalysis copyImage:toData:]
  -[VCPCNNGazeAnalysis createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:]
  -[VCPCNNGazeAnalysis detectEyeOpennessForFace:inBuffer:eyeOpenness:]


VCPCNNHandKeypointsDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNHandKeypointsDetector detector]

  // instance methods
  -[VCPCNNHandKeypointsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandKeypointsDetector copyImage:toData:]
  -[VCPCNNHandKeypointsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:]
  -[VCPCNNHandKeypointsDetector generateHandKeypoints:]
  -[VCPCNNHandKeypointsDetector cvtHeatmaps2Keypoints:outHeight:outWidth:outChannel:keypoints:]
  -[VCPCNNHandKeypointsDetector handKeypointsDetection:box:keypoints:]


VCPCNNMetalContext : NSObject /usr/lib/libc++.1.dylib
 @property  <MTLDevice> *device
 @property  <MTLCommandQueue> *commandQueue
 @property  <MTLCommandBuffer> *commandBuffer

  // class methods
  +[VCPCNNMetalContext supportGPU]
  +[VCPCNNMetalContext supportVectorForward]
  +[VCPCNNMetalContext sharedCommandQueue]

  // instance methods
  -[VCPCNNMetalContext .cxx_destruct]
  -[VCPCNNMetalContext device]
  -[VCPCNNMetalContext commandBuffer]
  -[VCPCNNMetalContext commandQueue]
  -[VCPCNNMetalContext setCommandBuffer:]
  -[VCPCNNMetalContext setCommandQueue:]
  -[VCPCNNMetalContext execute]
  -[VCPCNNMetalContext setDevice:]
  -[VCPCNNMetalContext initNewContext:]


VCPCNNModel : NSObject /usr/lib/libc++.1.dylib
 @property  VCPCNNData *output

  // instance methods
  -[VCPCNNModel init]
  -[VCPCNNModel .cxx_destruct]
  -[VCPCNNModel size]
  -[VCPCNNModel output]
  -[VCPCNNModel add:]
  -[VCPCNNModel initWithParameters:useGPU:]
  -[VCPCNNModel getGPUContext]
  -[VCPCNNModel prepareNetworkFromURL:withInputSize:]
  -[VCPCNNModel forward:]
  -[VCPCNNModel dynamicForward:paramFileUrl:cancel:]


VCPCNNModelEspresso : NSObject /usr/lib/libc++.1.dylib
 @property  {vector<espresso_buffer_t inputBlobs
 @property  {vector<espresso_buffer_t outputBlobs
 @property  {?=^v^v[4Q][4Q]QQQQQQQQQQi} inputBlob
 @property  {?=^v^v[4Q][4Q]QQQQQQQQQQi} outputBlob
 @property  NSString *resConfig

  // instance methods
  -[VCPCNNModelEspresso dealloc]
  -[VCPCNNModelEspresso .cxx_destruct]
  -[VCPCNNModelEspresso .cxx_construct]
  -[VCPCNNModelEspresso initWithParameters:inputNames:outputNames:]
  -[VCPCNNModelEspresso outputBlob]
  -[VCPCNNModelEspresso espressoForward:]
  -[VCPCNNModelEspresso prepareModelWithConfig:]
  -[VCPCNNModelEspresso inputBlob]
  -[VCPCNNModelEspresso softmax]
  -[VCPCNNModelEspresso normalization:]
  -[VCPCNNModelEspresso getPlanPhase]
  -[VCPCNNModelEspresso prepareModelInput:]
  -[VCPCNNModelEspresso prepareModelInputs:]
  -[VCPCNNModelEspresso espressoForwardInputs:]
  -[VCPCNNModelEspresso getEspressoContext]
  -[VCPCNNModelEspresso inputBlobs]
  -[VCPCNNModelEspresso setInputBlobs:]
  -[VCPCNNModelEspresso outputBlobs]
  -[VCPCNNModelEspresso setOutputBlobs:]
  -[VCPCNNModelEspresso setInputBlob:]
  -[VCPCNNModelEspresso setOutputBlob:]
  -[VCPCNNModelEspresso resConfig]


VCPCNNMPSDataSource : NSObject /usr/lib/libc++.1.dylib <MPSCNNConvolutionDataSource>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPCNNMPSDataSource load]
  -[VCPCNNMPSDataSource copyWithZone:]
  -[VCPCNNMPSDataSource .cxx_destruct]
  -[VCPCNNMPSDataSource label]
  -[VCPCNNMPSDataSource dataType]
  -[VCPCNNMPSDataSource weights]
  -[VCPCNNMPSDataSource descriptor]
  -[VCPCNNMPSDataSource biasTerms]
  -[VCPCNNMPSDataSource purge]
  -[VCPCNNMPSDataSource copyWithZone:device:]
  -[VCPCNNMPSDataSource initWith:convolutionDescriptor:kernelWeights:biasTerm:]


VCPCNNPetsDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNPetsDetector detector:]

  // instance methods
  -[VCPCNNPetsDetector copyImage:toData:withChannels:]
  -[VCPCNNPetsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetector createModel:srcWidth:]
  -[VCPCNNPetsDetector postProcBoxes:maxNumRegions:]
  -[VCPCNNPetsDetector petsDetection:petsRegions:petsFaceRegions:cancel:]
  -[VCPCNNPetsDetector generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:]
  -[VCPCNNPetsDetector generatePetsBoxes:faceBoxes:cancel:]
  -[VCPCNNPetsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetector nonMaxSuppression:]


VCPProtoMovieApplauseResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieApplauseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieApplauseResult isEqual:]
  -[VCPProtoMovieApplauseResult copyWithZone:]
  -[VCPProtoMovieApplauseResult .cxx_destruct]
  -[VCPProtoMovieApplauseResult dictionaryRepresentation]
  -[VCPProtoMovieApplauseResult confidence]
  -[VCPProtoMovieApplauseResult writeTo:]
  -[VCPProtoMovieApplauseResult mergeFrom:]
  -[VCPProtoMovieApplauseResult readFrom:]
  -[VCPProtoMovieApplauseResult copyTo:]
  -[VCPProtoMovieApplauseResult setConfidence:]
  -[VCPProtoMovieApplauseResult setTimeRange:]
  -[VCPProtoMovieApplauseResult timeRange]
  -[VCPProtoMovieApplauseResult exportToLegacyDictionary]


VCPCNNPetsDetectorEspresso : VCPCNNPetsDetector
  // class methods
  +[VCPCNNPetsDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNPetsDetectorEspresso dealloc]
  -[VCPCNNPetsDetectorEspresso .cxx_destruct]
  -[VCPCNNPetsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetectorEspresso createModel:srcWidth:]
  -[VCPCNNPetsDetectorEspresso initWithMaxNumRegions:]
  -[VCPCNNPetsDetectorEspresso generatePetsBoxes:faceBoxes:cancel:]


VCPCNNPoolingBlock : VCPCNNBlock
  // class methods
  +[VCPCNNPoolingBlock poolingBlockWithPoolX:poolY:chunk:]

  // instance methods
  -[VCPCNNPoolingBlock useGPU]
  -[VCPCNNPoolingBlock forward]
  -[VCPCNNPoolingBlock supportGPU]
  -[VCPCNNPoolingBlock constructBlock:context:]
  -[VCPCNNPoolingBlock initWithParameters:poolY:chunk:]


VCPCNNPoolingBlockGPU : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockGPU .cxx_destruct]
  -[VCPCNNPoolingBlockGPU forward]


VCPCNNPoolingBlockScalar : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockScalar forward]


VCPCNNPoolingBlockVector : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockVector forward]


VCPCNNPoseEstimator : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNPoseEstimator estimator]

  // instance methods
  -[VCPCNNPoseEstimator getInputBuffer]
  -[VCPCNNPoseEstimator computePoseScore:]
  -[VCPCNNPoseEstimator detectPoseForFace:inBuffer:yaw:]


VCPCNNPoseEstimatorEspresso : VCPCNNPoseEstimator
  // class methods
  +[VCPCNNPoseEstimatorEspresso sharedModel:]

  // instance methods
  -[VCPCNNPoseEstimatorEspresso init]
  -[VCPCNNPoseEstimatorEspresso dealloc]
  -[VCPCNNPoseEstimatorEspresso .cxx_destruct]
  -[VCPCNNPoseEstimatorEspresso getInputBuffer]
  -[VCPCNNPoseEstimatorEspresso computePoseScore:]


VCPProtoLivePhotoKeyFrameFaceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoBounds *faceBounds
 @property  float faceQuality

  // class methods
  +[VCPProtoLivePhotoKeyFrameFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameFaceResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameFaceResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameFaceResult .cxx_destruct]
  -[VCPProtoLivePhotoKeyFrameFaceResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameFaceResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameFaceResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameFaceResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameFaceResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameFaceResult setFaceBounds:]
  -[VCPProtoLivePhotoKeyFrameFaceResult faceBounds]
  -[VCPProtoLivePhotoKeyFrameFaceResult faceQuality]
  -[VCPProtoLivePhotoKeyFrameFaceResult setFaceQuality:]
  -[VCPProtoLivePhotoKeyFrameFaceResult exportToLegacyDictionary]


VCPCNNPoseEstimatorMPS : VCPCNNPoseEstimator
  // instance methods
  -[VCPCNNPoseEstimatorMPS init]
  -[VCPCNNPoseEstimatorMPS .cxx_destruct]
  -[VCPCNNPoseEstimatorMPS getInputBuffer]
  -[VCPCNNPoseEstimatorMPS computePoseScore:]


VCPCNNSmileDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNSmileDetector detector]

  // instance methods
  -[VCPCNNSmileDetector getInputBuffer]
  -[VCPCNNSmileDetector computeSmileScore:]
  -[VCPCNNSmileDetector detectSmileForFace:inBuffer:smile:]


VCPCNNSmileDetectorEspresso : VCPCNNSmileDetector
  // class methods
  +[VCPCNNSmileDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNSmileDetectorEspresso init]
  -[VCPCNNSmileDetectorEspresso dealloc]
  -[VCPCNNSmileDetectorEspresso .cxx_destruct]
  -[VCPCNNSmileDetectorEspresso getInputBuffer]
  -[VCPCNNSmileDetectorEspresso computeSmileScore:]


VCPCNNSmileDetectorMPS : VCPCNNSmileDetector
  // instance methods
  -[VCPCNNSmileDetectorMPS init]
  -[VCPCNNSmileDetectorMPS .cxx_destruct]
  -[VCPCNNSmileDetectorMPS getInputBuffer]
  -[VCPCNNSmileDetectorMPS computeSmileScore:]


VCPDatabaseBatchIterator : NSObject /usr/lib/libc++.1.dylib
 @property  PHAsset *asset
 @property  NSDictionary *analysis

  // class methods
  +[VCPDatabaseBatchIterator iteratorForAssets:withDatabaseReader:resultTypes:batchSize:]

  // instance methods
  -[VCPDatabaseBatchIterator .cxx_destruct]
  -[VCPDatabaseBatchIterator next]
  -[VCPDatabaseBatchIterator asset]
  -[VCPDatabaseBatchIterator nextBatch]
  -[VCPDatabaseBatchIterator initWithDatabaseReader:forAssets:resultsTypes:batchSize:]
  -[VCPDatabaseBatchIterator analysis]


VCPDatabaseReader : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPDatabaseReader shouldQueryInternalFields]
  +[VCPDatabaseReader databaseForPhotoLibrary:]

  // instance methods
  -[VCPDatabaseReader dealloc]
  -[VCPDatabaseReader .cxx_destruct]
  -[VCPDatabaseReader closeDatabase]
  -[VCPDatabaseReader openDatabase]
  -[VCPDatabaseReader initWithPhotoLibrary:]
  -[VCPDatabaseReader queryAnalysesForAssets:withTypes:]
  -[VCPDatabaseReader parseHeader:startColumn:analysis:]
  -[VCPDatabaseReader parseResults:typeColumn:dataColumn:results:]
  -[VCPDatabaseReader executeDatabaseBlock:]
  -[VCPDatabaseReader queryHeaderForAsset:analysis:assetId:]
  -[VCPDatabaseReader queryResultsForAssetId:analysis:]
  -[VCPDatabaseReader queryResultsForAssetId:withTypes:analysis:]
  -[VCPDatabaseReader queryHeadersForAssets:analyses:idMap:]
  -[VCPDatabaseReader queryResultsForAssets:withTypes:batchResults:]
  -[VCPDatabaseReader blacklistedLocalIdentifiersFromAssets:]
  -[VCPDatabaseReader queryBlacklistedLocalIdentifiers]
  -[VCPDatabaseReader queryAnalysisPropertiesForAsset:]
  -[VCPDatabaseReader queryFailedProcessingStatusFromAssets:forTaskID:]
  -[VCPDatabaseReader queryAnalysisPropertiesForAssets:]
  -[VCPDatabaseReader isAssetBlacklisted:blacklistDate:]
  -[VCPDatabaseReader queryAnalysisForAsset:]
  -[VCPDatabaseReader queryAssetsAnalyzedSince:]
  -[VCPDatabaseReader queryAnalysisForAsset:withTypes:]


VCPHuman : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long flags
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  float confidence

  // class methods
  +[VCPHuman flagsFromKeypoints:withMinConfidence:]

  // instance methods
  -[VCPHuman init]
  -[VCPHuman flags]
  -[VCPHuman confidence]
  -[VCPHuman bounds]
  -[VCPHuman setBounds:]
  -[VCPHuman setConfidence:]
  -[VCPHuman setFlags:]


VCPDeviceInformation : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPDeviceInformation isHomePod]
  +[VCPDeviceInformation canRenderVariation]


VCPProtoMovieHumanActionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float absoluteScore
 @property  float relativeScore
 @property  float humanScore

  // class methods
  +[VCPProtoMovieHumanActionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHumanActionResult isEqual:]
  -[VCPProtoMovieHumanActionResult copyWithZone:]
  -[VCPProtoMovieHumanActionResult .cxx_destruct]
  -[VCPProtoMovieHumanActionResult dictionaryRepresentation]
  -[VCPProtoMovieHumanActionResult writeTo:]
  -[VCPProtoMovieHumanActionResult mergeFrom:]
  -[VCPProtoMovieHumanActionResult readFrom:]
  -[VCPProtoMovieHumanActionResult copyTo:]
  -[VCPProtoMovieHumanActionResult setTimeRange:]
  -[VCPProtoMovieHumanActionResult timeRange]
  -[VCPProtoMovieHumanActionResult absoluteScore]
  -[VCPProtoMovieHumanActionResult setAbsoluteScore:]
  -[VCPProtoMovieHumanActionResult relativeScore]
  -[VCPProtoMovieHumanActionResult setRelativeScore:]
  -[VCPProtoMovieHumanActionResult humanScore]
  -[VCPProtoMovieHumanActionResult setHumanScore:]
  -[VCPProtoMovieHumanActionResult exportToLegacyDictionary]


VCPEdgeDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPEdgeDetector dealloc]
  -[VCPEdgeDetector noiseReduction:sigma:imageFiltered:]
  -[VCPEdgeDetector gradientEstimation:width:height:gradient:gradientMag:]
  -[VCPEdgeDetector isInImage:width:height:]
  -[VCPEdgeDetector initWithImage:edgeMap:width:height:widthExtension:heightExtension:]
  -[VCPEdgeDetector detectWithSigma:lowThreshold:highThreshold:]


VCPEffectsAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPEffectsAnalyzer isAutoLoopFramworkAvailable]
  +[VCPEffectsAnalyzer usePHAssetScene]
  +[VCPEffectsAnalyzer gatingResultKeyToIndex]
  +[VCPEffectsAnalyzer getResultIndex:]
  +[VCPEffectsAnalyzer gatingTypeKeys]

  // instance methods
  -[VCPEffectsAnalyzer enumerateMatchingScenesOfAsset:forLongExposureUsingBlock:]
  -[VCPEffectsAnalyzer generateStatsToBeCollectedFrom:]
  -[VCPEffectsAnalyzer reportLivePhotoEffectAnalysisResults:]
  -[VCPEffectsAnalyzer performanSceneClassificationOfImageFileAtURL:]
  -[VCPEffectsAnalyzer matchingNodeForSceneClassification:inSceneNames:]
  -[VCPEffectsAnalyzer initWithFlagHasFace:]
  -[VCPEffectsAnalyzer analyzeAsset:onDemand:cancel:statsFlags:results:]
  -[VCPEffectsAnalyzer initWithAnalysisResults:]


VCPImageExposurePreAnalyzer : VCPImageAnalyzer
 @property  float exposureScore

  // instance methods
  -[VCPImageExposurePreAnalyzer exposureScore]
  -[VCPImageExposurePreAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageExposurePreAnalyzer computeRegionNoise:blockTextureness:average:width:height:stride:]
  -[VCPImageExposurePreAnalyzer computeNoiseLevel:width:height:stride:textureness:]


VCPExifAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPExifAnalyzer .cxx_destruct]
  -[VCPExifAnalyzer transformUprightAboutTopLeft:]
  -[VCPExifAnalyzer addFaceResults:flags:]
  -[VCPExifAnalyzer initWithProperties:forAnalysisTypes:]
  -[VCPExifAnalyzer analyzeAsset:results:]


VCPFace : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  BOOL leftEyeClosed
 @property  BOOL rightEyeClosed
 @property  BOOL smile
 @property  long long yaw
 @property  int trackID
 @property  float confidence
 @property  float faceQuality
 @property  VNFaceObservation *observation

  // instance methods
  -[VCPFace init]
  -[VCPFace .cxx_destruct]
  -[VCPFace confidence]
  -[VCPFace setObservation:]
  -[VCPFace bounds]
  -[VCPFace setBounds:]
  -[VCPFace observation]
  -[VCPFace leftEyeClosed]
  -[VCPFace rightEyeClosed]
  -[VCPFace yaw]
  -[VCPFace trackID]
  -[VCPFace setYaw:]
  -[VCPFace setConfidence:]
  -[VCPFace setTrackID:]
  -[VCPFace setLeftEyeClosed:]
  -[VCPFace setRightEyeClosed:]
  -[VCPFace faceBounds:height:]
  -[VCPFace flagsForOrientation:width:height:]
  -[VCPFace faceBoundsWithTransform:height:transform:]
  -[VCPFace smile]
  -[VCPFace setSmile:]
  -[VCPFace faceQuality]
  -[VCPFace setFaceQuality:]


VCPFaceDetectionRange : NSObject /usr/lib/libc++.1.dylib
 @property  {?=qiIq} start
 @property  {?=qiIq} last
 @property  unsigned long flags
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  unsigned long position
 @property  unsigned long faceID

  // instance methods
  -[VCPFaceDetectionRange flags]
  -[VCPFaceDetectionRange start]
  -[VCPFaceDetectionRange position]
  -[VCPFaceDetectionRange bounds]
  -[VCPFaceDetectionRange setBounds:]
  -[VCPFaceDetectionRange setPosition:]
  -[VCPFaceDetectionRange setFlags:]
  -[VCPFaceDetectionRange setStart:]
  -[VCPFaceDetectionRange setLast:]
  -[VCPFaceDetectionRange last]
  -[VCPFaceDetectionRange faceID]
  -[VCPFaceDetectionRange setFaceID:]


VCPTimeMeasurement : NSObject /usr/lib/libc++.1.dylib
 @property  double elapsedTimeSeconds

  // instance methods
  -[VCPTimeMeasurement init]
  -[VCPTimeMeasurement stop]
  -[VCPTimeMeasurement start]
  -[VCPTimeMeasurement reset]
  -[VCPTimeMeasurement elapsedTimeSeconds]


VCPFingerprint : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *master
 @property  NSString *adjusted

  // class methods
  +[VCPFingerprint fingerprintWithMaster:adjusted:]

  // instance methods
  -[VCPFingerprint init]
  -[VCPFingerprint .cxx_destruct]
  -[VCPFingerprint master]
  -[VCPFingerprint initWithMaster:adjusted:]
  -[VCPFingerprint adjusted]
  -[VCPFingerprint isEqualToFingerprint:]


VCPFrameScoreFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPFrameScoreFilter dealloc]
  -[VCPFrameScoreFilter initWithFilterTabs:distanceVariance:diffVariance:]
  -[VCPFrameScoreFilter processFrameScore:validScore:]


VCPProtoLivePhotoKeyFrameStillResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness
 @property  float textureness
 @property  BOOL hasFlash
 @property  float stillTime

  // class methods
  +[VCPProtoLivePhotoKeyFrameStillResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameStillResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameStillResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameStillResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameStillResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameStillResult sharpness]
  -[VCPProtoLivePhotoKeyFrameStillResult setSharpness:]
  -[VCPProtoLivePhotoKeyFrameStillResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameStillResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameStillResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameStillResult hasFlash]
  -[VCPProtoLivePhotoKeyFrameStillResult textureness]
  -[VCPProtoLivePhotoKeyFrameStillResult setTextureness:]
  -[VCPProtoLivePhotoKeyFrameStillResult setHasFlash:]
  -[VCPProtoLivePhotoKeyFrameStillResult stillTime]
  -[VCPProtoLivePhotoKeyFrameStillResult setStillTime:]
  -[VCPProtoLivePhotoKeyFrameStillResult exportToLegacyDictionary]


VCPProtoImageSceneprintResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *sceneprintBlob

  // class methods
  +[VCPProtoImageSceneprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageSceneprintResult isEqual:]
  -[VCPProtoImageSceneprintResult copyWithZone:]
  -[VCPProtoImageSceneprintResult .cxx_destruct]
  -[VCPProtoImageSceneprintResult dictionaryRepresentation]
  -[VCPProtoImageSceneprintResult writeTo:]
  -[VCPProtoImageSceneprintResult mergeFrom:]
  -[VCPProtoImageSceneprintResult readFrom:]
  -[VCPProtoImageSceneprintResult copyTo:]
  -[VCPProtoImageSceneprintResult setSceneprintBlob:]
  -[VCPProtoImageSceneprintResult sceneprintBlob]
  -[VCPProtoImageSceneprintResult exportToLegacyDictionary]


VCPFullVideoAnalyzer : VCPVideoAnalyzer
 @property  float qualityScore
 @property  float actionScore
 @property  float interestingnessScore
 @property  float obstructionScore
 @property  float trackingScore

  // class methods
  +[VCPFullVideoAnalyzer useSceneprintInSceneAnalysis]

  // instance methods
  -[VCPFullVideoAnalyzer dealloc]
  -[VCPFullVideoAnalyzer .cxx_destruct]
  -[VCPFullVideoAnalyzer results]
  -[VCPFullVideoAnalyzer initWithTransform:]
  -[VCPFullVideoAnalyzer .cxx_construct]
  -[VCPFullVideoAnalyzer setActionScore:]
  -[VCPFullVideoAnalyzer actionScore]
  -[VCPFullVideoAnalyzer process:]
  -[VCPFullVideoAnalyzer seedAnalyzersWithPixelBuffer:startTime:]
  -[VCPFullVideoAnalyzer reviseFrameTrackScore:saliencyRegions:]
  -[VCPFullVideoAnalyzer processAndEstimateQualityScore:]
  -[VCPFullVideoAnalyzer setInterestingnessScore:]
  -[VCPFullVideoAnalyzer computeExposureScoreOfFrame:]
  -[VCPFullVideoAnalyzer interestingnessScore]
  -[VCPFullVideoAnalyzer addSceneAnalysisResult:to:optional:]
  -[VCPFullVideoAnalyzer estimateQualityScore:]
  -[VCPFullVideoAnalyzer addResult:to:forKey:optional:]
  -[VCPFullVideoAnalyzer initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:]
  -[VCPFullVideoAnalyzer prepareVideoAnalysisByScenes:]
  -[VCPFullVideoAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPFullVideoAnalyzer finishAnalysisPass:]
  -[VCPFullVideoAnalyzer privateResults]
  -[VCPFullVideoAnalyzer getSceneSwichFrequency]
  -[VCPFullVideoAnalyzer setNextCaptureFrame:]
  -[VCPFullVideoAnalyzer qualityScore]
  -[VCPFullVideoAnalyzer setQualityScore:]
  -[VCPFullVideoAnalyzer obstructionScore]
  -[VCPFullVideoAnalyzer setObstructionScore:]
  -[VCPFullVideoAnalyzer trackingScore]
  -[VCPFullVideoAnalyzer setTrackingScore:]


VCPGaborFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPGaborFilter dealloc]
  -[VCPGaborFilter createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:]
  -[VCPGaborFilter initWithNumberOfScales:numOfOrientations:width:height:]
  -[VCPGaborFilter processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:]


VCPHoughTransform : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPHoughTransform dealloc]
  -[VCPHoughTransform Transform]
  -[VCPHoughTransform initWithEdgeMap:mapWidth:mapHeight:angleStep:]
  -[VCPHoughTransform DetectLinesWithThreshold:output:]


VCPImageAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPImageAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageAnalyzer processTile:results:cancel:]
  -[VCPImageAnalyzer aggregateTileResults:tileRect:imageSize:landscape:results:]
  -[VCPImageAnalyzer analyzePixelBufferInTiles:results:cancel:]
  -[VCPImageAnalyzer calculateTextureness:height:width:sdof:result:]


VCPImageBlurAnalyzer : VCPBlurAnalyzer
 @property  float sharpness
 @property  float textureScore

  // instance methods
  -[VCPImageBlurAnalyzer .cxx_destruct]
  -[VCPImageBlurAnalyzer sharpness]
  -[VCPImageBlurAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageBlurAnalyzer textureScore]
  -[VCPImageBlurAnalyzer setFaceResults:]
  -[VCPImageBlurAnalyzer prepareFaceBlurModel:]
  -[VCPImageBlurAnalyzer scaleRegion:ofImage:toData:withWidth:andHeight:]
  -[VCPImageBlurAnalyzer getFaceScoreFromOutput:ratio:]
  -[VCPImageBlurAnalyzer computeLocalSharpness:]
  -[VCPImageBlurAnalyzer spatialPooling]
  -[VCPImageBlurAnalyzer computeCNNFaceSharpness:result:cancel:]
  -[VCPImageBlurAnalyzer computeSharpnessScore:forFacesInImage:]
  -[VCPImageBlurAnalyzer initWithFaceResults:sdof:]


VCPImageCompositionAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageCompositionAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPImageConverter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPImageConverter init]
  -[VCPImageConverter dealloc]
  -[VCPImageConverter resize:height:]
  -[VCPImageConverter initWithPixelFormat:]
  -[VCPImageConverter convertImage:yuvFrame:]


VCPImageDescriptor : NSObject /usr/lib/libc++.1.dylib <VCPDistanceDescriptorProtocol>
  // class methods
  +[VCPImageDescriptor usePHAssetData]
  +[VCPImageDescriptor preferredPixelFormat]
  +[VCPImageDescriptor descriptorWithImage:]
  +[VCPImageDescriptor descriptorWithData:]

  // instance methods
  -[VCPImageDescriptor initWithData:]
  -[VCPImageDescriptor .cxx_destruct]
  -[VCPImageDescriptor initWithImage:]
  -[VCPImageDescriptor serialize]
  -[VCPImageDescriptor computeDistance:toDescriptor:]


VCPImageExposureAnalyzer : VCPImageAnalyzer
 @property  float exposureScore

  // instance methods
  -[VCPImageExposureAnalyzer exposureScore]
  -[VCPImageExposureAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageExposureAnalyzer computeRegionNoise:blockTextureness:average:width:height:stride:]
  -[VCPImageExposureAnalyzer computeNoiseLevel:width:height:stride:textureness:]


VCPAnalysisProgressQuery : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPAnalysisProgressQuery queryProgress:forPhotoLibrary:andTaskID:]
  +[VCPAnalysisProgressQuery _processAssetBatch:withDatabase:]


VCPImageFaceDetector : VCPImageAnalyzer
  // class methods
  +[VCPImageFaceDetector faceDetector]

  // instance methods
  -[VCPImageFaceDetector analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageFaceDetector processTile:results:cancel:]
  -[VCPImageFaceDetector aggregateTileResults:tileRect:imageSize:landscape:results:]
  -[VCPImageFaceDetector faceDetection:faces:cancel:]
  -[VCPImageFaceDetector isDuplicate:withRect:]


VCPImageFaceExpressionAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageFaceExpressionAnalyzer .cxx_destruct]
  -[VCPImageFaceExpressionAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageFaceExpressionAnalyzer initWithFaceResults:]


VCPImageFaceQualityAnalyzer : VCPImageAnalyzer
 @property  NSMutableArray *faceQualityScores

  // instance methods
  -[VCPImageFaceQualityAnalyzer dealloc]
  -[VCPImageFaceQualityAnalyzer .cxx_destruct]
  -[VCPImageFaceQualityAnalyzer analyzeDetectedFaces:faceResults:cancel:]
  -[VCPImageFaceQualityAnalyzer faceQualityScores]
  -[VCPImageFaceQualityAnalyzer setFaceQualityScores:]


VCPImageLivePhotoBlurAnalyzer : VCPBlurAnalyzer
  // instance methods
  -[VCPImageLivePhotoBlurAnalyzer .cxx_destruct]
  -[VCPImageLivePhotoBlurAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageLivePhotoBlurAnalyzer initWithMovingObjectsResults:]


VCPImageManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPImageManager loggingEnabled]
  +[VCPImageManager sharedImageManager]
  +[VCPImageManager canDecodeAcceleratedUniformTypeIdentifier:]

  // instance methods
  -[VCPImageManager init]
  -[VCPImageManager dealloc]
  -[VCPImageManager .cxx_destruct]
  -[VCPImageManager flushCache]
  -[VCPImageManager createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPImageManager convertPixelBuffer:toPixelFormat:]
  -[VCPImageManager drawImage:withOrientation:maxDimension:pixelBuffer:]
  -[VCPImageManager acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:flushCache:]
  -[VCPImageManager decodeImageSource:pixelFormat:maxDimension:pixelBuffer:]
  -[VCPImageManager dataForResource:]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:]
  -[VCPImageManager imageForResource:pixelFormat:]
  -[VCPImageManager imageForResource:pixelFormat:maxDimension:]
  -[VCPImageManager pixelBufferWithFormat:fromImageURL:flushCache:]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromImageURL:]


VCPProtoMovieHumanPoseResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence
 @property  VCPProtoBounds *bounds
 @property  int flags

  // class methods
  +[VCPProtoMovieHumanPoseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHumanPoseResult isEqual:]
  -[VCPProtoMovieHumanPoseResult copyWithZone:]
  -[VCPProtoMovieHumanPoseResult .cxx_destruct]
  -[VCPProtoMovieHumanPoseResult flags]
  -[VCPProtoMovieHumanPoseResult dictionaryRepresentation]
  -[VCPProtoMovieHumanPoseResult confidence]
  -[VCPProtoMovieHumanPoseResult writeTo:]
  -[VCPProtoMovieHumanPoseResult bounds]
  -[VCPProtoMovieHumanPoseResult setBounds:]
  -[VCPProtoMovieHumanPoseResult mergeFrom:]
  -[VCPProtoMovieHumanPoseResult readFrom:]
  -[VCPProtoMovieHumanPoseResult copyTo:]
  -[VCPProtoMovieHumanPoseResult setConfidence:]
  -[VCPProtoMovieHumanPoseResult setFlags:]
  -[VCPProtoMovieHumanPoseResult setTimeRange:]
  -[VCPProtoMovieHumanPoseResult timeRange]
  -[VCPProtoMovieHumanPoseResult exportToLegacyDictionary]


VCPImagePetsAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImagePetsAnalyzer .cxx_destruct]
  -[VCPImagePetsAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImagePetsAnalyzer initWithMaxNumRegions:]
  -[VCPImagePetsAnalyzer convertResultsToDict:results:]


VCPImageQualityAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  float qualityScore

  // instance methods
  -[VCPImageQualityAnalyzer qualityScore]
  -[VCPImageQualityAnalyzer analyzeImageQuality:irisPhotoOffsetSec:cancel:]


VCPImageSaliencyAnalyzer : VCPImageAnalyzer
  // class methods
  +[VCPImageSaliencyAnalyzer analyzerWith:prune:]

  // instance methods
  -[VCPImageSaliencyAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageSaliencyAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzer getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzer processTile:results:cancel:]
  -[VCPImageSaliencyAnalyzer aggregateTileResults:tileRect:imageSize:landscape:results:]
  -[VCPImageSaliencyAnalyzer initWithMaxNumRegions:prune:]
  -[VCPImageSaliencyAnalyzer copyImage:toData:withChunk:]
  -[VCPImageSaliencyAnalyzer outputScaling]
  -[VCPImageSaliencyAnalyzer computeScore:width:height:posX:posY:]
  -[VCPImageSaliencyAnalyzer scaleImage:toData:withWidth:andHeight:]
  -[VCPImageSaliencyAnalyzer getSalientRegions:]
  -[VCPImageSaliencyAnalyzer saliencyDetection:salientRegions:cancel:]
  -[VCPImageSaliencyAnalyzer pruneRegions:]
  -[VCPImageSaliencyAnalyzer generateSalientRegion:outHeight:outWidth:]


VCPImageSaliencyAnalyzerBinary : VCPImageSaliencyAnalyzer
  // instance methods
  -[VCPImageSaliencyAnalyzerBinary .cxx_destruct]
  -[VCPImageSaliencyAnalyzerBinary prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerBinary getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzerBinary outputScaling]
  -[VCPImageSaliencyAnalyzerBinary getSalientRegions:]


VCPImageSaliencyAnalyzerFull : VCPImageSaliencyAnalyzer
  // instance methods
  -[VCPImageSaliencyAnalyzerFull .cxx_destruct]
  -[VCPImageSaliencyAnalyzerFull prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerFull getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzerFull getSalientRegions:]


VCPImageSaliencyAnalyzerFullEspresso : VCPImageSaliencyAnalyzer
  // class methods
  +[VCPImageSaliencyAnalyzerFullEspresso sharedModel:]

  // instance methods
  -[VCPImageSaliencyAnalyzerFullEspresso dealloc]
  -[VCPImageSaliencyAnalyzerFullEspresso .cxx_destruct]
  -[VCPImageSaliencyAnalyzerFullEspresso prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerFullEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzerFullEspresso getSalientRegions:]


VCPPreAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPPreAnalyzer _allowANE]
  +[VCPPreAnalyzer _enableSceneAssetConcurrency]

  // instance methods
  -[VCPPreAnalyzer init]
  -[VCPPreAnalyzer dealloc]
  -[VCPPreAnalyzer .cxx_destruct]
  -[VCPPreAnalyzer .cxx_construct]
  -[VCPPreAnalyzer _createPixelBufferPool:withPixelFormat:]
  -[VCPPreAnalyzer _loadAndScaleThumbnailWithImageURL:toScaled32BGRABuffer:]
  -[VCPPreAnalyzer _convertFromBuffer:toLumaPixelBuffer:]
  -[VCPPreAnalyzer _configureRequest:withRevision:]
  -[VCPPreAnalyzer _generateSceneClassifications:withClassificationResults:andJunkImageResults:]
  -[VCPPreAnalyzer _createAestheticsRequest:andClassificationRequest:andSceneprintRequest:andJunkImageRequest:andSaliencyImageRequest:]
  -[VCPPreAnalyzer _collectSceneAnalysisResults:withClassificationResults:andJunkImageResults:andAestheticsResults:andSaliencyResults:andSceneprintResults:]
  -[VCPPreAnalyzer _performSceneAnalysis:withRequestHandler:]
  -[VCPPreAnalyzer _performBlurAnalysis:withBuffer:andIsSDOF:]
  -[VCPPreAnalyzer _performExposureAnalysis:withBuffer:]
  -[VCPPreAnalyzer _loadImageURL:isPano:withRequestHandler:andLumaPixelBuffer:]
  -[VCPPreAnalyzer _performAnalysis:isSDOF:withRequestHandler:andLumaPixelBuffer:]
  -[VCPPreAnalyzer analyzeWithImageURL:isPano:isSDOF:completionHandler:]


VCPInterAssetAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPInterAssetAnalyzer thumbnailSizeForAsset:withResources:]
  +[VCPInterAssetAnalyzer canUseLastFrameOfAsset:withResources:]

  // instance methods
  -[VCPInterAssetAnalyzer init]
  -[VCPInterAssetAnalyzer _generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:]
  -[VCPInterAssetAnalyzer _getThumbnailForAsset:withResouces:andPixelFormat:]
  -[VCPInterAssetAnalyzer computeDistance:fromArray:toArray:]
  -[VCPInterAssetAnalyzer computeDistance:withDescriptorClass:fromAsset:toAsset:]
  -[VCPInterAssetAnalyzer generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:]


VCPJunkAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPJunkAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPLandmarkValidator : NSObject /usr/lib/libc++.1.dylib
 @property  ^f orientation

  // instance methods
  -[VCPLandmarkValidator dealloc]
  -[VCPLandmarkValidator .cxx_destruct]
  -[VCPLandmarkValidator orientation]
  -[VCPLandmarkValidator setOrientation:]
  -[VCPLandmarkValidator initWithModelFile:paramFile:numTri:triList:angle:]
  -[VCPLandmarkValidator validateOneImage:landmarks:numofLandmarks:score:]


VCPLightMotionAnalyzer : VCPVideoAnalyzer
 @property  float actionScore

  // class methods
  +[VCPLightMotionAnalyzer autoLiveMotionScore:]

  // instance methods
  -[VCPLightMotionAnalyzer init]
  -[VCPLightMotionAnalyzer dealloc]
  -[VCPLightMotionAnalyzer .cxx_destruct]
  -[VCPLightMotionAnalyzer .cxx_construct]
  -[VCPLightMotionAnalyzer actionScore]
  -[VCPLightMotionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPLightMotionAnalyzer cameraMotionDetection:]
  -[VCPLightMotionAnalyzer generateThresholds:withConfidences:]
  -[VCPLightMotionAnalyzer initWithQueue:turbo:]
  -[VCPLightMotionAnalyzer prewarmWithWidth:height:]
  -[VCPLightMotionAnalyzer analyzeFrame:withTimestamp:andDuration:completion:]


VCPLightVideoAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *publicResults
 @property  NSDictionary *privateResults

  // instance methods
  -[VCPLightVideoAnalyzer .cxx_destruct]
  -[VCPLightVideoAnalyzer privateResults]
  -[VCPLightVideoAnalyzer findMetaTrackforType:]
  -[VCPLightVideoAnalyzer publicResults]
  -[VCPLightVideoAnalyzer processMetaTrackForType:cancel:flags:]
  -[VCPLightVideoAnalyzer checkTimeRangeConsistency]
  -[VCPLightVideoAnalyzer initWithAVAsset:forAnalysisTypes:]
  -[VCPLightVideoAnalyzer analyzeAsset:flags:]


VCPLogManager : NSObject /usr/lib/libc++.1.dylib
 @property  int logLevel

  // class methods
  +[VCPLogManager dateFormatter]
  +[VCPLogManager sharedLogManager]

  // instance methods
  -[VCPLogManager init]
  -[VCPLogManager logLevel]


VCPCNNHandsDetectorEspresso : VCPCNNHandsDetector
  // instance methods
  -[VCPCNNHandsDetectorEspresso dealloc]
  -[VCPCNNHandsDetectorEspresso .cxx_destruct]
  -[VCPCNNHandsDetectorEspresso .cxx_construct]
  -[VCPCNNHandsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandsDetectorEspresso initWithMaxNumRegions:]
  -[VCPCNNHandsDetectorEspresso generateHandsBoxes:]


VCPMovieCurationAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPMovieCurationAnalyzer .cxx_destruct]
  -[VCPMovieCurationAnalyzer results]
  -[VCPMovieCurationAnalyzer postProcessKeyFrames]
  -[VCPMovieCurationAnalyzer reportMovieCurationAnalysisResults:withSummaryAnalytics:]
  -[VCPMovieCurationAnalyzer addHighlight:to:]
  -[VCPMovieCurationAnalyzer addSummary:to:]
  -[VCPMovieCurationAnalyzer initWithAnalysisTypes:transform:timeRange:isLivePhoto:frameStats:hadFlash:keyFrameResults:]
  -[VCPMovieCurationAnalyzer analyzeKeyFrame:withTimestamp:andDuration:flags:]
  -[VCPMovieCurationAnalyzer loadVideoAnalysisResults:audioAnalysisResults:andFaceRanges:frameSize:]
  -[VCPMovieCurationAnalyzer generateMovieCurations]


VCPVideoKeyFrameResult : NSObject /usr/lib/libc++.1.dylib
 @property  {?=qiIq} timeStamp
 @property  float score

  // instance methods
  -[VCPVideoKeyFrameResult score]
  -[VCPVideoKeyFrameResult timeStamp]
  -[VCPVideoKeyFrameResult initWithTime:andScore:]


VCPMovieHighlightResult : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score
 @property  VCPVideoKeyFrameResult *keyFrame

  // instance methods
  -[VCPMovieHighlightResult .cxx_destruct]
  -[VCPMovieHighlightResult score]
  -[VCPMovieHighlightResult timerange]
  -[VCPMovieHighlightResult keyFrame]
  -[VCPMovieHighlightResult initWithTimeRange:score:andKeyFrame:]


VCPMovieCurationResults : NSObject /usr/lib/libc++.1.dylib
 @property  PHAsset *phAsset
 @property  NSMutableArray *highlights

  // instance methods
  -[VCPMovieCurationResults .cxx_destruct]
  -[VCPMovieCurationResults highlights]
  -[VCPMovieCurationResults initWithPHAsset:]
  -[VCPMovieCurationResults phAsset]


VCPMovieHighlight : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score
 @property  float junkScore
 @property  float qualityScore
 @property  float expressionScore
 @property  float actionScore
 @property  float voiceScore
 @property  float humanActionScore
 @property  float humanPoseScore
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bestPlaybackCrop
 @property  BOOL isAutoPlayable
 @property  BOOL isTrimmed
 @property  VCPImageDescriptor *descriptor
 @property  VCPVideoKeyFrame *keyFrame

  // instance methods
  -[VCPMovieHighlight .cxx_destruct]
  -[VCPMovieHighlight score]
  -[VCPMovieHighlight setActionScore:]
  -[VCPMovieHighlight actionScore]
  -[VCPMovieHighlight setScore:]
  -[VCPMovieHighlight descriptor]
  -[VCPMovieHighlight setDescriptor:]
  -[VCPMovieHighlight initWithTimeRange:]
  -[VCPMovieHighlight qualityScore]
  -[VCPMovieHighlight setQualityScore:]
  -[VCPMovieHighlight timerange]
  -[VCPMovieHighlight keyFrame]
  -[VCPMovieHighlight bestPlaybackCrop]
  -[VCPMovieHighlight isTrimmed]
  -[VCPMovieHighlight isAutoPlayable]
  -[VCPMovieHighlight junkScore]
  -[VCPMovieHighlight expressionScore]
  -[VCPMovieHighlight voiceScore]
  -[VCPMovieHighlight humanActionScore]
  -[VCPMovieHighlight humanPoseScore]
  -[VCPMovieHighlight mergeSegment:]
  -[VCPMovieHighlight isShort]
  -[VCPMovieHighlight copyScoresFrom:]
  -[VCPMovieHighlight checkAutoPlayable]
  -[VCPMovieHighlight setTimerange:]
  -[VCPMovieHighlight setJunkScore:]
  -[VCPMovieHighlight setExpressionScore:]
  -[VCPMovieHighlight setVoiceScore:]
  -[VCPMovieHighlight setHumanActionScore:]
  -[VCPMovieHighlight setHumanPoseScore:]
  -[VCPMovieHighlight setBestPlaybackCrop:]
  -[VCPMovieHighlight setIsAutoPlayable:]
  -[VCPMovieHighlight setIsTrimmed:]
  -[VCPMovieHighlight setKeyFrame:]


VCPExpressionSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  float score

  // instance methods
  -[VCPExpressionSegment score]
  -[VCPExpressionSegment setScore:]
  -[VCPExpressionSegment setTimeRange:]
  -[VCPExpressionSegment timeRange]


VCPMovieHighlightAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPMovieHighlightAnalyzer .cxx_destruct]
  -[VCPMovieHighlightAnalyzer results]
  -[VCPMovieHighlightAnalyzer addSegment:]
  -[VCPMovieHighlightAnalyzer initWithAnalysisType:isLivePhoto:hadFlash:]
  -[VCPMovieHighlightAnalyzer prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:humanActionResults:humanPoseResults:cameraMotionResults:frameSize:]
  -[VCPMovieHighlightAnalyzer generateHighlights]
  -[VCPMovieHighlightAnalyzer movieSummary]
  -[VCPMovieHighlightAnalyzer generateInitialSegments]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreWithConstraint]
  -[VCPMovieHighlightAnalyzer computeQualityTrimFor:]
  -[VCPMovieHighlightAnalyzer computeActionFaceTrimFor:]
  -[VCPMovieHighlightAnalyzer computeSteadyTranslationTrimFor:]
  -[VCPMovieHighlightAnalyzer generateExpressionSegments:]
  -[VCPMovieHighlightAnalyzer analyzeOverallQuality:]
  -[VCPMovieHighlightAnalyzer pickKeyFramesInRange:]
  -[VCPMovieHighlightAnalyzer computeBestPlaybackCrop:]
  -[VCPMovieHighlightAnalyzer mergeShortSegments]
  -[VCPMovieHighlightAnalyzer mergeSimilarSegments]
  -[VCPMovieHighlightAnalyzer SetKeyFramesForSegments:]
  -[VCPMovieHighlightAnalyzer computeExpressionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeActionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeVoiceScoreInTimeRange:]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreOfSegment:]
  -[VCPMovieHighlightAnalyzer evaluateSegment:]
  -[VCPMovieHighlightAnalyzer searchFeatureVectorOfSegment:]
  -[VCPMovieHighlightAnalyzer computeHumanActionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeHumanPoseScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer qualityScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer actionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer subtleMotionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer expressionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer voiceScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer junkScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer cameraMotionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer visualPleasingScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreOfRange:]


VCPMediaAnalysisService : NSObject /usr/lib/libc++.1.dylib <VCPMediaAnalysisClientProtocol>
  // class methods
  +[VCPMediaAnalysisService errorWithDescription:]
  +[VCPMediaAnalysisService queryProgress:forPhotoLibrary:andTaskID:]
  +[VCPMediaAnalysisService sharedAnalysisService]

  // instance methods
  -[VCPMediaAnalysisService init]
  -[VCPMediaAnalysisService invalidate]
  -[VCPMediaAnalysisService .cxx_destruct]
  -[VCPMediaAnalysisService connection]
  -[VCPMediaAnalysisService cancelAllRequests]
  -[VCPMediaAnalysisService cancelRequest:]
  -[VCPMediaAnalysisService notifyLibraryAvailableAtURL:]
  -[VCPMediaAnalysisService requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService reportProgress:forRequest:]
  -[VCPMediaAnalysisService requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]


VCPMediaAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPMediaAnalyzer sharedMediaAnalyzer]
  +[VCPMediaAnalyzer _getDistanceDescriptorClass]

  // instance methods
  -[VCPMediaAnalyzer init]
  -[VCPMediaAnalyzer dealloc]
  -[VCPMediaAnalyzer .cxx_destruct]
  -[VCPMediaAnalyzer connection]
  -[VCPMediaAnalyzer _addClassificationResults:analysis:]
  -[VCPMediaAnalyzer _metaAnalysisTypesForAsset:]
  -[VCPMediaAnalyzer _analyzeOndemand:forAnalysisTypes:withExistingAnalysis:storeAnalysis:]
  -[VCPMediaAnalyzer _databaseForPhotoLibrary:]
  -[VCPMediaAnalyzer requestAnalysisForAsset:withExistingAnalysis:andDatabase:analysisTypes:allowOndemand:]
  -[VCPMediaAnalyzer assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:]
  -[VCPMediaAnalyzer _getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:]
  -[VCPMediaAnalyzer _checkDuplicate:withAsset:duplicate:]
  -[VCPMediaAnalyzer _queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:]
  -[VCPMediaAnalyzer _typesToRemove:requested:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssets:allowOndemand:progressHandler:analyses:]
  -[VCPMediaAnalyzer _getDatabaseSandboxExtensionForPhotoLibraryURL:]
  -[VCPMediaAnalyzer requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:]
  -[VCPMediaAnalyzer cancelAnalysisWithRequestID:]
  -[VCPMediaAnalyzer assetsAnalyzedSinceDate:completionHandler:]
  -[VCPMediaAnalyzer distanceFromAsset:toAsset:duplicate:distance:]
  -[VCPMediaAnalyzer distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:]
  -[VCPMediaAnalyzer requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:]
  -[VCPMediaAnalyzer curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:]
  -[VCPMediaAnalyzer requestCallerIdentificationForFaces:]
  -[VCPMediaAnalyzer requestMovieHighlightsForAssets:]
  -[VCPMediaAnalyzer requestLivePhotoEffectsForAssets:allowOnDemand:flags:]
  -[VCPMediaAnalyzer completeStorage]


VCPMetaSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames

  // instance methods
  -[VCPMetaSegment init]
  -[VCPMetaSegment timeRange]
  -[VCPMetaSegment mergeSegment:]
  -[VCPMetaSegment numOfFrames]
  -[VCPMetaSegment updateSegment:]
  -[VCPMetaSegment resetSegment:]
  -[VCPMetaSegment finalizeAtTime:]


VCPMetaTrackDecoder : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPMetaTrackDecoder dealloc]
  -[VCPMetaTrackDecoder .cxx_destruct]
  -[VCPMetaTrackDecoder status]
  -[VCPMetaTrackDecoder initWithTrack:]
  -[VCPMetaTrackDecoder copyNextMetadataGroup]


VCPMovieAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL allowStreaming
 @property  long long status

  // class methods
  +[VCPMovieAnalyzer canAnalyzeUndegraded:withResources:]
  +[VCPMovieAnalyzer analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]

  // instance methods
  -[VCPMovieAnalyzer .cxx_destruct]
  -[VCPMovieAnalyzer status]
  -[VCPMovieAnalyzer privateResults]
  -[VCPMovieAnalyzer initWithPHAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer analyzeAsset:]
  -[VCPMovieAnalyzer processExistingAnalysisForTimeRange:analysisTypes:]
  -[VCPMovieAnalyzer createDecoderForTrack:timerange:]
  -[VCPMovieAnalyzer createVideoAnalyzer:withFrameStats:]
  -[VCPMovieAnalyzer analyzeVideoSegment:timerange:cancel:]
  -[VCPMovieAnalyzer loadPropertiesForAsset:]
  -[VCPMovieAnalyzer performMetadataAnalysisOnAsset:withCancelBlock:]
  -[VCPMovieAnalyzer analyzeVideoTrack:start:cancel:]
  -[VCPMovieAnalyzer generateKeyFrameResource:]
  -[VCPMovieAnalyzer initWithPHAsset:withPausedAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer allowStreaming]
  -[VCPMovieAnalyzer setAllowStreaming:]


VCPProtoImageHumanPoseResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds
 @property  int flags

  // class methods
  +[VCPProtoImageHumanPoseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageHumanPoseResult isEqual:]
  -[VCPProtoImageHumanPoseResult copyWithZone:]
  -[VCPProtoImageHumanPoseResult .cxx_destruct]
  -[VCPProtoImageHumanPoseResult flags]
  -[VCPProtoImageHumanPoseResult dictionaryRepresentation]
  -[VCPProtoImageHumanPoseResult confidence]
  -[VCPProtoImageHumanPoseResult writeTo:]
  -[VCPProtoImageHumanPoseResult bounds]
  -[VCPProtoImageHumanPoseResult setBounds:]
  -[VCPProtoImageHumanPoseResult mergeFrom:]
  -[VCPProtoImageHumanPoseResult readFrom:]
  -[VCPProtoImageHumanPoseResult copyTo:]
  -[VCPProtoImageHumanPoseResult setConfidence:]
  -[VCPProtoImageHumanPoseResult setFlags:]
  -[VCPProtoImageHumanPoseResult exportToLegacyDictionary]


VCPLivePhotoKeyFrameAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPLivePhotoKeyFrameAnalyzer dealloc]
  -[VCPLivePhotoKeyFrameAnalyzer initWithWidth:height:]
  -[VCPLivePhotoKeyFrameAnalyzer createFaceHeatMap:imageFaces:]
  -[VCPLivePhotoKeyFrameAnalyzer computeOverallFaceQualityScore:]
  -[VCPLivePhotoKeyFrameAnalyzer selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:]
  -[VCPLivePhotoKeyFrameAnalyzer fetchAndComputeScoreForKeyFrame:withResult:]
  -[VCPLivePhotoKeyFrameAnalyzer computeScoreForPhoto:withRefKeyFrame:]
  -[VCPLivePhotoKeyFrameAnalyzer reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:]
  -[VCPLivePhotoKeyFrameAnalyzer getFaceHeat:]
  -[VCPLivePhotoKeyFrameAnalyzer updateFaceHeatMap:numOfFrames:]
  -[VCPLivePhotoKeyFrameAnalyzer analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:]


VCPPhotoAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL allowStreaming
 @property  long long status

  // class methods
  +[VCPPhotoAnalyzer canAnalyzeUndegraded:withResources:]
  +[VCPPhotoAnalyzer resourceForAsset:withResources:]
  +[VCPPhotoAnalyzer analyzerWithVCPAsset:forAnalysisTypes:]

  // instance methods
  -[VCPPhotoAnalyzer .cxx_destruct]
  -[VCPPhotoAnalyzer status]
  -[VCPPhotoAnalyzer initWithPHAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPPhotoAnalyzer analyzeAsset:]
  -[VCPPhotoAnalyzer processExistingAnalyses:]
  -[VCPPhotoAnalyzer initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPPhotoAnalyzer updateDegradedFlagForMajorDimension:]
  -[VCPPhotoAnalyzer downscaleImage:scaledImage:majorDimension:]
  -[VCPPhotoAnalyzer existingAnalysisForMovieAnalyzer]
  -[VCPPhotoAnalyzer allowStreaming]
  -[VCPPhotoAnalyzer setAllowStreaming:]
  -[VCPPhotoAnalyzer analyzeImage:performedAnalyses:movingObjectResults:cancel:]


VCPPnPSolver : NSObject /usr/lib/libc++.1.dylib
 @property  {?=[4]} pose

  // instance methods
  -[VCPPnPSolver dealloc]
  -[VCPPnPSolver pose]
  -[VCPPnPSolver setPose:]
  -[VCPPnPSolver computeControlPointsCamera:Vt:]
  -[VCPPnPSolver computePoints3DCamera]
  -[VCPPnPSolver correctSigns]
  -[VCPPnPSolver computeRT:T:]
  -[VCPPnPSolver computeProjectionError:T:]
  -[VCPPnPSolver configureGaussNewton:R6x1:betas:jacobian:residual:]
  -[VCPPnPSolver getControlPoints]
  -[VCPPnPSolver computeBarycentricCoordinates]
  -[VCPPnPSolver computeSVDVt:Vt:]
  -[VCPPnPSolver computeL6x10:L6x10:]
  -[VCPPnPSolver computeR6x1:]
  -[VCPPnPSolver estimateBetasN1:R6x1:betas:]
  -[VCPPnPSolver estimateBetasN2:R6x1:betas:]
  -[VCPPnPSolver estimateBetasN3:R6x1:betas:]
  -[VCPPnPSolver optimizeBetas:R6x1:betas:]
  -[VCPPnPSolver estimateRT:betas:R:T:projectionError:]
  -[VCPPnPSolver estimatePose:]
  -[VCPPnPSolver initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:]
  -[VCPPnPSolver updateIntrinsic:vc:]
  -[VCPPnPSolver updateFocalLengthInPixels:]
  -[VCPPnPSolver estimateExtrinsicsWith:andPoints3D:andNumPoints:]


VCPSceneprintDescriptor : NSObject /usr/lib/libc++.1.dylib <VCPDistanceDescriptorProtocol>
  // class methods
  +[VCPSceneprintDescriptor usePHAssetData]
  +[VCPSceneprintDescriptor preferredPixelFormat]
  +[VCPSceneprintDescriptor descriptorWithImage:]
  +[VCPSceneprintDescriptor descriptorWithData:]

  // instance methods
  -[VCPSceneprintDescriptor initWithData:]
  -[VCPSceneprintDescriptor .cxx_destruct]
  -[VCPSceneprintDescriptor initWithImage:]
  -[VCPSceneprintDescriptor serialize]
  -[VCPSceneprintDescriptor computeDistance:toDescriptor:]


VCPSceneChangeAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPSceneChangeAnalyzer init]
  -[VCPSceneChangeAnalyzer .cxx_destruct]
  -[VCPSceneChangeAnalyzer results]
  -[VCPSceneChangeAnalyzer .cxx_construct]
  -[VCPSceneChangeAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPSceneChangeAnalyzer ComputeSceneDelta:]
  -[VCPSceneChangeAnalyzer decideLensSwitchPoint:]
  -[VCPSceneChangeAnalyzer PrintSegments]
  -[VCPSceneChangeAnalyzer finalizeAnalysisPass:]
  -[VCPSceneChangeAnalyzer isSegmentPoint]


VCPSceneChangeSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames

  // instance methods
  -[VCPSceneChangeSegment init]
  -[VCPSceneChangeSegment timeRange]
  -[VCPSceneChangeSegment mergeSegment:]
  -[VCPSceneChangeSegment numOfFrames]
  -[VCPSceneChangeSegment updateSegment:]
  -[VCPSceneChangeSegment resetSegment:]
  -[VCPSceneChangeSegment finalizeAtTime:]


VCPFaceShapeModel : NSObject /usr/lib/libc++.1.dylib
 @property  int processingMode
 @property  BOOL identityInit
 @property  * meshVertices
 @property  unsigned long vertexCount
 @property  int detectionModeCounterShapeModel

  // instance methods
  -[VCPFaceShapeModel dealloc]
  -[VCPFaceShapeModel .cxx_destruct]
  -[VCPFaceShapeModel initWithMode:]
  -[VCPFaceShapeModel vertexCount]
  -[VCPFaceShapeModel blendShapes]
  -[VCPFaceShapeModel setupModel:]
  -[VCPFaceShapeModel updateIntrinsic:vc:]
  -[VCPFaceShapeModel updateFocalLengthInPixels:]
  -[VCPFaceShapeModel getInternal3dLandmarksCoordinates:lm3dPos:]
  -[VCPFaceShapeModel getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:]
  -[VCPFaceShapeModel updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:]
  -[VCPFaceShapeModel project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:]
  -[VCPFaceShapeModel updateBoundaryLmForShapeOptimization]
  -[VCPFaceShapeModel updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:]
  -[VCPFaceShapeModel moveBoundaryLandmarks:output:isInput:]
  -[VCPFaceShapeModel projectAndUpdateBoundary]
  -[VCPFaceShapeModel optimizeProjectionMatrix:tracking:firstPass:]
  -[VCPFaceShapeModel updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:]
  -[VCPFaceShapeModel calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:]
  -[VCPFaceShapeModel updateMeshAndLm3dAfterExpressionChange]
  -[VCPFaceShapeModel calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:]
  -[VCPFaceShapeModel calculatePosePnpSolver:]
  -[VCPFaceShapeModel reestimateProjectionMatrixPnP]
  -[VCPFaceShapeModel updateIdentityShape:]
  -[VCPFaceShapeModel getPoseParam]
  -[VCPFaceShapeModel setCameraIntrinsics:uc:vc:]
  -[VCPFaceShapeModel getEulerAngle:]
  -[VCPFaceShapeModel resetIdentityAndExpressions]
  -[VCPFaceShapeModel trackFaceMesh:]
  -[VCPFaceShapeModel fitOneImage:]
  -[VCPFaceShapeModel getPose]
  -[VCPFaceShapeModel updateMeshVertices]
  -[VCPFaceShapeModel processingMode]
  -[VCPFaceShapeModel setProcessingMode:]
  -[VCPFaceShapeModel identityInit]
  -[VCPFaceShapeModel setIdentityInit:]
  -[VCPFaceShapeModel meshVertices]
  -[VCPFaceShapeModel detectionModeCounterShapeModel]
  -[VCPFaceShapeModel setDetectionModeCounterShapeModel:]


VCPFaceTensorModel : NSObject /usr/lib/libc++.1.dylib
 @property  int numVertices
 @property  ^f meanBlendshape
 @property  ^f tensorCoeff
 @property  ^f componentsBlendshape
 @property  ^i blendshapeComponentIndex

  // instance methods
  -[VCPFaceTensorModel dealloc]
  -[VCPFaceTensorModel numVertices]
  -[VCPFaceTensorModel initWithModelFile:]
  -[VCPFaceTensorModel meanBlendshape]
  -[VCPFaceTensorModel componentsBlendshape]
  -[VCPFaceTensorModel calculateMesh:numVertices:blendshapes:outputMesh:]
  -[VCPFaceTensorModel calculateModelBlendshapes:outputBlendshapes:]
  -[VCPFaceTensorModel tensorCoeff]
  -[VCPFaceTensorModel blendshapeComponentIndex]


VCPVanishingPointDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVanishingPointDetector dealloc]
  -[VCPVanishingPointDetector .cxx_destruct]
  -[VCPVanishingPointDetector initWithImage:]
  -[VCPVanishingPointDetector detect:withConfidence:dominantLine:]
  -[VCPVanishingPointDetector prepareImage:]
  -[VCPVanishingPointDetector calculateOrientationResponses]
  -[VCPVanishingPointDetector generateOrientationMap]
  -[VCPVanishingPointDetector generateLineWeightMap:weightMap:]
  -[VCPVanishingPointDetector voteVanishingPoint:]
  -[VCPVanishingPointDetector searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:]
  -[VCPVanishingPointDetector extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:]
  -[VCPVanishingPointDetector averageOrientationResponses:withCurrentMap:]
  -[VCPVanishingPointDetector smoothFiltering:width:height:]
  -[VCPVanishingPointDetector calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:]
  -[VCPVanishingPointDetector isVerticalOrHorizontal:]


VCPActionAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPActionAnalyzer init]
  -[VCPActionAnalyzer dealloc]
  -[VCPActionAnalyzer .cxx_destruct]
  -[VCPActionAnalyzer segments]
  -[VCPActionAnalyzer isActive:]
  -[VCPActionAnalyzer isScoreValid:]
  -[VCPActionAnalyzer decideSegmentPointUsingHinkleyDetector:]
  -[VCPActionAnalyzer updateActiveThreshold]
  -[VCPActionAnalyzer mergeSameTypeSegments]
  -[VCPActionAnalyzer printSegments:]
  -[VCPActionAnalyzer prepareTrimmingWithTrimStart:andTrimEnd:]
  -[VCPActionAnalyzer mergeConsecutiveShortSegments]
  -[VCPActionAnalyzer mergeSparseShortSegments]
  -[VCPActionAnalyzer analyzeFrameWithTimeRange:andActionScore:]
  -[VCPActionAnalyzer decideSegmentPointBasedOnActionScore:]
  -[VCPActionAnalyzer finalizeWithDestructiveTrimStart:trimEnd:]
  -[VCPActionAnalyzer postProcessSegmentsWithCaptureTime:trimStart:]
  -[VCPActionAnalyzer activeSegment]


VCPAsset : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL isPano
 @property  BOOL isLivePhoto
 @property  BOOL isScreenshot
 @property  BOOL isHDR
 @property  BOOL isSDOF
 @property  NSDictionary *exif
 @property  BOOL hadFlash
 @property  float exposureTimeSeconds
 @property  float photoOffsetSeconds
 @property  float originalPhotoOffsetSeconds
 @property  BOOL isSlowmo
 @property  BOOL isTimelapse
 @property  double duration
 @property  float slowmoRate
 @property  float timelapseRate
 @property  long long mediaType
 @property  unsigned long mediaSubtypes
 @property  unsigned long pixelWidth
 @property  unsigned long pixelHeight
 @property  NSDate *modificationDate
 @property  VCPFingerprint *fingerprint
 @property  BOOL isImage
 @property  BOOL isMovie
 @property  NSString *localIdentifier
 @property  NSURL *mainFileURL

  // class methods
  +[VCPAsset unimplementedExceptionForMethodName:]

  // instance methods
  -[VCPAsset duration]
  -[VCPAsset modificationDate]
  -[VCPAsset mediaType]
  -[VCPAsset localIdentifier]
  -[VCPAsset isImage]
  -[VCPAsset isMovie]
  -[VCPAsset movie]
  -[VCPAsset pixelWidth]
  -[VCPAsset pixelHeight]
  -[VCPAsset mainFileURL]
  -[VCPAsset fingerprint]
  -[VCPAsset isSlowmo]
  -[VCPAsset isLivePhoto]
  -[VCPAsset isTimelapse]
  -[VCPAsset isHDR]
  -[VCPAsset isSDOF]
  -[VCPAsset mediaSubtypes]
  -[VCPAsset isPano]
  -[VCPAsset isScreenshot]
  -[VCPAsset exif]
  -[VCPAsset imageWithPreferredDimension:]
  -[VCPAsset hadFlash]
  -[VCPAsset exposureTimeSeconds]
  -[VCPAsset photoOffsetSeconds]
  -[VCPAsset originalPhotoOffsetSeconds]
  -[VCPAsset slowmoRate]
  -[VCPAsset timelapseRate]
  -[VCPAsset streamedMovie]
  -[VCPAsset originalMovie]


VCPFaceGeometry : NSObject /usr/lib/libc++.1.dylib <NSSecureCoding>
 @property  unsigned long vertexCount
 @property  r^ vertices

  // class methods
  +[VCPFaceGeometry supportsSecureCoding]

  // instance methods
  -[VCPFaceGeometry dealloc]
  -[VCPFaceGeometry encodeWithCoder:]
  -[VCPFaceGeometry initWithCoder:]
  -[VCPFaceGeometry vertices]
  -[VCPFaceGeometry vertexCount]
  -[VCPFaceGeometry initWithVertices:vertexCount:]


VCPFaceAnchor : NSObject /usr/lib/libc++.1.dylib <NSSecureCoding>
 @property  {?=[4]} transform
 @property  NSDictionary *blendShapes
 @property  VCPFaceGeometry *geometry

  // class methods
  +[VCPFaceAnchor supportsSecureCoding]

  // instance methods
  -[VCPFaceAnchor encodeWithCoder:]
  -[VCPFaceAnchor initWithCoder:]
  -[VCPFaceAnchor .cxx_destruct]
  -[VCPFaceAnchor transform]
  -[VCPFaceAnchor geometry]
  -[VCPFaceAnchor blendShapes]
  -[VCPFaceAnchor initWithTransform:blendShapes:geometry:]


VCPCaptureAnalysisSession : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *aggregatedResults

  // class methods
  +[VCPCaptureAnalysisSession analyzerForAnalysisTypes:withPreferredTransform:properties:]
  +[VCPCaptureAnalysisSession aggregateAnalysisForTypes:withFramesMeta:properties:]

  // instance methods
  -[VCPCaptureAnalysisSession init]
  -[VCPCaptureAnalysisSession dealloc]
  -[VCPCaptureAnalysisSession .cxx_destruct]
  -[VCPCaptureAnalysisSession finalizeAnalysis]
  -[VCPCaptureAnalysisSession prewarmWithProperties:]
  -[VCPCaptureAnalysisSession analyzePixelBuffer:withTimestamp:andDuration:properties:error:]
  -[VCPCaptureAnalysisSession analyzePixelBuffer:withTimestamp:andDuration:properties:completion:]
  -[VCPCaptureAnalysisSession initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:]
  -[VCPCaptureAnalysisSession transformForAngle:pixelBuffer:]
  -[VCPCaptureAnalysisSession flipTransform:]
  -[VCPCaptureAnalysisSession rotateTransform:byAngle:]
  -[VCPCaptureAnalysisSession analyzeFrameWithTimeRange:analysisData:]
  -[VCPCaptureAnalysisSession shouldCutAt:stillPTS:withCut:]
  -[VCPCaptureAnalysisSession updatePreferredTransform:properties:]
  -[VCPCaptureAnalysisSession analyzeAudioBuffer:]
  -[VCPCaptureAnalysisSession aggregatedResults]


VCPClientDatabaseManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPClientDatabaseManager sharedDatabaseForPhotoLibrary:]
  +[VCPClientDatabaseManager sharedDatabaseManager]

  // instance methods
  -[VCPClientDatabaseManager init]
  -[VCPClientDatabaseManager .cxx_destruct]
  -[VCPClientDatabaseManager sharedDatabaseForPhotoLibrary:]


VCPContentAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPContentAnalysis contentAnalysis]

  // instance methods
  -[VCPContentAnalysis init]
  -[VCPContentAnalysis dealloc]
  -[VCPContentAnalysis .cxx_destruct]
  -[VCPContentAnalysis copyBlock:withStride:toBlock:]
  -[VCPContentAnalysis blockContentDetection:]
  -[VCPContentAnalysis detectPixelBuffer:contentType:]


VCPDefaultPhotoLibraryManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPDefaultPhotoLibraryManager sharedManager]

  // instance methods
  -[VCPDefaultPhotoLibraryManager init]
  -[VCPDefaultPhotoLibraryManager defaultPhotoLibrary]


VCPDownloadManager : NSObject /usr/lib/libc++.1.dylib <NSURLSessionTaskDelegate>
 @property  @? cancel
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPDownloadManager sharedManager]
  +[VCPDownloadManager maxSizeBytes]

  // instance methods
  -[VCPDownloadManager init]
  -[VCPDownloadManager .cxx_destruct]
  -[VCPDownloadManager cancel]
  -[VCPDownloadManager URLSession:task:didCompleteWithError:]
  -[VCPDownloadManager URLSession:dataTask:didReceiveData:]
  -[VCPDownloadManager flush]
  -[VCPDownloadManager setCancel:]
  -[VCPDownloadManager requestDownloadFromURL:]
  -[VCPDownloadManager requestDownloadOfResource:]


VCPVoteStats : NSObject /usr/lib/libc++.1.dylib
 @property  long long votes
 @property  long long count

  // instance methods
  -[VCPVoteStats count]
  -[VCPVoteStats setCount:]
  -[VCPVoteStats rate]
  -[VCPVoteStats initWithVotes:andCount:]
  -[VCPVoteStats votes]
  -[VCPVoteStats setVotes:]


VCPFaceRecognitionTask : NSOperation /System/Library/PrivateFrameworks/FTServices.framework/FTServices
  // instance methods
  -[VCPFaceRecognitionTask init]
  -[VCPFaceRecognitionTask .cxx_destruct]
  -[VCPFaceRecognitionTask recognizeFaces:]
  -[VCPFaceRecognitionTask recognizeFace:]


Face : NSManagedObject /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
 @property  NSData *facePrintBlob

  // class methods
  +[Face fetchRequest]


VCPFaceTimeFace : NSObject /usr/lib/libc++.1.dylib
 @property  VNFaceprint *faceprint

  // class methods
  +[VCPFaceTimeFace face]
  +[VCPFaceTimeFace faceFromManagedObject:]

  // instance methods
  -[VCPFaceTimeFace .cxx_destruct]
  -[VCPFaceTimeFace faceprint]
  -[VCPFaceTimeFace setFaceprint:]
  -[VCPFaceTimeFace managedObjectForContext:]


VCPProcessingStatusEntry : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long taskID
 @property  NSString *localIdentifier
 @property  unsigned long status
 @property  unsigned long attempts
 @property  NSDate *nextRetryDate

  // class methods
  +[VCPProcessingStatusEntry entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:]

  // instance methods
  -[VCPProcessingStatusEntry .cxx_destruct]
  -[VCPProcessingStatusEntry status]
  -[VCPProcessingStatusEntry localIdentifier]
  -[VCPProcessingStatusEntry taskID]
  -[VCPProcessingStatusEntry attempts]
  -[VCPProcessingStatusEntry initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:]
  -[VCPProcessingStatusEntry nextRetryDate]


VCPCNNFastGestureRecognition : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNFastGestureRecognition detector]

  // instance methods
  -[VCPCNNFastGestureRecognition getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNFastGestureRecognition createModel:srcWidth:]
  -[VCPCNNFastGestureRecognition getDetectionScore:]
  -[VCPCNNFastGestureRecognition planDestroy]
  -[VCPCNNFastGestureRecognition copyImage:toData:withChunk:]
  -[VCPCNNFastGestureRecognition createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNFastGestureRecognition gestureDetection:score:]


VCPProtoMovieSceneprintResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTime *timestamp
 @property  NSData *sceneprintBlob

  // class methods
  +[VCPProtoMovieSceneprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSceneprintResult isEqual:]
  -[VCPProtoMovieSceneprintResult copyWithZone:]
  -[VCPProtoMovieSceneprintResult .cxx_destruct]
  -[VCPProtoMovieSceneprintResult dictionaryRepresentation]
  -[VCPProtoMovieSceneprintResult timestamp]
  -[VCPProtoMovieSceneprintResult setTimestamp:]
  -[VCPProtoMovieSceneprintResult writeTo:]
  -[VCPProtoMovieSceneprintResult mergeFrom:]
  -[VCPProtoMovieSceneprintResult readFrom:]
  -[VCPProtoMovieSceneprintResult copyTo:]
  -[VCPProtoMovieSceneprintResult setSceneprintBlob:]
  -[VCPProtoMovieSceneprintResult sceneprintBlob]
  -[VCPProtoMovieSceneprintResult exportToLegacyDictionary]


VCPFaceTimePersistentStore : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceTimePersistentStore sharedInstance]

  // instance methods
  -[VCPFaceTimePersistentStore init]
  -[VCPFaceTimePersistentStore .cxx_destruct]
  -[VCPFaceTimePersistentStore fetchAllFaceTimeSessions]
  -[VCPFaceTimePersistentStore storeFaceTimeSession:]


VCPFaceTimeSession : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *sessionID
 @property  NSString *callerID
 @property  NSDate *date
 @property  NSArray *faces

  // class methods
  +[VCPFaceTimeSession session]
  +[VCPFaceTimeSession sessionFromManagedObject:]
  +[VCPFaceTimeSession createWithSessionID:callerID:andDate:]

  // instance methods
  -[VCPFaceTimeSession .cxx_destruct]
  -[VCPFaceTimeSession date]
  -[VCPFaceTimeSession faces]
  -[VCPFaceTimeSession setDate:]
  -[VCPFaceTimeSession sessionID]
  -[VCPFaceTimeSession setSessionID:]
  -[VCPFaceTimeSession addFace:]
  -[VCPFaceTimeSession callerID]
  -[VCPFaceTimeSession setCallerID:]
  -[VCPFaceTimeSession managedObjectForContext:]
  -[VCPFaceTimeSession initWithSessionID:callerID:andDate:]


VCPProtoMoviePetsResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMoviePetsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePetsResult isEqual:]
  -[VCPProtoMoviePetsResult copyWithZone:]
  -[VCPProtoMoviePetsResult .cxx_destruct]
  -[VCPProtoMoviePetsResult dictionaryRepresentation]
  -[VCPProtoMoviePetsResult confidence]
  -[VCPProtoMoviePetsResult writeTo:]
  -[VCPProtoMoviePetsResult bounds]
  -[VCPProtoMoviePetsResult setBounds:]
  -[VCPProtoMoviePetsResult mergeFrom:]
  -[VCPProtoMoviePetsResult readFrom:]
  -[VCPProtoMoviePetsResult copyTo:]
  -[VCPProtoMoviePetsResult setConfidence:]
  -[VCPProtoMoviePetsResult setTimeRange:]
  -[VCPProtoMoviePetsResult timeRange]
  -[VCPProtoMoviePetsResult exportToLegacyDictionary]


VCPFrameAnalysisStats : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL frameProcessedByVideoAnalyzer
 @property  float cameraMotionScore
 @property  float subjectActionScore
 @property  float interestingnessScore
 @property  float obstructionScore
 @property  float exposureScore
 @property  float colorfulnessScore
 @property  BOOL subMbMotionAvailable
 @property  float faceArea
 @property  BOOL frameProcessedByHumanAnalyzer
 @property  float humanPoseScore
 @property  float humanActionScore
 @property  BOOL frameProcessedByFaceDetector
 @property  NSMutableArray *detectedFaces
 @property  VCPVideoActivityDescriptor *videoActivityDescriptor

  // instance methods
  -[VCPFrameAnalysisStats init]
  -[VCPFrameAnalysisStats .cxx_destruct]
  -[VCPFrameAnalysisStats reset]
  -[VCPFrameAnalysisStats exposureScore]
  -[VCPFrameAnalysisStats setExposureScore:]
  -[VCPFrameAnalysisStats detectedFaces]
  -[VCPFrameAnalysisStats setDetectedFaces:]
  -[VCPFrameAnalysisStats setVideoActivityDescriptor:]
  -[VCPFrameAnalysisStats videoActivityDescriptor]
  -[VCPFrameAnalysisStats setCameraMotionScore:]
  -[VCPFrameAnalysisStats setSubjectActionScore:]
  -[VCPFrameAnalysisStats setInterestingnessScore:]
  -[VCPFrameAnalysisStats setColorfulnessScore:]
  -[VCPFrameAnalysisStats setFrameProcessedByVideoAnalyzer:]
  -[VCPFrameAnalysisStats setSubMbMotionAvailable:]
  -[VCPFrameAnalysisStats interestingnessScore]
  -[VCPFrameAnalysisStats obstructionScore]
  -[VCPFrameAnalysisStats setObstructionScore:]
  -[VCPFrameAnalysisStats humanActionScore]
  -[VCPFrameAnalysisStats humanPoseScore]
  -[VCPFrameAnalysisStats setHumanActionScore:]
  -[VCPFrameAnalysisStats setHumanPoseScore:]
  -[VCPFrameAnalysisStats frameProcessedByVideoAnalyzer]
  -[VCPFrameAnalysisStats cameraMotionScore]
  -[VCPFrameAnalysisStats subjectActionScore]
  -[VCPFrameAnalysisStats colorfulnessScore]
  -[VCPFrameAnalysisStats subMbMotionAvailable]
  -[VCPFrameAnalysisStats faceArea]
  -[VCPFrameAnalysisStats setFaceArea:]
  -[VCPFrameAnalysisStats frameProcessedByHumanAnalyzer]
  -[VCPFrameAnalysisStats setFrameProcessedByHumanAnalyzer:]
  -[VCPFrameAnalysisStats frameProcessedByFaceDetector]
  -[VCPFrameAnalysisStats setFrameProcessedByFaceDetector:]


VCPHomeKitAnalysisService : NSObject /usr/lib/libc++.1.dylib <VCPHomeKitAnalysisClientProtocol>
  // class methods
  +[VCPHomeKitAnalysisService analysisService]

  // instance methods
  -[VCPHomeKitAnalysisService init]
  -[VCPHomeKitAnalysisService .cxx_destruct]
  -[VCPHomeKitAnalysisService connection]
  -[VCPHomeKitAnalysisService cancelAllRequests]
  -[VCPHomeKitAnalysisService cancelRequest:]
  -[VCPHomeKitAnalysisService requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:]
  -[VCPHomeKitAnalysisService reportProgress:forRequest:]
  -[VCPHomeKitAnalysisService requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:]


VCPInMemoryAVAsset : AVURLAsset /System/Library/PrivateFrameworks/Celestial.framework/Celestial <AVAssetResourceLoaderDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPInMemoryAVAsset assetWithData:]

  // instance methods
  -[VCPInMemoryAVAsset initWithData:]
  -[VCPInMemoryAVAsset .cxx_destruct]
  -[VCPInMemoryAVAsset resourceLoader:shouldWaitForLoadingOfRequestedResource:]


VCPInternetReachability : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL hasWifiOrEthernetConnection

  // class methods
  +[VCPInternetReachability sharedInstance]

  // instance methods
  -[VCPInternetReachability init]
  -[VCPInternetReachability dealloc]
  -[VCPInternetReachability .cxx_destruct]
  -[VCPInternetReachability setReachabilityForFlags:update:]
  -[VCPInternetReachability hasWifiOrEthernetConnection]


VCPPhotosAsset : VCPAsset
 @property  NSArray *resources

  // class methods
  +[VCPPhotosAsset assetWithPHAsset:]

  // instance methods
  -[VCPPhotosAsset .cxx_destruct]
  -[VCPPhotosAsset duration]
  -[VCPPhotosAsset modificationDate]
  -[VCPPhotosAsset mediaType]
  -[VCPPhotosAsset localIdentifier]
  -[VCPPhotosAsset resources]
  -[VCPPhotosAsset movie]
  -[VCPPhotosAsset pixelWidth]
  -[VCPPhotosAsset pixelHeight]
  -[VCPPhotosAsset mainFileURL]
  -[VCPPhotosAsset fingerprint]
  -[VCPPhotosAsset mediaSubtypes]
  -[VCPPhotosAsset initWithPHAsset:]
  -[VCPPhotosAsset exif]
  -[VCPPhotosAsset imageWithPreferredDimension:]
  -[VCPPhotosAsset photoOffsetSeconds]
  -[VCPPhotosAsset originalPhotoOffsetSeconds]
  -[VCPPhotosAsset slowmoRate]
  -[VCPPhotosAsset streamedMovie]
  -[VCPPhotosAsset originalMovie]


VCPPriorityAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPPriorityAnalysis priorityAnalysis]

  // instance methods
  -[VCPPriorityAnalysis init]
  -[VCPPriorityAnalysis dealloc]
  -[VCPPriorityAnalysis .cxx_destruct]
  -[VCPPriorityAnalysis fastSignLanguageDetection:ofPixelBuffer:withMetadata:]
  -[VCPPriorityAnalysis calculatePriorityScore:ofPixelBuffer:withMetadata:]


VCPProtoAssetAnalysis : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  unsigned int version
 @property  unsigned int types
 @property  unsigned int flags
 @property  double date
 @property  BOOL hasQuality
 @property  double quality
 @property  BOOL hasStatsFlags
 @property  unsigned long statsFlags
 @property  NSString *assetIdentifier
 @property  double assetModificationDate
 @property  NSString *assetMasterFingerprint
 @property  BOOL hasAssetAdjustedFingerprint
 @property  NSString *assetAdjustedFingerprint
 @property  NSMutableArray *imageBlurResults
 @property  NSMutableArray *imageCompositionResults
 @property  NSMutableArray *imageFaceResults
 @property  NSMutableArray *imageFeatureResults
 @property  NSMutableArray *imageJunkResults
 @property  NSMutableArray *imageSaliencyResults
 @property  NSMutableArray *imageShotTypeResults
 @property  NSMutableArray *imagePetsResults
 @property  NSMutableArray *imagePetsFaceResults
 @property  NSMutableArray *imageSceneprintResults
 @property  NSMutableArray *livePhotoEffectsResults
 @property  NSMutableArray *livePhotoRecommendationResults
 @property  NSMutableArray *livePhotoSharpnessResults
 @property  NSMutableArray *livePhotoKeyFrameResults
 @property  NSMutableArray *livePhotoKeyFrameStillResults
 @property  NSMutableArray *movieActivityLevelResults
 @property  NSMutableArray *movieCameraMotionResults
 @property  NSMutableArray *movieClassificationResults
 @property  NSMutableArray *movieFaceResults
 @property  NSMutableArray *movieFaceprintResults
 @property  NSMutableArray *movieFeatureResults
 @property  NSMutableArray *movieFineSubjectMotionResults
 @property  NSMutableArray *movieInterestingnessResults
 @property  NSMutableArray *movieMovingObjectResults
 @property  NSMutableArray *movieMusicResults
 @property  NSMutableArray *movieObstructionResults
 @property  NSMutableArray *movieOrientationResults
 @property  NSMutableArray *moviePreEncodeResults
 @property  NSMutableArray *movieQualityResults
 @property  NSMutableArray *movieSaliencyResults
 @property  NSMutableArray *movieSceneResults
 @property  NSMutableArray *movieSceneprintResults
 @property  NSMutableArray *movieSubjectMotionResults
 @property  NSMutableArray *movieSubtleMotionResults
 @property  NSMutableArray *movieUtteranceResults
 @property  NSMutableArray *movieVoiceResults
 @property  NSMutableArray *movieSummaryResults
 @property  NSMutableArray *movieHighlightResults
 @property  NSMutableArray *imageExposureResults
 @property  NSMutableArray *imageHumanPoseResults
 @property  NSMutableArray *movieHumanPoseResults
 @property  NSMutableArray *movieApplauseResults
 @property  NSMutableArray *movieBabbleResults
 @property  NSMutableArray *movieCheeringResults
 @property  NSMutableArray *movieLaughterResults
 @property  NSMutableArray *movieHumanActionResults
 @property  NSMutableArray *movieLoudnessResults
 @property  NSMutableArray *moviePetsResults
 @property  NSMutableArray *moviePetsFaceResults

  // class methods
  +[VCPProtoAssetAnalysis imageBlurResultsType]
  +[VCPProtoAssetAnalysis imageCompositionResultsType]
  +[VCPProtoAssetAnalysis imageFaceResultsType]
  +[VCPProtoAssetAnalysis imageFeatureResultsType]
  +[VCPProtoAssetAnalysis imageJunkResultsType]
  +[VCPProtoAssetAnalysis imageSaliencyResultsType]
  +[VCPProtoAssetAnalysis imageShotTypeResultsType]
  +[VCPProtoAssetAnalysis imagePetsResultsType]
  +[VCPProtoAssetAnalysis imagePetsFaceResultsType]
  +[VCPProtoAssetAnalysis imageSceneprintResultsType]
  +[VCPProtoAssetAnalysis livePhotoEffectsResultsType]
  +[VCPProtoAssetAnalysis livePhotoRecommendationResultsType]
  +[VCPProtoAssetAnalysis livePhotoSharpnessResultsType]
  +[VCPProtoAssetAnalysis livePhotoKeyFrameResultsType]
  +[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsType]
  +[VCPProtoAssetAnalysis movieActivityLevelResultsType]
  +[VCPProtoAssetAnalysis movieCameraMotionResultsType]
  +[VCPProtoAssetAnalysis movieClassificationResultsType]
  +[VCPProtoAssetAnalysis movieFaceResultsType]
  +[VCPProtoAssetAnalysis movieFaceprintResultsType]
  +[VCPProtoAssetAnalysis movieFeatureResultsType]
  +[VCPProtoAssetAnalysis movieFineSubjectMotionResultsType]
  +[VCPProtoAssetAnalysis movieInterestingnessResultsType]
  +[VCPProtoAssetAnalysis movieMovingObjectResultsType]
  +[VCPProtoAssetAnalysis movieMusicResultsType]
  +[VCPProtoAssetAnalysis movieObstructionResultsType]
  +[VCPProtoAssetAnalysis movieOrientationResultsType]
  +[VCPProtoAssetAnalysis moviePreEncodeResultsType]
  +[VCPProtoAssetAnalysis movieQualityResultsType]
  +[VCPProtoAssetAnalysis movieSaliencyResultsType]
  +[VCPProtoAssetAnalysis movieSceneResultsType]
  +[VCPProtoAssetAnalysis movieSceneprintResultsType]
  +[VCPProtoAssetAnalysis movieSubjectMotionResultsType]
  +[VCPProtoAssetAnalysis movieSubtleMotionResultsType]
  +[VCPProtoAssetAnalysis movieUtteranceResultsType]
  +[VCPProtoAssetAnalysis movieVoiceResultsType]
  +[VCPProtoAssetAnalysis movieSummaryResultsType]
  +[VCPProtoAssetAnalysis movieHighlightResultsType]
  +[VCPProtoAssetAnalysis imageExposureResultsType]
  +[VCPProtoAssetAnalysis imageHumanPoseResultsType]
  +[VCPProtoAssetAnalysis movieHumanPoseResultsType]
  +[VCPProtoAssetAnalysis movieApplauseResultsType]
  +[VCPProtoAssetAnalysis movieBabbleResultsType]
  +[VCPProtoAssetAnalysis movieCheeringResultsType]
  +[VCPProtoAssetAnalysis movieLaughterResultsType]
  +[VCPProtoAssetAnalysis movieHumanActionResultsType]
  +[VCPProtoAssetAnalysis movieLoudnessResultsType]
  +[VCPProtoAssetAnalysis moviePetsResultsType]
  +[VCPProtoAssetAnalysis moviePetsFaceResultsType]
  +[VCPProtoAssetAnalysis imageAnalysisFromLegacyDictionary:]
  +[VCPProtoAssetAnalysis movieAnalysisFromLegacyDictionary:]

  // instance methods
  -[VCPProtoAssetAnalysis isEqual:]
  -[VCPProtoAssetAnalysis copyWithZone:]
  -[VCPProtoAssetAnalysis .cxx_destruct]
  -[VCPProtoAssetAnalysis date]
  -[VCPProtoAssetAnalysis flags]
  -[VCPProtoAssetAnalysis version]
  -[VCPProtoAssetAnalysis dictionaryRepresentation]
  -[VCPProtoAssetAnalysis setVersion:]
  -[VCPProtoAssetAnalysis writeTo:]
  -[VCPProtoAssetAnalysis setDate:]
  -[VCPProtoAssetAnalysis mergeFrom:]
  -[VCPProtoAssetAnalysis readFrom:]
  -[VCPProtoAssetAnalysis copyTo:]
  -[VCPProtoAssetAnalysis setFlags:]
  -[VCPProtoAssetAnalysis types]
  -[VCPProtoAssetAnalysis quality]
  -[VCPProtoAssetAnalysis setQuality:]
  -[VCPProtoAssetAnalysis setAssetIdentifier:]
  -[VCPProtoAssetAnalysis assetIdentifier]
  -[VCPProtoAssetAnalysis setTypes:]
  -[VCPProtoAssetAnalysis setHasQuality:]
  -[VCPProtoAssetAnalysis hasQuality]
  -[VCPProtoAssetAnalysis exportToLegacyDictionary]
  -[VCPProtoAssetAnalysis addImageBlurResults:]
  -[VCPProtoAssetAnalysis addImageCompositionResults:]
  -[VCPProtoAssetAnalysis addImageFaceResults:]
  -[VCPProtoAssetAnalysis addImageFeatureResults:]
  -[VCPProtoAssetAnalysis addImageJunkResults:]
  -[VCPProtoAssetAnalysis addImageSaliencyResults:]
  -[VCPProtoAssetAnalysis addImageShotTypeResults:]
  -[VCPProtoAssetAnalysis addLivePhotoRecommendationResults:]
  -[VCPProtoAssetAnalysis addLivePhotoSharpnessResults:]
  -[VCPProtoAssetAnalysis addMovieActivityLevelResults:]
  -[VCPProtoAssetAnalysis addMovieCameraMotionResults:]
  -[VCPProtoAssetAnalysis addMovieClassificationResults:]
  -[VCPProtoAssetAnalysis addMovieFaceResults:]
  -[VCPProtoAssetAnalysis addMovieFaceprintResults:]
  -[VCPProtoAssetAnalysis addMovieFeatureResults:]
  -[VCPProtoAssetAnalysis addMovieFineSubjectMotionResults:]
  -[VCPProtoAssetAnalysis addMovieInterestingnessResults:]
  -[VCPProtoAssetAnalysis addMovieMovingObjectResults:]
  -[VCPProtoAssetAnalysis addMovieMusicResults:]
  -[VCPProtoAssetAnalysis addMovieObstructionResults:]
  -[VCPProtoAssetAnalysis addMovieOrientationResults:]
  -[VCPProtoAssetAnalysis addMoviePreEncodeResults:]
  -[VCPProtoAssetAnalysis addMovieQualityResults:]
  -[VCPProtoAssetAnalysis addMovieSaliencyResults:]
  -[VCPProtoAssetAnalysis addMovieSceneResults:]
  -[VCPProtoAssetAnalysis addMovieSubjectMotionResults:]
  -[VCPProtoAssetAnalysis addMovieUtteranceResults:]
  -[VCPProtoAssetAnalysis addMovieVoiceResults:]
  -[VCPProtoAssetAnalysis addImagePetsResults:]
  -[VCPProtoAssetAnalysis addMovieSummaryResults:]
  -[VCPProtoAssetAnalysis addMovieHighlightResults:]
  -[VCPProtoAssetAnalysis addImageExposureResults:]
  -[VCPProtoAssetAnalysis addLivePhotoEffectsResults:]
  -[VCPProtoAssetAnalysis addImagePetsFaceResults:]
  -[VCPProtoAssetAnalysis addImageSceneprintResults:]
  -[VCPProtoAssetAnalysis addMovieSceneprintResults:]
  -[VCPProtoAssetAnalysis addImageHumanPoseResults:]
  -[VCPProtoAssetAnalysis addMovieHumanPoseResults:]
  -[VCPProtoAssetAnalysis addMovieApplauseResults:]
  -[VCPProtoAssetAnalysis addMovieBabbleResults:]
  -[VCPProtoAssetAnalysis addMovieCheeringResults:]
  -[VCPProtoAssetAnalysis addMovieLaughterResults:]
  -[VCPProtoAssetAnalysis addLivePhotoKeyFrameResults:]
  -[VCPProtoAssetAnalysis addLivePhotoKeyFrameStillResults:]
  -[VCPProtoAssetAnalysis addMovieHumanActionResults:]
  -[VCPProtoAssetAnalysis addMovieSubtleMotionResults:]
  -[VCPProtoAssetAnalysis addMovieLoudnessResults:]
  -[VCPProtoAssetAnalysis addMoviePetsResults:]
  -[VCPProtoAssetAnalysis addMoviePetsFaceResults:]
  -[VCPProtoAssetAnalysis setAssetMasterFingerprint:]
  -[VCPProtoAssetAnalysis setAssetAdjustedFingerprint:]
  -[VCPProtoAssetAnalysis imageBlurResultsCount]
  -[VCPProtoAssetAnalysis clearImageBlurResults]
  -[VCPProtoAssetAnalysis imageBlurResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageCompositionResultsCount]
  -[VCPProtoAssetAnalysis clearImageCompositionResults]
  -[VCPProtoAssetAnalysis imageCompositionResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageFaceResultsCount]
  -[VCPProtoAssetAnalysis clearImageFaceResults]
  -[VCPProtoAssetAnalysis imageFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageFeatureResultsCount]
  -[VCPProtoAssetAnalysis clearImageFeatureResults]
  -[VCPProtoAssetAnalysis imageFeatureResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageJunkResultsCount]
  -[VCPProtoAssetAnalysis clearImageJunkResults]
  -[VCPProtoAssetAnalysis imageJunkResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageSaliencyResultsCount]
  -[VCPProtoAssetAnalysis clearImageSaliencyResults]
  -[VCPProtoAssetAnalysis imageSaliencyResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageShotTypeResultsCount]
  -[VCPProtoAssetAnalysis clearImageShotTypeResults]
  -[VCPProtoAssetAnalysis imageShotTypeResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoRecommendationResults]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoSharpnessResults]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieActivityLevelResultsCount]
  -[VCPProtoAssetAnalysis clearMovieActivityLevelResults]
  -[VCPProtoAssetAnalysis movieActivityLevelResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieCameraMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieCameraMotionResults]
  -[VCPProtoAssetAnalysis movieCameraMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieClassificationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieClassificationResults]
  -[VCPProtoAssetAnalysis movieClassificationResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFaceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFaceResults]
  -[VCPProtoAssetAnalysis movieFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFaceprintResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFaceprintResults]
  -[VCPProtoAssetAnalysis movieFaceprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFeatureResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFeatureResults]
  -[VCPProtoAssetAnalysis movieFeatureResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFineSubjectMotionResults]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieInterestingnessResultsCount]
  -[VCPProtoAssetAnalysis clearMovieInterestingnessResults]
  -[VCPProtoAssetAnalysis movieInterestingnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieMovingObjectResultsCount]
  -[VCPProtoAssetAnalysis clearMovieMovingObjectResults]
  -[VCPProtoAssetAnalysis movieMovingObjectResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieMusicResultsCount]
  -[VCPProtoAssetAnalysis clearMovieMusicResults]
  -[VCPProtoAssetAnalysis movieMusicResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieObstructionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieObstructionResults]
  -[VCPProtoAssetAnalysis movieObstructionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieOrientationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieOrientationResults]
  -[VCPProtoAssetAnalysis movieOrientationResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePreEncodeResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePreEncodeResults]
  -[VCPProtoAssetAnalysis moviePreEncodeResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieQualityResultsCount]
  -[VCPProtoAssetAnalysis clearMovieQualityResults]
  -[VCPProtoAssetAnalysis movieQualityResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSaliencyResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSaliencyResults]
  -[VCPProtoAssetAnalysis movieSaliencyResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSceneResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSceneResults]
  -[VCPProtoAssetAnalysis movieSceneResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSubjectMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSubjectMotionResults]
  -[VCPProtoAssetAnalysis movieSubjectMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieUtteranceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieUtteranceResults]
  -[VCPProtoAssetAnalysis movieUtteranceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieVoiceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieVoiceResults]
  -[VCPProtoAssetAnalysis movieVoiceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imagePetsResultsCount]
  -[VCPProtoAssetAnalysis clearImagePetsResults]
  -[VCPProtoAssetAnalysis imagePetsResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSummaryResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSummaryResults]
  -[VCPProtoAssetAnalysis movieSummaryResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHighlightResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHighlightResults]
  -[VCPProtoAssetAnalysis movieHighlightResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageExposureResultsCount]
  -[VCPProtoAssetAnalysis clearImageExposureResults]
  -[VCPProtoAssetAnalysis imageExposureResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoEffectsResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoEffectsResults]
  -[VCPProtoAssetAnalysis livePhotoEffectsResultsAtIndex:]
  -[VCPProtoAssetAnalysis imagePetsFaceResultsCount]
  -[VCPProtoAssetAnalysis clearImagePetsFaceResults]
  -[VCPProtoAssetAnalysis imagePetsFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageSceneprintResultsCount]
  -[VCPProtoAssetAnalysis clearImageSceneprintResults]
  -[VCPProtoAssetAnalysis imageSceneprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSceneprintResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSceneprintResults]
  -[VCPProtoAssetAnalysis movieSceneprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageHumanPoseResultsCount]
  -[VCPProtoAssetAnalysis clearImageHumanPoseResults]
  -[VCPProtoAssetAnalysis imageHumanPoseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHumanPoseResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHumanPoseResults]
  -[VCPProtoAssetAnalysis movieHumanPoseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieApplauseResultsCount]
  -[VCPProtoAssetAnalysis clearMovieApplauseResults]
  -[VCPProtoAssetAnalysis movieApplauseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieBabbleResultsCount]
  -[VCPProtoAssetAnalysis clearMovieBabbleResults]
  -[VCPProtoAssetAnalysis movieBabbleResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieCheeringResultsCount]
  -[VCPProtoAssetAnalysis clearMovieCheeringResults]
  -[VCPProtoAssetAnalysis movieCheeringResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieLaughterResultsCount]
  -[VCPProtoAssetAnalysis clearMovieLaughterResults]
  -[VCPProtoAssetAnalysis movieLaughterResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoKeyFrameResults]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoKeyFrameStillResults]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHumanActionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHumanActionResults]
  -[VCPProtoAssetAnalysis movieHumanActionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSubtleMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSubtleMotionResults]
  -[VCPProtoAssetAnalysis movieSubtleMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieLoudnessResultsCount]
  -[VCPProtoAssetAnalysis clearMovieLoudnessResults]
  -[VCPProtoAssetAnalysis movieLoudnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePetsResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePetsResults]
  -[VCPProtoAssetAnalysis moviePetsResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePetsFaceResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePetsFaceResults]
  -[VCPProtoAssetAnalysis moviePetsFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis setStatsFlags:]
  -[VCPProtoAssetAnalysis setHasStatsFlags:]
  -[VCPProtoAssetAnalysis hasStatsFlags]
  -[VCPProtoAssetAnalysis hasAssetAdjustedFingerprint]
  -[VCPProtoAssetAnalysis statsFlags]
  -[VCPProtoAssetAnalysis assetModificationDate]
  -[VCPProtoAssetAnalysis setAssetModificationDate:]
  -[VCPProtoAssetAnalysis assetMasterFingerprint]
  -[VCPProtoAssetAnalysis assetAdjustedFingerprint]
  -[VCPProtoAssetAnalysis imageBlurResults]
  -[VCPProtoAssetAnalysis setImageBlurResults:]
  -[VCPProtoAssetAnalysis imageCompositionResults]
  -[VCPProtoAssetAnalysis setImageCompositionResults:]
  -[VCPProtoAssetAnalysis imageFaceResults]
  -[VCPProtoAssetAnalysis setImageFaceResults:]
  -[VCPProtoAssetAnalysis imageFeatureResults]
  -[VCPProtoAssetAnalysis setImageFeatureResults:]
  -[VCPProtoAssetAnalysis imageJunkResults]
  -[VCPProtoAssetAnalysis setImageJunkResults:]
  -[VCPProtoAssetAnalysis imageSaliencyResults]
  -[VCPProtoAssetAnalysis setImageSaliencyResults:]
  -[VCPProtoAssetAnalysis imageShotTypeResults]
  -[VCPProtoAssetAnalysis setImageShotTypeResults:]
  -[VCPProtoAssetAnalysis imagePetsResults]
  -[VCPProtoAssetAnalysis setImagePetsResults:]
  -[VCPProtoAssetAnalysis imagePetsFaceResults]
  -[VCPProtoAssetAnalysis setImagePetsFaceResults:]
  -[VCPProtoAssetAnalysis imageSceneprintResults]
  -[VCPProtoAssetAnalysis setImageSceneprintResults:]
  -[VCPProtoAssetAnalysis livePhotoEffectsResults]
  -[VCPProtoAssetAnalysis setLivePhotoEffectsResults:]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResults]
  -[VCPProtoAssetAnalysis setLivePhotoRecommendationResults:]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResults]
  -[VCPProtoAssetAnalysis setLivePhotoSharpnessResults:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResults]
  -[VCPProtoAssetAnalysis setLivePhotoKeyFrameResults:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResults]
  -[VCPProtoAssetAnalysis setLivePhotoKeyFrameStillResults:]
  -[VCPProtoAssetAnalysis movieActivityLevelResults]
  -[VCPProtoAssetAnalysis setMovieActivityLevelResults:]
  -[VCPProtoAssetAnalysis movieCameraMotionResults]
  -[VCPProtoAssetAnalysis setMovieCameraMotionResults:]
  -[VCPProtoAssetAnalysis movieClassificationResults]
  -[VCPProtoAssetAnalysis setMovieClassificationResults:]
  -[VCPProtoAssetAnalysis movieFaceResults]
  -[VCPProtoAssetAnalysis setMovieFaceResults:]
  -[VCPProtoAssetAnalysis movieFaceprintResults]
  -[VCPProtoAssetAnalysis setMovieFaceprintResults:]
  -[VCPProtoAssetAnalysis movieFeatureResults]
  -[VCPProtoAssetAnalysis setMovieFeatureResults:]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResults]
  -[VCPProtoAssetAnalysis setMovieFineSubjectMotionResults:]
  -[VCPProtoAssetAnalysis movieInterestingnessResults]
  -[VCPProtoAssetAnalysis setMovieInterestingnessResults:]
  -[VCPProtoAssetAnalysis movieMovingObjectResults]
  -[VCPProtoAssetAnalysis setMovieMovingObjectResults:]
  -[VCPProtoAssetAnalysis movieMusicResults]
  -[VCPProtoAssetAnalysis setMovieMusicResults:]
  -[VCPProtoAssetAnalysis movieObstructionResults]
  -[VCPProtoAssetAnalysis setMovieObstructionResults:]
  -[VCPProtoAssetAnalysis movieOrientationResults]
  -[VCPProtoAssetAnalysis setMovieOrientationResults:]
  -[VCPProtoAssetAnalysis moviePreEncodeResults]
  -[VCPProtoAssetAnalysis setMoviePreEncodeResults:]
  -[VCPProtoAssetAnalysis movieQualityResults]
  -[VCPProtoAssetAnalysis setMovieQualityResults:]
  -[VCPProtoAssetAnalysis movieSaliencyResults]
  -[VCPProtoAssetAnalysis setMovieSaliencyResults:]
  -[VCPProtoAssetAnalysis movieSceneResults]
  -[VCPProtoAssetAnalysis setMovieSceneResults:]
  -[VCPProtoAssetAnalysis movieSceneprintResults]
  -[VCPProtoAssetAnalysis setMovieSceneprintResults:]
  -[VCPProtoAssetAnalysis movieSubjectMotionResults]
  -[VCPProtoAssetAnalysis setMovieSubjectMotionResults:]
  -[VCPProtoAssetAnalysis movieSubtleMotionResults]
  -[VCPProtoAssetAnalysis setMovieSubtleMotionResults:]
  -[VCPProtoAssetAnalysis movieUtteranceResults]
  -[VCPProtoAssetAnalysis setMovieUtteranceResults:]
  -[VCPProtoAssetAnalysis movieVoiceResults]
  -[VCPProtoAssetAnalysis setMovieVoiceResults:]
  -[VCPProtoAssetAnalysis movieSummaryResults]
  -[VCPProtoAssetAnalysis setMovieSummaryResults:]
  -[VCPProtoAssetAnalysis movieHighlightResults]
  -[VCPProtoAssetAnalysis setMovieHighlightResults:]
  -[VCPProtoAssetAnalysis imageExposureResults]
  -[VCPProtoAssetAnalysis setImageExposureResults:]
  -[VCPProtoAssetAnalysis imageHumanPoseResults]
  -[VCPProtoAssetAnalysis setImageHumanPoseResults:]
  -[VCPProtoAssetAnalysis movieHumanPoseResults]
  -[VCPProtoAssetAnalysis setMovieHumanPoseResults:]
  -[VCPProtoAssetAnalysis movieApplauseResults]
  -[VCPProtoAssetAnalysis setMovieApplauseResults:]
  -[VCPProtoAssetAnalysis movieBabbleResults]
  -[VCPProtoAssetAnalysis setMovieBabbleResults:]
  -[VCPProtoAssetAnalysis movieCheeringResults]
  -[VCPProtoAssetAnalysis setMovieCheeringResults:]
  -[VCPProtoAssetAnalysis movieLaughterResults]
  -[VCPProtoAssetAnalysis setMovieLaughterResults:]
  -[VCPProtoAssetAnalysis movieHumanActionResults]
  -[VCPProtoAssetAnalysis setMovieHumanActionResults:]
  -[VCPProtoAssetAnalysis movieLoudnessResults]
  -[VCPProtoAssetAnalysis setMovieLoudnessResults:]
  -[VCPProtoAssetAnalysis moviePetsResults]
  -[VCPProtoAssetAnalysis setMoviePetsResults:]
  -[VCPProtoAssetAnalysis moviePetsFaceResults]
  -[VCPProtoAssetAnalysis setMoviePetsFaceResults:]
  -[VCPProtoAssetAnalysis setAttributesFromLegacyDictionary:]
  -[VCPProtoAssetAnalysis setResults:withClass:forPropertyKey:]
  -[VCPProtoAssetAnalysis exportResultsWithPropertyKey:toLegacyDictionary:withKey:]


VCPProtoBounds : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  double x0
 @property  double y0
 @property  double width
 @property  double height

  // class methods
  +[VCPProtoBounds boundsWithCGRect:]

  // instance methods
  -[VCPProtoBounds isEqual:]
  -[VCPProtoBounds copyWithZone:]
  -[VCPProtoBounds rectValue]
  -[VCPProtoBounds dictionaryRepresentation]
  -[VCPProtoBounds writeTo:]
  -[VCPProtoBounds width]
  -[VCPProtoBounds height]
  -[VCPProtoBounds setWidth:]
  -[VCPProtoBounds setHeight:]
  -[VCPProtoBounds mergeFrom:]
  -[VCPProtoBounds readFrom:]
  -[VCPProtoBounds copyTo:]
  -[VCPProtoBounds x0]
  -[VCPProtoBounds setX0:]
  -[VCPProtoBounds y0]
  -[VCPProtoBounds setY0:]


VCPImageMotionFlowAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageMotionFlowAnalyzer init]
  -[VCPImageMotionFlowAnalyzer dealloc]
  -[VCPImageMotionFlowAnalyzer .cxx_destruct]
  -[VCPImageMotionFlowAnalyzer .cxx_construct]
  -[VCPImageMotionFlowAnalyzer createModel]
  -[VCPImageMotionFlowAnalyzer copyImage:toData:withChannels:]
  -[VCPImageMotionFlowAnalyzer createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPImageMotionFlowAnalyzer analyzeImages:secondImage:moflow:cancel:]


VCPProtoClassification : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  unsigned int identifier
 @property  float confidence

  // instance methods
  -[VCPProtoClassification isEqual:]
  -[VCPProtoClassification copyWithZone:]
  -[VCPProtoClassification identifier]
  -[VCPProtoClassification setIdentifier:]
  -[VCPProtoClassification dictionaryRepresentation]
  -[VCPProtoClassification confidence]
  -[VCPProtoClassification writeTo:]
  -[VCPProtoClassification mergeFrom:]
  -[VCPProtoClassification readFrom:]
  -[VCPProtoClassification copyTo:]
  -[VCPProtoClassification setConfidence:]


VCPProtoImageBlurResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness
 @property  BOOL hasFaceSharpness
 @property  float faceSharpness

  // class methods
  +[VCPProtoImageBlurResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageBlurResult isEqual:]
  -[VCPProtoImageBlurResult copyWithZone:]
  -[VCPProtoImageBlurResult dictionaryRepresentation]
  -[VCPProtoImageBlurResult writeTo:]
  -[VCPProtoImageBlurResult sharpness]
  -[VCPProtoImageBlurResult setSharpness:]
  -[VCPProtoImageBlurResult mergeFrom:]
  -[VCPProtoImageBlurResult readFrom:]
  -[VCPProtoImageBlurResult copyTo:]
  -[VCPProtoImageBlurResult exportToLegacyDictionary]
  -[VCPProtoImageBlurResult setHasFaceSharpness:]
  -[VCPProtoImageBlurResult hasFaceSharpness]
  -[VCPProtoImageBlurResult faceSharpness]
  -[VCPProtoImageBlurResult setFaceSharpness:]


VCPProtoImageCompositionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoPoint *vanishingPoint
 @property  VCPProtoLine *dominantLine

  // class methods
  +[VCPProtoImageCompositionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageCompositionResult isEqual:]
  -[VCPProtoImageCompositionResult copyWithZone:]
  -[VCPProtoImageCompositionResult .cxx_destruct]
  -[VCPProtoImageCompositionResult dictionaryRepresentation]
  -[VCPProtoImageCompositionResult confidence]
  -[VCPProtoImageCompositionResult writeTo:]
  -[VCPProtoImageCompositionResult mergeFrom:]
  -[VCPProtoImageCompositionResult readFrom:]
  -[VCPProtoImageCompositionResult copyTo:]
  -[VCPProtoImageCompositionResult setConfidence:]
  -[VCPProtoImageCompositionResult setVanishingPoint:]
  -[VCPProtoImageCompositionResult vanishingPoint]
  -[VCPProtoImageCompositionResult exportToLegacyDictionary]
  -[VCPProtoImageCompositionResult setDominantLine:]
  -[VCPProtoImageCompositionResult dominantLine]


VCPProtoImageExposureResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float exposure
 @property  BOOL hasUnderExpose
 @property  float underExpose

  // class methods
  +[VCPProtoImageExposureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageExposureResult isEqual:]
  -[VCPProtoImageExposureResult copyWithZone:]
  -[VCPProtoImageExposureResult dictionaryRepresentation]
  -[VCPProtoImageExposureResult writeTo:]
  -[VCPProtoImageExposureResult mergeFrom:]
  -[VCPProtoImageExposureResult readFrom:]
  -[VCPProtoImageExposureResult copyTo:]
  -[VCPProtoImageExposureResult exposure]
  -[VCPProtoImageExposureResult setExposure:]
  -[VCPProtoImageExposureResult exportToLegacyDictionary]
  -[VCPProtoImageExposureResult setUnderExpose:]
  -[VCPProtoImageExposureResult setHasUnderExpose:]
  -[VCPProtoImageExposureResult hasUnderExpose]
  -[VCPProtoImageExposureResult underExpose]


VCPLoudnessAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPLoudnessAnalyzer init]
  -[VCPLoudnessAnalyzer dealloc]
  -[VCPLoudnessAnalyzer .cxx_destruct]
  -[VCPLoudnessAnalyzer results]
  -[VCPLoudnessAnalyzer .cxx_construct]
  -[VCPLoudnessAnalyzer setupWithSample:andSampleBatchSize:]
  -[VCPLoudnessAnalyzer processAudioSamples:timestamp:]
  -[VCPLoudnessAnalyzer finalizeAnalysisAtTime:]


VCPProtoImageFaceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int eyeExpression
 @property  int mouthExpression
 @property  int yaw
 @property  int position
 @property  VCPProtoBounds *bounds
 @property  BOOL isCloseup
 @property  BOOL hasFaceQuality
 @property  float faceQuality

  // class methods
  +[VCPProtoImageFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageFaceResult isEqual:]
  -[VCPProtoImageFaceResult copyWithZone:]
  -[VCPProtoImageFaceResult .cxx_destruct]
  -[VCPProtoImageFaceResult dictionaryRepresentation]
  -[VCPProtoImageFaceResult position]
  -[VCPProtoImageFaceResult writeTo:]
  -[VCPProtoImageFaceResult bounds]
  -[VCPProtoImageFaceResult setBounds:]
  -[VCPProtoImageFaceResult yaw]
  -[VCPProtoImageFaceResult setYaw:]
  -[VCPProtoImageFaceResult mergeFrom:]
  -[VCPProtoImageFaceResult readFrom:]
  -[VCPProtoImageFaceResult copyTo:]
  -[VCPProtoImageFaceResult setPosition:]
  -[VCPProtoImageFaceResult faceQuality]
  -[VCPProtoImageFaceResult setFaceQuality:]
  -[VCPProtoImageFaceResult exportToLegacyDictionary]
  -[VCPProtoImageFaceResult setHasFaceQuality:]
  -[VCPProtoImageFaceResult hasFaceQuality]
  -[VCPProtoImageFaceResult eyeExpression]
  -[VCPProtoImageFaceResult setEyeExpression:]
  -[VCPProtoImageFaceResult mouthExpression]
  -[VCPProtoImageFaceResult setMouthExpression:]
  -[VCPProtoImageFaceResult isCloseup]
  -[VCPProtoImageFaceResult setIsCloseup:]


VCPProtoImageFeatureResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *featureBlob

  // class methods
  +[VCPProtoImageFeatureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageFeatureResult isEqual:]
  -[VCPProtoImageFeatureResult copyWithZone:]
  -[VCPProtoImageFeatureResult .cxx_destruct]
  -[VCPProtoImageFeatureResult dictionaryRepresentation]
  -[VCPProtoImageFeatureResult writeTo:]
  -[VCPProtoImageFeatureResult mergeFrom:]
  -[VCPProtoImageFeatureResult readFrom:]
  -[VCPProtoImageFeatureResult copyTo:]
  -[VCPProtoImageFeatureResult exportToLegacyDictionary]
  -[VCPProtoImageFeatureResult setFeatureBlob:]
  -[VCPProtoImageFeatureResult featureBlob]


VCPProtoImageJunkResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence

  // class methods
  +[VCPProtoImageJunkResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageJunkResult isEqual:]
  -[VCPProtoImageJunkResult copyWithZone:]
  -[VCPProtoImageJunkResult dictionaryRepresentation]
  -[VCPProtoImageJunkResult confidence]
  -[VCPProtoImageJunkResult writeTo:]
  -[VCPProtoImageJunkResult mergeFrom:]
  -[VCPProtoImageJunkResult readFrom:]
  -[VCPProtoImageJunkResult copyTo:]
  -[VCPProtoImageJunkResult setConfidence:]
  -[VCPProtoImageJunkResult exportToLegacyDictionary]


VCPProtoImagePetsFaceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImagePetsFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImagePetsFaceResult isEqual:]
  -[VCPProtoImagePetsFaceResult copyWithZone:]
  -[VCPProtoImagePetsFaceResult .cxx_destruct]
  -[VCPProtoImagePetsFaceResult dictionaryRepresentation]
  -[VCPProtoImagePetsFaceResult confidence]
  -[VCPProtoImagePetsFaceResult writeTo:]
  -[VCPProtoImagePetsFaceResult bounds]
  -[VCPProtoImagePetsFaceResult setBounds:]
  -[VCPProtoImagePetsFaceResult mergeFrom:]
  -[VCPProtoImagePetsFaceResult readFrom:]
  -[VCPProtoImagePetsFaceResult copyTo:]
  -[VCPProtoImagePetsFaceResult setConfidence:]
  -[VCPProtoImagePetsFaceResult exportToLegacyDictionary]


VCPProtoMovieLaughterResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieLaughterResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieLaughterResult isEqual:]
  -[VCPProtoMovieLaughterResult copyWithZone:]
  -[VCPProtoMovieLaughterResult .cxx_destruct]
  -[VCPProtoMovieLaughterResult dictionaryRepresentation]
  -[VCPProtoMovieLaughterResult confidence]
  -[VCPProtoMovieLaughterResult writeTo:]
  -[VCPProtoMovieLaughterResult mergeFrom:]
  -[VCPProtoMovieLaughterResult readFrom:]
  -[VCPProtoMovieLaughterResult copyTo:]
  -[VCPProtoMovieLaughterResult setConfidence:]
  -[VCPProtoMovieLaughterResult setTimeRange:]
  -[VCPProtoMovieLaughterResult timeRange]
  -[VCPProtoMovieLaughterResult exportToLegacyDictionary]


VCPProtoImagePetsResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImagePetsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImagePetsResult isEqual:]
  -[VCPProtoImagePetsResult copyWithZone:]
  -[VCPProtoImagePetsResult .cxx_destruct]
  -[VCPProtoImagePetsResult dictionaryRepresentation]
  -[VCPProtoImagePetsResult confidence]
  -[VCPProtoImagePetsResult writeTo:]
  -[VCPProtoImagePetsResult bounds]
  -[VCPProtoImagePetsResult setBounds:]
  -[VCPProtoImagePetsResult mergeFrom:]
  -[VCPProtoImagePetsResult readFrom:]
  -[VCPProtoImagePetsResult copyTo:]
  -[VCPProtoImagePetsResult setConfidence:]
  -[VCPProtoImagePetsResult exportToLegacyDictionary]


VCPProtoImageSaliencyResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImageSaliencyResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageSaliencyResult isEqual:]
  -[VCPProtoImageSaliencyResult copyWithZone:]
  -[VCPProtoImageSaliencyResult .cxx_destruct]
  -[VCPProtoImageSaliencyResult dictionaryRepresentation]
  -[VCPProtoImageSaliencyResult confidence]
  -[VCPProtoImageSaliencyResult writeTo:]
  -[VCPProtoImageSaliencyResult bounds]
  -[VCPProtoImageSaliencyResult setBounds:]
  -[VCPProtoImageSaliencyResult mergeFrom:]
  -[VCPProtoImageSaliencyResult readFrom:]
  -[VCPProtoImageSaliencyResult copyTo:]
  -[VCPProtoImageSaliencyResult setConfidence:]
  -[VCPProtoImageSaliencyResult exportToLegacyDictionary]


VCPProtoImageShotTypeResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int shotType

  // class methods
  +[VCPProtoImageShotTypeResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageShotTypeResult isEqual:]
  -[VCPProtoImageShotTypeResult copyWithZone:]
  -[VCPProtoImageShotTypeResult dictionaryRepresentation]
  -[VCPProtoImageShotTypeResult writeTo:]
  -[VCPProtoImageShotTypeResult mergeFrom:]
  -[VCPProtoImageShotTypeResult readFrom:]
  -[VCPProtoImageShotTypeResult copyTo:]
  -[VCPProtoImageShotTypeResult shotType]
  -[VCPProtoImageShotTypeResult exportToLegacyDictionary]
  -[VCPProtoImageShotTypeResult setShotType:]


VCPProtoLine : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  VCPProtoPoint *start
 @property  VCPProtoPoint *end

  // class methods
  +[VCPProtoLine lineFromPoint:toPoint:]

  // instance methods
  -[VCPProtoLine isEqual:]
  -[VCPProtoLine copyWithZone:]
  -[VCPProtoLine .cxx_destruct]
  -[VCPProtoLine start]
  -[VCPProtoLine dictionaryRepresentation]
  -[VCPProtoLine end]
  -[VCPProtoLine writeTo:]
  -[VCPProtoLine mergeFrom:]
  -[VCPProtoLine readFrom:]
  -[VCPProtoLine copyTo:]
  -[VCPProtoLine setStart:]
  -[VCPProtoLine setEnd:]
  -[VCPProtoLine startPointValue]
  -[VCPProtoLine endPointValue]


VCPProtoMovieCheeringResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieCheeringResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieCheeringResult isEqual:]
  -[VCPProtoMovieCheeringResult copyWithZone:]
  -[VCPProtoMovieCheeringResult .cxx_destruct]
  -[VCPProtoMovieCheeringResult dictionaryRepresentation]
  -[VCPProtoMovieCheeringResult confidence]
  -[VCPProtoMovieCheeringResult writeTo:]
  -[VCPProtoMovieCheeringResult mergeFrom:]
  -[VCPProtoMovieCheeringResult readFrom:]
  -[VCPProtoMovieCheeringResult copyTo:]
  -[VCPProtoMovieCheeringResult setConfidence:]
  -[VCPProtoMovieCheeringResult setTimeRange:]
  -[VCPProtoMovieCheeringResult timeRange]
  -[VCPProtoMovieCheeringResult exportToLegacyDictionary]


VCPProtoLivePhotoEffectsRecipe : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int stabilizeResult
 @property  long long outputFrameDurValue
 @property  int cropRectX
 @property  int cropRectY
 @property  int cropRectHeight
 @property  int cropRectWidth
 @property  int timeScale
 @property  BOOL hasEpoch
 @property  long long epoch
 @property  BOOL hasFlags
 @property  int flags
 @property  NSMutableArray *frameInstructions
 @property  VCPProtoLivePhotoVariationParams *autoloop
 @property  VCPProtoLivePhotoVariationParams *bounce
 @property  VCPProtoLivePhotoVariationParams *longexposure
 @property  VCPProtoLivePhotoVariationParams *stabilize
 @property  int minVersion
 @property  int version

  // class methods
  +[VCPProtoLivePhotoEffectsRecipe resultFromLegacyDictionary:]
  +[VCPProtoLivePhotoEffectsRecipe frameInstructionsType]

  // instance methods
  -[VCPProtoLivePhotoEffectsRecipe isEqual:]
  -[VCPProtoLivePhotoEffectsRecipe copyWithZone:]
  -[VCPProtoLivePhotoEffectsRecipe .cxx_destruct]
  -[VCPProtoLivePhotoEffectsRecipe flags]
  -[VCPProtoLivePhotoEffectsRecipe version]
  -[VCPProtoLivePhotoEffectsRecipe dictionaryRepresentation]
  -[VCPProtoLivePhotoEffectsRecipe setVersion:]
  -[VCPProtoLivePhotoEffectsRecipe epoch]
  -[VCPProtoLivePhotoEffectsRecipe setEpoch:]
  -[VCPProtoLivePhotoEffectsRecipe writeTo:]
  -[VCPProtoLivePhotoEffectsRecipe mergeFrom:]
  -[VCPProtoLivePhotoEffectsRecipe readFrom:]
  -[VCPProtoLivePhotoEffectsRecipe copyTo:]
  -[VCPProtoLivePhotoEffectsRecipe setFlags:]
  -[VCPProtoLivePhotoEffectsRecipe bounce]
  -[VCPProtoLivePhotoEffectsRecipe timeScale]
  -[VCPProtoLivePhotoEffectsRecipe setHasFlags:]
  -[VCPProtoLivePhotoEffectsRecipe hasFlags]
  -[VCPProtoLivePhotoEffectsRecipe minVersion]
  -[VCPProtoLivePhotoEffectsRecipe setMinVersion:]
  -[VCPProtoLivePhotoEffectsRecipe hasEpoch]
  -[VCPProtoLivePhotoEffectsRecipe setHasEpoch:]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionary]
  -[VCPProtoLivePhotoEffectsRecipe addFrameInstructions:]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructionsCount]
  -[VCPProtoLivePhotoEffectsRecipe clearFrameInstructions]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructionsAtIndex:]
  -[VCPProtoLivePhotoEffectsRecipe setAutoloop:]
  -[VCPProtoLivePhotoEffectsRecipe setBounce:]
  -[VCPProtoLivePhotoEffectsRecipe setLongexposure:]
  -[VCPProtoLivePhotoEffectsRecipe setStabilize:]
  -[VCPProtoLivePhotoEffectsRecipe stabilizeResult]
  -[VCPProtoLivePhotoEffectsRecipe setStabilizeResult:]
  -[VCPProtoLivePhotoEffectsRecipe outputFrameDurValue]
  -[VCPProtoLivePhotoEffectsRecipe setOutputFrameDurValue:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectX]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectX:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectY]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectY:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectHeight]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectHeight:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectWidth]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectWidth:]
  -[VCPProtoLivePhotoEffectsRecipe setTimeScale:]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructions]
  -[VCPProtoLivePhotoEffectsRecipe setFrameInstructions:]
  -[VCPProtoLivePhotoEffectsRecipe autoloop]
  -[VCPProtoLivePhotoEffectsRecipe longexposure]
  -[VCPProtoLivePhotoEffectsRecipe stabilize]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionaryFromFrameInstruction:]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionaryFromParam:withLoopFlavor:]


VCPProtoLivePhotoEffectsResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  unsigned long loopSuggestionState
 @property  unsigned long longExposureSuggestionState
 @property  BOOL hasRecipeBlob
 @property  NSData *recipeBlob

  // class methods
  +[VCPProtoLivePhotoEffectsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoEffectsResult isEqual:]
  -[VCPProtoLivePhotoEffectsResult copyWithZone:]
  -[VCPProtoLivePhotoEffectsResult .cxx_destruct]
  -[VCPProtoLivePhotoEffectsResult dictionaryRepresentation]
  -[VCPProtoLivePhotoEffectsResult writeTo:]
  -[VCPProtoLivePhotoEffectsResult mergeFrom:]
  -[VCPProtoLivePhotoEffectsResult readFrom:]
  -[VCPProtoLivePhotoEffectsResult copyTo:]
  -[VCPProtoLivePhotoEffectsResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoEffectsResult setRecipeBlob:]
  -[VCPProtoLivePhotoEffectsResult hasRecipeBlob]
  -[VCPProtoLivePhotoEffectsResult loopSuggestionState]
  -[VCPProtoLivePhotoEffectsResult setLoopSuggestionState:]
  -[VCPProtoLivePhotoEffectsResult longExposureSuggestionState]
  -[VCPProtoLivePhotoEffectsResult setLongExposureSuggestionState:]
  -[VCPProtoLivePhotoEffectsResult recipeBlob]


VCPProtoLivePhotoFrameInstruction : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  long long timeValue
 @property  unsigned long homographyParamsCount
 @property  ^f homographyParams
 @property  int timeScale
 @property  long long epoch
 @property  int flags

  // class methods
  +[VCPProtoLivePhotoFrameInstruction resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoFrameInstruction dealloc]
  -[VCPProtoLivePhotoFrameInstruction isEqual:]
  -[VCPProtoLivePhotoFrameInstruction copyWithZone:]
  -[VCPProtoLivePhotoFrameInstruction flags]
  -[VCPProtoLivePhotoFrameInstruction dictionaryRepresentation]
  -[VCPProtoLivePhotoFrameInstruction epoch]
  -[VCPProtoLivePhotoFrameInstruction setEpoch:]
  -[VCPProtoLivePhotoFrameInstruction writeTo:]
  -[VCPProtoLivePhotoFrameInstruction mergeFrom:]
  -[VCPProtoLivePhotoFrameInstruction readFrom:]
  -[VCPProtoLivePhotoFrameInstruction copyTo:]
  -[VCPProtoLivePhotoFrameInstruction setFlags:]
  -[VCPProtoLivePhotoFrameInstruction timeScale]
  -[VCPProtoLivePhotoFrameInstruction exportToLegacyDictionary]
  -[VCPProtoLivePhotoFrameInstruction setTimeScale:]
  -[VCPProtoLivePhotoFrameInstruction homographyParamsCount]
  -[VCPProtoLivePhotoFrameInstruction clearHomographyParams]
  -[VCPProtoLivePhotoFrameInstruction homographyParamAtIndex:]
  -[VCPProtoLivePhotoFrameInstruction addHomographyParam:]
  -[VCPProtoLivePhotoFrameInstruction homographyParams]
  -[VCPProtoLivePhotoFrameInstruction setHomographyParams:count:]
  -[VCPProtoLivePhotoFrameInstruction timeValue]
  -[VCPProtoLivePhotoFrameInstruction setTimeValue:]


VCPProtoLivePhotoRecommendationResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore

  // class methods
  +[VCPProtoLivePhotoRecommendationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoRecommendationResult isEqual:]
  -[VCPProtoLivePhotoRecommendationResult copyWithZone:]
  -[VCPProtoLivePhotoRecommendationResult .cxx_destruct]
  -[VCPProtoLivePhotoRecommendationResult dictionaryRepresentation]
  -[VCPProtoLivePhotoRecommendationResult writeTo:]
  -[VCPProtoLivePhotoRecommendationResult mergeFrom:]
  -[VCPProtoLivePhotoRecommendationResult readFrom:]
  -[VCPProtoLivePhotoRecommendationResult copyTo:]
  -[VCPProtoLivePhotoRecommendationResult setTimeRange:]
  -[VCPProtoLivePhotoRecommendationResult timeRange]
  -[VCPProtoLivePhotoRecommendationResult qualityScore]
  -[VCPProtoLivePhotoRecommendationResult setQualityScore:]
  -[VCPProtoLivePhotoRecommendationResult exportToLegacyDictionary]


VCPProtoLivePhotoSharpnessResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness

  // class methods
  +[VCPProtoLivePhotoSharpnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoSharpnessResult isEqual:]
  -[VCPProtoLivePhotoSharpnessResult copyWithZone:]
  -[VCPProtoLivePhotoSharpnessResult dictionaryRepresentation]
  -[VCPProtoLivePhotoSharpnessResult writeTo:]
  -[VCPProtoLivePhotoSharpnessResult sharpness]
  -[VCPProtoLivePhotoSharpnessResult setSharpness:]
  -[VCPProtoLivePhotoSharpnessResult mergeFrom:]
  -[VCPProtoLivePhotoSharpnessResult readFrom:]
  -[VCPProtoLivePhotoSharpnessResult copyTo:]
  -[VCPProtoLivePhotoSharpnessResult exportToLegacyDictionary]


VCPProtoLivePhotoVariationParams : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int errorCode
 @property  BOOL hasLoopFadeLen
 @property  int loopFadeLen
 @property  BOOL hasLoopPeriod
 @property  int loopPeriod
 @property  BOOL hasLoopStart
 @property  int loopStart

  // class methods
  +[VCPProtoLivePhotoVariationParams resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoVariationParams isEqual:]
  -[VCPProtoLivePhotoVariationParams copyWithZone:]
  -[VCPProtoLivePhotoVariationParams dictionaryRepresentation]
  -[VCPProtoLivePhotoVariationParams writeTo:]
  -[VCPProtoLivePhotoVariationParams mergeFrom:]
  -[VCPProtoLivePhotoVariationParams readFrom:]
  -[VCPProtoLivePhotoVariationParams copyTo:]
  -[VCPProtoLivePhotoVariationParams errorCode]
  -[VCPProtoLivePhotoVariationParams setErrorCode:]
  -[VCPProtoLivePhotoVariationParams exportToLegacyDictionary]
  -[VCPProtoLivePhotoVariationParams setLoopFadeLen:]
  -[VCPProtoLivePhotoVariationParams setHasLoopFadeLen:]
  -[VCPProtoLivePhotoVariationParams hasLoopFadeLen]
  -[VCPProtoLivePhotoVariationParams setLoopPeriod:]
  -[VCPProtoLivePhotoVariationParams setHasLoopPeriod:]
  -[VCPProtoLivePhotoVariationParams hasLoopPeriod]
  -[VCPProtoLivePhotoVariationParams setLoopStart:]
  -[VCPProtoLivePhotoVariationParams setHasLoopStart:]
  -[VCPProtoLivePhotoVariationParams hasLoopStart]
  -[VCPProtoLivePhotoVariationParams loopFadeLen]
  -[VCPProtoLivePhotoVariationParams loopPeriod]
  -[VCPProtoLivePhotoVariationParams loopStart]


VCPProtoMovieActivityLevelResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float activityScore

  // class methods
  +[VCPProtoMovieActivityLevelResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieActivityLevelResult isEqual:]
  -[VCPProtoMovieActivityLevelResult copyWithZone:]
  -[VCPProtoMovieActivityLevelResult .cxx_destruct]
  -[VCPProtoMovieActivityLevelResult dictionaryRepresentation]
  -[VCPProtoMovieActivityLevelResult writeTo:]
  -[VCPProtoMovieActivityLevelResult mergeFrom:]
  -[VCPProtoMovieActivityLevelResult readFrom:]
  -[VCPProtoMovieActivityLevelResult copyTo:]
  -[VCPProtoMovieActivityLevelResult setTimeRange:]
  -[VCPProtoMovieActivityLevelResult timeRange]
  -[VCPProtoMovieActivityLevelResult setActivityScore:]
  -[VCPProtoMovieActivityLevelResult activityScore]
  -[VCPProtoMovieActivityLevelResult exportToLegacyDictionary]


VCPProtoMovieCameraMotionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int motionType
 @property  BOOL isFast

  // class methods
  +[VCPProtoMovieCameraMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieCameraMotionResult isEqual:]
  -[VCPProtoMovieCameraMotionResult copyWithZone:]
  -[VCPProtoMovieCameraMotionResult .cxx_destruct]
  -[VCPProtoMovieCameraMotionResult dictionaryRepresentation]
  -[VCPProtoMovieCameraMotionResult writeTo:]
  -[VCPProtoMovieCameraMotionResult mergeFrom:]
  -[VCPProtoMovieCameraMotionResult readFrom:]
  -[VCPProtoMovieCameraMotionResult copyTo:]
  -[VCPProtoMovieCameraMotionResult motionType]
  -[VCPProtoMovieCameraMotionResult setTimeRange:]
  -[VCPProtoMovieCameraMotionResult timeRange]
  -[VCPProtoMovieCameraMotionResult setMotionType:]
  -[VCPProtoMovieCameraMotionResult exportToLegacyDictionary]
  -[VCPProtoMovieCameraMotionResult isFast]
  -[VCPProtoMovieCameraMotionResult setIsFast:]


VCPHomeKitMotionAnalyzer : VCPVideoAnalyzer
 @property  float actionScore

  // instance methods
  -[VCPHomeKitMotionAnalyzer init]
  -[VCPHomeKitMotionAnalyzer dealloc]
  -[VCPHomeKitMotionAnalyzer .cxx_destruct]
  -[VCPHomeKitMotionAnalyzer .cxx_construct]
  -[VCPHomeKitMotionAnalyzer actionScore]
  -[VCPHomeKitMotionAnalyzer setPixelBuffer:]
  -[VCPHomeKitMotionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPHomeKitMotionAnalyzer regionsOfInterest]
  -[VCPHomeKitMotionAnalyzer calculateFrameDifference:]
  -[VCPHomeKitMotionAnalyzer computeRegionsofInterest]


VCPProtoMovieClassificationResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *classifications

  // class methods
  +[VCPProtoMovieClassificationResult resultFromLegacyDictionary:]
  +[VCPProtoMovieClassificationResult classificationType]

  // instance methods
  -[VCPProtoMovieClassificationResult isEqual:]
  -[VCPProtoMovieClassificationResult copyWithZone:]
  -[VCPProtoMovieClassificationResult .cxx_destruct]
  -[VCPProtoMovieClassificationResult dictionaryRepresentation]
  -[VCPProtoMovieClassificationResult writeTo:]
  -[VCPProtoMovieClassificationResult mergeFrom:]
  -[VCPProtoMovieClassificationResult readFrom:]
  -[VCPProtoMovieClassificationResult copyTo:]
  -[VCPProtoMovieClassificationResult setTimeRange:]
  -[VCPProtoMovieClassificationResult timeRange]
  -[VCPProtoMovieClassificationResult classifications]
  -[VCPProtoMovieClassificationResult exportToLegacyDictionary]
  -[VCPProtoMovieClassificationResult addClassification:]
  -[VCPProtoMovieClassificationResult classificationsCount]
  -[VCPProtoMovieClassificationResult clearClassifications]
  -[VCPProtoMovieClassificationResult classificationAtIndex:]
  -[VCPProtoMovieClassificationResult setClassifications:]


VCPProtoMovieFaceprintResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  unsigned int faceID
 @property  NSData *faceprintBlob

  // class methods
  +[VCPProtoMovieFaceprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFaceprintResult isEqual:]
  -[VCPProtoMovieFaceprintResult copyWithZone:]
  -[VCPProtoMovieFaceprintResult .cxx_destruct]
  -[VCPProtoMovieFaceprintResult dictionaryRepresentation]
  -[VCPProtoMovieFaceprintResult writeTo:]
  -[VCPProtoMovieFaceprintResult mergeFrom:]
  -[VCPProtoMovieFaceprintResult readFrom:]
  -[VCPProtoMovieFaceprintResult copyTo:]
  -[VCPProtoMovieFaceprintResult faceID]
  -[VCPProtoMovieFaceprintResult setFaceID:]
  -[VCPProtoMovieFaceprintResult exportToLegacyDictionary]
  -[VCPProtoMovieFaceprintResult setFaceprintBlob:]
  -[VCPProtoMovieFaceprintResult faceprintBlob]


VCPProtoMovieFaceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int mouthExpression
 @property  int position
 @property  VCPProtoBounds *bounds
 @property  BOOL isCloseup
 @property  int faceID

  // class methods
  +[VCPProtoMovieFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFaceResult isEqual:]
  -[VCPProtoMovieFaceResult copyWithZone:]
  -[VCPProtoMovieFaceResult .cxx_destruct]
  -[VCPProtoMovieFaceResult dictionaryRepresentation]
  -[VCPProtoMovieFaceResult position]
  -[VCPProtoMovieFaceResult writeTo:]
  -[VCPProtoMovieFaceResult bounds]
  -[VCPProtoMovieFaceResult setBounds:]
  -[VCPProtoMovieFaceResult mergeFrom:]
  -[VCPProtoMovieFaceResult readFrom:]
  -[VCPProtoMovieFaceResult copyTo:]
  -[VCPProtoMovieFaceResult setPosition:]
  -[VCPProtoMovieFaceResult setTimeRange:]
  -[VCPProtoMovieFaceResult timeRange]
  -[VCPProtoMovieFaceResult faceID]
  -[VCPProtoMovieFaceResult setFaceID:]
  -[VCPProtoMovieFaceResult exportToLegacyDictionary]
  -[VCPProtoMovieFaceResult mouthExpression]
  -[VCPProtoMovieFaceResult setMouthExpression:]
  -[VCPProtoMovieFaceResult isCloseup]
  -[VCPProtoMovieFaceResult setIsCloseup:]


VCPProtoMovieFeatureResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTime *timestamp
 @property  NSData *featureBlob

  // class methods
  +[VCPProtoMovieFeatureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFeatureResult isEqual:]
  -[VCPProtoMovieFeatureResult copyWithZone:]
  -[VCPProtoMovieFeatureResult .cxx_destruct]
  -[VCPProtoMovieFeatureResult dictionaryRepresentation]
  -[VCPProtoMovieFeatureResult timestamp]
  -[VCPProtoMovieFeatureResult setTimestamp:]
  -[VCPProtoMovieFeatureResult writeTo:]
  -[VCPProtoMovieFeatureResult mergeFrom:]
  -[VCPProtoMovieFeatureResult readFrom:]
  -[VCPProtoMovieFeatureResult copyTo:]
  -[VCPProtoMovieFeatureResult exportToLegacyDictionary]
  -[VCPProtoMovieFeatureResult setFeatureBlob:]
  -[VCPProtoMovieFeatureResult featureBlob]


VCPProtoMovieFineSubjectMotionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float actionScore

  // class methods
  +[VCPProtoMovieFineSubjectMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFineSubjectMotionResult isEqual:]
  -[VCPProtoMovieFineSubjectMotionResult copyWithZone:]
  -[VCPProtoMovieFineSubjectMotionResult .cxx_destruct]
  -[VCPProtoMovieFineSubjectMotionResult dictionaryRepresentation]
  -[VCPProtoMovieFineSubjectMotionResult writeTo:]
  -[VCPProtoMovieFineSubjectMotionResult setActionScore:]
  -[VCPProtoMovieFineSubjectMotionResult actionScore]
  -[VCPProtoMovieFineSubjectMotionResult mergeFrom:]
  -[VCPProtoMovieFineSubjectMotionResult readFrom:]
  -[VCPProtoMovieFineSubjectMotionResult copyTo:]
  -[VCPProtoMovieFineSubjectMotionResult setTimeRange:]
  -[VCPProtoMovieFineSubjectMotionResult timeRange]
  -[VCPProtoMovieFineSubjectMotionResult exportToLegacyDictionary]


VCPProtoMovieHighlightResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float curationScore
 @property  VCPProtoVideoKeyFrame *keyFrame

  // class methods
  +[VCPProtoMovieHighlightResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHighlightResult isEqual:]
  -[VCPProtoMovieHighlightResult copyWithZone:]
  -[VCPProtoMovieHighlightResult .cxx_destruct]
  -[VCPProtoMovieHighlightResult dictionaryRepresentation]
  -[VCPProtoMovieHighlightResult writeTo:]
  -[VCPProtoMovieHighlightResult mergeFrom:]
  -[VCPProtoMovieHighlightResult readFrom:]
  -[VCPProtoMovieHighlightResult copyTo:]
  -[VCPProtoMovieHighlightResult setTimeRange:]
  -[VCPProtoMovieHighlightResult timeRange]
  -[VCPProtoMovieHighlightResult curationScore]
  -[VCPProtoMovieHighlightResult setCurationScore:]
  -[VCPProtoMovieHighlightResult keyFrame]
  -[VCPProtoMovieHighlightResult setKeyFrame:]
  -[VCPProtoMovieHighlightResult exportToLegacyDictionary]


VCPProtoMovieInterestingnessResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float interestScore

  // class methods
  +[VCPProtoMovieInterestingnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieInterestingnessResult isEqual:]
  -[VCPProtoMovieInterestingnessResult copyWithZone:]
  -[VCPProtoMovieInterestingnessResult .cxx_destruct]
  -[VCPProtoMovieInterestingnessResult dictionaryRepresentation]
  -[VCPProtoMovieInterestingnessResult writeTo:]
  -[VCPProtoMovieInterestingnessResult mergeFrom:]
  -[VCPProtoMovieInterestingnessResult readFrom:]
  -[VCPProtoMovieInterestingnessResult copyTo:]
  -[VCPProtoMovieInterestingnessResult setTimeRange:]
  -[VCPProtoMovieInterestingnessResult timeRange]
  -[VCPProtoMovieInterestingnessResult exportToLegacyDictionary]
  -[VCPProtoMovieInterestingnessResult interestScore]
  -[VCPProtoMovieInterestingnessResult setInterestScore:]


VCPProtoMovieLoudnessResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  double energy
 @property  double peak

  // class methods
  +[VCPProtoMovieLoudnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieLoudnessResult isEqual:]
  -[VCPProtoMovieLoudnessResult copyWithZone:]
  -[VCPProtoMovieLoudnessResult .cxx_destruct]
  -[VCPProtoMovieLoudnessResult dictionaryRepresentation]
  -[VCPProtoMovieLoudnessResult writeTo:]
  -[VCPProtoMovieLoudnessResult mergeFrom:]
  -[VCPProtoMovieLoudnessResult readFrom:]
  -[VCPProtoMovieLoudnessResult copyTo:]
  -[VCPProtoMovieLoudnessResult setTimeRange:]
  -[VCPProtoMovieLoudnessResult timeRange]
  -[VCPProtoMovieLoudnessResult energy]
  -[VCPProtoMovieLoudnessResult setEnergy:]
  -[VCPProtoMovieLoudnessResult exportToLegacyDictionary]
  -[VCPProtoMovieLoudnessResult peak]
  -[VCPProtoMovieLoudnessResult setPeak:]


VCPProtoMovieMovingObjectResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *bounds

  // class methods
  +[VCPProtoMovieMovingObjectResult resultFromLegacyDictionary:]
  +[VCPProtoMovieMovingObjectResult boundsType]

  // instance methods
  -[VCPProtoMovieMovingObjectResult isEqual:]
  -[VCPProtoMovieMovingObjectResult copyWithZone:]
  -[VCPProtoMovieMovingObjectResult .cxx_destruct]
  -[VCPProtoMovieMovingObjectResult dictionaryRepresentation]
  -[VCPProtoMovieMovingObjectResult writeTo:]
  -[VCPProtoMovieMovingObjectResult bounds]
  -[VCPProtoMovieMovingObjectResult setBounds:]
  -[VCPProtoMovieMovingObjectResult mergeFrom:]
  -[VCPProtoMovieMovingObjectResult readFrom:]
  -[VCPProtoMovieMovingObjectResult copyTo:]
  -[VCPProtoMovieMovingObjectResult setTimeRange:]
  -[VCPProtoMovieMovingObjectResult timeRange]
  -[VCPProtoMovieMovingObjectResult exportToLegacyDictionary]
  -[VCPProtoMovieMovingObjectResult addBounds:]
  -[VCPProtoMovieMovingObjectResult boundsCount]
  -[VCPProtoMovieMovingObjectResult clearBounds]
  -[VCPProtoMovieMovingObjectResult boundsAtIndex:]


VCPProtoMovieMusicResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieMusicResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieMusicResult isEqual:]
  -[VCPProtoMovieMusicResult copyWithZone:]
  -[VCPProtoMovieMusicResult .cxx_destruct]
  -[VCPProtoMovieMusicResult dictionaryRepresentation]
  -[VCPProtoMovieMusicResult confidence]
  -[VCPProtoMovieMusicResult writeTo:]
  -[VCPProtoMovieMusicResult mergeFrom:]
  -[VCPProtoMovieMusicResult readFrom:]
  -[VCPProtoMovieMusicResult copyTo:]
  -[VCPProtoMovieMusicResult setConfidence:]
  -[VCPProtoMovieMusicResult setTimeRange:]
  -[VCPProtoMovieMusicResult timeRange]
  -[VCPProtoMovieMusicResult exportToLegacyDictionary]


VCPProtoMovieObstructionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float obstructionScore

  // class methods
  +[VCPProtoMovieObstructionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieObstructionResult isEqual:]
  -[VCPProtoMovieObstructionResult copyWithZone:]
  -[VCPProtoMovieObstructionResult .cxx_destruct]
  -[VCPProtoMovieObstructionResult dictionaryRepresentation]
  -[VCPProtoMovieObstructionResult writeTo:]
  -[VCPProtoMovieObstructionResult mergeFrom:]
  -[VCPProtoMovieObstructionResult readFrom:]
  -[VCPProtoMovieObstructionResult copyTo:]
  -[VCPProtoMovieObstructionResult setTimeRange:]
  -[VCPProtoMovieObstructionResult timeRange]
  -[VCPProtoMovieObstructionResult obstructionScore]
  -[VCPProtoMovieObstructionResult setObstructionScore:]
  -[VCPProtoMovieObstructionResult exportToLegacyDictionary]


VCPCNNHandsDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNHandsDetector detector:]

  // instance methods
  -[VCPCNNHandsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandsDetector copyImage:toData:]
  -[VCPCNNHandsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandsDetector retrieveBoxes:outHeight:outWidth:boxes:anchorBox:]
  -[VCPCNNHandsDetector nonMaxSuppression:]
  -[VCPCNNHandsDetector generateHandsBoxes:]
  -[VCPCNNHandsDetector generateHandsRegions:boxes:maxNumRegions:]
  -[VCPCNNHandsDetector handsDetection:handsRegions:]


VCPVideoHumanActionAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoHumanActionAnalyzer .cxx_destruct]
  -[VCPVideoHumanActionAnalyzer results]
  -[VCPVideoHumanActionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoHumanActionAnalyzer finishAnalysisPass:]
  -[VCPVideoHumanActionAnalyzer privateResults]
  -[VCPVideoHumanActionAnalyzer normDistance:point2:]
  -[VCPVideoHumanActionAnalyzer computeVar:index2:interVar:intraVar:]
  -[VCPVideoHumanActionAnalyzer scaleRect:scaleX:scaleY:]
  -[VCPVideoHumanActionAnalyzer computeActionScore]
  -[VCPVideoHumanActionAnalyzer intersectionOverUnion:rect:]
  -[VCPVideoHumanActionAnalyzer addActiveResults:]
  -[VCPVideoHumanActionAnalyzer processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:]
  -[VCPVideoHumanActionAnalyzer initWithFrameStats:]


VCPProtoMovieOrientationResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int orientation

  // class methods
  +[VCPProtoMovieOrientationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieOrientationResult isEqual:]
  -[VCPProtoMovieOrientationResult copyWithZone:]
  -[VCPProtoMovieOrientationResult .cxx_destruct]
  -[VCPProtoMovieOrientationResult dictionaryRepresentation]
  -[VCPProtoMovieOrientationResult orientation]
  -[VCPProtoMovieOrientationResult writeTo:]
  -[VCPProtoMovieOrientationResult setOrientation:]
  -[VCPProtoMovieOrientationResult mergeFrom:]
  -[VCPProtoMovieOrientationResult readFrom:]
  -[VCPProtoMovieOrientationResult copyTo:]
  -[VCPProtoMovieOrientationResult setTimeRange:]
  -[VCPProtoMovieOrientationResult timeRange]
  -[VCPProtoMovieOrientationResult exportToLegacyDictionary]


VCPProtoMoviePreEncodeResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *statisticsBlob

  // class methods
  +[VCPProtoMoviePreEncodeResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePreEncodeResult isEqual:]
  -[VCPProtoMoviePreEncodeResult copyWithZone:]
  -[VCPProtoMoviePreEncodeResult .cxx_destruct]
  -[VCPProtoMoviePreEncodeResult dictionaryRepresentation]
  -[VCPProtoMoviePreEncodeResult writeTo:]
  -[VCPProtoMoviePreEncodeResult mergeFrom:]
  -[VCPProtoMoviePreEncodeResult readFrom:]
  -[VCPProtoMoviePreEncodeResult copyTo:]
  -[VCPProtoMoviePreEncodeResult exportToLegacyDictionary]
  -[VCPProtoMoviePreEncodeResult setStatisticsBlob:]
  -[VCPProtoMoviePreEncodeResult statisticsBlob]


VCPProtoMovieQualityResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore

  // class methods
  +[VCPProtoMovieQualityResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieQualityResult isEqual:]
  -[VCPProtoMovieQualityResult copyWithZone:]
  -[VCPProtoMovieQualityResult .cxx_destruct]
  -[VCPProtoMovieQualityResult dictionaryRepresentation]
  -[VCPProtoMovieQualityResult writeTo:]
  -[VCPProtoMovieQualityResult mergeFrom:]
  -[VCPProtoMovieQualityResult readFrom:]
  -[VCPProtoMovieQualityResult copyTo:]
  -[VCPProtoMovieQualityResult setTimeRange:]
  -[VCPProtoMovieQualityResult timeRange]
  -[VCPProtoMovieQualityResult qualityScore]
  -[VCPProtoMovieQualityResult setQualityScore:]
  -[VCPProtoMovieQualityResult exportToLegacyDictionary]


VCPProtoMovieSaliencyResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMovieSaliencyResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSaliencyResult isEqual:]
  -[VCPProtoMovieSaliencyResult copyWithZone:]
  -[VCPProtoMovieSaliencyResult .cxx_destruct]
  -[VCPProtoMovieSaliencyResult dictionaryRepresentation]
  -[VCPProtoMovieSaliencyResult confidence]
  -[VCPProtoMovieSaliencyResult writeTo:]
  -[VCPProtoMovieSaliencyResult bounds]
  -[VCPProtoMovieSaliencyResult setBounds:]
  -[VCPProtoMovieSaliencyResult mergeFrom:]
  -[VCPProtoMovieSaliencyResult readFrom:]
  -[VCPProtoMovieSaliencyResult copyTo:]
  -[VCPProtoMovieSaliencyResult setConfidence:]
  -[VCPProtoMovieSaliencyResult setTimeRange:]
  -[VCPProtoMovieSaliencyResult timeRange]
  -[VCPProtoMovieSaliencyResult exportToLegacyDictionary]


VCPProtoMovieSceneResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore
 @property  BOOL hasDistanceToPreviousScene
 @property  float distanceToPreviousScene
 @property  BOOL hasFlickerScore
 @property  float flickerScore
 @property  BOOL hasSceneprintDistanceToPreviousScene
 @property  float sceneprintDistanceToPreviousScene

  // class methods
  +[VCPProtoMovieSceneResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSceneResult isEqual:]
  -[VCPProtoMovieSceneResult copyWithZone:]
  -[VCPProtoMovieSceneResult .cxx_destruct]
  -[VCPProtoMovieSceneResult dictionaryRepresentation]
  -[VCPProtoMovieSceneResult writeTo:]
  -[VCPProtoMovieSceneResult mergeFrom:]
  -[VCPProtoMovieSceneResult readFrom:]
  -[VCPProtoMovieSceneResult copyTo:]
  -[VCPProtoMovieSceneResult setTimeRange:]
  -[VCPProtoMovieSceneResult timeRange]
  -[VCPProtoMovieSceneResult qualityScore]
  -[VCPProtoMovieSceneResult setQualityScore:]
  -[VCPProtoMovieSceneResult exportToLegacyDictionary]
  -[VCPProtoMovieSceneResult setDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult setHasDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult hasDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult setFlickerScore:]
  -[VCPProtoMovieSceneResult setHasFlickerScore:]
  -[VCPProtoMovieSceneResult hasFlickerScore]
  -[VCPProtoMovieSceneResult setSceneprintDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult setHasSceneprintDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult hasSceneprintDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult distanceToPreviousScene]
  -[VCPProtoMovieSceneResult flickerScore]
  -[VCPProtoMovieSceneResult sceneprintDistanceToPreviousScene]


VCPProtoMovieSubjectMotionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  BOOL hasAction

  // class methods
  +[VCPProtoMovieSubjectMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSubjectMotionResult isEqual:]
  -[VCPProtoMovieSubjectMotionResult copyWithZone:]
  -[VCPProtoMovieSubjectMotionResult .cxx_destruct]
  -[VCPProtoMovieSubjectMotionResult dictionaryRepresentation]
  -[VCPProtoMovieSubjectMotionResult writeTo:]
  -[VCPProtoMovieSubjectMotionResult mergeFrom:]
  -[VCPProtoMovieSubjectMotionResult readFrom:]
  -[VCPProtoMovieSubjectMotionResult copyTo:]
  -[VCPProtoMovieSubjectMotionResult setHasAction:]
  -[VCPProtoMovieSubjectMotionResult hasAction]
  -[VCPProtoMovieSubjectMotionResult setTimeRange:]
  -[VCPProtoMovieSubjectMotionResult timeRange]
  -[VCPProtoMovieSubjectMotionResult exportToLegacyDictionary]


VCPProtoMovieSummaryResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float curationScore
 @property  BOOL hasKeyFrame
 @property  VCPProtoVideoKeyFrame *keyFrame
 @property  BOOL autoPlayable
 @property  BOOL hasPlaybackCrop
 @property  VCPProtoBounds *playbackCrop

  // class methods
  +[VCPProtoMovieSummaryResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSummaryResult isEqual:]
  -[VCPProtoMovieSummaryResult copyWithZone:]
  -[VCPProtoMovieSummaryResult .cxx_destruct]
  -[VCPProtoMovieSummaryResult dictionaryRepresentation]
  -[VCPProtoMovieSummaryResult writeTo:]
  -[VCPProtoMovieSummaryResult mergeFrom:]
  -[VCPProtoMovieSummaryResult readFrom:]
  -[VCPProtoMovieSummaryResult copyTo:]
  -[VCPProtoMovieSummaryResult setTimeRange:]
  -[VCPProtoMovieSummaryResult timeRange]
  -[VCPProtoMovieSummaryResult curationScore]
  -[VCPProtoMovieSummaryResult setCurationScore:]
  -[VCPProtoMovieSummaryResult keyFrame]
  -[VCPProtoMovieSummaryResult setKeyFrame:]
  -[VCPProtoMovieSummaryResult exportToLegacyDictionary]
  -[VCPProtoMovieSummaryResult setPlaybackCrop:]
  -[VCPProtoMovieSummaryResult hasKeyFrame]
  -[VCPProtoMovieSummaryResult hasPlaybackCrop]
  -[VCPProtoMovieSummaryResult autoPlayable]
  -[VCPProtoMovieSummaryResult setAutoPlayable:]
  -[VCPProtoMovieSummaryResult playbackCrop]


VCPProtoMovieUtteranceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange

  // class methods
  +[VCPProtoMovieUtteranceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieUtteranceResult isEqual:]
  -[VCPProtoMovieUtteranceResult copyWithZone:]
  -[VCPProtoMovieUtteranceResult .cxx_destruct]
  -[VCPProtoMovieUtteranceResult dictionaryRepresentation]
  -[VCPProtoMovieUtteranceResult writeTo:]
  -[VCPProtoMovieUtteranceResult mergeFrom:]
  -[VCPProtoMovieUtteranceResult readFrom:]
  -[VCPProtoMovieUtteranceResult copyTo:]
  -[VCPProtoMovieUtteranceResult setTimeRange:]
  -[VCPProtoMovieUtteranceResult timeRange]
  -[VCPProtoMovieUtteranceResult exportToLegacyDictionary]


VCPProtoMovieVoiceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieVoiceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieVoiceResult isEqual:]
  -[VCPProtoMovieVoiceResult copyWithZone:]
  -[VCPProtoMovieVoiceResult .cxx_destruct]
  -[VCPProtoMovieVoiceResult dictionaryRepresentation]
  -[VCPProtoMovieVoiceResult confidence]
  -[VCPProtoMovieVoiceResult writeTo:]
  -[VCPProtoMovieVoiceResult mergeFrom:]
  -[VCPProtoMovieVoiceResult readFrom:]
  -[VCPProtoMovieVoiceResult copyTo:]
  -[VCPProtoMovieVoiceResult setConfidence:]
  -[VCPProtoMovieVoiceResult setTimeRange:]
  -[VCPProtoMovieVoiceResult timeRange]
  -[VCPProtoMovieVoiceResult exportToLegacyDictionary]


VCPProtoPoint : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  double x
 @property  double y

  // class methods
  +[VCPProtoPoint pointWithPoint:]

  // instance methods
  -[VCPProtoPoint isEqual:]
  -[VCPProtoPoint copyWithZone:]
  -[VCPProtoPoint pointValue]
  -[VCPProtoPoint dictionaryRepresentation]
  -[VCPProtoPoint writeTo:]
  -[VCPProtoPoint mergeFrom:]
  -[VCPProtoPoint readFrom:]
  -[VCPProtoPoint copyTo:]
  -[VCPProtoPoint x]
  -[VCPProtoPoint y]
  -[VCPProtoPoint setX:]
  -[VCPProtoPoint setY:]


VCPProtoMoviePetsFaceResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMoviePetsFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePetsFaceResult isEqual:]
  -[VCPProtoMoviePetsFaceResult copyWithZone:]
  -[VCPProtoMoviePetsFaceResult .cxx_destruct]
  -[VCPProtoMoviePetsFaceResult dictionaryRepresentation]
  -[VCPProtoMoviePetsFaceResult confidence]
  -[VCPProtoMoviePetsFaceResult writeTo:]
  -[VCPProtoMoviePetsFaceResult bounds]
  -[VCPProtoMoviePetsFaceResult setBounds:]
  -[VCPProtoMoviePetsFaceResult mergeFrom:]
  -[VCPProtoMoviePetsFaceResult readFrom:]
  -[VCPProtoMoviePetsFaceResult copyTo:]
  -[VCPProtoMoviePetsFaceResult setConfidence:]
  -[VCPProtoMoviePetsFaceResult setTimeRange:]
  -[VCPProtoMoviePetsFaceResult timeRange]
  -[VCPProtoMoviePetsFaceResult exportToLegacyDictionary]


VCPProtoTime : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  long long value
 @property  int timescale
 @property  unsigned int flags
 @property  long long epoch

  // class methods
  +[VCPProtoTime timeWithCMTime:]

  // instance methods
  -[VCPProtoTime isEqual:]
  -[VCPProtoTime copyWithZone:]
  -[VCPProtoTime flags]
  -[VCPProtoTime value]
  -[VCPProtoTime setValue:]
  -[VCPProtoTime dictionaryRepresentation]
  -[VCPProtoTime epoch]
  -[VCPProtoTime setEpoch:]
  -[VCPProtoTime writeTo:]
  -[VCPProtoTime mergeFrom:]
  -[VCPProtoTime readFrom:]
  -[VCPProtoTime copyTo:]
  -[VCPProtoTime setFlags:]
  -[VCPProtoTime timescale]
  -[VCPProtoTime setTimescale:]
  -[VCPProtoTime timeValue]


VCPProtoTimeRange : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  VCPProtoTime *start
 @property  VCPProtoTime *duration

  // class methods
  +[VCPProtoTimeRange timeRangeWithCMTimeRange:]

  // instance methods
  -[VCPProtoTimeRange isEqual:]
  -[VCPProtoTimeRange copyWithZone:]
  -[VCPProtoTimeRange .cxx_destruct]
  -[VCPProtoTimeRange start]
  -[VCPProtoTimeRange dictionaryRepresentation]
  -[VCPProtoTimeRange duration]
  -[VCPProtoTimeRange writeTo:]
  -[VCPProtoTimeRange mergeFrom:]
  -[VCPProtoTimeRange readFrom:]
  -[VCPProtoTimeRange copyTo:]
  -[VCPProtoTimeRange setDuration:]
  -[VCPProtoTimeRange setStart:]
  -[VCPProtoTimeRange timeRangeValue]


VCPProtoVideoKeyFrame : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <NSCopying>
 @property  VCPProtoTime *timestamp
 @property  float curationScore

  // instance methods
  -[VCPProtoVideoKeyFrame isEqual:]
  -[VCPProtoVideoKeyFrame copyWithZone:]
  -[VCPProtoVideoKeyFrame .cxx_destruct]
  -[VCPProtoVideoKeyFrame dictionaryRepresentation]
  -[VCPProtoVideoKeyFrame timestamp]
  -[VCPProtoVideoKeyFrame setTimestamp:]
  -[VCPProtoVideoKeyFrame writeTo:]
  -[VCPProtoVideoKeyFrame mergeFrom:]
  -[VCPProtoVideoKeyFrame readFrom:]
  -[VCPProtoVideoKeyFrame copyTo:]
  -[VCPProtoVideoKeyFrame curationScore]
  -[VCPProtoVideoKeyFrame setCurationScore:]


VCPCallerIdentificationResult : NSObject /usr/lib/libc++.1.dylib
 @property  PHFace *face
 @property  NSString *callerIdentifier
 @property  float confidence

  // instance methods
  -[VCPCallerIdentificationResult .cxx_destruct]
  -[VCPCallerIdentificationResult confidence]
  -[VCPCallerIdentificationResult face]
  -[VCPCallerIdentificationResult initWithCallerIdentifier:face:andConfidence:]
  -[VCPCallerIdentificationResult callerIdentifier]


VCPRealTimeAnalysisService : NSObject /usr/lib/libc++.1.dylib <VCPRealTimeAnalysisClientProtocol>
  // class methods
  +[VCPRealTimeAnalysisService analysisService]
  +[VCPRealTimeAnalysisService errorWithStatus:andDescription:]

  // instance methods
  -[VCPRealTimeAnalysisService init]
  -[VCPRealTimeAnalysisService dealloc]
  -[VCPRealTimeAnalysisService invalidate]
  -[VCPRealTimeAnalysisService .cxx_destruct]
  -[VCPRealTimeAnalysisService connection]
  -[VCPRealTimeAnalysisService requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:]


VCPRTLandmarkDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPRTLandmarkDetector dealloc]
  -[VCPRTLandmarkDetector initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:]
  -[VCPRTLandmarkDetector detectLandmark:width:height:stride:facerect:prevResult:result:]
  -[VCPRTLandmarkDetector calculateFaceRectFromPrevLM:result:numOfLandmarks:]


VCPSceneTaxonomy : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPSceneTaxonomy sharedTaxonomy]

  // instance methods
  -[VCPSceneTaxonomy init]
  -[VCPSceneTaxonomy .cxx_destruct]
  -[VCPSceneTaxonomy sceneNameFromSceneId:]
  -[VCPSceneTaxonomy sceneIdFromSceneName:]


VCPSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames
 @property  unsigned long numOfValidFrames
 @property  float curationScore

  // instance methods
  -[VCPSegment init]
  -[VCPSegment score]
  -[VCPSegment setTimeRange:]
  -[VCPSegment timeRange]
  -[VCPSegment curationScore]
  -[VCPSegment setCurationScore:]
  -[VCPSegment updateDuration:]
  -[VCPSegment mergeSegment:]
  -[VCPSegment numOfFrames]
  -[VCPSegment copyFrom:]
  -[VCPSegment numOfValidFrames]
  -[VCPSegment sumOfScore]
  -[VCPSegment initWithTimestamp:score:valid:]
  -[VCPSegment updateWithFirstFrame:score:valid:]
  -[VCPSegment updateSegment:score:valid:]
  -[VCPSegment trimSegment:fromStart:]
  -[VCPSegment isContentTooShort]


VCPSharedInstanceManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPSharedInstanceManager sharedManager]

  // instance methods
  -[VCPSharedInstanceManager init]
  -[VCPSharedInstanceManager .cxx_destruct]
  -[VCPSharedInstanceManager reset]
  -[VCPSharedInstanceManager sharedInstanceWithIdentifier:andCreationBlock:]


VCPTrimAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPTrimAnalyzer init]
  -[VCPTrimAnalyzer .cxx_destruct]
  -[VCPTrimAnalyzer isReady]
  -[VCPTrimAnalyzer printSegments:]
  -[VCPTrimAnalyzer prepareTrimmingWithTrimStart:andTrimEnd:]
  -[VCPTrimAnalyzer analyzeFrameWithTimeRange:analysisData:]
  -[VCPTrimAnalyzer shouldCutAt:stillPTS:withCut:]
  -[VCPTrimAnalyzer generateCurationSegment]
  -[VCPTrimAnalyzer generateInterestingTrimBasedOnCaptureTime:]
  -[VCPTrimAnalyzer updateCurationThreshold]
  -[VCPTrimAnalyzer calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:]
  -[VCPTrimAnalyzer isCurated:]
  -[VCPTrimAnalyzer isTimestampSkipable:]
  -[VCPTrimAnalyzer checkTrimAt:captureTime:]
  -[VCPTrimAnalyzer finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:]
  -[VCPTrimAnalyzer bestTrimTimeRange]


VCPURLAsset : VCPAsset
  // class methods
  +[VCPURLAsset imageAssetWithURL:]
  +[VCPURLAsset livePhotoAssetWithImageURL:andMovieURL:]
  +[VCPURLAsset movieAssetWithURL:]

  // instance methods
  -[VCPURLAsset .cxx_destruct]
  -[VCPURLAsset duration]
  -[VCPURLAsset modificationDate]
  -[VCPURLAsset mediaType]
  -[VCPURLAsset initWithImageURL:]
  -[VCPURLAsset movie]
  -[VCPURLAsset pixelWidth]
  -[VCPURLAsset pixelHeight]
  -[VCPURLAsset mainFileURL]
  -[VCPURLAsset mediaSubtypes]
  -[VCPURLAsset exif]
  -[VCPURLAsset imageWithPreferredDimension:]
  -[VCPURLAsset photoOffsetSeconds]
  -[VCPURLAsset originalPhotoOffsetSeconds]
  -[VCPURLAsset slowmoRate]
  -[VCPURLAsset originalMovie]
  -[VCPURLAsset initWithImageURL:andMovieURL:]
  -[VCPURLAsset initWithMovieURL:]


VCPVideoChatAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVideoChatAnalysis videoChatAnalysis]

  // instance methods
  -[VCPVideoChatAnalysis init]
  -[VCPVideoChatAnalysis .cxx_destruct]
  -[VCPVideoChatAnalysis detectFaces:]
  -[VCPVideoChatAnalysis checkAddFaces]
  -[VCPVideoChatAnalysis analyzeFrame:]
  -[VCPVideoChatAnalysis persistAnalysis]


VCPVideoActivityAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoActivityAnalyzer .cxx_destruct]
  -[VCPVideoActivityAnalyzer results]
  -[VCPVideoActivityAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoActivityAnalyzer normalizeActivityDescriptor]
  -[VCPVideoActivityAnalyzer prepareActivityStats]
  -[VCPVideoActivityAnalyzer generateActivityDescriptor]
  -[VCPVideoActivityAnalyzer computeActivityScoreAtTime:]
  -[VCPVideoActivityAnalyzer resetActivityStatsAtTime:]
  -[VCPVideoActivityAnalyzer extractRequiredInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer extractRequiredClassificationInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer extractRequiredFaceInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer validationScoreOfTimeRange:fromResult:startIdx:]
  -[VCPVideoActivityAnalyzer actionScoreInTimeRange:]
  -[VCPVideoActivityAnalyzer validateActivityScores]
  -[VCPVideoActivityAnalyzer scaleBasedOnFaceForTimeRange:]
  -[VCPVideoActivityAnalyzer addSceneSwitchFrequencyConstributionToActivityLevel:]
  -[VCPVideoActivityAnalyzer addSceneClassificationContributionToActivityLevel:]
  -[VCPVideoActivityAnalyzer initWithFrameStats:]
  -[VCPVideoActivityAnalyzer preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:]
  -[VCPVideoActivityAnalyzer finishAnalysisPass:fpsRate:]


VCPCompactResult : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score

  // instance methods
  -[VCPCompactResult score]
  -[VCPCompactResult setScore:]
  -[VCPCompactResult timerange]
  -[VCPCompactResult setTimerange:]
  -[VCPCompactResult initWithTimerange:andScore:]


VCPVideoActivityDescriptor : NSObject /usr/lib/libc++.1.dylib
 @property  ^f descriptors

  // instance methods
  -[VCPVideoActivityDescriptor dealloc]
  -[VCPVideoActivityDescriptor reset]
  -[VCPVideoActivityDescriptor descriptors]
  -[VCPVideoActivityDescriptor initWithFrameWidthInMb:heightInMb:]
  -[VCPVideoActivityDescriptor ExtractActivityDescriptorFromStats:]
  -[VCPVideoActivityDescriptor spatialDescriptorWithMvMagnitudeMean:]


VCPProtoMovieSubtleMotionResult : PBCodable /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float actionScore

  // class methods
  +[VCPProtoMovieSubtleMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSubtleMotionResult isEqual:]
  -[VCPProtoMovieSubtleMotionResult copyWithZone:]
  -[VCPProtoMovieSubtleMotionResult .cxx_destruct]
  -[VCPProtoMovieSubtleMotionResult dictionaryRepresentation]
  -[VCPProtoMovieSubtleMotionResult writeTo:]
  -[VCPProtoMovieSubtleMotionResult setActionScore:]
  -[VCPProtoMovieSubtleMotionResult actionScore]
  -[VCPProtoMovieSubtleMotionResult mergeFrom:]
  -[VCPProtoMovieSubtleMotionResult readFrom:]
  -[VCPProtoMovieSubtleMotionResult copyTo:]
  -[VCPProtoMovieSubtleMotionResult setTimeRange:]
  -[VCPProtoMovieSubtleMotionResult timeRange]
  -[VCPProtoMovieSubtleMotionResult exportToLegacyDictionary]


VCPVideoAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVideoAnalyzer dependencies]

  // instance methods
  -[VCPVideoAnalyzer results]
  -[VCPVideoAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoAnalyzer finishAnalysisPass:]


VCPVideoFaceDetector : VCPVideoAnalyzer
  // class methods
  +[VCPVideoFaceDetector faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:cancel:]

  // instance methods
  -[VCPVideoFaceDetector .cxx_destruct]
  -[VCPVideoFaceDetector results]
  -[VCPVideoFaceDetector faceRanges]


VCPVideoFaceMeshAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  {?=[4]} pose
 @property  NSDictionary *blendShapes
 @property  unsigned long vertexCount
 @property  r^ vertices
 @property  BOOL bufferRotated

  // instance methods
  -[VCPVideoFaceMeshAnalyzer dealloc]
  -[VCPVideoFaceMeshAnalyzer .cxx_destruct]
  -[VCPVideoFaceMeshAnalyzer pose]
  -[VCPVideoFaceMeshAnalyzer vertices]
  -[VCPVideoFaceMeshAnalyzer setFrame:]
  -[VCPVideoFaceMeshAnalyzer vertexCount]
  -[VCPVideoFaceMeshAnalyzer isTracked]
  -[VCPVideoFaceMeshAnalyzer blendShapes]
  -[VCPVideoFaceMeshAnalyzer updateFocalLengthInPixels:]
  -[VCPVideoFaceMeshAnalyzer initWithFocalLengthInPixels:offline:]
  -[VCPVideoFaceMeshAnalyzer analyzeFrame:withFaceRect:withRotation:withTimestamp:]
  -[VCPVideoFaceMeshAnalyzer makeValidationDecision]
  -[VCPVideoFaceMeshAnalyzer updateIntrinsicWhenRotated]
  -[VCPVideoFaceMeshAnalyzer checkResolutionChange:withRotation:]
  -[VCPVideoFaceMeshAnalyzer validateFace:eulerAngles:]
  -[VCPVideoFaceMeshAnalyzer rotateLandmarks:width:height:landmarks:numLandmarks:]
  -[VCPVideoFaceMeshAnalyzer mapToCameraNegativeZ]
  -[VCPVideoFaceMeshAnalyzer bufferRotated]


VCPPetsRegion : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bound
 @property  float confidence

  // instance methods
  -[VCPPetsRegion confidence]
  -[VCPPetsRegion setConfidence:]
  -[VCPPetsRegion bound]
  -[VCPPetsRegion initWith:confidence:]
  -[VCPPetsRegion setBound:]


VCPVideoPetsAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoPetsAnalyzer .cxx_destruct]
  -[VCPVideoPetsAnalyzer results]
  -[VCPVideoPetsAnalyzer initWithTransform:]
  -[VCPVideoPetsAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoPetsAnalyzer finishAnalysisPass:]
  -[VCPVideoPetsAnalyzer parseResults:toDetections:atTime:fromTime:addActiveRegions:]
  -[VCPVideoPetsAnalyzer addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:]


VCPVideoFacePoseAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  {?=[4]} pose

  // instance methods
  -[VCPVideoFacePoseAnalyzer init]
  -[VCPVideoFacePoseAnalyzer .cxx_destruct]
  -[VCPVideoFacePoseAnalyzer pose]
  -[VCPVideoFacePoseAnalyzer setPose:]
  -[VCPVideoFacePoseAnalyzer updateFocalLengthInPixels:]
  -[VCPVideoFacePoseAnalyzer initWithFocalLengthInPixels:]
  -[VCPVideoFacePoseAnalyzer analyzeFrameForPose:withFaceRect:withTimestamp:]


VCPVideoFacePoseFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVideoFacePoseFilter reset]
  -[VCPVideoFacePoseFilter .cxx_construct]
  -[VCPVideoFacePoseFilter rotationToEulerAngles:angles:]
  -[VCPVideoFacePoseFilter kalmanFiltering:T:]
  -[VCPVideoFacePoseFilter eulerAnglesToRotation:R:]
  -[VCPVideoFacePoseFilter filteringPose:]


VCPVideoFullFaceDetector : VCPVideoFaceDetector
  // instance methods
  -[VCPVideoFullFaceDetector dealloc]
  -[VCPVideoFullFaceDetector .cxx_destruct]
  -[VCPVideoFullFaceDetector initWithTransform:]
  -[VCPVideoFullFaceDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoFullFaceDetector finishAnalysisPass:]
  -[VCPVideoFullFaceDetector frameFaceResults]
  -[VCPVideoFullFaceDetector initWithTransform:withExistingFaceprints:frameStats:]
  -[VCPVideoFullFaceDetector faceRanges]
  -[VCPVideoFullFaceDetector compareFace:withFace:]
  -[VCPVideoFullFaceDetector removeSmallestKeyFace]
  -[VCPVideoFullFaceDetector detectTrackFacesInFrame:withTimestamp:faces:]
  -[VCPVideoFullFaceDetector clusterFaces]
  -[VCPVideoFullFaceDetector updateWithExistingFaces]
  -[VCPVideoFullFaceDetector locationChange:relativeTo:landscape:]
  -[VCPVideoFullFaceDetector minProcessTimeIntervalInSecs]
  -[VCPVideoFullFaceDetector detectFaces:faces:]


VCPCNNHandKeypointsDetectorEspresso : VCPCNNHandKeypointsDetector
  // instance methods
  -[VCPCNNHandKeypointsDetectorEspresso init]
  -[VCPCNNHandKeypointsDetectorEspresso dealloc]
  -[VCPCNNHandKeypointsDetectorEspresso .cxx_destruct]
  -[VCPCNNHandKeypointsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandKeypointsDetectorEspresso generateHandKeypoints:]


VCPVideoGlobalAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVideoGlobalAnalyzer analyzeOverallQuality:withFpsRate:]
  -[VCPVideoGlobalAnalyzer generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:]
  -[VCPVideoGlobalAnalyzer setActivityLevel:]
  -[VCPVideoGlobalAnalyzer hasMeaningfulSceneSegment:withFpsRate:]
  -[VCPVideoGlobalAnalyzer assetQualityScoreFromAnalysis:withFpsRate:]
  -[VCPVideoGlobalAnalyzer assetActionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetExpressionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetVoiceScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetJunkScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetCameraMotionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer scaleForTimeRange:basedOnFace:]
  -[VCPVideoGlobalAnalyzer isJunkTimeRange:basedOnResults:]
  -[VCPVideoGlobalAnalyzer subjectActivityInTimeRange:fromResults:]
  -[VCPVideoGlobalAnalyzer cameraActivityfromQuality:]
  -[VCPVideoGlobalAnalyzer assetActivityLevelFromAnalysisResults:]


VCPVideoKeyFrame : NSObject /usr/lib/libc++.1.dylib
 @property  {?=qiIq} timestamp
 @property  float score
 @property  float semanticScore
 @property  float sharpness
 @property  float faceSharpness
 @property  float exposureScore
 @property  BOOL isHeadingFrame
 @property  float textureScore
 @property  unsigned long statsFlags
 @property  NSMutableArray *detectedFaces
 @property  NSMutableArray *faceQualityScores
 @property  NSMutableDictionary *frameResults
 @property  float overallFaceQualityScore
 @property  float qualityScoreForLivePhoto
 @property  float globalQualityScore
 @property  float visualPleasingScore
 @property  float penaltyScore
 @property  float contentScore
 @property  float humanPoseScore
 @property  float humanActionScore

  // instance methods
  -[VCPVideoKeyFrame .cxx_destruct]
  -[VCPVideoKeyFrame timestamp]
  -[VCPVideoKeyFrame score]
  -[VCPVideoKeyFrame setTimestamp:]
  -[VCPVideoKeyFrame sharpness]
  -[VCPVideoKeyFrame setSharpness:]
  -[VCPVideoKeyFrame setScore:]
  -[VCPVideoKeyFrame exposureScore]
  -[VCPVideoKeyFrame setExposureScore:]
  -[VCPVideoKeyFrame detectedFaces]
  -[VCPVideoKeyFrame setDetectedFaces:]
  -[VCPVideoKeyFrame semanticScore]
  -[VCPVideoKeyFrame initWithLivePhoto:]
  -[VCPVideoKeyFrame setContentScore:]
  -[VCPVideoKeyFrame contentScore]
  -[VCPVideoKeyFrame frameResults]
  -[VCPVideoKeyFrame setGlobalQualityScore:]
  -[VCPVideoKeyFrame qualityScoreForLivePhoto]
  -[VCPVideoKeyFrame setQualityScoreForLivePhoto:]
  -[VCPVideoKeyFrame visualPleasingScore]
  -[VCPVideoKeyFrame setVisualPleasingScore:]
  -[VCPVideoKeyFrame overallFaceQualityScore]
  -[VCPVideoKeyFrame setOverallFaceQualityScore:]
  -[VCPVideoKeyFrame penaltyScore]
  -[VCPVideoKeyFrame setPenaltyScore:]
  -[VCPVideoKeyFrame textureScore]
  -[VCPVideoKeyFrame setTextureScore:]
  -[VCPVideoKeyFrame globalQualityScore]
  -[VCPVideoKeyFrame faceQualityScores]
  -[VCPVideoKeyFrame setFaceQualityScores:]
  -[VCPVideoKeyFrame humanActionScore]
  -[VCPVideoKeyFrame humanPoseScore]
  -[VCPVideoKeyFrame setHumanActionScore:]
  -[VCPVideoKeyFrame setHumanPoseScore:]
  -[VCPVideoKeyFrame setSemanticScore:]
  -[VCPVideoKeyFrame copyFrom:]
  -[VCPVideoKeyFrame setStatsFlags:]
  -[VCPVideoKeyFrame statsFlags]
  -[VCPVideoKeyFrame faceSharpness]
  -[VCPVideoKeyFrame isHeadingFrame]
  -[VCPVideoKeyFrame computeGlobalQuality]
  -[VCPVideoKeyFrame computeScoreFromColorfulness]
  -[VCPVideoKeyFrame computeScoreFromExposure]
  -[VCPVideoKeyFrame computeExpressionScore]
  -[VCPVideoKeyFrame computeScoreFromAction]
  -[VCPVideoKeyFrame computeGlobalQualityForLivePhoto]
  -[VCPVideoKeyFrame computeVisualPleasingScore]
  -[VCPVideoKeyFrame computePenaltyScore]
  -[VCPVideoKeyFrame computeContentScore]
  -[VCPVideoKeyFrame computeCurationScoreComponents]
  -[VCPVideoKeyFrame storeFrameResults]
  -[VCPVideoKeyFrame printStats]
  -[VCPVideoKeyFrame setFrameResults:]
  -[VCPVideoKeyFrame loadKeyFrameResult:timestamp:]
  -[VCPVideoKeyFrame setFaceSharpness:]
  -[VCPVideoKeyFrame computeCurationScore]
  -[VCPVideoKeyFrame hasGoodSubjectAction]
  -[VCPVideoKeyFrame setIsHeadingFrame:]
  -[VCPVideoKeyFrame resetStatsFlag]
  -[VCPVideoKeyFrame setFaceStatsFlag:detectedFaces:]
  -[VCPVideoKeyFrame setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:]


VCPVideoKeyFrameAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVideoKeyFrameAnalyzer .cxx_destruct]
  -[VCPVideoKeyFrameAnalyzer initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:]
  -[VCPVideoKeyFrameAnalyzer analyzeFrame:withTimestamp:]
  -[VCPVideoKeyFrameAnalyzer preparePostProcessingStatsFromFaceRange:junkResults:]
  -[VCPVideoKeyFrameAnalyzer postProcess]
  -[VCPVideoKeyFrameAnalyzer keyFrames]
  -[VCPVideoKeyFrameAnalyzer keyFrameScores]
  -[VCPVideoKeyFrameAnalyzer setKeyFrameTime:isHeadingFrame:]
  -[VCPVideoKeyFrameAnalyzer prepareFrameStats:]
  -[VCPVideoKeyFrameAnalyzer computeSharpnessOfFrame:]
  -[VCPVideoKeyFrameAnalyzer computeFaceQualityOfFrame:]
  -[VCPVideoKeyFrameAnalyzer finalizeKeyFrame]
  -[VCPVideoKeyFrameAnalyzer adjustScoreByFace]
  -[VCPVideoKeyFrameAnalyzer modulateByJunk]
  -[VCPVideoKeyFrameAnalyzer modulateByTimeRange]
  -[VCPVideoKeyFrameAnalyzer setBlurAnalyzerFaceResults:]
  -[VCPVideoKeyFrameAnalyzer loadKeyFrameResults:]
  -[VCPVideoKeyFrameAnalyzer modulateByExposure]
  -[VCPVideoKeyFrameAnalyzer computeMinDistanceBetween:withSet:]


VCPVideoLightFaceDetector : VCPVideoFaceDetector
  // instance methods
  -[VCPVideoLightFaceDetector dealloc]
  -[VCPVideoLightFaceDetector .cxx_destruct]
  -[VCPVideoLightFaceDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoLightFaceDetector finishAnalysisPass:]
  -[VCPVideoLightFaceDetector initWithTransform:frameStats:]
  -[VCPVideoLightFaceDetector minProcessTimeIntervalInSecs]
  -[VCPVideoLightFaceDetector detectFaces:faces:]


VCPVideoMetaAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *publicResults
 @property  NSDictionary *privateResults

  // class methods
  +[VCPVideoMetaAnalyzer analyzerForTrackType:withTransform:]

  // instance methods
  -[VCPVideoMetaAnalyzer finalizeAnalysis]
  -[VCPVideoMetaAnalyzer privateResults]
  -[VCPVideoMetaAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaAnalyzer publicResults]


VCPVideoMetaFaceAnalyzer : VCPVideoMetaAnalyzer
  // instance methods
  -[VCPVideoMetaFaceAnalyzer .cxx_destruct]
  -[VCPVideoMetaFaceAnalyzer initWithTransform:]
  -[VCPVideoMetaFaceAnalyzer finalizeAnalysis]
  -[VCPVideoMetaFaceAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaFaceAnalyzer publicResults]
  -[VCPVideoMetaFaceAnalyzer flipTransform:]


VCPVideoMetaFocusAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *results

  // instance methods
  -[VCPVideoMetaFocusAnalyzer init]
  -[VCPVideoMetaFocusAnalyzer .cxx_destruct]
  -[VCPVideoMetaFocusAnalyzer results]
  -[VCPVideoMetaFocusAnalyzer finalizeAnalysis]
  -[VCPVideoMetaFocusAnalyzer addSegmentToResults]
  -[VCPVideoMetaFocusAnalyzer processFrameMetadata:]


VCPVideoMetaFocusSegment : VCPMetaSegment
 @property  long long focusStatus

  // instance methods
  -[VCPVideoMetaFocusSegment resetSegment:atTime:]
  -[VCPVideoMetaFocusSegment focusStatus]
  -[VCPVideoMetaFocusSegment initWithFocusStatus:atTime:]
  -[VCPVideoMetaFocusSegment updateSegment:atTime:]
  -[VCPVideoMetaFocusSegment setFocusStatus:]


VCPVideoMetaLivePhotoMetaAnalyzer : VCPVideoMetaAnalyzer
  // class methods
  +[VCPVideoMetaLivePhotoMetaAnalyzer defaultDesiredKeys]

  // instance methods
  -[VCPVideoMetaLivePhotoMetaAnalyzer init]
  -[VCPVideoMetaLivePhotoMetaAnalyzer .cxx_destruct]
  -[VCPVideoMetaLivePhotoMetaAnalyzer finalizeAnalysis]
  -[VCPVideoMetaLivePhotoMetaAnalyzer privateResults]
  -[VCPVideoMetaLivePhotoMetaAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer convertLivePhotoStruct:toDictionary:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer convertLivePhotoBinary:toDictionary:]


VCPVideoMetaMotionAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *results

  // instance methods
  -[VCPVideoMetaMotionAnalyzer init]
  -[VCPVideoMetaMotionAnalyzer .cxx_destruct]
  -[VCPVideoMetaMotionAnalyzer results]
  -[VCPVideoMetaMotionAnalyzer .cxx_construct]
  -[VCPVideoMetaMotionAnalyzer finalizeAnalysis]
  -[VCPVideoMetaMotionAnalyzer mergeSimilarSegments]
  -[VCPVideoMetaMotionAnalyzer processFrameMetadata:]
  -[VCPVideoMetaMotionAnalyzer decideSegmentPointBasedOn:]


VCPVideoMetaMotionSegment : VCPMetaSegment
 @property  float absMotion
 @property  float stabilityScore

  // instance methods
  -[VCPVideoMetaMotionSegment mergeSegment:]
  -[VCPVideoMetaMotionSegment finalizeAtTime:]
  -[VCPVideoMetaMotionSegment resetSegment:atTime:]
  -[VCPVideoMetaMotionSegment updateSegment:atTime:]
  -[VCPVideoMetaMotionSegment stabilityScore]
  -[VCPVideoMetaMotionSegment initWithAbsMotion:atTime:]
  -[VCPVideoMetaMotionSegment absMotion]
  -[VCPVideoMetaMotionSegment setAbsMotion:]
  -[VCPVideoMetaMotionSegment setStabilityScore:]


VCPVideMetaOrientationAnalyzer : VCPVideoMetaAnalyzer
  // instance methods
  -[VCPVideMetaOrientationAnalyzer init]
  -[VCPVideMetaOrientationAnalyzer .cxx_destruct]
  -[VCPVideMetaOrientationAnalyzer processMetadataGroup:flags:]
  -[VCPVideMetaOrientationAnalyzer publicResults]
  -[VCPVideMetaOrientationAnalyzer convertQuickTimeVideoOrientationToUIOrientation:]


VCPVideoObjectTracker : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} objectBoundsInitial
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} objectBounds
 @property  float confidence
 @property  {?=qiIq} start
 @property  int lostCount

  // instance methods
  -[VCPVideoObjectTracker .cxx_destruct]
  -[VCPVideoObjectTracker start]
  -[VCPVideoObjectTracker confidence]
  -[VCPVideoObjectTracker initWithObjectBounds:inFrame:timestamp:]
  -[VCPVideoObjectTracker trackObjectInFrame:]
  -[VCPVideoObjectTracker objectBoundsInitial]
  -[VCPVideoObjectTracker objectBounds]
  -[VCPVideoObjectTracker lostCount]


VCPSaliencyRegion : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bound
 @property  float confidence

  // class methods
  +[VCPSaliencyRegion salientRegionsFromPixelBuffer:]
  +[VCPSaliencyRegion attachSalientRegions:toPixelBuffer:]

  // instance methods
  -[VCPSaliencyRegion confidence]
  -[VCPSaliencyRegion setConfidence:]
  -[VCPSaliencyRegion bound]
  -[VCPSaliencyRegion initWith:confidence:]
  -[VCPSaliencyRegion setBound:]


VCPVideoSaliencyAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoSaliencyAnalyzer .cxx_destruct]
  -[VCPVideoSaliencyAnalyzer results]
  -[VCPVideoSaliencyAnalyzer initWithTransform:]
  -[VCPVideoSaliencyAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoSaliencyAnalyzer finishAnalysisPass:]
  -[VCPVideoSaliencyAnalyzer isOutOfBoundary:]
  -[VCPVideoSaliencyAnalyzer updateConfidence:prevBound:newBound:width:height:]
  -[VCPVideoSaliencyAnalyzer pruneRegions:withOverlapRatio:]
  -[VCPVideoSaliencyAnalyzer boundDistance:relativeTo:landscape:]


VCPClassification : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *sceneId
 @property  float duration
 @property  float sumConfidence

  // instance methods
  -[VCPClassification .cxx_destruct]
  -[VCPClassification duration]
  -[VCPClassification setDuration:]
  -[VCPClassification initWithSceneId:withDuration:withConfidence:]
  -[VCPClassification sceneId]
  -[VCPClassification setSceneId:]
  -[VCPClassification sumConfidence]
  -[VCPClassification setSumConfidence:]


VCPVideoSceneClassifier : VCPVideoAnalyzer
 @property  NSDictionary *frameScenes
 @property  NSArray *sceneResults

  // instance methods
  -[VCPVideoSceneClassifier init]
  -[VCPVideoSceneClassifier dealloc]
  -[VCPVideoSceneClassifier .cxx_destruct]
  -[VCPVideoSceneClassifier results]
  -[VCPVideoSceneClassifier analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoSceneClassifier finishAnalysisPass:]
  -[VCPVideoSceneClassifier addResult:start:duration:keyIsName:]
  -[VCPVideoSceneClassifier compareObjectsOfInterest:withScenes:]
  -[VCPVideoSceneClassifier addAggregatedScenes:timerange:]
  -[VCPVideoSceneClassifier frameScenes]
  -[VCPVideoSceneClassifier sceneResults]
  -[VCPVideoSceneClassifier setSceneResults:]


VCPVideoTrackDecoder : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVideoTrackDecoder decodeDimensionsForTrack:]

  // instance methods
  -[VCPVideoTrackDecoder init]
  -[VCPVideoTrackDecoder .cxx_destruct]
  -[VCPVideoTrackDecoder status]
  -[VCPVideoTrackDecoder settings]
  -[VCPVideoTrackDecoder initWithTrack:]
  -[VCPVideoTrackDecoder copyNextSampleBuffer]
  -[VCPVideoTrackDecoder getNextCaptureSampleBuffer]


VCPVideoTrackStandardDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackStandardDecoder dealloc]
  -[VCPVideoTrackStandardDecoder .cxx_destruct]
  -[VCPVideoTrackStandardDecoder status]
  -[VCPVideoTrackStandardDecoder copyNextSampleBuffer]
  -[VCPVideoTrackStandardDecoder initWithTrack:timerange:]


VCPVideoTrackSubsamplingDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackSubsamplingDecoder dealloc]
  -[VCPVideoTrackSubsamplingDecoder .cxx_destruct]
  -[VCPVideoTrackSubsamplingDecoder status]
  -[VCPVideoTrackSubsamplingDecoder copyNextSampleBuffer]
  -[VCPVideoTrackSubsamplingDecoder getNextCaptureSampleBuffer]
  -[VCPVideoTrackSubsamplingDecoder initWithTrack:timerange:atInterval:]


VCPVideoTrackSyncDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackSyncDecoder dealloc]
  -[VCPVideoTrackSyncDecoder .cxx_destruct]
  -[VCPVideoTrackSyncDecoder status]
  -[VCPVideoTrackSyncDecoder copyNextSampleBuffer]
  -[VCPVideoTrackSyncDecoder initWithTrack:timerange:]
  -[VCPVideoTrackSyncDecoder findNextSample:timerange:]
  -[VCPVideoTrackSyncDecoder decodeSample:sample:]
  -[VCPVideoTrackSyncDecoder decodeTask]


VCPVoiceDetector : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *voiceDetections

  // class methods
  +[VCPVoiceDetector detector]

  // instance methods
  -[VCPVoiceDetector init]
  -[VCPVoiceDetector .cxx_destruct]
  -[VCPVoiceDetector results]
  -[VCPVoiceDetector loadModel]
  -[VCPVoiceDetector setupWithSample:andSampleBatchSize:]
  -[VCPVoiceDetector processAudioSamples:timestamp:]
  -[VCPVoiceDetector finalizeAnalysisAtTime:]
  -[VCPVoiceDetector audioFormatRequirements]
  -[VCPVoiceDetector voiceDetections]
  -[VCPVoiceDetector setVoiceDetections:]
  -[VCPVoiceDetector addDetectionFromTime:toTime:result:]
  -[VCPVoiceDetector setupWithAudioStream:]


VCPVoiceDetectorV2 : VCPVoiceDetector
  // instance methods
  -[VCPVoiceDetectorV2 init]
  -[VCPVoiceDetectorV2 dealloc]
  -[VCPVoiceDetectorV2 results]
  -[VCPVoiceDetectorV2 loadModel]
  -[VCPVoiceDetectorV2 processAudioSamples:timestamp:]
  -[VCPVoiceDetectorV2 finalizeAnalysisAtTime:]
  -[VCPVoiceDetectorV2 setupWithAudioStream:]


VCPCtrTracker : NSObject /usr/lib/libc++.1.dylib <VCPBaseTracker>
 @property  ^{CGPoint=dd} box
 @property  BOOL stableInd
 @property  BOOL lostTrackInd
 @property  float confidence

  // instance methods
  -[VCPCtrTracker init]
  -[VCPCtrTracker dealloc]
  -[VCPCtrTracker confidence]
  -[VCPCtrTracker setConfidence:]
  -[VCPCtrTracker box]
  -[VCPCtrTracker setBox:]
  -[VCPCtrTracker setupTrackerWithReferenceFrame:withROI:]
  -[VCPCtrTracker trackInFrame:]
  -[VCPCtrTracker lostTrackInd]
  -[VCPCtrTracker stableInd]
  -[VCPCtrTracker setStableInd:]
  -[VCPCtrTracker setLostTrackInd:]


AVAsset(MediaAnalysis)
	// instance methods
	-[AVAsset(MediaAnalysis) vcp_enabledTracksWithMediaType:]
	-[AVAsset(MediaAnalysis) vcp_isShortMovie]
	-[AVAsset(MediaAnalysis) vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:]
	-[AVAsset(MediaAnalysis) vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:]
	-[AVAsset(MediaAnalysis) vcp_firstEnabledTrackWithMediaType:]
	-[AVAsset(MediaAnalysis) vcp_livePhotoStillDisplayTime]
	-[AVAsset(MediaAnalysis) vcp_assetWithoutAdjustments:duration:]

PFVideoAVObjectBuilder(CMTimerange)
	// instance methods
	-[PFVideoAVObjectBuilder(CMTimerange) vcp_convertToOriginalTimerangeFromScaledTimerange:]

AVAssetTrack(MediaAnalysis)
	// instance methods
	-[AVAssetTrack(MediaAnalysis) vcp_orientation]
	-[AVAssetTrack(MediaAnalysis) vcp_endTime]
	-[AVAssetTrack(MediaAnalysis) vcp_startTime]

PHAsset(FullAnalysis)
	// class methods
	+[PHAsset(FullAnalysis) vcp_fullAnalysisTypesForAssetType:]
	+[PHAsset(FullAnalysis) vcp_fetchOptionsForLibrary:forTaskID:]
	+[PHAsset(FullAnalysis) vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:]
	+[PHAsset(FullAnalysis) vcp_usePHFace]
	+[PHAsset(FullAnalysis) vcp_usePHFaceExpression]

	// instance methods
	-[PHAsset(FullAnalysis) vcp_isShortMovie]
	-[PHAsset(FullAnalysis) vcp_isLivePhoto]
	-[PHAsset(FullAnalysis) vcp_fullAnalysisTypes]
	-[PHAsset(FullAnalysis) vcp_fullAnalysisTypesForResources:]
	-[PHAsset(FullAnalysis) vcp_modificationDate]
	-[PHAsset(FullAnalysis) vcp_isVideoSlowmo]
	-[PHAsset(FullAnalysis) vcp_fingerprint:]
	-[PHAsset(FullAnalysis) vcp_queryPHFaces:results:]
	-[PHAsset(FullAnalysis) vcp_faceRectFrom:]
	-[PHAsset(FullAnalysis) vcp_flagsForPHFace:withFaceRect:]
	-[PHAsset(FullAnalysis) vcp_typeDescription]
	-[PHAsset(FullAnalysis) vcp_isPano]
	-[PHAsset(FullAnalysis) vcp_isSdofPhoto]
	-[PHAsset(FullAnalysis) vcp_isVideoTimelapse]
	-[PHAsset(FullAnalysis) vcp_originalSize]

NSMutableArray(PHAssetResource)
	// instance methods
	-[NSMutableArray(PHAssetResource) vcp_sortBySize]

NSArray(PHAssetResource)
	// instance methods
	-[NSArray(PHAssetResource) vcp_hasLocalMovie:]
	-[NSArray(PHAssetResource) vcp_thumbnailResource]
	-[NSArray(PHAssetResource) vcp_avAsset:]
	-[NSArray(PHAssetResource) vcp_localPhotoResourcesSorted:]
	-[NSArray(PHAssetResource) vcp_hasLocalPhoto:]
	-[NSArray(PHAssetResource) vcp_isOriginalLocal]
	-[NSArray(PHAssetResource) vcp_hasLocalAdjustments]
	-[NSArray(PHAssetResource) vcp_resourceWithType:]
	-[NSArray(PHAssetResource) vcp_smallResourceMeetingCriteria:]
	-[NSArray(PHAssetResource) vcp_localMovieResourcesSorted:]
	-[NSArray(PHAssetResource) vcp_originalResource]
	-[NSArray(PHAssetResource) vcp_originalVideoResource]
	-[NSArray(PHAssetResource) vcp_getFpsRate]
	-[NSArray(PHAssetResource) vcp_hasLocalSlowmo]
	-[NSArray(PHAssetResource) vcp_adjustmentsResource]
	-[NSArray(PHAssetResource) vcp_smallMovieDerivativeResource]

NSBundle(VCPMediaAnalysis)
	// class methods
	+[NSBundle(VCPMediaAnalysis) vcp_mediaAnalysisBundle]

NSDictionary(Exif)
	// class methods
	+[NSDictionary(Exif) vcp_exifFromImageURL:]

	// instance methods
	-[NSDictionary(Exif) vcp_dateModified]
	-[NSDictionary(Exif) vcp_version]
	-[NSDictionary(Exif) vcp_quality]
	-[NSDictionary(Exif) vcp_types]
	-[NSDictionary(Exif) vcp_degraded]
	-[NSDictionary(Exif) vcp_flags]
	-[NSDictionary(Exif) vcp_results]
	-[NSDictionary(Exif) vcp_statsFlags]
	-[NSDictionary(Exif) vcp_syncPoint]
	-[NSDictionary(Exif) vcp_dateAnalyzed]
	-[NSDictionary(Exif) vcp_fingerprint]
	-[NSDictionary(Exif) vcp_streamedVideo]
	-[NSDictionary(Exif) vcp_time]
	-[NSDictionary(Exif) vcp_timerange]
	-[NSDictionary(Exif) vcp_flashFired]
	-[NSDictionary(Exif) vcp_scaledExposureTime]

NSMutableDictionary(MediaAnalysis)
	// instance methods
	-[NSMutableDictionary(MediaAnalysis) vcp_setVersion:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setDateModified:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setDateAnalyzed:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setFingerprint:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setResult:forKey:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addTypes:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setSyncPoint:]
	-[NSMutableDictionary(MediaAnalysis) vcp_appendResults:]
	-[NSMutableDictionary(MediaAnalysis) vcp_removeSyncPoint]
	-[NSMutableDictionary(MediaAnalysis) vcp_appendResult:forKey:]
	-[NSMutableDictionary(MediaAnalysis) vcp_mutableResults]
	-[NSMutableDictionary(MediaAnalysis) vcp_setResults:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setTimerange:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setQuality:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setStatsFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setTypes:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addEntriesFromResults:]
	-[NSMutableDictionary(MediaAnalysis) vcp_removeResultForKey:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addStatsFlags:]

NSPredicate(MediaAnalysis)
	// class methods
	+[NSPredicate(MediaAnalysis) vcp_photosPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_stillPhotosPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_livePhotosPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_moviesPredicate:]

PHAssetResource(MediaAnalysis)
	// class methods
	+[PHAssetResource(MediaAnalysis) vcp_allResourcesForAsset:]

	// instance methods
	-[PHAssetResource(MediaAnalysis) vcp_size]
	-[PHAssetResource(MediaAnalysis) vcp_isLocallyAvailable]
	-[PHAssetResource(MediaAnalysis) vcp_isPhotoResourceUsable:]
	-[PHAssetResource(MediaAnalysis) vcp_isMovie]
	-[PHAssetResource(MediaAnalysis) vcp_isVideoResourceUsable:]
	-[PHAssetResource(MediaAnalysis) vcp_isPhoto]
	-[PHAssetResource(MediaAnalysis) vcp_isDecodable]
	-[PHAssetResource(MediaAnalysis) vcp_fileSize]
	-[PHAssetResource(MediaAnalysis) vcp_avAsset]

PHPhotoLibrary(MediaAnalysis)
	// class methods
	+[PHPhotoLibrary(MediaAnalysis) vcp_defaultURL]
	+[PHPhotoLibrary(MediaAnalysis) vcp_defaultPhotoLibrary]
	+[PHPhotoLibrary(MediaAnalysis) vcp_defaultMediaAnalysisDatabaseFilepath]

	// instance methods
	-[PHPhotoLibrary(MediaAnalysis) vcp_mediaAnalysisDatabaseFilepath]
	-[PHPhotoLibrary(MediaAnalysis) vcp_url]
	-[PHPhotoLibrary(MediaAnalysis) vcp_mediaAnalysisDirectory]
	-[PHPhotoLibrary(MediaAnalysis) vcp_assetCountForTaskID:]
	-[PHPhotoLibrary(MediaAnalysis) vcp_assetCountWithMediaType:forTaskID:]
	-[PHPhotoLibrary(MediaAnalysis) vcp_assetCountWithInternalPredicate:forTaskID:]
	-[PHPhotoLibrary(MediaAnalysis) vcp_isCPLEnabled]
	-[PHPhotoLibrary(MediaAnalysis) vcp_isCPLSyncComplete]
	-[PHPhotoLibrary(MediaAnalysis) vcp_isCPLDownloadComplete]

VNClustererBuilder(BackwardCompatability)
	// instance methods
	-[VNClustererBuilder(BackwardCompatability) vcp_updateModelByAddingFaces:]

01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAsset 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetImageGenerator 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReader 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderOutputMetadataAdaptor 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderSampleReferenceOutput 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderTrackOutput 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetTrack 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioFormat 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioPCMBuffer 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMetadataItem 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMutableComposition 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVTimedMetadataGroup 
01 00 0a00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVURLAsset 
01 00 2100 /System/Library/Frameworks/OpenGLES.framework/OpenGLES: EAGLContext 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNBinaryConvolution 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNConvolution 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNConvolutionDescriptor 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNDepthWiseConvolutionDescriptor 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNFullyConnected 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNPoolingMax 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImage 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImageDescriptor 
01 00 1f00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSTemporaryImage 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSArray 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSBundle 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSCompoundPredicate 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSData 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDate 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSDateFormatter 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDictionary 
01 00 0d00 /System/Library/Frameworks/CoreData.framework/CoreData: NSEntityDescription 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSError 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSException 
01 00 0d00 /System/Library/Frameworks/CoreData.framework/CoreData: NSFetchRequest 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileManager 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedArchiver 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedUnarchiver 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSLocale 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSLock 
01 00 0d00 /System/Library/Frameworks/CoreData.framework/CoreData: NSManagedObject 
01 00 0d00 /System/Library/Frameworks/CoreData.framework/CoreData: NSManagedObjectModel 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableArray 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableData 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableDictionary 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableSet 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSMutableString 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSMutableURLRequest 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumber 
01 00 2a00 /usr/lib/libobjc.A.dylib: NSObject 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSOperation 
01 00 0d00 /System/Library/Frameworks/CoreData.framework/CoreData: NSPersistentContainer 
01 00 0d00 /System/Library/Frameworks/CoreData.framework/CoreData: NSPersistentStoreDescription 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSPredicate 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSPropertyListSerialization 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSSet 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSSortDescriptor 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSString 
01 00 0e00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSURL 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSURLSession 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSURLSessionConfiguration 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSUUID 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSXPCConnection 
01 00 1600 /System/Library/Frameworks/Foundation.framework/Foundation: NSXPCInterface 
01 00 2500 /System/Library/PrivateFrameworks/ProtocolBuffer.framework/ProtocolBuffer: PBCodable 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFSlowMotionConfiguration 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFVideoAVObjectBuilder 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFVideoAdjustments 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAsset 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResource 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResourceManager 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResourceRequestOptions 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFace 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFetchOptions 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHPhotoLibrary 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHSceneClassification 
01 00 2600 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNAudioStreamAnalyzer 
01 00 2600 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectSoundRequest 
01 00 2600 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectionResult 
01 00 0300 /System/Library/PrivateFrameworks/TelephonyUtilities.framework/TelephonyUtilities: TUCallCenter 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyImageAestheticsRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyJunkImageRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNClustererBuilder 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNClustererBuilderOptions 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNCreateFaceprintRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNCreateImageprintRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNCreateSceneprintRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceCaptureQualityRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceRectanglesRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNFaceprint 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNGenerateAttentionBasedSaliencyImageRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNIdentifyJunkRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNImageRequestHandler 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNImageprint 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNProcessingDevice 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNSceneClassificationRequest 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNSceneObservation 
01 00 2900 /System/Library/Frameworks/Vision.framework/Vision: VNSceneprint 
