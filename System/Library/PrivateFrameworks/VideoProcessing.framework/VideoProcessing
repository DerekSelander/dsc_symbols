|| __DATA.__data _VCPPhotosProcessing_ForceFullScanKey
|| __DATA.__data _VCPProcessingTask_MaxNumberOfAssetToProcess
|| __DATA.__data _VCPTurboProcessing_DutyCyclingKey
|| __DATA.__data _VCPTurboProcessing_QualityOfServiceKey
|| __DATA.__data _VCPTurboProcessing_VCPTaskIDsKey
|| __DATA.__data _VCPVideoStabilizationProcessing_GyroKey
|| __DATA.__data _VCPVideoStabilizationProcessing_PixelKey
|| __DATA.__objc_data _OBJC_CLASS_$_VCPCallerIdentificationResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPCaptureAnalysisSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPContentAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPDownloadManager
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceAnchor
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceClusterer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceGeometry
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceProcessingServiceWorker
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceUtils
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFullAnalysisURLProcessingTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHandObservation
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHandPoseImageRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHandPoseVideoRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeFaceIdentificationTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeKitAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeKitAnalysisSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeResidentMaintenanceTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHumanPoseImageRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHumanPoseVideoRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageConverter
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageHandsAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPInMemoryAVAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPInternetReachability
|| __DATA.__objc_data _OBJC_CLASS_$_VCPKeypoint
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMetaTrackDecoder
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieCurationResults
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieHighlightResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPersonBuilder
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPersonObservation
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPhotosPersistenceDelegate
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPhotosSceneprintAssetProcessingTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPriorityAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPProtoAssetAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPRealTimeAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPSceneTaxonomy
|| __DATA.__objc_data _OBJC_CLASS_$_VCPURLAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoChatAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoKeyFrameResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoProcessor
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoProcessorSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoStabilizationAssetProcessingTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoStabilizer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVisualIntelligenceAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVoiceOverAssetProcessingTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVoiceOverService
|| __DATA_CONST.__const _HomeKitAnalysisServiceName
|| __DATA_CONST.__const _HomeKitSessionAnalysisServiceName
|| __DATA_CONST.__const _MediaAnalysisActivityLevelResultsKey
|| __DATA_CONST.__const _MediaAnalysisAdjustedFingerprintKey
|| __DATA_CONST.__const _MediaAnalysisAnalysisTypesKey
|| __DATA_CONST.__const _MediaAnalysisApplauseResultsKey
|| __DATA_CONST.__const _MediaAnalysisBabbleResultsKey
|| __DATA_CONST.__const _MediaAnalysisBlurResultsKey
|| __DATA_CONST.__const _MediaAnalysisCameraMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisCheeringResultsKey
|| __DATA_CONST.__const _MediaAnalysisClassificationResultsKey
|| __DATA_CONST.__const _MediaAnalysisCompositionResultsKey
|| __DATA_CONST.__const _MediaAnalysisDateAnalyzedKey
|| __DATA_CONST.__const _MediaAnalysisDateModifiedKey
|| __DATA_CONST.__const _MediaAnalysisDistanceResultsKey
|| __DATA_CONST.__const _MediaAnalysisDomain
|| __DATA_CONST.__const _MediaAnalysisExposureResultsKey
|| __DATA_CONST.__const _MediaAnalysisFacePrintResultsKey
|| __DATA_CONST.__const _MediaAnalysisFaceResultsKey
|| __DATA_CONST.__const _MediaAnalysisFeatureVectorResultsKey
|| __DATA_CONST.__const _MediaAnalysisFineSubjectMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisFlagsKey
|| __DATA_CONST.__const _MediaAnalysisHandsResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanActionClassificationResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanActionResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanPoseInternalResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanPoseResultsKey
|| __DATA_CONST.__const _MediaAnalysisInterestingnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisObjectsResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisRecommendResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisSharpnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisJunkResultsKey
|| __DATA_CONST.__const _MediaAnalysisKeyFrameResourceResultsKey
|| __DATA_CONST.__const _MediaAnalysisLaughterResultsKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoEffectsResultsKey
|| __DATA_CONST.__const _MediaAnalysisLoudnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisMasterFingerprintKey
|| __DATA_CONST.__const _MediaAnalysisMovieHighlightResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovieSummaryResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovingObjectResultsKey
|| __DATA_CONST.__const _MediaAnalysisMusicResultsKey
|| __DATA_CONST.__const _MediaAnalysisObstructionResultsKey
|| __DATA_CONST.__const _MediaAnalysisOrientationResultsKey
|| __DATA_CONST.__const _MediaAnalysisPetsFaceResultsKey
|| __DATA_CONST.__const _MediaAnalysisPetsResultsKey
|| __DATA_CONST.__const _MediaAnalysisPhotosServiceName
|| __DATA_CONST.__const _MediaAnalysisPreEncodeResultsKey
|| __DATA_CONST.__const _MediaAnalysisQualityKey
|| __DATA_CONST.__const _MediaAnalysisQualityResultsKey
|| __DATA_CONST.__const _MediaAnalysisRealTimeServiceName
|| __DATA_CONST.__const _MediaAnalysisResultAestheticAllScoresKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticFailureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticHarmoniousColorScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticImmersivenessScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticInterestingSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticIntrusiveObjectPresenceScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticLivelyColorScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticLowKeyLightingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticNoiseScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticOverallScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantCameraTiltScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantCompositionScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantLightingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantPatternScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantPerspectiveScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantPostProcessingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantReflectionsScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantSymmetryScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticSharplyFocusedSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticTastefullyBlurredScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticWellChosenBackgroundScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticWellFramedSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticWellTimedShotScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAttributesKey
|| __DATA_CONST.__const _MediaAnalysisResultBestPlaybackCropAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultClassificationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDistanceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDominantLineAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDuplicateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDurationKey
|| __DATA_CONST.__const _MediaAnalysisResultEnergyAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePoseYawAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePositionAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePrintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceQualityAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFeatureVectorAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFlagsKey
|| __DATA_CONST.__const _MediaAnalysisResultFlashAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultGyroStabilizationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsKeypointsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsKeypointsConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionScoreAbsoluteAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionScoreRelativeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanKeypointsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanScoreAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultIndexAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultJunkAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultJunkConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameContentScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameExposureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameFaceQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameGlobalQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFramePenaltyScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameScoreAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameSharpnessScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTextureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTimeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTimestampKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameVisualPleasingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsGatingDescriptionsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsMatchingScenesAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsRecipeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLongExposureSuggestionStateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLoopSuggestionStateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultMovingObjectsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultNeighborAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultNeighborDateModifiedAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultOrientationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPeakAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPetsBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPetsConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPreEncodeDataAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultQualityKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyAcceptableCropKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyObjectnessAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyPreferredCropKey
|| __DATA_CONST.__const _MediaAnalysisResultSceneprintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSceneprintDistanceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSharpnessAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSharpnessFacesAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultShotTypeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSlowMoFlickerAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSongSignatureAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultStabilizationAnalysisConfidence
|| __DATA_CONST.__const _MediaAnalysisResultStabilizationRecipeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultStartKey
|| __DATA_CONST.__const _MediaAnalysisResultStillTimeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSummaryTimerangeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultTextureAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultUnderExposeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultVanishingPointAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultVanishingPointConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultsKey
|| __DATA_CONST.__const _MediaAnalysisSaliencyResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneChangeResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneprintResultsKey
|| __DATA_CONST.__const _MediaAnalysisServiceName
|| __DATA_CONST.__const _MediaAnalysisShotTypeResultsKey
|| __DATA_CONST.__const _MediaAnalysisSongResultsKey
|| __DATA_CONST.__const _MediaAnalysisStatsFlagsKey
|| __DATA_CONST.__const _MediaAnalysisSubjectMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisSubtleMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisSyncPointKey
|| __DATA_CONST.__const _MediaAnalysisTrackingResultsKey
|| __DATA_CONST.__const _MediaAnalysisUtteranceResultsKey
|| __DATA_CONST.__const _MediaAnalysisVersionKey
|| __DATA_CONST.__const _MediaAnalysisVideoStabilizationResultsKey
|| __DATA_CONST.__const _MediaAnalysisVoiceResultsKey
|| __DATA_CONST.__const _VCPAnalysisCountFailedKey
|| __DATA_CONST.__const _VCPAnalysisCountProcessedKey
|| __DATA_CONST.__const _VCPAnalysisCountTotalAllowedKey
|| __DATA_CONST.__const _VCPAnalysisResultUsingBestResourceKey
|| __DATA_CONST.__const _VCPAnalysisResultWarningImageTooSmallKey
|| __DATA_CONST.__const _VCPAnalyticsEventDasDutyCycleKey
|| __DATA_CONST.__const _VCPAnalyticsEventDasDutyCycleTaskKey
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyAvgSpeed
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyDuration
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyPreviousQoS
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyPreviousQoSDuration
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyQoS
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyQoSDelay
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyRequestedQoS
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyTaskName
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowInnerUp
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowOuterUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowOuterUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekPuff
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekSquintLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekSquintRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeBlinkLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeBlinkRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookInLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookInRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookOutLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookOutRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeSquintLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeSquintRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeWideLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeWideRight
|| __DATA_CONST.__const _VCPBlendShapeLocationJawForward
|| __DATA_CONST.__const _VCPBlendShapeLocationJawLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationJawOpen
|| __DATA_CONST.__const _VCPBlendShapeLocationJawRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthClose
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthDimpleLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthDimpleRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFrownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFrownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFunnel
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLowerDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLowerDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPressLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPressRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPucker
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRollLower
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRollUpper
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthShrugLower
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthShrugUpper
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthSmileLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthSmileRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthStretchLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthStretchRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthUpperUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthUpperUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationNoseSneerLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationNoseSneerRight
|| __DATA_CONST.__const _VCPBoundingBoxKey
|| __DATA_CONST.__const _VCPCaptureAnalysisAggregatedSubjectMotionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisDispatchQueuePropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisDurationKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceAnchorResultKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceBoundsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceResultsKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceRollAnglesPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFlagsKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFocalLengthInPixelsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFrameHeightPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFrameWidthPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisGlobalMotionKey
|| __DATA_CONST.__const _VCPCaptureAnalysisInterestingnessScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObjectsMotionKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObjectsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObstructionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisQualityKey
|| __DATA_CONST.__const _VCPCaptureAnalysisRegionsOfInterestResultKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSceneChangeScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSharpnessScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisStartKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSubjectMotionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisTrackingScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisTurboModePropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisVoiceResultsKey
|| __DATA_CONST.__const _VCPConfidenceKey
|| __DATA_CONST.__const _VCPContentTypeKey
|| __DATA_CONST.__const _VCPFaceMetadataArrayKey
|| __DATA_CONST.__const _VCPFaceRectangleKey
|| __DATA_CONST.__const _VCPFaceRollKey
|| __DATA_CONST.__const _VCPFaceYawKey
|| __DATA_CONST.__const _VCPFacesToDelete
|| __DATA_CONST.__const _VCPFacesToPersist
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonPromoterRequestAdvancedStatusKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonPromoterStatusKey
|| __DATA_CONST.__const _VCPMediaAnalysisService_InProcessOption
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowOnDemand
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowOnDemandGyro
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowOnDemandPixel
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowStreaming
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_KeepPrivateResults
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_MaxHighlightDuration
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_Standalone
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_StoreAnalysis
|| __DATA_CONST.__const _VCPPhotoLibrariesDefaultsKey
|| __DATA_CONST.__const _VCPPriorityScoreKey
|| __DATA_CONST.__const _VCPQuickFaceIDModelLastGenerationKey
|| __DATA_CONST.__const _VCPQuickFaceIdentification
|| __DATA_CONST.__const _VCPRequestForceCPUPropertyKey
|| __DATA_CONST.__const _VCPRequestFrameHeightPropertyKey
|| __DATA_CONST.__const _VCPRequestFrameWidthPropertyKey
|| __DATA_CONST.__const _VCPRequestHumanActionWinSizePropertyKey
|| __DATA_CONST.__const _VCPRequestMaxNumOfHandsPropertyKey
|| __DATA_CONST.__const _VCPRequestRevisionPropertyKey
|| __DATA_CONST.__const _VCPTaskProcessingService_ServiceName
|| __DATA_CONST.__const _VCPVideoProcessor_FramesPerSecondKey
|| __DATA_CONST.__const _VCPVisualIntelligence_AddressKey
|| __DATA_CONST.__const _VCPVisualIntelligence_EmailAddressKey
|| __DATA_CONST.__const _VCPVisualIntelligence_EventKey
|| __DATA_CONST.__const _VCPVisualIntelligence_FlightInfoKey
|| __DATA_CONST.__const _VCPVisualIntelligence_LinkKey
|| __DATA_CONST.__const _VCPVisualIntelligence_PhoneNumberKey
|| __DATA_CONST.__const _VCPVisualIntelligence_TitleKey
|| __DATA_CONST.__const _VCPVisualIntelligence_TrackingInfoKey
|| __DATA_CONST.__const _VCPVisualIntelligence_TranscriptKey
|| __DATA_CONST.__const _VCPVoiceOver_FaceProcessingType
|| __DATA_CONST.__const _VCPVoiceOver_InProcessOption
|| __DATA_CONST.__const _VCPVoiceOver_SceneProcessingType
|| __DATA_CONST.__const _VCPVoiceOver_ServiceIdentifier
|| __DATA_CONST.__const _kMAComputeOperationType_ImageAnalysis
|| __DATA_CONST.__const _kMAComputeOperationType_MovieAnalysis
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPDeviceInformation
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPEffectsAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceCropManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceMerger
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFingerprint
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPImageDescriptor
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPImageManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPInterAssetAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPLogManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMABaseTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMediaAnalysisService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMediaAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotoAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosAsset
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosQuickFaceIdentificationLibraryProcessingTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosQuickFaceIdentificationManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPreAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPProtoLivePhotoEffectsRecipe
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPTimeMeasurement
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPTimer
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VCPMABaseTask
|| __TEXT.__const _MediaAnalysisBlacklistAgeOutInterval
|| __TEXT.__const _MediaAnalysisBlacklistThreshold
|| __TEXT.__const _MediaAnalysisChangedVersion17
|| __TEXT.__const _MediaAnalysisChangedVersion3
|| __TEXT.__const _MediaAnalysisChangedVersion6
|| __TEXT.__const _MediaAnalysisChangedVersion7
|| __TEXT.__const _MediaAnalysisDeleteRetainInterval
|| __TEXT.__const _MediaAnalysisDistanceUnknown
|| __TEXT.__const _MediaAnalysisFlagsCameraAll
|| __TEXT.__const _MediaAnalysisQualityUnknown
|| __TEXT.__const _MediaAnalysisTypeAllInternal
|| __TEXT.__const _MediaAnalysisVersion
|| __TEXT.__const _VCPLogToOSLogType
|| __TEXT.__const _VCPMAFullAnalysisTypesImage
|| __TEXT.__const _VCPMAFullAnalysisTypesLivePhoto
|| __TEXT.__const _VCPMAFullAnalysisTypesMovie
|| __TEXT.__const _VCPMAFullAnalysisTypesThumbnail
|| __TEXT.__const _VCPPhotosFaceAnalysisTaskID
|| __TEXT.__const _VCPPhotosFaceProcessingVersion
|| __TEXT.__const _VCPPhotosMediaAnalysisTaskID
|| __TEXT.__const _VCPPhotosMultiWorkerAnalysisTaskID
|| __TEXT.__const _VCPPhotosSceneAnalysisTaskID
|| __TEXT.__const _VCPPhotosSceneProcessingVersion
|| __TEXT.__const _VCPQuickFaceIDModelMaxPersons
|| __TEXT.__text _DeviceHasANE
|| __TEXT.__text _MAComputeRequest_Create
|| __TEXT.__text _MAComputeRequest_ParseOutput
|| __TEXT.__text _MAComputeRequest_Start
|| __TEXT.__text _MediaAnalysisConvertAnalysisToOriginalTime
|| __TEXT.__text _MediaAnalysisFlagsForTypes
|| __TEXT.__text _MediaAnalysisLogLevel
|| __TEXT.__text _MediaAnalysisPostProcessSlowmoResults
|| __TEXT.__text _MediaAnalysisPurgeResources
|| __TEXT.__text _MediaAnalysisResultsKeyToType
|| __TEXT.__text _MediaAnalysisResultsKeysForAnalysisTypes
|| __TEXT.__text _MediaAnalysisResultsTypeToKey
|| __TEXT.__text _MediaAnalysisResultsUpdatedSince
|| __TEXT.__text _MediaAnalysisStripInternalResultsFromAnalysis
|| __TEXT.__text _MediaAnalysisStripKeyframeResourceResultsFromAnalysis
|| __TEXT.__text _MediaAnalysisStripOutdatedAnalysis
|| __TEXT.__text _MediaAnalysisTypeDescription
|| __TEXT.__text _MediaAnalysisTypeShortDescription
|| __TEXT.__text _MediaAnalysisTypesUpdatedSince
|| __TEXT.__text _SocType
|| __TEXT.__text _VCPBaseRetryIntervalSeconds
|| __TEXT.__text _VCPBuildPersons
|| __TEXT.__text _VCPCodecGetProperties
|| __TEXT.__text _VCPCodecGetProperty
|| __TEXT.__text _VCPCompressionSessionCompleteFrames
|| __TEXT.__text _VCPCompressionSessionCopyProperty
|| __TEXT.__text _VCPCompressionSessionCopySupportedPropertyDictionary
|| __TEXT.__text _VCPCompressionSessionCreate
|| __TEXT.__text _VCPCompressionSessionEncodeFrame
|| __TEXT.__text _VCPCompressionSessionGetPixelBufferPool
|| __TEXT.__text _VCPCompressionSessionGetTypeID
|| __TEXT.__text _VCPCompressionSessionInvalidate
|| __TEXT.__text _VCPCompressionSessionSetProperty
|| __TEXT.__text _VCPDecompressionSessionCheckIfLastSubFrame
|| __TEXT.__text _VCPDecompressionSessionCopyBlackPixelBuffer
|| __TEXT.__text _VCPDecompressionSessionCopyProperty
|| __TEXT.__text _VCPDecompressionSessionCopySerializableProperties
|| __TEXT.__text _VCPDecompressionSessionCopySupportedPropertyDictionary
|| __TEXT.__text _VCPDecompressionSessionCreate
|| __TEXT.__text _VCPDecompressionSessionDecodeFrame
|| __TEXT.__text _VCPDecompressionSessionFinishDelayedFrames
|| __TEXT.__text _VCPDecompressionSessionGetTypeID
|| __TEXT.__text _VCPDecompressionSessionInvalidate
|| __TEXT.__text _VCPDecompressionSessionSetProperties
|| __TEXT.__text _VCPDecompressionSessionSetProperty
|| __TEXT.__text _VCPDecompressionSessionWaitForAsynchronousFrames
|| __TEXT.__text _VCPMAQoSDescription
|| __TEXT.__text _VCPParseConfigurationRecordAndCreateParameterSets
|| __TEXT.__text _VCPParseParameterSetsAndCreateConfigurationRecord
|| __TEXT.__text _VCPPerformance_LogMeasurement
|| __TEXT.__text _VCPPerformance_RecordMeasurement
|| __TEXT.__text _VCPPerformance_ReportSummary
|| __TEXT.__text _VCPProcessingStatusDescription
|| __TEXT.__text _VCPProcessingStatusShortDescription
|| __TEXT.__text _VCPPromotePersons
|| __TEXT.__text _VCPRateControlSessionBeforeEmitEncodedFrame
|| __TEXT.__text _VCPRateControlSessionBeforeEncodeFrame
|| __TEXT.__text _VCPRateControlSessionBeforePrepareToEncodeFrame
|| __TEXT.__text _VCPRateControlSessionCompleteFrames
|| __TEXT.__text _VCPRateControlSessionCopyProperty
|| __TEXT.__text _VCPRateControlSessionCopySupportedPropertyDictionary
|| __TEXT.__text _VCPRateControlSessionCreate
|| __TEXT.__text _VCPRateControlSessionInvalidate
|| __TEXT.__text _VCPRateControlSessionSetProperty
|| __TEXT.__text _VCPReadCodecConfigParams
|| __TEXT.__text _VCPReadFrameSliceHeader
|| __TEXT.__text _VCPReadHEVCSliceHeader
|| __TEXT.__text _VCPSessionCopyProperty
|| __TEXT.__text _VCPSessionCreate
|| __TEXT.__text _VCPSessionCreateDefaultBufferProperties
|| __TEXT.__text _VCPSessionExecute
|| __TEXT.__text _VCPSessionGetTypeID
|| __TEXT.__text _VCPSessionSetProperty
|| __TEXT.__text _VCPSignPostLog
|| __TEXT.__text _VCPSpecialLabelFromSceneClassificationID
|| __TEXT.__text _VCPTaskIDDescription
|| __TEXT.__text _VCPVersionForTask
|| __TEXT.__text _VPModuleInitialize
__ AVFoundation: _AVFileTypeAVCI
__ AVFoundation: _AVFileTypeHEIC
__ AVFoundation: _AVFileTypeHEIF
__ AVFoundation: _AVFileTypeMPEG4
__ AVFoundation: _AVFileTypeQuickTimeMovie
__ AVFoundation: _AVFormatIDKey
__ AVFoundation: _AVLinearPCMBitDepthKey
__ AVFoundation: _AVLinearPCMIsBigEndianKey
__ AVFoundation: _AVLinearPCMIsFloatKey
__ AVFoundation: _AVLinearPCMIsNonInterleaved
__ AVFoundation: _AVMediaTypeAudio
__ AVFoundation: _AVMediaTypeMetadata
__ AVFoundation: _AVMediaTypeVideo
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataDetectedFace
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataVideoOrientation
__ AVFoundation: _AVMetadataKeySpaceQuickTimeMetadata
__ AVFoundation: _AVMetadataQuickTimeMetadataKeyContentIdentifier
__ AVFoundation: _AVNumberOfChannelsKey
__ AVFoundation: _AVSampleRateKey
__ AVFoundation: _AVVideoCodecKey
__ AVFoundation: _AVVideoCodecTypeH264
__ AVFoundation: _OBJC_CLASS_$_AVAsset
__ AVFoundation: _OBJC_CLASS_$_AVAssetImageGenerator
__ AVFoundation: _OBJC_CLASS_$_AVAssetReader
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderOutputMetadataAdaptor
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderSampleReferenceOutput
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderTrackOutput
__ AVFoundation: _OBJC_CLASS_$_AVAssetTrack
__ AVFoundation: _OBJC_CLASS_$_AVAssetWriter
__ AVFoundation: _OBJC_CLASS_$_AVAssetWriterInput
__ AVFoundation: _OBJC_CLASS_$_AVAssetWriterInputMetadataAdaptor
__ AVFoundation: _OBJC_CLASS_$_AVAudioFormat
__ AVFoundation: _OBJC_CLASS_$_AVAudioPCMBuffer
__ AVFoundation: _OBJC_CLASS_$_AVMetadataItem
__ AVFoundation: _OBJC_CLASS_$_AVMutableComposition
__ AVFoundation: _OBJC_CLASS_$_AVTimedMetadataGroup
__ AVFoundation: _OBJC_CLASS_$_AVURLAsset
__ AVFoundation: _OBJC_METACLASS_$_AVURLAsset
__ Accelerate: _sgetrf_
__ Accelerate: _sgetri_
__ Accelerate: _vDSP_create_fftsetup
__ Accelerate: _vDSP_ctoz
__ Accelerate: _vDSP_deq22
__ Accelerate: _vDSP_destroy_fftsetup
__ Accelerate: _vDSP_dotpr
__ Accelerate: _vDSP_f3x3
__ Accelerate: _vDSP_f5x5
__ Accelerate: _vDSP_fft2d_zrip
__ Accelerate: _vDSP_imgfir
__ Accelerate: _vDSP_maxmgv
__ Accelerate: _vDSP_mmul
__ Accelerate: _vDSP_mtrans
__ Accelerate: _vDSP_normalize
__ Accelerate: _vDSP_sve
__ Accelerate: _vDSP_svesq
__ Accelerate: _vDSP_vabs
__ Accelerate: _vDSP_vadd
__ Accelerate: _vDSP_vclr
__ Accelerate: _vDSP_vfill
__ Accelerate: _vDSP_vfltu8
__ Accelerate: _vDSP_vsadd
__ Accelerate: _vDSP_vsdiv
__ Accelerate: _vDSP_vsmul
__ Accelerate: _vDSP_vsorti
__ Accelerate: _vDSP_vsub
__ Accelerate: _vDSP_ztoc
__ Accelerate: _vDSP_zvcmul
__ Accelerate: _vDSP_zvmags
__ Accelerate: _vImageScale_ARGB8888
__ Accelerate: _vImageScale_Planar8
__ AppleCVA: _kCVAFaceKit_DetectedFacesArray
__ AudioToolbox: _AudioComponentFindNext
__ AudioToolbox: _AudioComponentInstanceDispose
__ AudioToolbox: _AudioComponentInstanceNew
__ AudioToolbox: _AudioUnitAddPropertyListener
__ AudioToolbox: _AudioUnitGetProperty
__ AudioToolbox: _AudioUnitInitialize
__ AudioToolbox: _AudioUnitProcessMultiple
__ AudioToolbox: _AudioUnitReset
__ AudioToolbox: _AudioUnitSetProperty
__ AutoLoop: _autoloopSettingsDestroy
__ AutoLoop: _autoloopSettingsSetDisableStabilizationGPU
__ AutoLoop: _autoloopSettingsSetGating
__ AutoLoop: _autoloopSettingsSetOptimizeForMemoryUse
__ AutoLoop: _createAutoLoopSettingsForAsset
__ AutoLoop: _createBundleDefaultGatingClassifierURL
__ AutoLoop: _getGatingResult
__ AutoLoop: _liveAnalysisResultDestroy
__ AutoLoop: _liveAnalysisResultToDictionary
__ AutoLoop: _runLiveAnalysisPipeline
__ CMCapture: _FigLivePhotoMetadataComputeDeserializationSize
__ CMCapture: _FigLivePhotoMetadataDeserializeIntoBuffer
__ CMCapture: _kFigCaptureSampleBufferAttachmentKey_MetadataDictionary
__ CMCapture: _kFigCaptureStreamMetadata_AEAverage
__ CMCapture: _kFigCaptureStreamMetadata_AGC
__ CMCapture: _kFigCaptureStreamMetadata_AWBBGain
__ CMCapture: _kFigCaptureStreamMetadata_AWBGGain
__ CMCapture: _kFigCaptureStreamMetadata_AWBRGain
__ CMCapture: _kFigCaptureStreamMetadata_ExposureTime
__ CMCapture: _kFigCaptureStreamMetadata_NormalizedSNR
__ CMCapture: _kFigCaptureStreamMetadata_ispDGain
__ CMCapture: _kFigCaptureStreamMetadata_sensorDGain
__ CMCapture: _kFigFaceDetectionMetadataArray
__ CMCapture: _kFigFaceDetectionMetadata_FaceID
__ CMCapture: _kFigFaceDetectionMetadata_Rect
__ CMCapture: _kFigFaceDetectionMetadata_Roll
__ CMCapture: _kFigFaceDetectionMetadata_Yaw
__ CMCapture: _kFigMetadataDataType_QuickTimeMetadataLivePhotoInfo
__ CMCapture: _kFigMetadataIdentifier_QuickTimeMetadataLivePhotoInfo
__ CoreAnalytics: _AnalyticsSendEventLazy
__ CoreAppleCVA: __ZN3cva12VecLibLapackIfE5ormqrENS_4math8MULTSIDEENS2_5TRANSEiiiPfiS5_S5_iS5_i
__ CoreAppleCVA: __ZN3cva6VecLibIfE4gemmEbbiiifPKfiS3_ifPfi
__ CoreAppleCVA: __ZN3cva6vecLib5geqrfIfEEviiPT_iS3_S3_iPi
__ CoreAppleCVA: __ZN3cva6vecLib5gesvdIfEEvcciiPKT_iPS2_S5_iS5_iS5_iPi
__ CoreAppleCVA: __ZN3cva6vecLib5trtrsIfEEvccciiPKT_iPS2_iPi
__ CoreData: _NSOverwriteMergePolicy
__ CoreData: _OBJC_CLASS_$_NSEntityDescription
__ CoreData: _OBJC_CLASS_$_NSFetchRequest
__ CoreData: _OBJC_CLASS_$_NSManagedObject
__ CoreData: _OBJC_CLASS_$_NSManagedObjectModel
__ CoreData: _OBJC_CLASS_$_NSPersistentContainer
__ CoreData: _OBJC_CLASS_$_NSPersistentStoreDescription
__ CoreData: _OBJC_METACLASS_$_NSManagedObject
__ CoreFoundation: _CFAllocatorAllocate
__ CoreFoundation: _CFAllocatorDeallocate
__ CoreFoundation: _CFArrayAppendValue
__ CoreFoundation: _CFArrayCreate
__ CoreFoundation: _CFArrayCreateCopy
__ CoreFoundation: _CFArrayCreateMutable
__ CoreFoundation: _CFArrayGetCount
__ CoreFoundation: _CFArrayGetTypeID
__ CoreFoundation: _CFArrayGetValueAtIndex
__ CoreFoundation: _CFArrayInsertValueAtIndex
__ CoreFoundation: _CFArrayRemoveAllValues
__ CoreFoundation: _CFArrayRemoveValueAtIndex
__ CoreFoundation: _CFBooleanGetTypeID
__ CoreFoundation: _CFBooleanGetValue
__ CoreFoundation: _CFBundleCopyResourcesDirectoryURL
__ CoreFoundation: _CFBundleGetBundleWithIdentifier
__ CoreFoundation: _CFCopyTypeIDDescription
__ CoreFoundation: _CFDataAppendBytes
__ CoreFoundation: _CFDataCreate
__ CoreFoundation: _CFDataCreateMutable
__ CoreFoundation: _CFDataCreateWithBytesNoCopy
__ CoreFoundation: _CFDataGetBytePtr
__ CoreFoundation: _CFDataGetBytes
__ CoreFoundation: _CFDataGetLength
__ CoreFoundation: _CFDataGetMutableBytePtr
__ CoreFoundation: _CFDataGetTypeID
__ CoreFoundation: _CFDataIncreaseLength
__ CoreFoundation: _CFDataSetLength
__ CoreFoundation: _CFDictionaryAddValue
__ CoreFoundation: _CFDictionaryApplyFunction
__ CoreFoundation: _CFDictionaryContainsKey
__ CoreFoundation: _CFDictionaryCreate
__ CoreFoundation: _CFDictionaryCreateCopy
__ CoreFoundation: _CFDictionaryCreateMutable
__ CoreFoundation: _CFDictionaryCreateMutableCopy
__ CoreFoundation: _CFDictionaryGetCount
__ CoreFoundation: _CFDictionaryGetTypeID
__ CoreFoundation: _CFDictionaryGetValue
__ CoreFoundation: _CFDictionaryGetValueIfPresent
__ CoreFoundation: _CFDictionaryRemoveValue
__ CoreFoundation: _CFDictionarySetValue
__ CoreFoundation: _CFEqual
__ CoreFoundation: _CFGetTypeID
__ CoreFoundation: _CFHash
__ CoreFoundation: _CFLog
__ CoreFoundation: _CFNumberCompare
__ CoreFoundation: _CFNumberCreate
__ CoreFoundation: _CFNumberGetType
__ CoreFoundation: _CFNumberGetTypeID
__ CoreFoundation: _CFNumberGetValue
__ CoreFoundation: _CFPreferencesCopyAppValue
__ CoreFoundation: _CFPreferencesGetAppBooleanValue
__ CoreFoundation: _CFPreferencesGetAppIntegerValue
__ CoreFoundation: _CFPropertyListCreateData
__ CoreFoundation: _CFPropertyListCreateWithData
__ CoreFoundation: _CFRelease
__ CoreFoundation: _CFRetain
__ CoreFoundation: _CFSetAddValue
__ CoreFoundation: _CFSetContainsValue
__ CoreFoundation: _CFSetCreateMutable
__ CoreFoundation: _CFShow
__ CoreFoundation: _CFStringAppendFormat
__ CoreFoundation: _CFStringCompare
__ CoreFoundation: _CFStringCreateArrayBySeparatingStrings
__ CoreFoundation: _CFStringCreateCopy
__ CoreFoundation: _CFStringCreateMutable
__ CoreFoundation: _CFStringCreateMutableCopy
__ CoreFoundation: _CFStringCreateWithCString
__ CoreFoundation: _CFStringCreateWithFormat
__ CoreFoundation: _CFStringFindAndReplace
__ CoreFoundation: _CFStringGetCString
__ CoreFoundation: _CFStringGetCStringPtr
__ CoreFoundation: _CFStringGetDoubleValue
__ CoreFoundation: _CFStringGetLength
__ CoreFoundation: _CFStringGetMaximumSizeForEncoding
__ CoreFoundation: _CFStringGetTypeID
__ CoreFoundation: _CFURLCopyPath
__ CoreFoundation: _CFURLCreateAbsoluteURLWithBytes
__ CoreFoundation: _CFURLCreateWithString
__ CoreFoundation: _NSRangeException
__ CoreFoundation: _NSURLContentModificationDateKey
__ CoreFoundation: _NSURLTypeIdentifierKey
__ CoreFoundation: _OBJC_CLASS_$_NSArray
__ CoreFoundation: _OBJC_CLASS_$_NSConstantArray
__ CoreFoundation: _OBJC_CLASS_$_NSData
__ CoreFoundation: _OBJC_CLASS_$_NSDate
__ CoreFoundation: _OBJC_CLASS_$_NSDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSException
__ CoreFoundation: _OBJC_CLASS_$_NSLocale
__ CoreFoundation: _OBJC_CLASS_$_NSMutableArray
__ CoreFoundation: _OBJC_CLASS_$_NSMutableData
__ CoreFoundation: _OBJC_CLASS_$_NSMutableDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSMutableSet
__ CoreFoundation: _OBJC_CLASS_$_NSNull
__ CoreFoundation: _OBJC_CLASS_$_NSSet
__ CoreFoundation: _OBJC_CLASS_$_NSTimeZone
__ CoreFoundation: _OBJC_CLASS_$_NSURL
__ CoreFoundation: _OBJC_EHTYPE_$_NSException
__ CoreFoundation: __CFRuntimeCreateInstance
__ CoreFoundation: __CFRuntimeRegisterClass
__ CoreFoundation: ___CFConstantStringClassReference
__ CoreFoundation: ___NSArray0__struct
__ CoreFoundation: ___NSDictionary0__struct
__ CoreFoundation: ___kCFBooleanFalse
__ CoreFoundation: ___kCFBooleanTrue
__ CoreFoundation: _kCFAllocatorDefault
__ CoreFoundation: _kCFAllocatorNull
__ CoreFoundation: _kCFBooleanFalse
__ CoreFoundation: _kCFBooleanTrue
__ CoreFoundation: _kCFTypeArrayCallBacks
__ CoreFoundation: _kCFTypeDictionaryKeyCallBacks
__ CoreFoundation: _kCFTypeDictionaryValueCallBacks
__ CoreFoundation: _kCFTypeSetCallBacks
__ CoreGraphics: _CGAffineTransformConcat
__ CoreGraphics: _CGAffineTransformIdentity
__ CoreGraphics: _CGAffineTransformMakeScale
__ CoreGraphics: _CGBitmapContextCreate
__ CoreGraphics: _CGColorSpaceCreateDeviceRGB
__ CoreGraphics: _CGContextConcatCTM
__ CoreGraphics: _CGContextDrawImage
__ CoreGraphics: _CGImageGetHeight
__ CoreGraphics: _CGImageGetProperty
__ CoreGraphics: _CGImageGetWidth
__ CoreGraphics: _CGPointZero
__ CoreGraphics: _CGRectApplyAffineTransform
__ CoreGraphics: _CGRectCreateDictionaryRepresentation
__ CoreGraphics: _CGRectGetMaxX
__ CoreGraphics: _CGRectGetMaxY
__ CoreGraphics: _CGRectGetMidX
__ CoreGraphics: _CGRectGetMidY
__ CoreGraphics: _CGRectGetMinX
__ CoreGraphics: _CGRectGetMinY
__ CoreGraphics: _CGRectIntersection
__ CoreGraphics: _CGRectIntersectsRect
__ CoreGraphics: _CGRectIsEmpty
__ CoreGraphics: _CGRectIsInfinite
__ CoreGraphics: _CGRectIsNull
__ CoreGraphics: _CGRectMakeWithDictionaryRepresentation
__ CoreGraphics: _CGRectNull
__ CoreGraphics: _CGRectUnion
__ CoreGraphics: _CGRectZero
__ CoreGraphics: _CGSizeCreateDictionaryRepresentation
__ CoreGraphics: _CGSizeZero
__ CoreGraphics: _kCGImagePropertyIOSurface
__ CoreMedia: _CMAudioFormatDescriptionGetStreamBasicDescription
__ CoreMedia: _CMBaseObjectGetDerivedStorage
__ CoreMedia: _CMBaseObjectGetVTable
__ CoreMedia: _CMBlockBufferAccessDataBytes
__ CoreMedia: _CMBlockBufferAppendBufferReference
__ CoreMedia: _CMBlockBufferAppendMemoryBlock
__ CoreMedia: _CMBlockBufferAssureBlockMemory
__ CoreMedia: _CMBlockBufferCopyDataBytes
__ CoreMedia: _CMBlockBufferCreateWithBufferReference
__ CoreMedia: _CMBlockBufferCreateWithMemoryBlock
__ CoreMedia: _CMBlockBufferGetDataLength
__ CoreMedia: _CMBlockBufferGetDataPointer
__ CoreMedia: _CMBlockBufferReplaceDataBytes
__ CoreMedia: _CMByteStreamGetClassID
__ CoreMedia: _CMDerivedObjectCreate
__ CoreMedia: _CMFormatDescriptionGetExtension
__ CoreMedia: _CMFormatDescriptionGetExtensions
__ CoreMedia: _CMFormatDescriptionGetMediaSubType
__ CoreMedia: _CMGetAttachment
__ CoreMedia: _CMMetadataFormatDescriptionCreateWithMetadataSpecifications
__ CoreMedia: _CMMetadataFormatDescriptionGetIdentifiers
__ CoreMedia: _CMSampleBufferCreate
__ CoreMedia: _CMSampleBufferCreateCopyWithNewTiming
__ CoreMedia: _CMSampleBufferCreateForImageBuffer
__ CoreMedia: _CMSampleBufferGetDataBuffer
__ CoreMedia: _CMSampleBufferGetDuration
__ CoreMedia: _CMSampleBufferGetFormatDescription
__ CoreMedia: _CMSampleBufferGetImageBuffer
__ CoreMedia: _CMSampleBufferGetNumSamples
__ CoreMedia: _CMSampleBufferGetOutputDuration
__ CoreMedia: _CMSampleBufferGetOutputPresentationTimeStamp
__ CoreMedia: _CMSampleBufferGetPresentationTimeStamp
__ CoreMedia: _CMSampleBufferGetSampleAttachmentsArray
__ CoreMedia: _CMSampleBufferGetSampleSize
__ CoreMedia: _CMSampleBufferGetSampleTimingInfo
__ CoreMedia: _CMTimeAdd
__ CoreMedia: _CMTimeCompare
__ CoreMedia: _CMTimeConvertScale
__ CoreMedia: _CMTimeCopyAsDictionary
__ CoreMedia: _CMTimeGetSeconds
__ CoreMedia: _CMTimeMake
__ CoreMedia: _CMTimeMakeFromDictionary
__ CoreMedia: _CMTimeMakeWithEpoch
__ CoreMedia: _CMTimeMakeWithSeconds
__ CoreMedia: _CMTimeMultiply
__ CoreMedia: _CMTimeMultiplyByFloat64
__ CoreMedia: _CMTimeMultiplyByRatio
__ CoreMedia: _CMTimeRangeContainsTime
__ CoreMedia: _CMTimeRangeContainsTimeRange
__ CoreMedia: _CMTimeRangeCopyAsDictionary
__ CoreMedia: _CMTimeRangeEqual
__ CoreMedia: _CMTimeRangeFromTimeToTime
__ CoreMedia: _CMTimeRangeGetEnd
__ CoreMedia: _CMTimeRangeGetIntersection
__ CoreMedia: _CMTimeRangeGetUnion
__ CoreMedia: _CMTimeRangeMake
__ CoreMedia: _CMTimeRangeMakeFromDictionary
__ CoreMedia: _CMTimeSubtract
__ CoreMedia: _CMVideoFormatDescriptionCreateForImageBuffer
__ CoreMedia: _CMVideoFormatDescriptionCreateFromH264ParameterSets
__ CoreMedia: _CMVideoFormatDescriptionGetCleanAperture
__ CoreMedia: _CMVideoFormatDescriptionGetDimensions
__ CoreMedia: _CMVideoFormatDescriptionGetPresentationDimensions
__ CoreMedia: _FigFormatDescriptionRelease
__ CoreMedia: _FigMetadataFormatDescriptionGetLocalIDForMetadataIdentifyingFactors
__ CoreMedia: _FigMetadataFormatDescriptionGetSetupDataForLocalID
__ CoreMedia: _FigSignalErrorAt
__ CoreMedia: _FigThreadGetMachThreadPriorityValue
__ CoreMedia: _FigThreadRunOnce
__ CoreMedia: _kCMByteStreamProperty_AvailableLength
__ CoreMedia: _kCMByteStreamProperty_EntireLength
__ CoreMedia: _kCMByteStreamProperty_EntireLengthAvailableOnDemand
__ CoreMedia: _kCMByteStreamProperty_ReadSupported
__ CoreMedia: _kCMByteStreamProperty_URL
__ CoreMedia: _kCMByteStreamProperty_WriteSupported
__ CoreMedia: _kCMFormatDescriptionExtension_FormatName
__ CoreMedia: _kCMFormatDescriptionExtension_SampleDescriptionExtensionAtoms
__ CoreMedia: _kCMMetadataBaseDataType_SInt8
__ CoreMedia: _kCMMetadataFormatDescriptionMetadataSpecificationKey_DataType
__ CoreMedia: _kCMMetadataFormatDescriptionMetadataSpecificationKey_Identifier
__ CoreMedia: _kCMSampleAttachmentKey_DependsOnOthers
__ CoreMedia: _kCMSampleAttachmentKey_EarlierDisplayTimesAllowed
__ CoreMedia: _kCMSampleAttachmentKey_IsDependedOnByOthers
__ CoreMedia: _kCMSampleAttachmentKey_NotSync
__ CoreMedia: _kCMSampleAttachmentKey_PartialSync
__ CoreMedia: _kCMTimeIndefinite
__ CoreMedia: _kCMTimeInvalid
__ CoreMedia: _kCMTimeNegativeInfinity
__ CoreMedia: _kCMTimePositiveInfinity
__ CoreMedia: _kCMTimeRangeInvalid
__ CoreMedia: _kCMTimeRangeZero
__ CoreMedia: _kCMTimeZero
__ CoreMedia: _kFigByteStreamProperty_UTI
__ CoreMedia: _kFigMetadataIdentifier_QuickTimeMetadataStillImageTime
__ CoreServices: _UTTypeConformsTo
__ CoreServices: _UTTypeCreatePreferredIdentifierForTag
__ CoreServices: _kUTTagClassFilenameExtension
__ CoreServices: _kUTTypeImage
__ CoreServices: _kUTTypeJPEG
__ CoreServices: _kUTTypeMovie
__ CoreServices: _kUTTypeVideo
__ CoreVideo: _CVBufferGetAttachment
__ CoreVideo: _CVBufferGetAttachments
__ CoreVideo: _CVBufferPropagateAttachments
__ CoreVideo: _CVBufferSetAttachment
__ CoreVideo: _CVBufferSetAttachments
__ CoreVideo: _CVColorPrimariesGetIntegerCodePointForString
__ CoreVideo: _CVColorPrimariesGetStringForIntegerCodePoint
__ CoreVideo: _CVMetalTextureCacheCreate
__ CoreVideo: _CVMetalTextureCacheCreateTextureFromImage
__ CoreVideo: _CVMetalTextureGetTexture
__ CoreVideo: _CVPixelBufferCreate
__ CoreVideo: _CVPixelBufferCreateResolvedAttributesDictionary
__ CoreVideo: _CVPixelBufferCreateWithIOSurface
__ CoreVideo: _CVPixelBufferGetBaseAddress
__ CoreVideo: _CVPixelBufferGetBaseAddressOfPlane
__ CoreVideo: _CVPixelBufferGetBytesPerRow
__ CoreVideo: _CVPixelBufferGetBytesPerRowOfPlane
__ CoreVideo: _CVPixelBufferGetDataSize
__ CoreVideo: _CVPixelBufferGetExtendedPixels
__ CoreVideo: _CVPixelBufferGetHeight
__ CoreVideo: _CVPixelBufferGetHeightOfPlane
__ CoreVideo: _CVPixelBufferGetIOSurface
__ CoreVideo: _CVPixelBufferGetPixelFormatType
__ CoreVideo: _CVPixelBufferGetPlaneCount
__ CoreVideo: _CVPixelBufferGetWidth
__ CoreVideo: _CVPixelBufferGetWidthOfPlane
__ CoreVideo: _CVPixelBufferIsCompatibleWithAttributes
__ CoreVideo: _CVPixelBufferIsPlanar
__ CoreVideo: _CVPixelBufferLockBaseAddress
__ CoreVideo: _CVPixelBufferPoolCreate
__ CoreVideo: _CVPixelBufferPoolCreatePixelBuffer
__ CoreVideo: _CVPixelBufferPoolGetPixelBufferAttributes
__ CoreVideo: _CVPixelBufferPoolRelease
__ CoreVideo: _CVPixelBufferPoolRetain
__ CoreVideo: _CVPixelBufferPoolSetMaxBufferAge
__ CoreVideo: _CVPixelBufferRelease
__ CoreVideo: _CVPixelBufferRetain
__ CoreVideo: _CVPixelBufferUnlockBaseAddress
__ CoreVideo: _CVPixelFormatDescriptionGetDescriptionWithPixelFormatType
__ CoreVideo: _CVTransferFunctionGetIntegerCodePointForString
__ CoreVideo: _CVTransferFunctionGetStringForIntegerCodePoint
__ CoreVideo: _CVYCbCrMatrixGetIntegerCodePointForString
__ CoreVideo: _CVYCbCrMatrixGetStringForIntegerCodePoint
__ CoreVideo: _kCVImageBufferChromaLocationBottomFieldKey
__ CoreVideo: _kCVImageBufferChromaLocationTopFieldKey
__ CoreVideo: _kCVImageBufferChromaLocation_Bottom
__ CoreVideo: _kCVImageBufferChromaLocation_BottomLeft
__ CoreVideo: _kCVImageBufferChromaLocation_Center
__ CoreVideo: _kCVImageBufferChromaLocation_Left
__ CoreVideo: _kCVImageBufferChromaLocation_Top
__ CoreVideo: _kCVImageBufferChromaLocation_TopLeft
__ CoreVideo: _kCVImageBufferCleanApertureHeightKey
__ CoreVideo: _kCVImageBufferCleanApertureHorizontalOffsetKey
__ CoreVideo: _kCVImageBufferCleanApertureKey
__ CoreVideo: _kCVImageBufferCleanApertureVerticalOffsetKey
__ CoreVideo: _kCVImageBufferCleanApertureWidthKey
__ CoreVideo: _kCVImageBufferColorPrimariesKey
__ CoreVideo: _kCVImageBufferColorPrimaries_EBU_3213
__ CoreVideo: _kCVImageBufferColorPrimaries_ITU_R_709_2
__ CoreVideo: _kCVImageBufferColorPrimaries_SMPTE_C
__ CoreVideo: _kCVImageBufferPixelAspectRatioHorizontalSpacingKey
__ CoreVideo: _kCVImageBufferPixelAspectRatioKey
__ CoreVideo: _kCVImageBufferPixelAspectRatioVerticalSpacingKey
__ CoreVideo: _kCVImageBufferSpillMapKey
__ CoreVideo: _kCVImageBufferTransferFunctionKey
__ CoreVideo: _kCVImageBufferTransferFunction_ITU_R_709_2
__ CoreVideo: _kCVImageBufferTransferFunction_SMPTE_240M_1995
__ CoreVideo: _kCVImageBufferTransferFunction_UseGamma
__ CoreVideo: _kCVImageBufferYCbCrMatrixKey
__ CoreVideo: _kCVImageBufferYCbCrMatrix_ITU_R_601_4
__ CoreVideo: _kCVImageBufferYCbCrMatrix_ITU_R_709_2
__ CoreVideo: _kCVImageBufferYCbCrMatrix_SMPTE_240M_1995
__ CoreVideo: _kCVMetalTextureCacheMaximumTextureAgeKey
__ CoreVideo: _kCVMetalTextureUsage
__ CoreVideo: _kCVPixelBufferBytesPerRowAlignmentKey
__ CoreVideo: _kCVPixelBufferCacheModeKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsBottomKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsLeftKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsRightKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsTopKey
__ CoreVideo: _kCVPixelBufferHeightKey
__ CoreVideo: _kCVPixelBufferIOSurfacePropertiesKey
__ CoreVideo: _kCVPixelBufferPixelFormatTypeKey
__ CoreVideo: _kCVPixelBufferPlaneAlignmentKey
__ CoreVideo: _kCVPixelBufferPoolMinimumBufferCountKey
__ CoreVideo: _kCVPixelBufferWidthKey
__ CoreVideo: _kCVPixelFormatCompressionType
__ CoreVideo: _kCVPixelFormatPlanes
__ DataDetectorsCore: _OBJC_CLASS_$_DDScannerService
__ DataDetectorsCore: _OBJC_CLASS_$_DDScannerServiceConfiguration
__ Espresso: _espresso_context_destroy
__ Espresso: _espresso_create_context
__ Espresso: _espresso_create_plan
__ Espresso: _espresso_network_bind_buffer
__ Espresso: _espresso_network_select_configuration
__ Espresso: _espresso_plan_add_network
__ Espresso: _espresso_plan_build
__ Espresso: _espresso_plan_build_clean
__ Espresso: _espresso_plan_destroy
__ Espresso: _espresso_plan_execute_sync
__ Espresso: _espresso_plan_get_phase
__ Foundation: _NSAllMapTableKeys
__ Foundation: _NSClassFromString
__ Foundation: _NSCocoaErrorDomain
__ Foundation: _NSLocalizedDescriptionKey
__ Foundation: _NSLog
__ Foundation: _NSOSStatusErrorDomain
__ Foundation: _NSPointFromString
__ Foundation: _NSRectFromString
__ Foundation: _NSSizeFromString
__ Foundation: _NSStringFromClass
__ Foundation: _NSStringFromPoint
__ Foundation: _NSStringFromRect
__ Foundation: _NSStringFromSize
__ Foundation: _NSTemporaryDirectory
__ Foundation: _OBJC_CLASS_$_NSBundle
__ Foundation: _OBJC_CLASS_$_NSCompoundPredicate
__ Foundation: _OBJC_CLASS_$_NSConstantDoubleNumber
__ Foundation: _OBJC_CLASS_$_NSConstantFloatNumber
__ Foundation: _OBJC_CLASS_$_NSConstantIntegerNumber
__ Foundation: _OBJC_CLASS_$_NSCountedSet
__ Foundation: _OBJC_CLASS_$_NSDateFormatter
__ Foundation: _OBJC_CLASS_$_NSError
__ Foundation: _OBJC_CLASS_$_NSFileManager
__ Foundation: _OBJC_CLASS_$_NSIndexSet
__ Foundation: _OBJC_CLASS_$_NSKeyedArchiver
__ Foundation: _OBJC_CLASS_$_NSKeyedUnarchiver
__ Foundation: _OBJC_CLASS_$_NSLock
__ Foundation: _OBJC_CLASS_$_NSMapTable
__ Foundation: _OBJC_CLASS_$_NSMutableString
__ Foundation: _OBJC_CLASS_$_NSNumber
__ Foundation: _OBJC_CLASS_$_NSNumberFormatter
__ Foundation: _OBJC_CLASS_$_NSOperation
__ Foundation: _OBJC_CLASS_$_NSPredicate
__ Foundation: _OBJC_CLASS_$_NSProcessInfo
__ Foundation: _OBJC_CLASS_$_NSProgress
__ Foundation: _OBJC_CLASS_$_NSPropertyListSerialization
__ Foundation: _OBJC_CLASS_$_NSSortDescriptor
__ Foundation: _OBJC_CLASS_$_NSString
__ Foundation: _OBJC_CLASS_$_NSUUID
__ Foundation: _OBJC_CLASS_$_NSValue
__ Foundation: _OBJC_CLASS_$_NSXPCConnection
__ Foundation: _OBJC_CLASS_$_NSXPCInterface
__ Foundation: _OBJC_METACLASS_$_NSOperation
__ IOKit: _IOObjectRelease
__ IOKit: _IORegistryEntryCreateCFProperty
__ IOKit: _IORegistryEntryFromPath
__ IOKit: _IORegistryEntrySearchCFProperty
__ IOKit: _IOServiceGetMatchingService
__ IOKit: _IOServiceMatching
__ IOKit: _kIOMasterPortDefault
__ IOSurface: _IOSurfaceCreate
__ IOSurface: _IOSurfaceGetAddressFormatOfPlane
__ IOSurface: _IOSurfaceGetAllocSize
__ IOSurface: _IOSurfaceGetBaseAddress
__ IOSurface: _IOSurfaceGetBaseAddressOfCompressedTileDataRegionOfPlane
__ IOSurface: _IOSurfaceGetBaseAddressOfCompressedTileHeaderRegionOfPlane
__ IOSurface: _IOSurfaceGetBaseAddressOfPlane
__ IOSurface: _IOSurfaceGetBytesPerRowOfPlane
__ IOSurface: _IOSurfaceGetCompressedTileHeightOfPlane
__ IOSurface: _IOSurfaceGetCompressedTileWidthOfPlane
__ IOSurface: _IOSurfaceGetCompressionTypeOfPlane
__ IOSurface: _IOSurfaceGetHeight
__ IOSurface: _IOSurfaceGetHeightInCompressedTilesOfPlane
__ IOSurface: _IOSurfaceGetHeightOfPlane
__ IOSurface: _IOSurfaceGetHorizontalPixelOffsetWithinCompressedTileArrayOfPlane
__ IOSurface: _IOSurfaceGetID
__ IOSurface: _IOSurfaceGetPixelFormat
__ IOSurface: _IOSurfaceGetPlaneCount
__ IOSurface: _IOSurfaceGetRegistryID
__ IOSurface: _IOSurfaceGetTileFormat
__ IOSurface: _IOSurfaceGetVerticalPixelOffsetWithinCompressedTileArrayOfPlane
__ IOSurface: _IOSurfaceGetWidth
__ IOSurface: _IOSurfaceGetWidthInCompressedTilesOfPlane
__ IOSurface: _IOSurfaceGetWidthOfPlane
__ IOSurface: _IOSurfaceIsTiled
__ IOSurface: _IOSurfaceLock
__ IOSurface: _IOSurfaceLookup
__ IOSurface: _IOSurfaceSetValue
__ IOSurface: _IOSurfaceUnlock
__ IOSurface: _kIOSurfaceAddressFormat
__ IOSurface: _kIOSurfaceAllocSize
__ IOSurface: _kIOSurfaceBufferTileFormat
__ IOSurface: _kIOSurfaceBufferTileMode
__ IOSurface: _kIOSurfaceBytesPerElement
__ IOSurface: _kIOSurfaceBytesPerRow
__ IOSurface: _kIOSurfaceCacheMode
__ IOSurface: _kIOSurfaceHeight
__ IOSurface: _kIOSurfaceIsGlobal
__ IOSurface: _kIOSurfaceName
__ IOSurface: _kIOSurfacePixelFormat
__ IOSurface: _kIOSurfacePlaneBytesPerCompressedTileHeader
__ IOSurface: _kIOSurfacePlaneBytesPerElement
__ IOSurface: _kIOSurfacePlaneBytesPerRow
__ IOSurface: _kIOSurfacePlaneBytesPerRowOfCompressedTileHeaderGroups
__ IOSurface: _kIOSurfacePlaneBytesPerRowOfTileData
__ IOSurface: _kIOSurfacePlaneBytesPerTileData
__ IOSurface: _kIOSurfacePlaneCompressedTileDataRegionOffset
__ IOSurface: _kIOSurfacePlaneCompressedTileHeaderRegionOffset
__ IOSurface: _kIOSurfacePlaneCompressedTileHeight
__ IOSurface: _kIOSurfacePlaneCompressedTileWidth
__ IOSurface: _kIOSurfacePlaneCompressionType
__ IOSurface: _kIOSurfacePlaneElementHeight
__ IOSurface: _kIOSurfacePlaneElementWidth
__ IOSurface: _kIOSurfacePlaneHTPCPredictionSelector
__ IOSurface: _kIOSurfacePlaneHTPCVerticalHeaderGroupingMode
__ IOSurface: _kIOSurfacePlaneHeight
__ IOSurface: _kIOSurfacePlaneHeightInCompressedTiles
__ IOSurface: _kIOSurfacePlaneHorizontalPixelOffsetWithinCompressedTileArray
__ IOSurface: _kIOSurfacePlaneInfo
__ IOSurface: _kIOSurfacePlaneOffset
__ IOSurface: _kIOSurfacePlaneSize
__ IOSurface: _kIOSurfacePlaneVerticalPixelOffsetWithinCompressedTileArray
__ IOSurface: _kIOSurfacePlaneWidth
__ IOSurface: _kIOSurfacePlaneWidthInCompressedTiles
__ IOSurface: _kIOSurfaceWidth
__ IOSurfaceAccelerator: _IOSurfaceAcceleratorCreate
__ IOSurfaceAccelerator: _IOSurfaceAcceleratorSetCustomFilter
__ IOSurfaceAccelerator: _IOSurfaceAcceleratorTransformSurface
__ IOSurfaceAccelerator: _kIOSurfaceAcceleratorUseCustomFilter
__ ImageIO: _CGImageSourceCopyPropertiesAtIndex
__ ImageIO: _CGImageSourceCreateImageAtIndex
__ ImageIO: _CGImageSourceCreateWithData
__ ImageIO: _CGImageSourceCreateWithURL
__ ImageIO: _kCGImagePropertyExifAuxDictionary
__ ImageIO: _kCGImagePropertyExifAuxROIRegionFaceType
__ ImageIO: _kCGImagePropertyExifAuxROIRegionHeight
__ ImageIO: _kCGImagePropertyExifAuxROIRegionList
__ ImageIO: _kCGImagePropertyExifAuxROIRegionType
__ ImageIO: _kCGImagePropertyExifAuxROIRegionWidth
__ ImageIO: _kCGImagePropertyExifAuxROIRegionX
__ ImageIO: _kCGImagePropertyExifAuxROIRegionY
__ ImageIO: _kCGImagePropertyExifDictionary
__ ImageIO: _kCGImagePropertyExifExposureTime
__ ImageIO: _kCGImagePropertyExifFlash
__ ImageIO: _kCGImagePropertyMakerAppleDictionary
__ ImageIO: _kCGImagePropertyOrientation
__ ImageIO: _kCGImagePropertyPixelHeight
__ ImageIO: _kCGImagePropertyPixelWidth
__ ImageIO: _kCGImageSourceShouldCache
__ ImageIO: _kCGImageSourceSkipMetadata
__ ImageIO: _kCGImageSourceSubsampleFactor
__ ImageIO: _kCGImageSourceUseCoreImage
__ ImageIO: _kCGImageSourceUseHardwareAcceleration
__ InertiaCam: _ICAnalysisAddFrame
__ InertiaCam: _ICAnalysisInit
__ InertiaCam: _ICAnalysisStopAndGetResult
__ InertiaCam: _ICCalcCinematicL1Corrections
__ InertiaCam: _ICDestroyResult
__ InertiaCam: _ICGetAnalysisConfidence
__ InertiaCam: _ICGetResultConfidence
__ InertiaCam: _ICGetResultHomographies
__ InertiaCam: _ICGetResultStats
__ InertiaCam: _ICStoreAnalyticsViaDodML
__ InertiaCam: _ICSynthesizeAnalysis
__ InertiaCam: _IC_ANALYTICS_SOURCETYPE_LIVEPHOTO
__ InertiaCam: _IC_ANALYTICS_SOURCETYPE_OTHERVIDEO
__ InertiaCam: _IC_A_FRAMEINSTRUCTIONS
__ InertiaCam: _IC_A_FRAMETRANSFORM_HOMOGRAPHY
__ InertiaCam: _IC_A_FRAMETRANSFORM_RAWTIME
__ InertiaCam: _IC_A_HOMOGRAPHIES_INVERTED
__ InertiaCam: _IC_A_HOMOGRAPHIES_MAP_TO_REFERENCE
__ InertiaCam: _IC_A_REQUESTED_CROP_RECT
__ InertiaCam: _IC_A_SOURCE_SIZE
__ InertiaCam: _IC_A_STAT_FRAME_COUNT
__ InertiaCam: _IC_A_TRIM_DURATION
__ InertiaCam: _IC_A_TRIM_START_TIME
__ InertiaCam: _IC_C_CROP_FRACTION
__ InertiaCam: _IC_C_FIRST_INDEX
__ InertiaCam: _IC_C_LAST_INDEX
__ InertiaCam: _IC_C_MOTION_BLUR_VECTOR
__ MediaToolbox: _FigAssetCreateWithByteStream
__ MediaToolbox: _FigAssetReaderCreateWithAsset
__ MediaToolbox: _FigPhotoDecompressionContainerCreateDictionaryDescription
__ MediaToolbox: _FigPhotoDecompressionContainerCreateImageForIndex
__ MediaToolbox: _FigPhotoDecompressionSessionCreate
__ MediaToolbox: _FigPhotoDecompressionSessionCreateContainer
__ MediaToolbox: _FigPhotoDecompressionSessionDiscardCachedBuffers
__ MediaToolbox: _kFigFileType_QuickTimeMovie
__ MediaToolbox: _kFigPhotoDecompressionContainerDescription_PrimaryImageIndex
__ MediaToolbox: _kFigPhotoDecompressionOption_ApplyTransform
__ MediaToolbox: _kFigPhotoDecompressionOption_MaxPixelSize
__ MediaToolbox: _kFigPhotoDecompressionOption_OutputPixelFormat
__ Metal: _MTLCreateSystemDefaultDevice
__ MetalPerformanceShaders: _MPSSetHeapCacheDuration
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNBinaryConvolution
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNConvolution
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNConvolutionDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNDepthWiseConvolutionDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNFullyConnected
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNPoolingMax
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImage
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImageDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSTemporaryImage
__ PhotoLibraryServices: _kPLLocationUtilsCoarseLocationHorizontalAccuracy
__ Photos: _OBJC_CLASS_$_PHAsset
__ Photos: _OBJC_CLASS_$_PHAssetChangeRequest
__ Photos: _OBJC_CLASS_$_PHAssetCollection
__ Photos: _OBJC_CLASS_$_PHAssetResource
__ Photos: _OBJC_CLASS_$_PHAssetResourceManager
__ Photos: _OBJC_CLASS_$_PHAssetResourceRequestOptions
__ Photos: _OBJC_CLASS_$_PHFace
__ Photos: _OBJC_CLASS_$_PHFaceChangeRequest
__ Photos: _OBJC_CLASS_$_PHFaceCrop
__ Photos: _OBJC_CLASS_$_PHFaceCropChangeRequest
__ Photos: _OBJC_CLASS_$_PHFaceGroup
__ Photos: _OBJC_CLASS_$_PHFaceGroupChangeRequest
__ Photos: _OBJC_CLASS_$_PHFaceprint
__ Photos: _OBJC_CLASS_$_PHFetchOptions
__ Photos: _OBJC_CLASS_$_PHFetchResult
__ Photos: _OBJC_CLASS_$_PHMoment
__ Photos: _OBJC_CLASS_$_PHObject
__ Photos: _OBJC_CLASS_$_PHPerson
__ Photos: _OBJC_CLASS_$_PHPersonChangeRequest
__ Photos: _OBJC_CLASS_$_PHPhotoLibrary
__ Photos: _OBJC_CLASS_$_PHSceneClassification
__ Photos: _PHAssetPropertySetCore
__ Photos: _PHAssetPropertySetFaceWorker
__ Photos: _PHAssetPropertySetIdentifier
__ Photos: _PHAssetPropertySetOriginalMetadata
__ Photos: _PHAssetPropertySetPlacesCore
__ Photos: _PHAssetPropertySetSceneAnalysis
__ Photos: _PHFacePropertySetClustering
__ Photos: _PHFacePropertySetCore
__ Photos: _PHFacePropertySetIdentifier
__ Photos: _PHFacePropertySetPersonBuilder
__ Photos: _PHPhotosErrorDomain
__ PhotosFormats: _OBJC_CLASS_$_PFPhotosFaceUtilities
__ PhotosFormats: _OBJC_CLASS_$_PFSlowMotionConfiguration
__ PhotosFormats: _OBJC_CLASS_$_PFVideoAVObjectBuilder
__ PhotosFormats: _OBJC_CLASS_$_PFVideoAdjustments
__ PhotosFormats: _PFPhotosSceneProcessingFromCameraVersion
__ ProtocolBuffer: _OBJC_CLASS_$_PBCodable
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._bytes
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._error
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._length
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._pos
__ ProtocolBuffer: _OBJC_METACLASS_$_PBCodable
__ ProtocolBuffer: _PBDataWriterPlaceMark
__ ProtocolBuffer: _PBDataWriterRecallMark
__ ProtocolBuffer: _PBDataWriterWriteBOOLField
__ ProtocolBuffer: _PBDataWriterWriteDataField
__ ProtocolBuffer: _PBDataWriterWriteDoubleField
__ ProtocolBuffer: _PBDataWriterWriteFloatField
__ ProtocolBuffer: _PBDataWriterWriteInt32Field
__ ProtocolBuffer: _PBDataWriterWriteInt64Field
__ ProtocolBuffer: _PBDataWriterWriteStringField
__ ProtocolBuffer: _PBDataWriterWriteSubmessage
__ ProtocolBuffer: _PBDataWriterWriteUint32Field
__ ProtocolBuffer: _PBDataWriterWriteUint64Field
__ ProtocolBuffer: _PBReaderPlaceMark
__ ProtocolBuffer: _PBReaderReadData
__ ProtocolBuffer: _PBReaderReadString
__ ProtocolBuffer: _PBReaderRecallMark
__ ProtocolBuffer: _PBReaderSkipValueWithTag
__ ProtocolBuffer: _PBRepeatedFloatAdd
__ ProtocolBuffer: _PBRepeatedFloatClear
__ ProtocolBuffer: _PBRepeatedFloatCopy
__ ProtocolBuffer: _PBRepeatedFloatHash
__ ProtocolBuffer: _PBRepeatedFloatIsEqual
__ ProtocolBuffer: _PBRepeatedFloatNSArray
__ ProtocolBuffer: _PBRepeatedFloatSet
__ ProtocolBuffer: _PBRepeatedInt64Add
__ ProtocolBuffer: _PBRepeatedInt64Clear
__ ProtocolBuffer: _PBRepeatedInt64Copy
__ ProtocolBuffer: _PBRepeatedInt64Hash
__ ProtocolBuffer: _PBRepeatedInt64IsEqual
__ ProtocolBuffer: _PBRepeatedInt64NSArray
__ ProtocolBuffer: _PBRepeatedInt64Set
__ ProtocolBuffer: __ZN2PB13TextFormatter11beginObjectEPKc
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKcd
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKcf
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKci
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKcj
__ ProtocolBuffer: __ZN2PB13TextFormatter9endObjectEv
__ ProtocolBuffer: __ZN2PB4BaseD2Ev
__ ProtocolBuffer: __ZN2PB6Reader10recallMarkERKNS_10ReaderMarkE
__ ProtocolBuffer: __ZN2PB6Reader4skipEjhi
__ ProtocolBuffer: __ZN2PB6Reader9placeMarkERNS_10ReaderMarkE
__ ProtocolBuffer: __ZN2PB6ReaderC1EPKhm
__ ProtocolBuffer: __ZN2PB6Writer11writeVarIntEij
__ ProtocolBuffer: __ZN2PB6Writer11writeVarIntEjj
__ ProtocolBuffer: __ZN2PB6Writer15writeSubmessageERKNS_4BaseEj
__ ProtocolBuffer: __ZN2PB6Writer5writeEdj
__ ProtocolBuffer: __ZN2PB6Writer5writeEfj
__ ProtocolBuffer: __ZN2PB6WriterC1Ev
__ ProtocolBuffer: __ZN2PB6WriterD1Ev
__ ProtocolBuffer: __ZTIN2PB4BaseE
__ SoftLinking: __sl_dlopen_audited
__ SoundAnalysis: _OBJC_CLASS_$_SNAudioStreamAnalyzer
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectSoundRequest
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectionResult
__ SoundAnalysis: _SNSoundIdentifierApplause
__ SoundAnalysis: _SNSoundIdentifierBabble
__ SoundAnalysis: _SNSoundIdentifierCheering
__ SoundAnalysis: _SNSoundIdentifierLaughter
__ SoundAnalysis: _SNSoundIdentifierMusic
__ SoundAnalysis: _SNSoundIdentifierSpeech
__ SystemConfiguration: _SCNetworkReachabilityCreateWithAddress
__ SystemConfiguration: _SCNetworkReachabilityGetFlags
__ SystemConfiguration: _SCNetworkReachabilitySetCallback
__ SystemConfiguration: _SCNetworkReachabilitySetDispatchQueue
__ TelephonyUtilities: _OBJC_CLASS_$_TUCallCenter
__ VideoToolbox: _VTCompressionSessionCompleteFrames
__ VideoToolbox: _VTCompressionSessionCreate
__ VideoToolbox: _VTCompressionSessionEncodeFrame
__ VideoToolbox: _VTCompressionSessionGetPixelBufferPool
__ VideoToolbox: _VTCompressionSessionInvalidate
__ VideoToolbox: _VTCompressionSessionPrepareToEncodeFrames
__ VideoToolbox: _VTCompressionSessionSetProperty
__ VideoToolbox: _VTDecompressionSessionCanAcceptFormatDescription
__ VideoToolbox: _VTDecompressionSessionCopyBlackPixelBuffer
__ VideoToolbox: _VTDecompressionSessionCopyProperty
__ VideoToolbox: _VTDecompressionSessionCopySerializableProperties
__ VideoToolbox: _VTDecompressionSessionCopySupportedPropertyDictionary
__ VideoToolbox: _VTDecompressionSessionCreate
__ VideoToolbox: _VTDecompressionSessionDecodeFrame
__ VideoToolbox: _VTDecompressionSessionFinishDelayedFrames
__ VideoToolbox: _VTDecompressionSessionInvalidate
__ VideoToolbox: _VTDecompressionSessionSetProperties
__ VideoToolbox: _VTDecompressionSessionSetProperty
__ VideoToolbox: _VTDecompressionSessionWaitForAsynchronousFrames
__ VideoToolbox: _VTEncoderSessionCreateVideoFormatDescription
__ VideoToolbox: _VTEncoderSessionDequeueDecodeTimeStamp
__ VideoToolbox: _VTEncoderSessionEmitEncodedFrame
__ VideoToolbox: _VTEncoderSessionEnqueuePresentationTimeStamp
__ VideoToolbox: _VTEncoderSessionSetPixelBufferAttributes
__ VideoToolbox: _VTImageRotationSessionCreate
__ VideoToolbox: _VTImageRotationSessionTransferImage
__ VideoToolbox: _VTPixelTransferSessionCreate
__ VideoToolbox: _VTPixelTransferSessionTransferImage
__ VideoToolbox: _VTRegisterVideoEncoderWithInfo
__ VideoToolbox: _VTSelectAndCreateVideoEncoderInstance
__ VideoToolbox: _VTSessionCopyProperty
__ VideoToolbox: _VTSessionCopySupportedPropertyDictionary
__ VideoToolbox: _VTSessionSetProperty
__ VideoToolbox: _VTVideoEncoderGetCMBaseObject
__ VideoToolbox: _VTVideoEncoderGetClassID
__ VideoToolbox: _kVTCompressionPropertyKey_AllowFrameReordering
__ VideoToolbox: _kVTCompressionPropertyKey_AllowTemporalCompression
__ VideoToolbox: _kVTCompressionPropertyKey_AverageBitRate
__ VideoToolbox: _kVTCompressionPropertyKey_ColorPrimaries
__ VideoToolbox: _kVTCompressionPropertyKey_ConnectionID
__ VideoToolbox: _kVTCompressionPropertyKey_DataRateLimits
__ VideoToolbox: _kVTCompressionPropertyKey_Depth
__ VideoToolbox: _kVTCompressionPropertyKey_EnsureTIJacinto4Compatibility
__ VideoToolbox: _kVTCompressionPropertyKey_ExpectedFrameRate
__ VideoToolbox: _kVTCompressionPropertyKey_FigThreadPriority
__ VideoToolbox: _kVTCompressionPropertyKey_H264EntropyMode
__ VideoToolbox: _kVTCompressionPropertyKey_HDRMetadataInsertionMode
__ VideoToolbox: _kVTCompressionPropertyKey_InputPixelFormat
__ VideoToolbox: _kVTCompressionPropertyKey_InsertTrailingBytes
__ VideoToolbox: _kVTCompressionPropertyKey_MaxKeyFrameInterval
__ VideoToolbox: _kVTCompressionPropertyKey_MaxKeyFrameIntervalDuration
__ VideoToolbox: _kVTCompressionPropertyKey_MaximizePowerEfficiency
__ VideoToolbox: _kVTCompressionPropertyKey_MinNumRepeatedFramesToEncode
__ VideoToolbox: _kVTCompressionPropertyKey_NegotiationDetails
__ VideoToolbox: _kVTCompressionPropertyKey_NumberOfPendingFrames
__ VideoToolbox: _kVTCompressionPropertyKey_NumberOfSubFrameSections
__ VideoToolbox: _kVTCompressionPropertyKey_OutputBitDepth
__ VideoToolbox: _kVTCompressionPropertyKey_PixelAspectRatio
__ VideoToolbox: _kVTCompressionPropertyKey_PreserveDynamicHDRMetadata
__ VideoToolbox: _kVTCompressionPropertyKey_PrioritizeEncodingSpeedOverQuality
__ VideoToolbox: _kVTCompressionPropertyKey_Priority
__ VideoToolbox: _kVTCompressionPropertyKey_ProfileLevel
__ VideoToolbox: _kVTCompressionPropertyKey_RealTime
__ VideoToolbox: _kVTCompressionPropertyKey_RequestedMaxEncoderLatency
__ VideoToolbox: _kVTCompressionPropertyKey_SourceFrameCount
__ VideoToolbox: _kVTCompressionPropertyKey_TransferFunction
__ VideoToolbox: _kVTCompressionPropertyKey_Usage
__ VideoToolbox: _kVTCompressionPropertyKey_YCbCrMatrix
__ VideoToolbox: _kVTDecompressionPropertyKey_ActiveVideoResolution
__ VideoToolbox: _kVTDecompressionPropertyKey_ExtraInLoopChromaFilter
__ VideoToolbox: _kVTDecompressionPropertyKey_PixelBufferPool
__ VideoToolbox: _kVTDecompressionPropertyKey_VideoResolutionAdaptationType
__ VideoToolbox: _kVTDecompressionResolutionKey_Height
__ VideoToolbox: _kVTDecompressionResolutionKey_Width
__ VideoToolbox: _kVTEncodeFrameOptionKey_AcknowledgedTokens
__ VideoToolbox: _kVTEncodeFrameOptionKey_AverageBurstyErrorLength
__ VideoToolbox: _kVTEncodeFrameOptionKey_FECNumBitsAdded
__ VideoToolbox: _kVTEncodeFrameOptionKey_FirstMbInDuplicateSlices
__ VideoToolbox: _kVTEncodeFrameOptionKey_FirstMbInRecvSlices
__ VideoToolbox: _kVTEncodeFrameOptionKey_FirstMbInSkipSlices
__ VideoToolbox: _kVTEncodeFrameOptionKey_ForceKeyFrame
__ VideoToolbox: _kVTEncodeFrameOptionKey_ForceRefresh
__ VideoToolbox: _kVTEncodeFrameOptionKey_LimitFrameSize
__ VideoToolbox: _kVTEncodeFrameOptionKey_PacketErrorRate
__ VideoToolbox: _kVTEncodeFrameOptionKey_PacketHeaderBitsAdded
__ VideoToolbox: _kVTEncodeFrameOptionKey_RepeatedFrame
__ VideoToolbox: _kVTEncodeFrameOptionKey_RoundTripDelay
__ VideoToolbox: _kVTEncodeFrameOptionKey_SectionID
__ VideoToolbox: _kVTEncodeFrameOptionKey_SectionOffsets
__ VideoToolbox: _kVTEncodeFrameOptionKey_VisibleRectangle
__ VideoToolbox: _kVTH264EntropyMode_CABAC
__ VideoToolbox: _kVTHDRMetadataInsertionMode_Auto
__ VideoToolbox: _kVTImageBufferVisibleRectangleKey
__ VideoToolbox: _kVTPixelTransferPropertyKey_DestinationYCbCrMatrix
__ VideoToolbox: _kVTPixelTransferPropertyKey_ScalingMode
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_1_3
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_3_0
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_3_1
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_3_2
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_4_0
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_4_1
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_4_2
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_5_0
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_5_1
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_5_2
__ VideoToolbox: _kVTProfileLevel_H264_Baseline_AutoLevel
__ VideoToolbox: _kVTProfileLevel_H264_High_3_0
__ VideoToolbox: _kVTProfileLevel_H264_High_3_1
__ VideoToolbox: _kVTProfileLevel_H264_High_3_2
__ VideoToolbox: _kVTProfileLevel_H264_High_4_0
__ VideoToolbox: _kVTProfileLevel_H264_High_4_1
__ VideoToolbox: _kVTProfileLevel_H264_High_4_2
__ VideoToolbox: _kVTProfileLevel_H264_High_5_0
__ VideoToolbox: _kVTProfileLevel_H264_High_5_1
__ VideoToolbox: _kVTProfileLevel_H264_High_5_2
__ VideoToolbox: _kVTProfileLevel_H264_High_AutoLevel
__ VideoToolbox: _kVTProfileLevel_H264_Main_3_0
__ VideoToolbox: _kVTProfileLevel_H264_Main_3_1
__ VideoToolbox: _kVTProfileLevel_H264_Main_3_2
__ VideoToolbox: _kVTProfileLevel_H264_Main_4_0
__ VideoToolbox: _kVTProfileLevel_H264_Main_4_1
__ VideoToolbox: _kVTProfileLevel_H264_Main_4_2
__ VideoToolbox: _kVTProfileLevel_H264_Main_5_0
__ VideoToolbox: _kVTProfileLevel_H264_Main_5_1
__ VideoToolbox: _kVTProfileLevel_H264_Main_5_2
__ VideoToolbox: _kVTProfileLevel_H264_Main_AutoLevel
__ VideoToolbox: _kVTProfileLevel_HEVC_Main10_AutoLevel
__ VideoToolbox: _kVTProfileLevel_HEVC_Main444_AutoLevel
__ VideoToolbox: _kVTProfileLevel_HEVC_Main_AutoLevel
__ VideoToolbox: _kVTPropertySupportedValueListKey
__ VideoToolbox: _kVTSampleAttachmentKey_EncodedFrameAvgQP
__ VideoToolbox: _kVTSampleAttachmentKey_FECGroupID
__ VideoToolbox: _kVTSampleAttachmentKey_FECLastFrameInGroup
__ VideoToolbox: _kVTSampleAttachmentKey_FECLevelOfProtection
__ VideoToolbox: _kVTSampleAttachmentKey_PadByteCount
__ VideoToolbox: _kVTSampleAttachmentKey_ReferenceWasRefreshed
__ VideoToolbox: _kVTSampleAttachmentKey_RequireAcknowledgementToken
__ VideoToolbox: _kVTScalingMode_CropSourceToCleanAperture
__ VideoToolbox: _kVTVideoDecoderSpecification_Usage
__ VideoToolbox: _kVTVideoEncoderList_EncoderID
__ VideoToolbox: _kVTVideoEncoderSpecification_CMSession
__ VideoToolbox: _kVTVideoEncoderSpecification_RequireHardwareAcceleratedVideoEncoder
__ VideoToolbox: _kVTVideoEncoder_Hide
__ VideoToolbox: _kVTVideoEncoder_IsHardwareAccelerated
__ VideoToolbox: _kVTVideoEncoder_Rating
__ Vision: _OBJC_CLASS_$_VN5kJNH3eYuyaLxNpZr5Z7zi
__ Vision: _OBJC_CLASS_$_VN6Mb1ME89lyW3HpahkEygIG
__ Vision: _OBJC_CLASS_$_VNAlignFaceRectangleRequest
__ Vision: _OBJC_CLASS_$_VNClassifyFaceAttributesRequest
__ Vision: _OBJC_CLASS_$_VNClassifyImageAestheticsRequest
__ Vision: _OBJC_CLASS_$_VNClassifyJunkImageRequest
__ Vision: _OBJC_CLASS_$_VNClassifyPotentialLandmarkRequest
__ Vision: _OBJC_CLASS_$_VNClustererBuilder
__ Vision: _OBJC_CLASS_$_VNClustererBuilderOptions
__ Vision: _OBJC_CLASS_$_VNClustererQuery
__ Vision: _OBJC_CLASS_$_VNCreateFaceTorsoprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateFaceprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateImageprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateSceneprintRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceCaptureQualityRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceExpressionsRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceLandmarksRequest
__ Vision: _OBJC_CLASS_$_VNDetectFacePoseRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceRectanglesRequest
__ Vision: _OBJC_CLASS_$_VNFaceObservation
__ Vision: _OBJC_CLASS_$_VNFaceTorsoprint
__ Vision: _OBJC_CLASS_$_VNFaceprint
__ Vision: _OBJC_CLASS_$_VNGenerateAttentionBasedSaliencyImageRequest
__ Vision: _OBJC_CLASS_$_VNGenerateObjectnessBasedSaliencyImageRequest
__ Vision: _OBJC_CLASS_$_VNIdentifyJunkRequest
__ Vision: _OBJC_CLASS_$_VNImageBlurScoreRequest
__ Vision: _OBJC_CLASS_$_VNImageExposureScoreRequest
__ Vision: _OBJC_CLASS_$_VNImageRequestHandler
__ Vision: _OBJC_CLASS_$_VNImageprint
__ Vision: _OBJC_CLASS_$_VNProcessingDevice
__ Vision: _OBJC_CLASS_$_VNRecognizeObjectsRequest
__ Vision: _OBJC_CLASS_$_VNRecognizeTextRequest
__ Vision: _OBJC_CLASS_$_VNSceneClassificationRequest
__ Vision: _OBJC_CLASS_$_VNSceneObservation
__ Vision: _OBJC_CLASS_$_VNSceneprint
__ Vision: _OBJC_CLASS_$_VNSession
__ Vision: _OBJC_CLASS_$_VNVYvzEtX1JlUdu8xx5qhDI
__ Vision: _VN0af6454e97767772ce64a19ddaf61f0c
__ Vision: _VN1yPD9G185LIMKFd9RgandG6vUu4B3DZk
__ Vision: _VN220a6626eb3cb51295a4e250ad9da319
__ Vision: _VN2DSYD77FUMKqtcogofprEd
__ Vision: _VN2vIWnsZbk4Su55oeWfKDq1
__ Vision: _VN35FOB1QhtSfYGRIJvTgtTq
__ Vision: _VN3FNQUJVIs2puI1uPc9mxh7
__ Vision: _VN4MFjUmPIIWefw2ZktBTwVB
__ Vision: _VN4QuphG8kE4qDaDycivBkX5
__ Vision: _VN62b042cc67e0a7d589ecdb58232fe23d
__ Vision: _VN6XNMvaRunPpzWjGa9uUHD6
__ Vision: _VN6ZsEIQ9ri2eF1vhsxw5COm
__ Vision: _VN6cM1E1jfvMnUZoEeDjinPOtJKpacqIpr
__ Vision: _VN79a8f83d9d55eb4eb2c9695902c47b53
__ Vision: _VN7gQUejje8mmnE9GSTsVBVV
__ Vision: _VN81aedeb999c79d74e79af7f1c922cf97
__ Vision: _VN9bdc36cda32be948a5089e37392596ec
__ Vision: _VN9f5b8e9dc1b3c824d79372f87b072ee3
__ Vision: _VNClusteringAlgorithm_Greedy
__ Vision: _VNExpressionFaceSmiling
__ Vision: _VNFaceAttributeAgeAdult
__ Vision: _VNFaceAttributeAgeBaby
__ Vision: _VNFaceAttributeAgeChild
__ Vision: _VNFaceAttributeAgeSenior
__ Vision: _VNFaceAttributeAgeYoungAdult
__ Vision: _VNFaceAttributeBald
__ Vision: _VNFaceAttributeEyesClosed
__ Vision: _VNFaceAttributeEyesOpen
__ Vision: _VNFaceAttributeFaceHairBeard
__ Vision: _VNFaceAttributeFaceHairGoatee
__ Vision: _VNFaceAttributeFaceHairMoustache
__ Vision: _VNFaceAttributeFaceHairStubble
__ Vision: _VNFaceAttributeFaceHairUnsure
__ Vision: _VNFaceAttributeGlassesNone
__ Vision: _VNFaceAttributeGlassesPrescription
__ Vision: _VNFaceAttributeGlassesSunglasses
__ Vision: _VNFaceAttributeHairColorBlack
__ Vision: _VNFaceAttributeHairColorBlonde
__ Vision: _VNFaceAttributeHairColorBrown
__ Vision: _VNFaceAttributeHairColorGray
__ Vision: _VNFaceAttributeHairColorRed
__ Vision: _VNFaceAttributeHairColorWhite
__ Vision: _VNFaceAttributeNotBald
__ Vision: _VNFaceAttributeNotSmiling
__ Vision: _VNFaceAttributeSmiling
__ Vision: _VNPotentialLandmarkIdentifier
__ Vision: _VNRequestWarningImageTooSmall
__ Vision: _VNRequestWarningImageTooSmallForFaceObservations
__ Vision: _VNSY8t4EoTztuqIL02g8uVA0
__ Vision: _VNVideoProcessingOptionFrameCadence
__ Vision: _VNVideoProcessingOptionTimeInterval
__ Vision: _VNa0c07362d05e1dafb35b96d20d5ce42d
__ Vision: _VNa9xpOJNvRoaW9plFGZ9Eo0
__ Vision: _VNacdca02f0900c2cb198193f3eec7b6c9
__ Vision: _VNbe5c67b06e95370f5a7b67b13e73637c
__ Vision: _VNeeab04670e53ebeb25150a31963a1aa6
__ Vision: _VNmNJnu0xlW8CZXt6hJ7Rpb0
__ libMobileGestalt.dylib: _MGGetBoolAnswer
__ libMobileGestalt.dylib: _MGGetStringAnswer
__ libSystem.B.dylib: _APP_SANDBOX_READ_WRITE
__ libSystem.B.dylib: _CC_MD5_Final
__ libSystem.B.dylib: _CC_MD5_Init
__ libSystem.B.dylib: _CC_MD5_Update
__ libSystem.B.dylib: _CC_SHA1
__ libSystem.B.dylib: __Block_copy
__ libSystem.B.dylib: __Block_object_assign
__ libSystem.B.dylib: __Block_object_dispose
__ libSystem.B.dylib: __Block_release
__ libSystem.B.dylib: __NSConcreteGlobalBlock
__ libSystem.B.dylib: __NSConcreteStackBlock
__ libSystem.B.dylib: __Unwind_Resume
__ libSystem.B.dylib: ___assert_rtn
__ libSystem.B.dylib: ___chkstk_darwin
__ libSystem.B.dylib: ___cxa_atexit
__ libSystem.B.dylib: ___error
__ libSystem.B.dylib: ___fpclassifyd
__ libSystem.B.dylib: ___memcpy_chk
__ libSystem.B.dylib: ___sincos_stret
__ libSystem.B.dylib: ___sincosf_stret
__ libSystem.B.dylib: ___stack_chk_fail
__ libSystem.B.dylib: ___stack_chk_guard
__ libSystem.B.dylib: ___stderrp
__ libSystem.B.dylib: ___stdoutp
__ libSystem.B.dylib: ___strlcpy_chk
__ libSystem.B.dylib: __dispatch_main_q
__ libSystem.B.dylib: __dispatch_source_type_timer
__ libSystem.B.dylib: __os_log_default
__ libSystem.B.dylib: __os_log_error_impl
__ libSystem.B.dylib: __os_log_impl
__ libSystem.B.dylib: __os_signpost_emit_with_name_impl
__ libSystem.B.dylib: _abort
__ libSystem.B.dylib: _abort_report_np
__ libSystem.B.dylib: _acosf
__ libSystem.B.dylib: _asinf
__ libSystem.B.dylib: _atan2f
__ libSystem.B.dylib: _atanf
__ libSystem.B.dylib: _atof
__ libSystem.B.dylib: _atoi
__ libSystem.B.dylib: _atol
__ libSystem.B.dylib: _bzero
__ libSystem.B.dylib: _calloc
__ libSystem.B.dylib: _cos
__ libSystem.B.dylib: _cosf
__ libSystem.B.dylib: _dispatch_apply
__ libSystem.B.dylib: _dispatch_async
__ libSystem.B.dylib: _dispatch_get_global_queue
__ libSystem.B.dylib: _dispatch_group_async
__ libSystem.B.dylib: _dispatch_group_async_f
__ libSystem.B.dylib: _dispatch_group_create
__ libSystem.B.dylib: _dispatch_group_enter
__ libSystem.B.dylib: _dispatch_group_leave
__ libSystem.B.dylib: _dispatch_group_wait
__ libSystem.B.dylib: _dispatch_once
__ libSystem.B.dylib: _dispatch_once_f
__ libSystem.B.dylib: _dispatch_queue_attr_make_with_qos_class
__ libSystem.B.dylib: _dispatch_queue_create
__ libSystem.B.dylib: _dispatch_release
__ libSystem.B.dylib: _dispatch_resume
__ libSystem.B.dylib: _dispatch_semaphore_create
__ libSystem.B.dylib: _dispatch_semaphore_signal
__ libSystem.B.dylib: _dispatch_semaphore_wait
__ libSystem.B.dylib: _dispatch_source_cancel
__ libSystem.B.dylib: _dispatch_source_create
__ libSystem.B.dylib: _dispatch_source_set_event_handler
__ libSystem.B.dylib: _dispatch_source_set_timer
__ libSystem.B.dylib: _dispatch_sync
__ libSystem.B.dylib: _dispatch_time
__ libSystem.B.dylib: _dlerror
__ libSystem.B.dylib: _dlsym
__ libSystem.B.dylib: _erff
__ libSystem.B.dylib: _exit
__ libSystem.B.dylib: _exp
__ libSystem.B.dylib: _exp2
__ libSystem.B.dylib: _exp2f
__ libSystem.B.dylib: _expf
__ libSystem.B.dylib: _fclose
__ libSystem.B.dylib: _fflush
__ libSystem.B.dylib: _fgets
__ libSystem.B.dylib: _fmod
__ libSystem.B.dylib: _fmodf
__ libSystem.B.dylib: _fopen
__ libSystem.B.dylib: _fprintf
__ libSystem.B.dylib: _fputc
__ libSystem.B.dylib: _fread
__ libSystem.B.dylib: _free
__ libSystem.B.dylib: _fscanf
__ libSystem.B.dylib: _fseek
__ libSystem.B.dylib: _ftell
__ libSystem.B.dylib: _fwrite
__ libSystem.B.dylib: _hypotf
__ libSystem.B.dylib: _kdebug_trace
__ libSystem.B.dylib: _log
__ libSystem.B.dylib: _log10
__ libSystem.B.dylib: _log10f
__ libSystem.B.dylib: _log2
__ libSystem.B.dylib: _log2f
__ libSystem.B.dylib: _logf
__ libSystem.B.dylib: _mach_absolute_time
__ libSystem.B.dylib: _mach_task_self_
__ libSystem.B.dylib: _mach_timebase_info
__ libSystem.B.dylib: _malloc
__ libSystem.B.dylib: _matrix_identity_float4x4
__ libSystem.B.dylib: _memcmp
__ libSystem.B.dylib: _memcpy
__ libSystem.B.dylib: _memmove
__ libSystem.B.dylib: _memset
__ libSystem.B.dylib: _memset_pattern16
__ libSystem.B.dylib: _memset_pattern4
__ libSystem.B.dylib: _os_log_create
__ libSystem.B.dylib: _os_log_type_enabled
__ libSystem.B.dylib: _os_signpost_enabled
__ libSystem.B.dylib: _os_signpost_id_generate
__ libSystem.B.dylib: _posix_memalign
__ libSystem.B.dylib: _pow
__ libSystem.B.dylib: _powf
__ libSystem.B.dylib: _printf
__ libSystem.B.dylib: _pthread_attr_destroy
__ libSystem.B.dylib: _pthread_attr_init
__ libSystem.B.dylib: _pthread_attr_setdetachstate
__ libSystem.B.dylib: _pthread_cond_broadcast
__ libSystem.B.dylib: _pthread_cond_destroy
__ libSystem.B.dylib: _pthread_cond_init
__ libSystem.B.dylib: _pthread_cond_signal
__ libSystem.B.dylib: _pthread_cond_wait
__ libSystem.B.dylib: _pthread_create
__ libSystem.B.dylib: _pthread_join
__ libSystem.B.dylib: _pthread_mach_thread_np
__ libSystem.B.dylib: _pthread_mutex_destroy
__ libSystem.B.dylib: _pthread_mutex_init
__ libSystem.B.dylib: _pthread_mutex_lock
__ libSystem.B.dylib: _pthread_mutex_unlock
__ libSystem.B.dylib: _pthread_once
__ libSystem.B.dylib: _pthread_setname_np
__ libSystem.B.dylib: _puts
__ libSystem.B.dylib: _qos_class_self
__ libSystem.B.dylib: _qsort
__ libSystem.B.dylib: _sandbox_extension_consume
__ libSystem.B.dylib: _sandbox_extension_issue_file
__ libSystem.B.dylib: _sandbox_extension_release
__ libSystem.B.dylib: _semaphore_create
__ libSystem.B.dylib: _semaphore_destroy
__ libSystem.B.dylib: _semaphore_signal
__ libSystem.B.dylib: _semaphore_wait
__ libSystem.B.dylib: _setpriority
__ libSystem.B.dylib: _sin
__ libSystem.B.dylib: _sinf
__ libSystem.B.dylib: _snprintf
__ libSystem.B.dylib: _sscanf
__ libSystem.B.dylib: _strchr
__ libSystem.B.dylib: _strcmp
__ libSystem.B.dylib: _strdup
__ libSystem.B.dylib: _strlcpy
__ libSystem.B.dylib: _strlen
__ libSystem.B.dylib: _strncmp
__ libSystem.B.dylib: _strncpy
__ libSystem.B.dylib: _strnlen
__ libSystem.B.dylib: _strsep
__ libSystem.B.dylib: _strstr
__ libSystem.B.dylib: _strtod
__ libSystem.B.dylib: _strtoimax
__ libSystem.B.dylib: _strtok
__ libSystem.B.dylib: _strtok_r
__ libSystem.B.dylib: _strtol
__ libSystem.B.dylib: _strtoll
__ libSystem.B.dylib: _sysctlbyname
__ libSystem.B.dylib: _syslog
__ libSystem.B.dylib: _tan
__ libSystem.B.dylib: _thread_info
__ libSystem.B.dylib: _thread_policy_set
__ libSystem.B.dylib: dyld_stub_binder
__ libc++.1.dylib: __ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info
__ libc++.1.dylib: __ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNKSt3__121__basic_string_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNKSt3__16locale9use_facetERNS0_2idE
__ libc++.1.dylib: __ZNKSt3__18ios_base6getlocEv
__ libc++.1.dylib: __ZNKSt9exception4whatEv
__ libc++.1.dylib: __ZNSt11logic_errorC2EPKc
__ libc++.1.dylib: __ZNSt12length_errorD1Ev
__ libc++.1.dylib: __ZNSt12out_of_rangeD1Ev
__ libc++.1.dylib: __ZNSt13exception_ptrC1ERKS_
__ libc++.1.dylib: __ZNSt13exception_ptrD1Ev
__ libc++.1.dylib: __ZNSt3__111__call_onceERVmPvPFvS2_E
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6resizeEmc
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE9push_backEc
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC1ERKS5_
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEED1Ev
__ libc++.1.dylib: __ZNSt3__112future_errorC1ENS_10error_codeE
__ libc++.1.dylib: __ZNSt3__112future_errorD1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE3putEc
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE5flushEv
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE6sentryC1ERS3_
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE6sentryD1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED0Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEb
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEd
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEi
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEl
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEm
__ libc++.1.dylib: __ZNSt3__114__shared_countD2Ev
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE4syncEv
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE5imbueERKNS_6localeE
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE5uflowEv
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE6setbufEPcl
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE6xsgetnEPcl
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE6xsputnEPKcl
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEE9showmanycEv
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEEC2Ev
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt3__115future_categoryEv
__ libc++.1.dylib: __ZNSt3__117__assoc_sub_state10__sub_waitERNS_11unique_lockINS_5mutexEEE
__ libc++.1.dylib: __ZNSt3__117__assoc_sub_state13set_exceptionESt13exception_ptr
__ libc++.1.dylib: __ZNSt3__117__assoc_sub_state16__on_zero_sharedEv
__ libc++.1.dylib: __ZNSt3__117__assoc_sub_state4waitEv
__ libc++.1.dylib: __ZNSt3__117__assoc_sub_state9set_valueEv
__ libc++.1.dylib: __ZNSt3__118condition_variable10notify_allEv
__ libc++.1.dylib: __ZNSt3__118condition_variable4waitERNS_11unique_lockINS_5mutexEEE
__ libc++.1.dylib: __ZNSt3__118condition_variableD1Ev
__ libc++.1.dylib: __ZNSt3__119__shared_weak_count14__release_weakEv
__ libc++.1.dylib: __ZNSt3__119__shared_weak_count4lockEv
__ libc++.1.dylib: __ZNSt3__119__shared_weak_countD2Ev
__ libc++.1.dylib: __ZNSt3__120__throw_system_errorEiPKc
__ libc++.1.dylib: __ZNSt3__14cerrE
__ libc++.1.dylib: __ZNSt3__14coutE
__ libc++.1.dylib: __ZNSt3__15ctypeIcE2idE
__ libc++.1.dylib: __ZNSt3__15mutex4lockEv
__ libc++.1.dylib: __ZNSt3__15mutex6unlockEv
__ libc++.1.dylib: __ZNSt3__15mutexD1Ev
__ libc++.1.dylib: __ZNSt3__16futureIvEC1EPNS_17__assoc_sub_stateE
__ libc++.1.dylib: __ZNSt3__16futureIvED1Ev
__ libc++.1.dylib: __ZNSt3__16localeD1Ev
__ libc++.1.dylib: __ZNSt3__18ios_base33__set_badbit_and_consider_rethrowEv
__ libc++.1.dylib: __ZNSt3__18ios_base4initEPv
__ libc++.1.dylib: __ZNSt3__18ios_base5clearEj
__ libc++.1.dylib: __ZNSt3__19basic_iosIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt9exceptionD2Ev
__ libc++.1.dylib: __ZSt13set_terminatePFvvE
__ libc++.1.dylib: __ZSt17current_exceptionv
__ libc++.1.dylib: __ZSt17rethrow_exceptionSt13exception_ptr
__ libc++.1.dylib: __ZSt7nothrow
__ libc++.1.dylib: __ZSt9terminatev
__ libc++.1.dylib: __ZTINSt3__113basic_ostreamIcNS_11char_traitsIcEEEE
__ libc++.1.dylib: __ZTINSt3__115basic_streambufIcNS_11char_traitsIcEEEE
__ libc++.1.dylib: __ZTINSt3__119__shared_weak_countE
__ libc++.1.dylib: __ZTIi
__ libc++.1.dylib: __ZTVN10__cxxabiv117__class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv120__si_class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv121__vmi_class_type_infoE
__ libc++.1.dylib: __ZTVNSt3__117__assoc_sub_stateE
__ libc++.1.dylib: __ZTVSt12length_error
__ libc++.1.dylib: __ZTVSt12out_of_range
__ libc++.1.dylib: __ZTv0_n24_NSt3__113basic_ostreamIcNS_11char_traitsIcEEED0Ev
__ libc++.1.dylib: __ZTv0_n24_NSt3__113basic_ostreamIcNS_11char_traitsIcEEED1Ev
__ libc++.1.dylib: __ZdaPv
__ libc++.1.dylib: __ZdaPvRKSt9nothrow_t
__ libc++.1.dylib: __ZdaPvSt11align_val_t
__ libc++.1.dylib: __ZdlPv
__ libc++.1.dylib: __ZdlPvRKSt9nothrow_t
__ libc++.1.dylib: __ZdlPvSt11align_val_t
__ libc++.1.dylib: __Znam
__ libc++.1.dylib: __ZnamRKSt9nothrow_t
__ libc++.1.dylib: __ZnamSt11align_val_t
__ libc++.1.dylib: __ZnamSt11align_val_tRKSt9nothrow_t
__ libc++.1.dylib: __Znwm
__ libc++.1.dylib: __ZnwmRKSt9nothrow_t
__ libc++.1.dylib: __ZnwmSt11align_val_t
__ libc++.1.dylib: __ZnwmSt11align_val_tRKSt9nothrow_t
__ libc++.1.dylib: ___cxa_allocate_exception
__ libc++.1.dylib: ___cxa_begin_catch
__ libc++.1.dylib: ___cxa_end_catch
__ libc++.1.dylib: ___cxa_free_exception
__ libc++.1.dylib: ___cxa_guard_abort
__ libc++.1.dylib: ___cxa_guard_acquire
__ libc++.1.dylib: ___cxa_guard_release
__ libc++.1.dylib: ___cxa_pure_virtual
__ libc++.1.dylib: ___cxa_rethrow
__ libc++.1.dylib: ___cxa_throw
__ libc++.1.dylib: ___gxx_personality_v0
__ libobjc.A.dylib: _OBJC_CLASS_$_NSObject
__ libobjc.A.dylib: _OBJC_METACLASS_$_NSObject
__ libobjc.A.dylib: ___objc_personality_v0
__ libobjc.A.dylib: __objc_empty_cache
__ libobjc.A.dylib: _objc_alloc
__ libobjc.A.dylib: _objc_alloc_init
__ libobjc.A.dylib: _objc_autorelease
__ libobjc.A.dylib: _objc_autoreleasePoolPop
__ libobjc.A.dylib: _objc_autoreleasePoolPush
__ libobjc.A.dylib: _objc_autoreleaseReturnValue
__ libobjc.A.dylib: _objc_begin_catch
__ libobjc.A.dylib: _objc_copyStruct
__ libobjc.A.dylib: _objc_copyWeak
__ libobjc.A.dylib: _objc_destroyWeak
__ libobjc.A.dylib: _objc_end_catch
__ libobjc.A.dylib: _objc_enumerationMutation
__ libobjc.A.dylib: _objc_exception_rethrow
__ libobjc.A.dylib: _objc_exception_throw
__ libobjc.A.dylib: _objc_getAssociatedObject
__ libobjc.A.dylib: _objc_getClass
__ libobjc.A.dylib: _objc_getProperty
__ libobjc.A.dylib: _objc_initWeak
__ libobjc.A.dylib: _objc_loadWeakRetained
__ libobjc.A.dylib: _objc_msgSend
__ libobjc.A.dylib: _objc_msgSendSuper2
__ libobjc.A.dylib: _objc_opt_class
__ libobjc.A.dylib: _objc_opt_isKindOfClass
__ libobjc.A.dylib: _objc_opt_new
__ libobjc.A.dylib: _objc_opt_respondsToSelector
__ libobjc.A.dylib: _objc_release
__ libobjc.A.dylib: _objc_retain
__ libobjc.A.dylib: _objc_retainAutorelease
__ libobjc.A.dylib: _objc_retainAutoreleaseReturnValue
__ libobjc.A.dylib: _objc_retainAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_retainBlock
__ libobjc.A.dylib: _objc_setAssociatedObject
__ libobjc.A.dylib: _objc_setProperty_atomic
__ libobjc.A.dylib: _objc_setProperty_atomic_copy
__ libobjc.A.dylib: _objc_setProperty_nonatomic_copy
__ libobjc.A.dylib: _objc_storeStrong
__ libobjc.A.dylib: _objc_storeWeak
__ libobjc.A.dylib: _objc_sync_enter
__ libobjc.A.dylib: _objc_sync_exit
__ libobjc.A.dylib: _objc_unsafeClaimAutoreleasedReturnValue
__ libsqlite3.dylib: _sqlite3_bind_double
__ libsqlite3.dylib: _sqlite3_bind_int
__ libsqlite3.dylib: _sqlite3_bind_int64
__ libsqlite3.dylib: _sqlite3_bind_null
__ libsqlite3.dylib: _sqlite3_bind_text
__ libsqlite3.dylib: _sqlite3_close
__ libsqlite3.dylib: _sqlite3_column_blob
__ libsqlite3.dylib: _sqlite3_column_bytes
__ libsqlite3.dylib: _sqlite3_column_double
__ libsqlite3.dylib: _sqlite3_column_int
__ libsqlite3.dylib: _sqlite3_column_int64
__ libsqlite3.dylib: _sqlite3_column_text
__ libsqlite3.dylib: _sqlite3_column_type
__ libsqlite3.dylib: _sqlite3_finalize
__ libsqlite3.dylib: _sqlite3_open
__ libsqlite3.dylib: _sqlite3_prepare_v2
__ libsqlite3.dylib: _sqlite3_step
VCPAudioAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPAudioAnalyzer processSampleBuffer:]
  -[VCPAudioAnalyzer dealloc]
  -[VCPAudioAnalyzer .cxx_destruct]
  -[VCPAudioAnalyzer processAudioSamples:timestamp:]
  -[VCPAudioAnalyzer finalizeAnalysisAtTime:]
  -[VCPAudioAnalyzer audioFormatRequirements]
  -[VCPAudioAnalyzer setupWithSample:]
  -[VCPAudioAnalyzer voiceDetections]
  -[VCPAudioAnalyzer initWithAnalysisTypes:forStreaming:]
  -[VCPAudioAnalyzer analyzeAsset:cancel:results:]
  -[VCPAudioAnalyzer analyzeSampleBuffer:]


VCPSoundDetector : NSObject /usr/lib/libc++.1.dylib <SNResultsObserving>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPSoundDetector results]
  -[VCPSoundDetector .cxx_destruct]
  -[VCPSoundDetector finalizeAnalysisAtTime:]
  -[VCPSoundDetector addDetectionFromTime:toTime:confidence:]
  -[VCPSoundDetector request:didProduceResult:]
  -[VCPSoundDetector initWithTrackStart:threshold:resultsKey:]


VCPAudioClassifier : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPAudioClassifier results]
  -[VCPAudioClassifier initWithTypes:]
  -[VCPAudioClassifier .cxx_destruct]
  -[VCPAudioClassifier setupWithSample:andSampleBatchSize:]
  -[VCPAudioClassifier processAudioSamples:timestamp:]
  -[VCPAudioClassifier finalizeAnalysisAtTime:]


VCPVideoStabilizer : VCPVideoAnalyzer
 @property  ^v analysisResultRef
 @property  ^v correctionResultRef
 @property  NSDictionary *results
 @property  float cropFraction
 @property  NSMutableArray *motionBlurVector
 @property  BOOL gyroStabilization
 @property  float analysisConfidence
 @property  BOOL validStabilization

  // class methods
  +[VCPVideoStabilizer videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:]
  +[VCPVideoStabilizer saveStabilizationRecipe]

  // instance methods
  -[VCPVideoStabilizer setResults:]
  -[VCPVideoStabilizer init]
  -[VCPVideoStabilizer results]
  -[VCPVideoStabilizer dealloc]
  -[VCPVideoStabilizer .cxx_destruct]
  -[VCPVideoStabilizer correctionResultRef]
  -[VCPVideoStabilizer setCorrectionResultRef:]
  -[VCPVideoStabilizer cropFraction]
  -[VCPVideoStabilizer setCropFraction:]
  -[VCPVideoStabilizer motionBlurVector]
  -[VCPVideoStabilizer setMotionBlurVector:]
  -[VCPVideoStabilizer gyroStabilization]
  -[VCPVideoStabilizer validStabilization]
  -[VCPVideoStabilizer setGyroStabilization:]
  -[VCPVideoStabilizer setAnalysisResultRef:]
  -[VCPVideoStabilizer analysisResultRef]
  -[VCPVideoStabilizer setAnalysisConfidence:]
  -[VCPVideoStabilizer analysisConfidence]
  -[VCPVideoStabilizer setValidStabilization:]
  -[VCPVideoStabilizer convertAnalysisResult]
  -[VCPVideoStabilizer finishAnalysisPass:]


VCPImageHumanPoseAnalyzer : VCPImageAnalyzer
 @property  BOOL trackingMode

  // class methods
  +[VCPImageHumanPoseAnalyzer sharedModel:]
  +[VCPImageHumanPoseAnalyzer saveKeypoints]

  // instance methods
  -[VCPImageHumanPoseAnalyzer init]
  -[VCPImageHumanPoseAnalyzer setTrackingMode:]
  -[VCPImageHumanPoseAnalyzer dealloc]
  -[VCPImageHumanPoseAnalyzer .cxx_destruct]
  -[VCPImageHumanPoseAnalyzer configForAspectRatio:]
  -[VCPImageHumanPoseAnalyzer createModelWithHeight:srcWidth:]
  -[VCPImageHumanPoseAnalyzer reInitModel]
  -[VCPImageHumanPoseAnalyzer parsePersons:width:height:]
  -[VCPImageHumanPoseAnalyzer processPersons:width:height:]
  -[VCPImageHumanPoseAnalyzer copyImage:toData:withChannels:]
  -[VCPImageHumanPoseAnalyzer createInput:withBuffer:modelInputHeight:modelInputWidth:]
  -[VCPImageHumanPoseAnalyzer generateHumanPose:]
  -[VCPImageHumanPoseAnalyzer initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:]
  -[VCPImageHumanPoseAnalyzer updateModelForAspectRatio:]
  -[VCPImageHumanPoseAnalyzer preferredInputFormat:height:format:]
  -[VCPImageHumanPoseAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageHumanPoseAnalyzer trackingMode]


VCPProtoLivePhotoKeyFrameResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  double timestamp
 @property  float qualityScoreForLivePhoto
 @property  float visualPleasingScore
 @property  float overallFaceQualityScore
 @property  float exposureScore
 @property  float penaltyScore
 @property  float textureScore
 @property  float sharpness
 @property  NSMutableArray *faceResults
 @property  BOOL hasGlobalQualityScore
 @property  float globalQualityScore
 @property  BOOL hasContentScore
 @property  float contentScore

  // class methods
  +[VCPProtoLivePhotoKeyFrameResult faceResultsType]
  +[VCPProtoLivePhotoKeyFrameResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameResult exposureScore]
  -[VCPProtoLivePhotoKeyFrameResult contentScore]
  -[VCPProtoLivePhotoKeyFrameResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoKeyFrameResult setContentScore:]
  -[VCPProtoLivePhotoKeyFrameResult .cxx_destruct]
  -[VCPProtoLivePhotoKeyFrameResult timestamp]
  -[VCPProtoLivePhotoKeyFrameResult setTimestamp:]
  -[VCPProtoLivePhotoKeyFrameResult setExposureScore:]
  -[VCPProtoLivePhotoKeyFrameResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameResult sharpness]
  -[VCPProtoLivePhotoKeyFrameResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameResult faceResultsCount]
  -[VCPProtoLivePhotoKeyFrameResult addFaceResults:]
  -[VCPProtoLivePhotoKeyFrameResult clearFaceResults]
  -[VCPProtoLivePhotoKeyFrameResult faceResultsAtIndex:]
  -[VCPProtoLivePhotoKeyFrameResult setGlobalQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult setHasGlobalQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult hasGlobalQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult setHasContentScore:]
  -[VCPProtoLivePhotoKeyFrameResult hasContentScore]
  -[VCPProtoLivePhotoKeyFrameResult qualityScoreForLivePhoto]
  -[VCPProtoLivePhotoKeyFrameResult setQualityScoreForLivePhoto:]
  -[VCPProtoLivePhotoKeyFrameResult visualPleasingScore]
  -[VCPProtoLivePhotoKeyFrameResult setVisualPleasingScore:]
  -[VCPProtoLivePhotoKeyFrameResult overallFaceQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult setOverallFaceQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult penaltyScore]
  -[VCPProtoLivePhotoKeyFrameResult setPenaltyScore:]
  -[VCPProtoLivePhotoKeyFrameResult textureScore]
  -[VCPProtoLivePhotoKeyFrameResult setTextureScore:]
  -[VCPProtoLivePhotoKeyFrameResult faceResults]
  -[VCPProtoLivePhotoKeyFrameResult setFaceResults:]
  -[VCPProtoLivePhotoKeyFrameResult globalQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameResult setSharpness:]
  -[VCPProtoLivePhotoKeyFrameResult mergeFrom:]


VCPBlurAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPBlurAnalyzer computeSharpnessScore:forObjects:inImage:]
  -[VCPBlurAnalyzer computeRegionSharpness:width:height:stride:]


VCPBoundingBox : NSObject /usr/lib/libc++.1.dylib
 @property  float minX
 @property  float maxX
 @property  float minY
 @property  float maxY
 @property  float confidence
 @property  float flag

  // instance methods
  -[VCPBoundingBox maxX]
  -[VCPBoundingBox minX]
  -[VCPBoundingBox minY]
  -[VCPBoundingBox maxY]
  -[VCPBoundingBox setFlag:]
  -[VCPBoundingBox area]
  -[VCPBoundingBox setMaxX:]
  -[VCPBoundingBox intersect:]
  -[VCPBoundingBox union:]
  -[VCPBoundingBox setConfidence:]
  -[VCPBoundingBox confidence]
  -[VCPBoundingBox setMinX:]
  -[VCPBoundingBox setMinY:]
  -[VCPBoundingBox setMaxY:]
  -[VCPBoundingBox flag]
  -[VCPBoundingBox initWithXYAndSize:y:width:height:confidence:]
  -[VCPBoundingBox initWithCenterAndSize:y:width:height:confidence:]
  -[VCPBoundingBox computeIntersectionOverUnion:]
  -[VCPBoundingBox getCGRectWithClipWidth:height:]


VCPProtoMovieBabbleResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieBabbleResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieBabbleResult copyWithZone:]
  -[VCPProtoMovieBabbleResult setTimeRange:]
  -[VCPProtoMovieBabbleResult exportToLegacyDictionary]
  -[VCPProtoMovieBabbleResult setConfidence:]
  -[VCPProtoMovieBabbleResult .cxx_destruct]
  -[VCPProtoMovieBabbleResult timeRange]
  -[VCPProtoMovieBabbleResult confidence]
  -[VCPProtoMovieBabbleResult readFrom:]
  -[VCPProtoMovieBabbleResult writeTo:]
  -[VCPProtoMovieBabbleResult isEqual:]
  -[VCPProtoMovieBabbleResult copyTo:]
  -[VCPProtoMovieBabbleResult dictionaryRepresentation]
  -[VCPProtoMovieBabbleResult mergeFrom:]


VCPCNNBlock : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *inputSize
 @property  NSMutableArray *outputSize
 @property  VCPCNNData *input
 @property  VCPCNNData *output
 @property  VCPCNNMetalContext *context
 @property  BOOL generateOutput

  // instance methods
  -[VCPCNNBlock context]
  -[VCPCNNBlock input]
  -[VCPCNNBlock output]
  -[VCPCNNBlock setInput:]
  -[VCPCNNBlock outputSize]
  -[VCPCNNBlock .cxx_destruct]
  -[VCPCNNBlock useGPU]
  -[VCPCNNBlock forward]
  -[VCPCNNBlock inputSize]
  -[VCPCNNBlock generateOutput]
  -[VCPCNNBlock setGenerateOutput:]
  -[VCPCNNBlock setInputSize:]
  -[VCPCNNBlock supportGPU]
  -[VCPCNNBlock constructBlock:context:]
  -[VCPCNNBlock readFromDisk:quantFactor:]
  -[VCPCNNBlock setOutput:]
  -[VCPCNNBlock setOutputSize:]


VCPCNNBlurAnalyzer : VCPImageAnalyzer
 @property  BOOL sdof

  // class methods
  +[VCPCNNBlurAnalyzer analyzer]
  +[VCPCNNBlurAnalyzer analyzerWithRevision:]

  // instance methods
  -[VCPCNNBlurAnalyzer scaleRegion:ofImage:toData:withWidth:andHeight:]
  -[VCPCNNBlurAnalyzer sdof]
  -[VCPCNNBlurAnalyzer computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:]
  -[VCPCNNBlurAnalyzer init]
  -[VCPCNNBlurAnalyzer initWithRevision:]
  -[VCPCNNBlurAnalyzer getRevision]
  -[VCPCNNBlurAnalyzer calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:]
  -[VCPCNNBlurAnalyzer copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:]
  -[VCPCNNBlurAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzer getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzer computeSharpnessScore:textureness:contrast:imgWidth:cancel:]
  -[VCPCNNBlurAnalyzer setSdof:]


VCPCNNBlurAnalyzerEspresso : VCPCNNBlurAnalyzer
  // class methods
  +[VCPCNNBlurAnalyzerEspresso sharedModel:]
  +[VCPCNNBlurAnalyzerEspresso sharedModelPoolWithRevision:]

  // instance methods
  -[VCPCNNBlurAnalyzerEspresso init]
  -[VCPCNNBlurAnalyzerEspresso dealloc]
  -[VCPCNNBlurAnalyzerEspresso .cxx_destruct]
  -[VCPCNNBlurAnalyzerEspresso initWithRevision:]
  -[VCPCNNBlurAnalyzerEspresso calculateScoreFromNetworkOutputV2:]
  -[VCPCNNBlurAnalyzerEspresso copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:]
  -[VCPCNNBlurAnalyzerEspresso prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzerEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzerEspresso computeSharpnessScore:textureness:contrast:imgWidth:cancel:]


VCPCNNBlurAnalyzerMPS : VCPCNNBlurAnalyzer
  // instance methods
  -[VCPCNNBlurAnalyzerMPS init]
  -[VCPCNNBlurAnalyzerMPS .cxx_destruct]
  -[VCPCNNBlurAnalyzerMPS prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzerMPS getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzerMPS computeSharpnessScore:textureness:contrast:imgWidth:cancel:]


VCPCNNConvBlock : VCPCNNBlock
  // class methods
  +[VCPCNNConvBlock convBlockClass:]
  +[VCPCNNConvBlock convBlockWithFilterSize:filterNum:chunk:reLU:padding:]
  +[VCPCNNConvBlock convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]

  // instance methods
  -[VCPCNNConvBlock .cxx_destruct]
  -[VCPCNNConvBlock useGPU]
  -[VCPCNNConvBlock supportGPU]
  -[VCPCNNConvBlock initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]
  -[VCPCNNConvBlock constructBlock:context:]


VCPCNNConvBlockBinary : VCPCNNBlock
  // instance methods
  -[VCPCNNConvBlockBinary dealloc]
  -[VCPCNNConvBlockBinary .cxx_destruct]
  -[VCPCNNConvBlockBinary useGPU]
  -[VCPCNNConvBlockBinary initWithParameters:filterNum:convType:reLU:padding:]
  -[VCPCNNConvBlockBinary forward]
  -[VCPCNNConvBlockBinary supportGPU]
  -[VCPCNNConvBlockBinary constructBlock:context:]
  -[VCPCNNConvBlockBinary readFromDisk:quantFactor:]
  -[VCPCNNConvBlockBinary fillConvWeightsGPU]
  -[VCPCNNConvBlockBinary gpuForward]


VCPCNNConvBlockGPU : VCPCNNConvBlock
  // instance methods
  -[VCPCNNConvBlockGPU dealloc]
  -[VCPCNNConvBlockGPU .cxx_destruct]
  -[VCPCNNConvBlockGPU forward]
  -[VCPCNNConvBlockGPU releaseBatchNormMemory]
  -[VCPCNNConvBlockGPU readFromDisk:quantFactor:]
  -[VCPCNNConvBlockGPU readBatchNormParam:quantFactor:]
  -[VCPCNNConvBlockGPU fillConvWeightsGPU]
  -[VCPCNNConvBlockGPU gpuForward]


VCPCNNConvBlockScalar : VCPCNNConvBlock
  // instance methods
  -[VCPCNNConvBlockScalar forward]
  -[VCPCNNConvBlockScalar readFromDisk:quantFactor:]


VCPCNNConvBlockVector : VCPCNNConvBlock
  // class methods
  +[VCPCNNConvBlockVector isFilterSizeSupported:]

  // instance methods
  -[VCPCNNConvBlockVector forward]
  -[VCPCNNConvBlockVector initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]
  -[VCPCNNConvBlockVector readFromDisk:quantFactor:]
  -[VCPCNNConvBlockVector straightForwardForChunkFour]
  -[VCPCNNConvBlockVector chunkFourForward]


VCPCNNData : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *size
 @property  ^f data
 @property  BOOL isInputOutput
 @property  MPSImage *mpsImg
 @property  VCPCNNMetalContext *context

  // class methods
  +[VCPCNNData cnnData]
  +[VCPCNNData cnnDataWithGPUContext:]
  +[VCPCNNData cnnDataClass]
  +[VCPCNNData cnnDataWithPlane:height:width:context:]

  // instance methods
  -[VCPCNNData context]
  -[VCPCNNData setData:]
  -[VCPCNNData init]
  -[VCPCNNData dealloc]
  -[VCPCNNData size]
  -[VCPCNNData mpsImg]
  -[VCPCNNData .cxx_destruct]
  -[VCPCNNData normalization]
  -[VCPCNNData setContext:]
  -[VCPCNNData data]
  -[VCPCNNData softmax]
  -[VCPCNNData setSize:]
  -[VCPCNNData allocBuffers:]
  -[VCPCNNData reallocGPUTemporalBuffers]
  -[VCPCNNData readFromDisk:quantFactor:]
  -[VCPCNNData initWithGPUContext:]
  -[VCPCNNData initWithParameters:height:width:context:]
  -[VCPCNNData bufferAllocCPU]
  -[VCPCNNData convertCPUData2GPU]
  -[VCPCNNData convertGPUData2CPU]
  -[VCPCNNData copyImage:withChunk:]
  -[VCPCNNData isInputOutput]
  -[VCPCNNData setIsInputOutput:]
  -[VCPCNNData setMpsImg:]
  -[VCPCNNData randInit]


VCPCNNDataGPU : VCPCNNData
  // instance methods
  -[VCPCNNDataGPU allocBuffers:]
  -[VCPCNNDataGPU reallocGPUTemporalBuffers]
  -[VCPCNNDataGPU convertCPUData2GPU]
  -[VCPCNNDataGPU convertGPUData2CPU]
  -[VCPCNNDataGPU bufferAllocGPU]


VCPCNNEspressoContext : NSObject /usr/lib/libc++.1.dylib
 @property  ^v espressoContext

  // class methods
  +[VCPCNNEspressoContext supportGPU]
  +[VCPCNNEspressoContext createContextWithForceCPU:]
  +[VCPCNNEspressoContext sharedEspressoContext:]

  // instance methods
  -[VCPCNNEspressoContext initWithForceCPU:shared:]
  -[VCPCNNEspressoContext espressoContext]


VCPCNNFaceLandmarkDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNFaceLandmarkDetector detector]

  // instance methods
  -[VCPCNNFaceLandmarkDetector .cxx_destruct]
  -[VCPCNNFaceLandmarkDetector landmarks]
  -[VCPCNNFaceLandmarkDetector getInputBuffer]
  -[VCPCNNFaceLandmarkDetector computeLandmarks:]
  -[VCPCNNFaceLandmarkDetector analyzeFrame:withFaceBounds:]


VCPCNNFaceLandmarkDetectorEspresso : VCPCNNFaceLandmarkDetector
  // class methods
  +[VCPCNNFaceLandmarkDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNFaceLandmarkDetectorEspresso init]
  -[VCPCNNFaceLandmarkDetectorEspresso dealloc]
  -[VCPCNNFaceLandmarkDetectorEspresso .cxx_destruct]
  -[VCPCNNFaceLandmarkDetectorEspresso getInputBuffer]
  -[VCPCNNFaceLandmarkDetectorEspresso computeLandmarks:]


VCPCNNFaceLandmarkDetectorMPS : VCPCNNFaceLandmarkDetector
  // instance methods
  -[VCPCNNFaceLandmarkDetectorMPS init]
  -[VCPCNNFaceLandmarkDetectorMPS .cxx_destruct]
  -[VCPCNNFaceLandmarkDetectorMPS getInputBuffer]
  -[VCPCNNFaceLandmarkDetectorMPS computeLandmarks:]


VCPCNNFlattenBlock : VCPCNNBlock
  // instance methods
  -[VCPCNNFlattenBlock forward]
  -[VCPCNNFlattenBlock constructBlock:context:]
  -[VCPCNNFlattenBlock initWithParameters:]


VCPCNNFullConnectionBlock : VCPCNNBlock
  // class methods
  +[VCPCNNFullConnectionBlock fcBlockWithNumNeurons:NeuronType:]

  // instance methods
  -[VCPCNNFullConnectionBlock dealloc]
  -[VCPCNNFullConnectionBlock useGPU]
  -[VCPCNNFullConnectionBlock supportGPU]
  -[VCPCNNFullConnectionBlock constructBlock:context:]
  -[VCPCNNFullConnectionBlock readFromDisk:quantFactor:]
  -[VCPCNNFullConnectionBlock initWithParameters:NeuronType:]
  -[VCPCNNFullConnectionBlock readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:]
  -[VCPCNNFullConnectionBlock loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNFullConnectionBlockGPU : VCPCNNFullConnectionBlock
  // instance methods
  -[VCPCNNFullConnectionBlockGPU .cxx_destruct]
  -[VCPCNNFullConnectionBlockGPU forward]
  -[VCPCNNFullConnectionBlockGPU setupMPS]
  -[VCPCNNFullConnectionBlockGPU convVCPNeuronTypeToMPS:]
  -[VCPCNNFullConnectionBlockGPU shuffleWeights:fromSrc:inputChannels:inputHeight:inputWidth:outputChannels:]
  -[VCPCNNFullConnectionBlockGPU loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNFullConnectionBlockScalar : VCPCNNFullConnectionBlock
  // instance methods
  -[VCPCNNFullConnectionBlockScalar forward]
  -[VCPCNNFullConnectionBlockScalar loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNGazeAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNGazeAnalysis sharedModel:]

  // instance methods
  -[VCPCNNGazeAnalysis init]
  -[VCPCNNGazeAnalysis dealloc]
  -[VCPCNNGazeAnalysis .cxx_destruct]
  -[VCPCNNGazeAnalysis copyImage:toData:]
  -[VCPCNNGazeAnalysis createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:]
  -[VCPCNNGazeAnalysis detectEyeOpennessForFace:inBuffer:eyeOpenness:]


VCPVideoGyroStabilizer : VCPVideoStabilizer
  // instance methods
  -[VCPVideoGyroStabilizer .cxx_destruct]
  -[VCPVideoGyroStabilizer initWithMetadata:sourceSize:cropRect:]
  -[VCPVideoGyroStabilizer storeAnalytics:isLivePhoto:]
  -[VCPVideoGyroStabilizer convertAnalysisResult]


VCPCNNHandKeypointsDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNHandKeypointsDetector detector:sharedModel:modelName:]

  // instance methods
  -[VCPCNNHandKeypointsDetector handKeypointsDetection:box:keypoints:keypointConfidence:]
  -[VCPCNNHandKeypointsDetector copyImage:toData:]
  -[VCPCNNHandKeypointsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:]
  -[VCPCNNHandKeypointsDetector generateHandKeypoints:keypointConfidence:offset:]
  -[VCPCNNHandKeypointsDetector cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:]
  -[VCPCNNHandKeypointsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:]


VCPCNNMetalContext : NSObject /usr/lib/libc++.1.dylib
 @property  <MTLDevice> *device
 @property  <MTLCommandQueue> *commandQueue
 @property  <MTLCommandBuffer> *commandBuffer

  // class methods
  +[VCPCNNMetalContext supportGPU]
  +[VCPCNNMetalContext supportVectorForward]
  +[VCPCNNMetalContext sharedCommandQueue]

  // instance methods
  -[VCPCNNMetalContext execute]
  -[VCPCNNMetalContext device]
  -[VCPCNNMetalContext setCommandQueue:]
  -[VCPCNNMetalContext .cxx_destruct]
  -[VCPCNNMetalContext setCommandBuffer:]
  -[VCPCNNMetalContext commandQueue]
  -[VCPCNNMetalContext setDevice:]
  -[VCPCNNMetalContext initNewContext:]
  -[VCPCNNMetalContext commandBuffer]


VCPHumanPoseVideoRequest : VCPRequest
  // instance methods
  -[VCPHumanPoseVideoRequest initWithOptions:]
  -[VCPHumanPoseVideoRequest init]
  -[VCPHumanPoseVideoRequest .cxx_destruct]
  -[VCPHumanPoseVideoRequest computeActionScoreForPerson:]
  -[VCPHumanPoseVideoRequest associatePersons:withExisingPersons:]
  -[VCPHumanPoseVideoRequest normDistance:point2:]
  -[VCPHumanPoseVideoRequest computeVarWithID:index1:index2:interVar:intraVar:]
  -[VCPHumanPoseVideoRequest bodyDistance:withBodyB:]
  -[VCPHumanPoseVideoRequest processSampleBuffer:withOptions:error:]
  -[VCPHumanPoseVideoRequest preferredInputSizeWithOptions:error:]
  -[VCPHumanPoseVideoRequest preferredPixelFormat]
  -[VCPHumanPoseVideoRequest cleanupWithOptions:error:]


VCPCNNModel : NSObject /usr/lib/libc++.1.dylib
 @property  VCPCNNData *output

  // instance methods
  -[VCPCNNModel output]
  -[VCPCNNModel init]
  -[VCPCNNModel size]
  -[VCPCNNModel .cxx_destruct]
  -[VCPCNNModel dynamicForward:paramFileUrl:cancel:]
  -[VCPCNNModel forward:]
  -[VCPCNNModel initWithParameters:useGPU:]
  -[VCPCNNModel getGPUContext]
  -[VCPCNNModel add:]
  -[VCPCNNModel prepareNetworkFromURL:withInputSize:]


VCPCNNModelEspresso : NSObject /usr/lib/libc++.1.dylib
 @property  {vector<espresso_buffer_t inputBlobs
 @property  {vector<espresso_buffer_t outputBlobs
 @property  {?=^v^v[4Q][4Q]QQQQQQQQQQi} inputBlob
 @property  {?=^v^v[4Q][4Q]QQQQQQQQQQi} outputBlob
 @property  NSString *resConfig

  // instance methods
  -[VCPCNNModelEspresso .cxx_construct]
  -[VCPCNNModelEspresso dealloc]
  -[VCPCNNModelEspresso .cxx_destruct]
  -[VCPCNNModelEspresso softmax]
  -[VCPCNNModelEspresso inputBlob]
  -[VCPCNNModelEspresso initWithParameters:inputNames:outputNames:properties:]
  -[VCPCNNModelEspresso outputBlob]
  -[VCPCNNModelEspresso espressoForward:]
  -[VCPCNNModelEspresso prepareModelWithConfig:]
  -[VCPCNNModelEspresso normalization:]
  -[VCPCNNModelEspresso getPlanPhase]
  -[VCPCNNModelEspresso prepareModelInput:]
  -[VCPCNNModelEspresso prepareModelInputs:]
  -[VCPCNNModelEspresso espressoForwardInputs:]
  -[VCPCNNModelEspresso getEspressoContext]
  -[VCPCNNModelEspresso inputBlobs]
  -[VCPCNNModelEspresso setInputBlobs:]
  -[VCPCNNModelEspresso outputBlobs]
  -[VCPCNNModelEspresso setOutputBlobs:]
  -[VCPCNNModelEspresso setInputBlob:]
  -[VCPCNNModelEspresso setOutputBlob:]
  -[VCPCNNModelEspresso resConfig]


VCPCNNMPSDataSource : NSObject /usr/lib/libc++.1.dylib <MPSCNNConvolutionDataSource>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPCNNMPSDataSource copyWithZone:]
  -[VCPCNNMPSDataSource biasTerms]
  -[VCPCNNMPSDataSource load]
  -[VCPCNNMPSDataSource weights]
  -[VCPCNNMPSDataSource .cxx_destruct]
  -[VCPCNNMPSDataSource label]
  -[VCPCNNMPSDataSource dataType]
  -[VCPCNNMPSDataSource descriptor]
  -[VCPCNNMPSDataSource purge]
  -[VCPCNNMPSDataSource initWith:convolutionDescriptor:kernelWeights:biasTerm:]
  -[VCPCNNMPSDataSource copyWithZone:device:]


VCPCNNPetsDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNPetsDetector detector:]

  // instance methods
  -[VCPCNNPetsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetector copyImage:toData:withChannels:]
  -[VCPCNNPetsDetector nonMaxSuppression:]
  -[VCPCNNPetsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetector postProcBoxes:maxNumRegions:]
  -[VCPCNNPetsDetector petsDetection:petsRegions:petsFaceRegions:cancel:]
  -[VCPCNNPetsDetector generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:]
  -[VCPCNNPetsDetector createModel:srcWidth:]
  -[VCPCNNPetsDetector generatePetsBoxes:faceBoxes:cancel:]


VCPProtoMovieApplauseResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieApplauseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieApplauseResult copyWithZone:]
  -[VCPProtoMovieApplauseResult setTimeRange:]
  -[VCPProtoMovieApplauseResult exportToLegacyDictionary]
  -[VCPProtoMovieApplauseResult setConfidence:]
  -[VCPProtoMovieApplauseResult .cxx_destruct]
  -[VCPProtoMovieApplauseResult timeRange]
  -[VCPProtoMovieApplauseResult confidence]
  -[VCPProtoMovieApplauseResult readFrom:]
  -[VCPProtoMovieApplauseResult writeTo:]
  -[VCPProtoMovieApplauseResult isEqual:]
  -[VCPProtoMovieApplauseResult copyTo:]
  -[VCPProtoMovieApplauseResult dictionaryRepresentation]
  -[VCPProtoMovieApplauseResult mergeFrom:]


VCPCNNPetsDetectorEspresso : VCPCNNPetsDetector
  // class methods
  +[VCPCNNPetsDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNPetsDetectorEspresso dealloc]
  -[VCPCNNPetsDetectorEspresso .cxx_destruct]
  -[VCPCNNPetsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetectorEspresso initWithMaxNumRegions:]
  -[VCPCNNPetsDetectorEspresso createModel:srcWidth:]
  -[VCPCNNPetsDetectorEspresso generatePetsBoxes:faceBoxes:cancel:]


VCPCNNPoolingBlock : VCPCNNBlock
  // class methods
  +[VCPCNNPoolingBlock poolingBlockWithPoolX:poolY:chunk:]

  // instance methods
  -[VCPCNNPoolingBlock useGPU]
  -[VCPCNNPoolingBlock forward]
  -[VCPCNNPoolingBlock supportGPU]
  -[VCPCNNPoolingBlock constructBlock:context:]
  -[VCPCNNPoolingBlock initWithParameters:poolY:chunk:]


VCPCNNPoolingBlockGPU : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockGPU .cxx_destruct]
  -[VCPCNNPoolingBlockGPU forward]


VCPCNNPoolingBlockScalar : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockScalar forward]


VCPVideoProcessor : NSObject /usr/lib/libc++.1.dylib
 @property  @? progressHandler

  // instance methods
  -[VCPVideoProcessor initWithURL:]
  -[VCPVideoProcessor .cxx_destruct]
  -[VCPVideoProcessor setProgressHandler:]
  -[VCPVideoProcessor progressHandler]
  -[VCPVideoProcessor cancel]
  -[VCPVideoProcessor _analyzeWithStart:andDuration:error:]
  -[VCPVideoProcessor analyzeWithStart:andDuration:error:]
  -[VCPVideoProcessor addRequest:withConfiguration:error:]
  -[VCPVideoProcessor removeRequest:error:]


VCPCNNPoolingBlockVector : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockVector forward]


VCPCNNPoseEstimator : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNPoseEstimator estimator]

  // instance methods
  -[VCPCNNPoseEstimator detectPoseForFace:inBuffer:yaw:]
  -[VCPCNNPoseEstimator getInputBuffer]
  -[VCPCNNPoseEstimator computePoseScore:]


VCPVideoProcessorSession : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned int orientation

  // instance methods
  -[VCPVideoProcessorSession init]
  -[VCPVideoProcessorSession .cxx_construct]
  -[VCPVideoProcessorSession .cxx_destruct]
  -[VCPVideoProcessorSession setOrientation:]
  -[VCPVideoProcessorSession orientation]
  -[VCPVideoProcessorSession shouldProcessSampleWithTimeRange:atSamplingInterval:]
  -[VCPVideoProcessorSession processSampleBuffer:withEndTime:error:]
  -[VCPVideoProcessorSession addRequest:withConfiguration:error:]
  -[VCPVideoProcessorSession removeRequest:error:]
  -[VCPVideoProcessorSession processSampleBuffer:error:]
  -[VCPVideoProcessorSession flushWithEndTime:error:]


VCPCNNPoseEstimatorEspresso : VCPCNNPoseEstimator
  // class methods
  +[VCPCNNPoseEstimatorEspresso sharedModel:]

  // instance methods
  -[VCPCNNPoseEstimatorEspresso init]
  -[VCPCNNPoseEstimatorEspresso dealloc]
  -[VCPCNNPoseEstimatorEspresso .cxx_destruct]
  -[VCPCNNPoseEstimatorEspresso getInputBuffer]
  -[VCPCNNPoseEstimatorEspresso computePoseScore:]


VCPProtoLivePhotoKeyFrameFaceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoBounds *faceBounds
 @property  float faceQuality

  // class methods
  +[VCPProtoLivePhotoKeyFrameFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameFaceResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameFaceResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoKeyFrameFaceResult .cxx_destruct]
  -[VCPProtoLivePhotoKeyFrameFaceResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameFaceResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameFaceResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameFaceResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameFaceResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameFaceResult faceBounds]
  -[VCPProtoLivePhotoKeyFrameFaceResult setFaceBounds:]
  -[VCPProtoLivePhotoKeyFrameFaceResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameFaceResult faceQuality]
  -[VCPProtoLivePhotoKeyFrameFaceResult setFaceQuality:]


VCPCNNPoseEstimatorMPS : VCPCNNPoseEstimator
  // instance methods
  -[VCPCNNPoseEstimatorMPS init]
  -[VCPCNNPoseEstimatorMPS .cxx_destruct]
  -[VCPCNNPoseEstimatorMPS getInputBuffer]
  -[VCPCNNPoseEstimatorMPS computePoseScore:]


VCPCNNSmileDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNSmileDetector detector]

  // instance methods
  -[VCPCNNSmileDetector detectSmileForFace:inBuffer:smile:]
  -[VCPCNNSmileDetector getInputBuffer]
  -[VCPCNNSmileDetector computeSmileScore:]


VCPCNNSmileDetectorEspresso : VCPCNNSmileDetector
  // class methods
  +[VCPCNNSmileDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNSmileDetectorEspresso init]
  -[VCPCNNSmileDetectorEspresso dealloc]
  -[VCPCNNSmileDetectorEspresso .cxx_destruct]
  -[VCPCNNSmileDetectorEspresso getInputBuffer]
  -[VCPCNNSmileDetectorEspresso computeSmileScore:]


VCPCNNSmileDetectorMPS : VCPCNNSmileDetector
  // instance methods
  -[VCPCNNSmileDetectorMPS init]
  -[VCPCNNSmileDetectorMPS .cxx_destruct]
  -[VCPCNNSmileDetectorMPS getInputBuffer]
  -[VCPCNNSmileDetectorMPS computeSmileScore:]


VCPDatabaseBatchIterator : NSObject /usr/lib/libc++.1.dylib
 @property  PHAsset *asset
 @property  NSDictionary *analysis

  // class methods
  +[VCPDatabaseBatchIterator iteratorForAssets:withDatabaseReader:resultTypes:batchSize:]

  // instance methods
  -[VCPDatabaseBatchIterator asset]
  -[VCPDatabaseBatchIterator next]
  -[VCPDatabaseBatchIterator .cxx_destruct]
  -[VCPDatabaseBatchIterator analysis]
  -[VCPDatabaseBatchIterator nextBatch]
  -[VCPDatabaseBatchIterator initWithDatabaseReader:forAssets:resultsTypes:batchSize:]


VCPDatabaseReader : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPDatabaseReader databaseForPhotoLibrary:]
  +[VCPDatabaseReader shouldQueryInternalFields]

  // instance methods
  -[VCPDatabaseReader closeDatabase]
  -[VCPDatabaseReader initWithPhotoLibrary:]
  -[VCPDatabaseReader queryAnalysisPropertiesForAssets:]
  -[VCPDatabaseReader blacklistedLocalIdentifiersFromAssets:]
  -[VCPDatabaseReader queryFailedProcessingStatusFromAssets:forTaskID:]
  -[VCPDatabaseReader countForTaskID:withProcessingStatus:]
  -[VCPDatabaseReader queryAnalysisForAsset:]
  -[VCPDatabaseReader dealloc]
  -[VCPDatabaseReader .cxx_destruct]
  -[VCPDatabaseReader isAssetBlacklisted:blacklistDate:]
  -[VCPDatabaseReader queryAssetsAnalyzedSince:]
  -[VCPDatabaseReader queryAnalysisForAsset:withTypes:]
  -[VCPDatabaseReader queryAnalysesForAssets:withTypes:]
  -[VCPDatabaseReader parseHeader:startColumn:analysis:]
  -[VCPDatabaseReader parseResults:typeColumn:dataColumn:results:]
  -[VCPDatabaseReader executeDatabaseBlock:]
  -[VCPDatabaseReader queryHeaderForAsset:analysis:assetId:]
  -[VCPDatabaseReader queryResultsForAssetId:analysis:]
  -[VCPDatabaseReader queryResultsForAssetId:withTypes:analysis:]
  -[VCPDatabaseReader queryHeadersForAssets:analyses:idMap:]
  -[VCPDatabaseReader queryResultsForAssets:withTypes:batchResults:]
  -[VCPDatabaseReader queryBlacklistedLocalIdentifiers]
  -[VCPDatabaseReader queryAnalysisPropertiesForAsset:]
  -[VCPDatabaseReader queryLocalIdentifiersForTaskID:withStatus:]
  -[VCPDatabaseReader openDatabase]


VCPHuman : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long flags
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  float confidence

  // class methods
  +[VCPHuman flagsFromKeypoints:withMinConfidence:]

  // instance methods
  -[VCPHuman init]
  -[VCPHuman setFlags:]
  -[VCPHuman setConfidence:]
  -[VCPHuman confidence]
  -[VCPHuman setBounds:]
  -[VCPHuman bounds]
  -[VCPHuman flags]


VCPDeviceInformation : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPDeviceInformation isHomePod]
  +[VCPDeviceInformation canRenderVariation]


VCPProtoMovieStabilizationResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float analysisConfidence
 @property  BOOL gyroStabilization
 @property  BOOL hasRecipeBlob
 @property  NSData *recipeBlob

  // class methods
  +[VCPProtoMovieStabilizationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieStabilizationResult copyWithZone:]
  -[VCPProtoMovieStabilizationResult exportToLegacyDictionary]
  -[VCPProtoMovieStabilizationResult .cxx_destruct]
  -[VCPProtoMovieStabilizationResult readFrom:]
  -[VCPProtoMovieStabilizationResult writeTo:]
  -[VCPProtoMovieStabilizationResult setRecipeBlob:]
  -[VCPProtoMovieStabilizationResult hasRecipeBlob]
  -[VCPProtoMovieStabilizationResult recipeBlob]
  -[VCPProtoMovieStabilizationResult isEqual:]
  -[VCPProtoMovieStabilizationResult gyroStabilization]
  -[VCPProtoMovieStabilizationResult setGyroStabilization:]
  -[VCPProtoMovieStabilizationResult setAnalysisConfidence:]
  -[VCPProtoMovieStabilizationResult analysisConfidence]
  -[VCPProtoMovieStabilizationResult copyTo:]
  -[VCPProtoMovieStabilizationResult dictionaryRepresentation]
  -[VCPProtoMovieStabilizationResult mergeFrom:]


VCPProtoMovieHumanActionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float absoluteScore
 @property  float relativeScore
 @property  float humanScore

  // class methods
  +[VCPProtoMovieHumanActionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHumanActionResult copyWithZone:]
  -[VCPProtoMovieHumanActionResult setTimeRange:]
  -[VCPProtoMovieHumanActionResult exportToLegacyDictionary]
  -[VCPProtoMovieHumanActionResult .cxx_destruct]
  -[VCPProtoMovieHumanActionResult timeRange]
  -[VCPProtoMovieHumanActionResult readFrom:]
  -[VCPProtoMovieHumanActionResult writeTo:]
  -[VCPProtoMovieHumanActionResult isEqual:]
  -[VCPProtoMovieHumanActionResult copyTo:]
  -[VCPProtoMovieHumanActionResult dictionaryRepresentation]
  -[VCPProtoMovieHumanActionResult absoluteScore]
  -[VCPProtoMovieHumanActionResult mergeFrom:]
  -[VCPProtoMovieHumanActionResult setAbsoluteScore:]
  -[VCPProtoMovieHumanActionResult relativeScore]
  -[VCPProtoMovieHumanActionResult setRelativeScore:]
  -[VCPProtoMovieHumanActionResult humanScore]
  -[VCPProtoMovieHumanActionResult setHumanScore:]


VCPEdgeDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPEdgeDetector dealloc]
  -[VCPEdgeDetector noiseReduction:sigma:imageFiltered:]
  -[VCPEdgeDetector gradientEstimation:width:height:gradient:gradientMag:]
  -[VCPEdgeDetector isInImage:width:height:]
  -[VCPEdgeDetector initWithImage:edgeMap:width:height:widthExtension:heightExtension:]
  -[VCPEdgeDetector detectWithSigma:lowThreshold:highThreshold:]


VCPEffectsAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPEffectsAnalyzer isAutoLoopFramworkAvailable]
  +[VCPEffectsAnalyzer usePHAssetScene]
  +[VCPEffectsAnalyzer gatingResultKeyToIndex]
  +[VCPEffectsAnalyzer getResultIndex:]
  +[VCPEffectsAnalyzer gatingTypeKeys]

  // instance methods
  -[VCPEffectsAnalyzer initWithFlagHasFaceOrPet:]
  -[VCPEffectsAnalyzer analyzeAsset:onDemand:cancel:statsFlags:results:]
  -[VCPEffectsAnalyzer enumerateMatchingScenesOfAsset:forLongExposureUsingBlock:]
  -[VCPEffectsAnalyzer generateStatsToBeCollectedFrom:]
  -[VCPEffectsAnalyzer reportLivePhotoEffectAnalysisResults:]
  -[VCPEffectsAnalyzer performanSceneClassificationOfImageFileAtURL:]
  -[VCPEffectsAnalyzer matchingNodeForSceneClassification:inSceneNames:]
  -[VCPEffectsAnalyzer initWithAnalysisResults:]


VCPImageExposurePreAnalyzer : VCPImageAnalyzer
 @property  float exposureScore

  // instance methods
  -[VCPImageExposurePreAnalyzer exposureScore]
  -[VCPImageExposurePreAnalyzer computeRegionNoise:blockTextureness:average:width:height:stride:]
  -[VCPImageExposurePreAnalyzer computeNoiseLevel:width:height:stride:textureness:]
  -[VCPImageExposurePreAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPTimer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPTimer timerWithInterval:unit:oneShot:andBlock:]
  +[VCPTimer timerWithIntervalSeconds:isOneShot:andBlock:]

  // instance methods
  -[VCPTimer destroy]
  -[VCPTimer dealloc]
  -[VCPTimer .cxx_destruct]
  -[VCPTimer initWithIntervalNanoseconds:isOneShot:andBlock:]


VCPExifAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPExifAnalyzer .cxx_destruct]
  -[VCPExifAnalyzer transformUprightAboutTopLeft:]
  -[VCPExifAnalyzer addFaceResults:flags:]
  -[VCPExifAnalyzer initWithProperties:forAnalysisTypes:]
  -[VCPExifAnalyzer analyzeAsset:results:]


VCPFace : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  BOOL leftEyeClosed
 @property  BOOL rightEyeClosed
 @property  BOOL smile
 @property  long long yaw
 @property  int trackID
 @property  float confidence
 @property  float faceQuality
 @property  VNFaceObservation *observation

  // instance methods
  -[VCPFace trackID]
  -[VCPFace init]
  -[VCPFace yaw]
  -[VCPFace smile]
  -[VCPFace setYaw:]
  -[VCPFace setConfidence:]
  -[VCPFace .cxx_destruct]
  -[VCPFace confidence]
  -[VCPFace setObservation:]
  -[VCPFace setTrackID:]
  -[VCPFace setBounds:]
  -[VCPFace bounds]
  -[VCPFace observation]
  -[VCPFace leftEyeClosed]
  -[VCPFace rightEyeClosed]
  -[VCPFace setLeftEyeClosed:]
  -[VCPFace setRightEyeClosed:]
  -[VCPFace faceBounds:height:]
  -[VCPFace flagsForOrientation:width:height:]
  -[VCPFace faceBoundsWithTransform:height:transform:]
  -[VCPFace setSmile:]
  -[VCPFace faceQuality]
  -[VCPFace setFaceQuality:]


VCPFaceDetectionRange : NSObject /usr/lib/libc++.1.dylib
 @property  {?=qiIq} start
 @property  {?=qiIq} last
 @property  unsigned long flags
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  unsigned long position
 @property  unsigned long faceID

  // instance methods
  -[VCPFaceDetectionRange position]
  -[VCPFaceDetectionRange setPosition:]
  -[VCPFaceDetectionRange setFlags:]
  -[VCPFaceDetectionRange setLast:]
  -[VCPFaceDetectionRange faceID]
  -[VCPFaceDetectionRange setStart:]
  -[VCPFaceDetectionRange setBounds:]
  -[VCPFaceDetectionRange bounds]
  -[VCPFaceDetectionRange flags]
  -[VCPFaceDetectionRange last]
  -[VCPFaceDetectionRange setFaceID:]
  -[VCPFaceDetectionRange start]


VCPTimeMeasurement : NSObject /usr/lib/libc++.1.dylib
 @property  double elapsedTimeSeconds
 @property  BOOL started

  // instance methods
  -[VCPTimeMeasurement started]
  -[VCPTimeMeasurement init]
  -[VCPTimeMeasurement stop]
  -[VCPTimeMeasurement reset]
  -[VCPTimeMeasurement elapsedTimeSeconds]
  -[VCPTimeMeasurement start]


VCPEvent : NSObject /usr/lib/libc++.1.dylib <NSSecureCoding>
 @property  NSDate *startDate
 @property  NSDate *endDate
 @property  NSTimeZone *timeZone
 @property  BOOL allDay
 @property  NSString *title
 @property  NSString *location
 @property  NSURL *url
 @property  NSString *notes

  // class methods
  +[VCPEvent supportsSecureCoding]

  // instance methods
  -[VCPEvent allDay]
  -[VCPEvent timeZone]
  -[VCPEvent setAllDay:]
  -[VCPEvent url]
  -[VCPEvent setEndDate:]
  -[VCPEvent startDate]
  -[VCPEvent setTimeZone:]
  -[VCPEvent .cxx_destruct]
  -[VCPEvent setTitle:]
  -[VCPEvent setNotes:]
  -[VCPEvent setLocation:]
  -[VCPEvent encodeWithCoder:]
  -[VCPEvent setUrl:]
  -[VCPEvent endDate]
  -[VCPEvent title]
  -[VCPEvent notes]
  -[VCPEvent location]
  -[VCPEvent setStartDate:]
  -[VCPEvent initWithCoder:]


VCPVisualIntelligenceAnalysisService : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVisualIntelligenceAnalysisService service]

  // instance methods
  -[VCPVisualIntelligenceAnalysisService init]
  -[VCPVisualIntelligenceAnalysisService .cxx_destruct]
  -[VCPVisualIntelligenceAnalysisService requestShareSheetProcessingForPixelBuffer:withOptions:andCompletionHandler:]
  -[VCPVisualIntelligenceAnalysisService requestShareSheetProcessingForAssetURL:withOptions:andCompletionHandler:]


VCPHomeFaceIdentificationTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
  // class methods
  +[VCPHomeFaceIdentificationTask taskWithFaceCrop:andCompletionHandler:]

  // instance methods
  -[VCPHomeFaceIdentificationTask run]
  -[VCPHomeFaceIdentificationTask dealloc]
  -[VCPHomeFaceIdentificationTask .cxx_destruct]
  -[VCPHomeFaceIdentificationTask run:]
  -[VCPHomeFaceIdentificationTask resourceRequirement]
  -[VCPHomeFaceIdentificationTask cancel]
  -[VCPHomeFaceIdentificationTask initWithFaceCrop:andCompletionHandler:]
  -[VCPHomeFaceIdentificationTask configureRequest:withRevision:]


VCPFingerprint : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *master
 @property  NSString *adjusted

  // class methods
  +[VCPFingerprint fingerprintWithMaster:adjusted:]

  // instance methods
  -[VCPFingerprint adjusted]
  -[VCPFingerprint init]
  -[VCPFingerprint master]
  -[VCPFingerprint .cxx_destruct]
  -[VCPFingerprint initWithMaster:adjusted:]
  -[VCPFingerprint isEqualToFingerprint:]


VCPFaceAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceAnalyzer _allowANE]

  // instance methods
  -[VCPFaceAnalyzer _rectFromMappingNormalizedRect:toBounds:]
  -[VCPFaceAnalyzer _pvFaceArrayFromAsset:]
  -[VCPFaceAnalyzer analyzeWithImage:andAsset:andOptions:andResults:]
  -[VCPFaceAnalyzer _performAnalysis:withRequestHandler:options:sourceWidth:sourceHeight:]
  -[VCPFaceAnalyzer initWithContext:]
  -[VCPFaceAnalyzer dealloc]
  -[VCPFaceAnalyzer .cxx_destruct]
  -[VCPFaceAnalyzer _createFaceRectanglesRequest:andFaceprintRequest:]
  -[VCPFaceAnalyzer getPVFaceFromVNFaceObservation:withSourceWidth:andSourceHeight:andVisionRequests:andAlgorithmVersion:andError:]
  -[VCPFaceAnalyzer _verifiedPersonsFetchResultWithLocalIdentifiers:andPhotoLibrary:andError:]
  -[VCPFaceAnalyzer _refineAnalysis:forAsset:andImage:]
  -[VCPFaceAnalyzer _configureRequest:withRevision:]
  -[VCPFaceAnalyzer _createBlurRequests:andExposureRequests:forFaceObservations:]
  -[VCPFaceAnalyzer _qualityMeasureForFace:countOfFacesOnAsset:]
  -[VCPFaceAnalyzer _addRegion:toBoundingBox:]
  -[VCPFaceAnalyzer _createFaceRectanglesRequest:andFaceLandmarksRequest:andFaceExpressionsRequest:andFacePoseRequest:andFaceprintRequest:andClassifyFaceAttributesRequest:andFaceCaptureQualityRequest:]
  -[VCPFaceAnalyzer _checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:]


VCPFrameScoreFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPFrameScoreFilter dealloc]
  -[VCPFrameScoreFilter initWithFilterTabs:distanceVariance:diffVariance:]
  -[VCPFrameScoreFilter processFrameScore:validScore:]


VCPProtoLivePhotoKeyFrameStillResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness
 @property  float textureness
 @property  BOOL hasFlash
 @property  float stillTime

  // class methods
  +[VCPProtoLivePhotoKeyFrameStillResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameStillResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameStillResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoKeyFrameStillResult hasFlash]
  -[VCPProtoLivePhotoKeyFrameStillResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameStillResult sharpness]
  -[VCPProtoLivePhotoKeyFrameStillResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameStillResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameStillResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameStillResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameStillResult setSharpness:]
  -[VCPProtoLivePhotoKeyFrameStillResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameStillResult textureness]
  -[VCPProtoLivePhotoKeyFrameStillResult setTextureness:]
  -[VCPProtoLivePhotoKeyFrameStillResult setHasFlash:]
  -[VCPProtoLivePhotoKeyFrameStillResult stillTime]
  -[VCPProtoLivePhotoKeyFrameStillResult setStillTime:]


VCPProtoImageSceneprintResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *sceneprintBlob

  // class methods
  +[VCPProtoImageSceneprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageSceneprintResult copyWithZone:]
  -[VCPProtoImageSceneprintResult exportToLegacyDictionary]
  -[VCPProtoImageSceneprintResult .cxx_destruct]
  -[VCPProtoImageSceneprintResult readFrom:]
  -[VCPProtoImageSceneprintResult writeTo:]
  -[VCPProtoImageSceneprintResult isEqual:]
  -[VCPProtoImageSceneprintResult copyTo:]
  -[VCPProtoImageSceneprintResult dictionaryRepresentation]
  -[VCPProtoImageSceneprintResult mergeFrom:]
  -[VCPProtoImageSceneprintResult setSceneprintBlob:]
  -[VCPProtoImageSceneprintResult sceneprintBlob]


VCPFullVideoAnalyzer : VCPVideoAnalyzer
 @property  float qualityScore
 @property  float actionScore
 @property  float interestingnessScore
 @property  float obstructionScore
 @property  float trackingScore
 @property  NSDictionary *objectsMotion
 @property  NSArray *globalMotion

  // class methods
  +[VCPFullVideoAnalyzer useSceneprintInSceneAnalysis]

  // instance methods
  -[VCPFullVideoAnalyzer results]
  -[VCPFullVideoAnalyzer .cxx_construct]
  -[VCPFullVideoAnalyzer dealloc]
  -[VCPFullVideoAnalyzer .cxx_destruct]
  -[VCPFullVideoAnalyzer initWithTransform:]
  -[VCPFullVideoAnalyzer process:]
  -[VCPFullVideoAnalyzer setActionScore:]
  -[VCPFullVideoAnalyzer actionScore]
  -[VCPFullVideoAnalyzer analyzeFrame:withTimestamp:andDuration:properties:flags:]
  -[VCPFullVideoAnalyzer seedAnalyzersWithPixelBuffer:startTime:]
  -[VCPFullVideoAnalyzer isStableMetaMotion:]
  -[VCPFullVideoAnalyzer qualityScore]
  -[VCPFullVideoAnalyzer estimateExpressionScore:encodeStats:frameWidth:frameHeight:]
  -[VCPFullVideoAnalyzer reviseFrameTrackScore:saliencyRegions:]
  -[VCPFullVideoAnalyzer privateResults]
  -[VCPFullVideoAnalyzer processAndEstimateQualityScore:]
  -[VCPFullVideoAnalyzer setInterestingnessScore:]
  -[VCPFullVideoAnalyzer interestingnessScore]
  -[VCPFullVideoAnalyzer computeExposureScoreOfFrame:]
  -[VCPFullVideoAnalyzer addSceneAnalysisResult:to:optional:]
  -[VCPFullVideoAnalyzer estimateQualityScore:]
  -[VCPFullVideoAnalyzer addResult:to:forKey:optional:]
  -[VCPFullVideoAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPFullVideoAnalyzer getSceneSwichFrequency]
  -[VCPFullVideoAnalyzer setNextCaptureFrame:]
  -[VCPFullVideoAnalyzer initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:]
  -[VCPFullVideoAnalyzer prepareVideoAnalysisByScenes:]
  -[VCPFullVideoAnalyzer prepareLivePhotoAnalysisByScenes:]
  -[VCPFullVideoAnalyzer finishAnalysisPass:]
  -[VCPFullVideoAnalyzer setQualityScore:]
  -[VCPFullVideoAnalyzer obstructionScore]
  -[VCPFullVideoAnalyzer setObstructionScore:]
  -[VCPFullVideoAnalyzer trackingScore]
  -[VCPFullVideoAnalyzer setTrackingScore:]
  -[VCPFullVideoAnalyzer objectsMotion]
  -[VCPFullVideoAnalyzer globalMotion]


VCPGaborFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPGaborFilter dealloc]
  -[VCPGaborFilter createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:]
  -[VCPGaborFilter initWithNumberOfScales:numOfOrientations:width:height:]
  -[VCPGaborFilter processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:]


VCPHoughTransform : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPHoughTransform dealloc]
  -[VCPHoughTransform Transform]
  -[VCPHoughTransform initWithEdgeMap:mapWidth:mapHeight:angleStep:]
  -[VCPHoughTransform DetectLinesWithThreshold:output:]


VCPCNNPersonKeypointsDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPCNNPersonKeypointsDetector dealloc]
  -[VCPCNNPersonKeypointsDetector .cxx_destruct]
  -[VCPCNNPersonKeypointsDetector copyImage:toData:]
  -[VCPCNNPersonKeypointsDetector parseKeypoints:]
  -[VCPCNNPersonKeypointsDetector initWithForceCPU:sharedModel:]
  -[VCPCNNPersonKeypointsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:]
  -[VCPCNNPersonKeypointsDetector analyzeFrame:withBox:keypoints:]


VCPImageAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPImageAnalyzer calculateTextureness:height:width:sdof:result:]
  -[VCPImageAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageAnalyzer processTile:results:cancel:]
  -[VCPImageAnalyzer aggregateTileResults:tileRect:imageSize:landscape:results:]
  -[VCPImageAnalyzer analyzePixelBufferInTiles:results:cancel:]


VCPImageBlurAnalyzer : VCPBlurAnalyzer
 @property  float sharpness
 @property  float textureScore

  // instance methods
  -[VCPImageBlurAnalyzer initWithFaceResults:sdof:revision:]
  -[VCPImageBlurAnalyzer prepareFaceBlurModel:]
  -[VCPImageBlurAnalyzer scaleRegion:ofImage:toData:withWidth:andHeight:]
  -[VCPImageBlurAnalyzer getFaceScoreFromOutput:ratio:]
  -[VCPImageBlurAnalyzer spatialPooling]
  -[VCPImageBlurAnalyzer estimateDistance:prevHomography:]
  -[VCPImageBlurAnalyzer analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:]
  -[VCPImageBlurAnalyzer computeLocalSharpness:]
  -[VCPImageBlurAnalyzer computeCNNFaceSharpness:result:cancel:]
  -[VCPImageBlurAnalyzer computeSharpnessScore:forFacesInImage:]
  -[VCPImageBlurAnalyzer computeGyroSharpness:]
  -[VCPImageBlurAnalyzer initWithFaceResults:sdof:]
  -[VCPImageBlurAnalyzer setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:]
  -[VCPImageBlurAnalyzer .cxx_destruct]
  -[VCPImageBlurAnalyzer sharpness]
  -[VCPImageBlurAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageBlurAnalyzer textureScore]
  -[VCPImageBlurAnalyzer setFaceResults:]


VCPMABaseTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
 @property  @? completionHandler
 @property  @? cancelBlock

  // instance methods
  -[VCPMABaseTask run]
  -[VCPMABaseTask isCanceled]
  -[VCPMABaseTask init]
  -[VCPMABaseTask dealloc]
  -[VCPMABaseTask .cxx_destruct]
  -[VCPMABaseTask run:]
  -[VCPMABaseTask resourceRequirement]
  -[VCPMABaseTask cancel]
  -[VCPMABaseTask initWithCompletionHandler:]
  -[VCPMABaseTask completionHandler]
  -[VCPMABaseTask setCancelBlock:]
  -[VCPMABaseTask cancelBlock]


VCPImageCompositionAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageCompositionAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPImageConverter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPImageConverter resize:height:]
  -[VCPImageConverter init]
  -[VCPImageConverter dealloc]
  -[VCPImageConverter initWithPixelFormat:]
  -[VCPImageConverter convertImage:yuvFrame:]


VCPImageDescriptor : NSObject /usr/lib/libc++.1.dylib <VCPDistanceDescriptorProtocol>
  // class methods
  +[VCPImageDescriptor usePHAssetData]
  +[VCPImageDescriptor descriptorWithImage:]
  +[VCPImageDescriptor descriptorWithData:]
  +[VCPImageDescriptor preferredPixelFormat]

  // instance methods
  -[VCPImageDescriptor serialize]
  -[VCPImageDescriptor initWithImage:]
  -[VCPImageDescriptor computeDistance:toDescriptor:]
  -[VCPImageDescriptor .cxx_destruct]
  -[VCPImageDescriptor initWithData:]


VCPImageExposureAnalyzer : VCPImageAnalyzer
 @property  float exposureScore

  // instance methods
  -[VCPImageExposureAnalyzer exposureScore]
  -[VCPImageExposureAnalyzer computeRegionNoise:blockTextureness:average:width:height:stride:]
  -[VCPImageExposureAnalyzer computeNoiseLevel:width:height:stride:textureness:]
  -[VCPImageExposureAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPAnalysisProgressQuery : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPAnalysisProgressQuery _countMediaAnalysisWithAssetBatch:andDatabase:]
  +[VCPAnalysisProgressQuery _countFaceAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countSceneAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countAnalysisWithAssetBatch:andDatabase:andTaskID:]
  +[VCPAnalysisProgressQuery _countFailuresWithAssetBatch:andDatabase:andTaskID:]
  +[VCPAnalysisProgressQuery _screenProgress]
  +[VCPAnalysisProgressQuery queryProgressDetail:forPhotoLibrary:andTaskID:]
  +[VCPAnalysisProgressQuery _processedPredicateForTaskID:]
  +[VCPAnalysisProgressQuery _queryProgressDetailExpress:forPhotoLibrary:andTaskID:]
  +[VCPAnalysisProgressQuery _scanPhotoLibrary:withTaskID:andStatistics:]
  +[VCPAnalysisProgressQuery queryProgress:forPhotoLibrary:andTaskID:]


VCPImageFaceDetector : VCPImageAnalyzer
  // class methods
  +[VCPImageFaceDetector faceDetector]

  // instance methods
  -[VCPImageFaceDetector faceDetection:faces:cancel:]
  -[VCPImageFaceDetector isDuplicate:withRect:]
  -[VCPImageFaceDetector analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageFaceDetector processTile:results:cancel:]
  -[VCPImageFaceDetector aggregateTileResults:tileRect:imageSize:landscape:results:]


VCPImageFaceExpressionAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageFaceExpressionAnalyzer initWithFaceResults:]
  -[VCPImageFaceExpressionAnalyzer .cxx_destruct]
  -[VCPImageFaceExpressionAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPVideoStabilizationAssetProcessingTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
  // class methods
  +[VCPVideoStabilizationAssetProcessingTask taskWithAssets:andOptions:andCompletionHandler:]

  // instance methods
  -[VCPVideoStabilizationAssetProcessingTask run]
  -[VCPVideoStabilizationAssetProcessingTask main]
  -[VCPVideoStabilizationAssetProcessingTask initWithAssets:andOptions:andCompletionHandler:]
  -[VCPVideoStabilizationAssetProcessingTask dealloc]
  -[VCPVideoStabilizationAssetProcessingTask .cxx_destruct]
  -[VCPVideoStabilizationAssetProcessingTask resourceRequirement]
  -[VCPVideoStabilizationAssetProcessingTask cancel]


VCPImageFaceQualityAnalyzer : VCPImageAnalyzer
 @property  NSMutableArray *faceQualityScores

  // instance methods
  -[VCPImageFaceQualityAnalyzer analyzeDetectedFaces:faceResults:cancel:]
  -[VCPImageFaceQualityAnalyzer faceQualityScores]
  -[VCPImageFaceQualityAnalyzer setFaceQualityScores:]
  -[VCPImageFaceQualityAnalyzer dealloc]
  -[VCPImageFaceQualityAnalyzer .cxx_destruct]


VCPImageLivePhotoBlurAnalyzer : VCPBlurAnalyzer
  // instance methods
  -[VCPImageLivePhotoBlurAnalyzer initWithMovingObjectsResults:]
  -[VCPImageLivePhotoBlurAnalyzer .cxx_destruct]
  -[VCPImageLivePhotoBlurAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPPhotosQuickFaceIdentificationLibraryProcessingTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
  // class methods
  +[VCPPhotosQuickFaceIdentificationLibraryProcessingTask _concurrentFaceProcessing]
  +[VCPPhotosQuickFaceIdentificationLibraryProcessingTask taskWithPhotoLibraries:andCompletionHandler:]

  // instance methods
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask run]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask init]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask _analyzeAsset:withManager:]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask dealloc]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask .cxx_destruct]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask run:]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask resourceRequirement]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask cancel]
  -[VCPPhotosQuickFaceIdentificationLibraryProcessingTask initWithPhotoLibraries:andCompletionHandler:]


VCPKeypoint : NSObject /usr/lib/libc++.1.dylib
 @property  {CGPoint=dd} location
 @property  float confidence

  // instance methods
  -[VCPKeypoint setConfidence:]
  -[VCPKeypoint confidence]
  -[VCPKeypoint setLocation:]
  -[VCPKeypoint location]


VCPPersonObservation : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *keypoints
 @property  float relativeActionScore
 @property  float absoluteActionScore
 @property  int personID
 @property  int revision

  // instance methods
  -[VCPPersonObservation setRevision:]
  -[VCPPersonObservation revision]
  -[VCPPersonObservation setKeypoints:]
  -[VCPPersonObservation relativeActionScore]
  -[VCPPersonObservation absoluteActionScore]
  -[VCPPersonObservation .cxx_destruct]
  -[VCPPersonObservation keypoints]
  -[VCPPersonObservation setRelativeActionScore:]
  -[VCPPersonObservation setAbsoluteActionScore:]
  -[VCPPersonObservation setPersonID:]
  -[VCPPersonObservation personID]


VCPHandObservation : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *keypoints
 @property  int handID
 @property  int revision

  // instance methods
  -[VCPHandObservation handID]
  -[VCPHandObservation setRevision:]
  -[VCPHandObservation revision]
  -[VCPHandObservation setKeypoints:]
  -[VCPHandObservation setHandID:]
  -[VCPHandObservation .cxx_destruct]
  -[VCPHandObservation keypoints]


VCPImageManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPImageManager sharedImageManager]
  +[VCPImageManager loggingEnabled]
  +[VCPImageManager canDecodeAcceleratedUniformTypeIdentifier:]

  // instance methods
  -[VCPImageManager init]
  -[VCPImageManager convertPixelBuffer:toPixelFormat:]
  -[VCPImageManager createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPImageManager drawImage:withOrientation:maxDimension:pixelBuffer:]
  -[VCPImageManager acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:flushCache:]
  -[VCPImageManager decodeImageSource:pixelFormat:maxDimension:pixelBuffer:]
  -[VCPImageManager dataForResource:]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:]
  -[VCPImageManager imageForResource:pixelFormat:]
  -[VCPImageManager imageForResource:pixelFormat:maxDimension:]
  -[VCPImageManager pixelBufferWithFormat:fromImageURL:flushCache:]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromImageURL:]
  -[VCPImageManager dealloc]
  -[VCPImageManager .cxx_destruct]
  -[VCPImageManager flushCache]


VCPProtoMovieHumanPoseResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence
 @property  VCPProtoBounds *bounds
 @property  int flags

  // class methods
  +[VCPProtoMovieHumanPoseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHumanPoseResult copyWithZone:]
  -[VCPProtoMovieHumanPoseResult setTimeRange:]
  -[VCPProtoMovieHumanPoseResult exportToLegacyDictionary]
  -[VCPProtoMovieHumanPoseResult setFlags:]
  -[VCPProtoMovieHumanPoseResult setConfidence:]
  -[VCPProtoMovieHumanPoseResult .cxx_destruct]
  -[VCPProtoMovieHumanPoseResult timeRange]
  -[VCPProtoMovieHumanPoseResult confidence]
  -[VCPProtoMovieHumanPoseResult setBounds:]
  -[VCPProtoMovieHumanPoseResult readFrom:]
  -[VCPProtoMovieHumanPoseResult bounds]
  -[VCPProtoMovieHumanPoseResult writeTo:]
  -[VCPProtoMovieHumanPoseResult isEqual:]
  -[VCPProtoMovieHumanPoseResult flags]
  -[VCPProtoMovieHumanPoseResult copyTo:]
  -[VCPProtoMovieHumanPoseResult dictionaryRepresentation]
  -[VCPProtoMovieHumanPoseResult mergeFrom:]


VCPMergeCandidatePair : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *person1LocalIdentifier
 @property  NSString *person2LocalIdentifier
 @property  NSString *reason

  // class methods
  +[VCPMergeCandidatePair mergeCandidatePairWithPerson:andPerson:reason:]

  // instance methods
  -[VCPMergeCandidatePair initWithPerson:andPerson:reason:]
  -[VCPMergeCandidatePair person1LocalIdentifier]
  -[VCPMergeCandidatePair person2LocalIdentifier]
  -[VCPMergeCandidatePair .cxx_destruct]
  -[VCPMergeCandidatePair isEqual:]
  -[VCPMergeCandidatePair reason]


VCPPhotosPersistenceDelegate : NSObject /usr/lib/libc++.1.dylib <PVPersistenceDelegate, PVPersonPromoterDelegate>
 @property  BOOL personBuilderMergeCandidatesDisabled
 @property  @? updateBlock
 @property  unsigned int faceAlgorithmUmbrellaVersion
 @property  unsigned int sceneAlgorithmUmbrellaVersion
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPPhotosPersistenceDelegate newAllFacesFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newFacesDeterministicSortDescriptors]
  +[VCPPhotosPersistenceDelegate enumerateFetchResult:withBatchSize:handler:]
  +[VCPPhotosPersistenceDelegate newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newVisibleFacesFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newAssetFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newAllPersonsFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newVerifiedPersonsFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:]

  // instance methods
  -[VCPPhotosPersistenceDelegate countOfClusteredFaces]
  -[VCPPhotosPersistenceDelegate initWithPhotoLibrary:]
  -[VCPPhotosPersistenceDelegate suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:]
  -[VCPPhotosPersistenceDelegate _ungroupFaceClusterSequenceNumbers:canceler:error:]
  -[VCPPhotosPersistenceDelegate _localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:withCanceler:]
  -[VCPPhotosPersistenceDelegate _faceToFaceCountMapForFaces:]
  -[VCPPhotosPersistenceDelegate facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:]
  -[VCPPhotosPersistenceDelegate photoLibrary]
  -[VCPPhotosPersistenceDelegate _categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:canceler:photoLibrary:]
  -[VCPPhotosPersistenceDelegate _buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:canceler:context:]
  -[VCPPhotosPersistenceDelegate _updatedFaceGroupByFGLocalIdentifierFromClusterCSNsWithCanceler:fetchLimit:]
  -[VCPPhotosPersistenceDelegate _enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:]
  -[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
  -[VCPPhotosPersistenceDelegate _facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:]
  -[VCPPhotosPersistenceDelegate _cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:canceler:error:]
  -[VCPPhotosPersistenceDelegate .cxx_destruct]
  -[VCPPhotosPersistenceDelegate _level0ClusterIdForFaceCSN:level0Clusters:]
  -[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
  -[VCPPhotosPersistenceDelegate densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:]
  -[VCPPhotosPersistenceDelegate countOfUnclusteredClusteringEligibleFaces]
  -[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
  -[VCPPhotosPersistenceDelegate _getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:canceler:]
  -[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:]
  -[VCPPhotosPersistenceDelegate logPVInfoMessage:]
  -[VCPPhotosPersistenceDelegate fetchFaceWithClusterSequenceNumber:error:]
  -[VCPPhotosPersistenceDelegate performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:]
  -[VCPPhotosPersistenceDelegate countOfFaces]
  -[VCPPhotosPersistenceDelegate updateBlock]
  -[VCPPhotosPersistenceDelegate sceneAlgorithmUmbrellaVersion]
  -[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
  -[VCPPhotosPersistenceDelegate fetchPersonWithLocalIdentifier:options:error:]
  -[VCPPhotosPersistenceDelegate resetLibraryClustersWithCanceler:error:]
  -[VCPPhotosPersistenceDelegate setPersonBuilderMergeCandidatesDisabled:]
  -[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
  -[VCPPhotosPersistenceDelegate unclusteredClusteringEligibleFaceLocalIdentifiers:]
  -[VCPPhotosPersistenceDelegate countOfClusteringEligibleFaces]
  -[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
  -[VCPPhotosPersistenceDelegate _representativenessByFaceCSNFromFaces:canceler:]
  -[VCPPhotosPersistenceDelegate personBuilderMergeCandidatesDisabled]
  -[VCPPhotosPersistenceDelegate facesFromAsset:]
  -[VCPPhotosPersistenceDelegate setSceneAlgorithmUmbrellaVersion:]
  -[VCPPhotosPersistenceDelegate needsPersonBuilding]
  -[VCPPhotosPersistenceDelegate otherFacesOnAssetWithFace:options:]
  -[VCPPhotosPersistenceDelegate _getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:]
  -[VCPPhotosPersistenceDelegate logPVErrorMessage:]
  -[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:]
  -[VCPPhotosPersistenceDelegate cleanupMergeCandidatesWithMinimumFaceGroupSize:canceler:error:]
  -[VCPPhotosPersistenceDelegate removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:canceler:error:]
  -[VCPPhotosPersistenceDelegate _updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:]
  -[VCPPhotosPersistenceDelegate logPVDebugMessage:]
  -[VCPPhotosPersistenceDelegate keyFaceForPerson:qualityMeasureByFace:updateBlock:]
  -[VCPPhotosPersistenceDelegate fetchFaceWithLocalIdentifier:error:]
  -[VCPPhotosPersistenceDelegate _getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:]
  -[VCPPhotosPersistenceDelegate _completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:canceler:context:error:]
  -[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:]
  -[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
  -[VCPPhotosPersistenceDelegate logPVWarningMessage:]
  -[VCPPhotosPersistenceDelegate setUpdateBlock:]
  -[VCPPhotosPersistenceDelegate _resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:canceler:error:]
  -[VCPPhotosPersistenceDelegate _fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:]
  -[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:]
  -[VCPPhotosPersistenceDelegate faceAlgorithmUmbrellaVersion]
  -[VCPPhotosPersistenceDelegate dedupeGraphVerifiedPersonsInFaceGroup:personCache:]
  -[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:]
  -[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
  -[VCPPhotosPersistenceDelegate setFaceAlgorithmUmbrellaVersion:]
  -[VCPPhotosPersistenceDelegate deleteEmptyGroupsAndReturnError:]
  -[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
  -[VCPPhotosPersistenceDelegate deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:]
  -[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:]
  -[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
  -[VCPPhotosPersistenceDelegate _duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:]
  -[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:]
  -[VCPPhotosPersistenceDelegate _fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:]
  -[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:]


VCPCNNPersonDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPCNNPersonDetector .cxx_construct]
  -[VCPCNNPersonDetector .cxx_destruct]
  -[VCPCNNPersonDetector generatePersonBoxes:]
  -[VCPCNNPersonDetector generatePersonRegions:boxes:maxNumRegions:]
  -[VCPCNNPersonDetector createInput:withBuffer:inputHeight:inputWidth:]
  -[VCPCNNPersonDetector personDetection:personRegions:cancel:]
  -[VCPCNNPersonDetector initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:]
  -[VCPCNNPersonDetector retrieveBoxes:outHeight:outWidth:boxes:anchorBox:]
  -[VCPCNNPersonDetector nonMaxSuppression:]
  -[VCPCNNPersonDetector copyImage:toData:]


VCPImagePetsAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImagePetsAnalyzer .cxx_destruct]
  -[VCPImagePetsAnalyzer convertResultsToDict:results:]
  -[VCPImagePetsAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImagePetsAnalyzer initWithMaxNumRegions:]


VCPImageQualityAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  float qualityScore

  // instance methods
  -[VCPImageQualityAnalyzer analyzeImageQuality:irisPhotoOffsetSec:cancel:]
  -[VCPImageQualityAnalyzer qualityScore]


VCPImageSaliencyAnalyzer : VCPImageAnalyzer
  // class methods
  +[VCPImageSaliencyAnalyzer analyzerWith:prune:]

  // instance methods
  -[VCPImageSaliencyAnalyzer initWithMaxNumRegions:prune:]
  -[VCPImageSaliencyAnalyzer copyImage:toData:withChunk:]
  -[VCPImageSaliencyAnalyzer outputScaling]
  -[VCPImageSaliencyAnalyzer pruneRegions:]
  -[VCPImageSaliencyAnalyzer computeScore:width:height:posX:posY:]
  -[VCPImageSaliencyAnalyzer scaleImage:toData:withWidth:andHeight:]
  -[VCPImageSaliencyAnalyzer getSalientRegions:]
  -[VCPImageSaliencyAnalyzer saliencyDetection:salientRegions:cancel:]
  -[VCPImageSaliencyAnalyzer generateSalientRegion:outHeight:outWidth:]
  -[VCPImageSaliencyAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageSaliencyAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzer getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzer processTile:results:cancel:]
  -[VCPImageSaliencyAnalyzer aggregateTileResults:tileRect:imageSize:landscape:results:]


VCPImageSaliencyAnalyzerBinary : VCPImageSaliencyAnalyzer
  // instance methods
  -[VCPImageSaliencyAnalyzerBinary .cxx_destruct]
  -[VCPImageSaliencyAnalyzerBinary outputScaling]
  -[VCPImageSaliencyAnalyzerBinary getSalientRegions:]
  -[VCPImageSaliencyAnalyzerBinary prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerBinary getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]


VCPImageSaliencyAnalyzerFull : VCPImageSaliencyAnalyzer
  // instance methods
  -[VCPImageSaliencyAnalyzerFull .cxx_destruct]
  -[VCPImageSaliencyAnalyzerFull getSalientRegions:]
  -[VCPImageSaliencyAnalyzerFull prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerFull getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]


VCPImageSaliencyAnalyzerFullEspresso : VCPImageSaliencyAnalyzer
  // class methods
  +[VCPImageSaliencyAnalyzerFullEspresso sharedModel:]

  // instance methods
  -[VCPImageSaliencyAnalyzerFullEspresso dealloc]
  -[VCPImageSaliencyAnalyzerFullEspresso .cxx_destruct]
  -[VCPImageSaliencyAnalyzerFullEspresso getSalientRegions:]
  -[VCPImageSaliencyAnalyzerFullEspresso prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerFullEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]


VCPSceneProcessingImageManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPSceneProcessingImageManager imageManager]

  // instance methods
  -[VCPSceneProcessingImageManager .cxx_construct]
  -[VCPSceneProcessingImageManager dealloc]
  -[VCPSceneProcessingImageManager .cxx_destruct]
  -[VCPSceneProcessingImageManager _createPixelBufferPool]
  -[VCPSceneProcessingImageManager _createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPSceneProcessingImageManager loadFullPixelBuffer:scaledPixelBuffer:fromImageURL:isPano:]


VCPPreAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPPreAnalyzer _useR14J9]
  +[VCPPreAnalyzer _includeDO]
  +[VCPPreAnalyzer _includeSO]
  +[VCPPreAnalyzer _panoVNRequestMethod]
  +[VCPPreAnalyzer _includeLM]
  +[VCPPreAnalyzer _includeNSFW]
  +[VCPPreAnalyzer _getNSFWModelRevision]
  +[VCPPreAnalyzer _includeSE]
  +[VCPPreAnalyzer _getSERevision]
  +[VCPPreAnalyzer _includeSDG]
  +[VCPPreAnalyzer _getSDGModelRevision]
  +[VCPPreAnalyzer _getSHRevision]
  +[VCPPreAnalyzer _enableSceneAssetConcurrency]
  +[VCPPreAnalyzer _allowANE]

  // instance methods
  -[VCPPreAnalyzer init]
  -[VCPPreAnalyzer .cxx_construct]
  -[VCPPreAnalyzer dealloc]
  -[VCPPreAnalyzer .cxx_destruct]
  -[VCPPreAnalyzer _createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPPreAnalyzer _createPixelBufferPool:withPixelFormat:]
  -[VCPPreAnalyzer _convertFromBuffer:toLumaPixelBuffer:isPano:]
  -[VCPPreAnalyzer _parseClassificationObservations:toClassificationResults:]
  -[VCPPreAnalyzer _generateSceneClassifications:withClassificationResults:andDOResults:andJunkImageResults:andLMResults:andNSFWResults:andSEResults:andSDGResults:]
  -[VCPPreAnalyzer _performBlurAnalysis:withPixelBuffer:usingAnalyzer:]
  -[VCPPreAnalyzer _performSceneAnalysis:withRequestHandler:]
  -[VCPPreAnalyzer _createAestheticsRequest:andClassificationRequest:andSceneprintRequest:andJunkImageRequest:andSaliencyImageRequest:andDORequest:andLMRequest:andNSFWRequest:andSERequest:andSDGRequest:andSORequest:andRawSceneprintRequest:]
  -[VCPPreAnalyzer _collectSceneAnalysisResults:withClassificationResults:andJunkImageResults:andAestheticsResults:andSaliencyResults:andSceneprintResults:andDOResults:andLMResults:andNSFWResults:andSEResults:andSDGResults:andSaliencyObjectnessResults:]
  -[VCPPreAnalyzer _performBlurAnalysis:withLumaPixelBuffer:isPano:isSDOF:]
  -[VCPPreAnalyzer _performExposureAnalysis:withLumaPixelBuffer:]
  -[VCPPreAnalyzer _loadImageURL:isPano:withRequestHandler:session:andLumaPixelBuffer:]
  -[VCPPreAnalyzer _performAnalysis:isPano:isSDOF:withRequestHandler:andLumaPixelBuffer:]
  -[VCPPreAnalyzer analyzeWithImageURL:isPano:isSDOF:completionHandler:]
  -[VCPPreAnalyzer analyzeWithPixelBuffer:isPano:isSDOF:results:cancel:]
  -[VCPPreAnalyzer _configureRequest:withRevision:]


VCPInterAssetAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPInterAssetAnalyzer thumbnailSizeForAsset:withResources:]
  +[VCPInterAssetAnalyzer canUseLastFrameOfAsset:withResources:]

  // instance methods
  -[VCPInterAssetAnalyzer init]
  -[VCPInterAssetAnalyzer _generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:]
  -[VCPInterAssetAnalyzer _getThumbnailForAsset:withResouces:andPixelFormat:]
  -[VCPInterAssetAnalyzer computeDistance:fromArray:toArray:]
  -[VCPInterAssetAnalyzer computeDistance:withDescriptorClass:fromAsset:toAsset:]
  -[VCPInterAssetAnalyzer generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:]


VCPShareSheetAssetProcessingTask : VCPMABaseTask <VCPMAImageProcessingTaskProtocol>
  // class methods
  +[VCPShareSheetAssetProcessingTask taskWithPixelBuffer:options:andCompletionHandler:]
  +[VCPShareSheetAssetProcessingTask taskWithAssetURL:options:andCompletionHandler:]

  // instance methods
  -[VCPShareSheetAssetProcessingTask .cxx_construct]
  -[VCPShareSheetAssetProcessingTask .cxx_destruct]
  -[VCPShareSheetAssetProcessingTask run:]
  -[VCPShareSheetAssetProcessingTask processObservations:]


VCPJunkAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPJunkAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPLandmarkValidator : NSObject /usr/lib/libc++.1.dylib
 @property  ^f orientation

  // instance methods
  -[VCPLandmarkValidator dealloc]
  -[VCPLandmarkValidator .cxx_destruct]
  -[VCPLandmarkValidator initWithModelFile:paramFile:numTri:triList:angle:]
  -[VCPLandmarkValidator validateOneImage:landmarks:numofLandmarks:score:]
  -[VCPLandmarkValidator setOrientation:]
  -[VCPLandmarkValidator orientation]


VCPLightMotionAnalyzer : VCPVideoAnalyzer
 @property  float actionScore

  // class methods
  +[VCPLightMotionAnalyzer autoLiveMotionScore:]

  // instance methods
  -[VCPLightMotionAnalyzer init]
  -[VCPLightMotionAnalyzer .cxx_construct]
  -[VCPLightMotionAnalyzer dealloc]
  -[VCPLightMotionAnalyzer .cxx_destruct]
  -[VCPLightMotionAnalyzer cameraMotionDetection:]
  -[VCPLightMotionAnalyzer generateThresholds:withConfidences:]
  -[VCPLightMotionAnalyzer initWithQueue:turbo:]
  -[VCPLightMotionAnalyzer prewarmWithWidth:height:]
  -[VCPLightMotionAnalyzer analyzeFrame:withTimestamp:andDuration:completion:]
  -[VCPLightMotionAnalyzer actionScore]
  -[VCPLightMotionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]


VCPLightVideoAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *publicResults
 @property  NSDictionary *privateResults

  // instance methods
  -[VCPLightVideoAnalyzer .cxx_destruct]
  -[VCPLightVideoAnalyzer publicResults]
  -[VCPLightVideoAnalyzer findMetaTrackforType:]
  -[VCPLightVideoAnalyzer processMetaTrackForType:cancel:flags:]
  -[VCPLightVideoAnalyzer checkTimeRangeConsistency]
  -[VCPLightVideoAnalyzer postProcessOrientationResults]
  -[VCPLightVideoAnalyzer initWithAVAsset:forAnalysisTypes:]
  -[VCPLightVideoAnalyzer analyzeAsset:flags:]
  -[VCPLightVideoAnalyzer privateResults]


VCPLogManager : NSObject /usr/lib/libc++.1.dylib
 @property  int logLevel

  // class methods
  +[VCPLogManager dateFormatter]
  +[VCPLogManager sharedLogManager]

  // instance methods
  -[VCPLogManager init]
  -[VCPLogManager logLevel]


VCPCNNHandsDetectorEspresso : VCPCNNHandsDetector
  // instance methods
  -[VCPCNNHandsDetectorEspresso dealloc]
  -[VCPCNNHandsDetectorEspresso .cxx_destruct]
  -[VCPCNNHandsDetectorEspresso createModelWithResConfig:]
  -[VCPCNNHandsDetectorEspresso updateModelWithResConfig:]
  -[VCPCNNHandsDetectorEspresso initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:]
  -[VCPCNNHandsDetectorEspresso generateHandsBoxes:]
  -[VCPCNNHandsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]


VCPMovieCurationAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPMovieCurationAnalyzer results]
  -[VCPMovieCurationAnalyzer .cxx_destruct]
  -[VCPMovieCurationAnalyzer setMaxHighlightDuration:]
  -[VCPMovieCurationAnalyzer postProcessKeyFrames]
  -[VCPMovieCurationAnalyzer reportMovieCurationAnalysisResults:withSummaryAnalytics:]
  -[VCPMovieCurationAnalyzer addHighlight:to:]
  -[VCPMovieCurationAnalyzer addSummary:to:]
  -[VCPMovieCurationAnalyzer initWithAnalysisTypes:transform:timeRange:isLivePhoto:frameStats:hadFlash:hadZoom:keyFrameResults:]
  -[VCPMovieCurationAnalyzer analyzeKeyFrame:withTimestamp:andDuration:flags:]
  -[VCPMovieCurationAnalyzer loadVideoAnalysisResults:audioAnalysisResults:andFaceRanges:frameSize:]
  -[VCPMovieCurationAnalyzer generateMovieCurations]


VCPVideoKeyFrameResult : NSObject /usr/lib/libc++.1.dylib
 @property  {?=qiIq} timeStamp
 @property  float score

  // instance methods
  -[VCPVideoKeyFrameResult timeStamp]
  -[VCPVideoKeyFrameResult initWithTime:andScore:]
  -[VCPVideoKeyFrameResult score]


VCPMovieHighlightResult : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score
 @property  VCPVideoKeyFrameResult *keyFrame

  // instance methods
  -[VCPMovieHighlightResult .cxx_destruct]
  -[VCPMovieHighlightResult timerange]
  -[VCPMovieHighlightResult initWithTimeRange:score:andKeyFrame:]
  -[VCPMovieHighlightResult score]
  -[VCPMovieHighlightResult keyFrame]


VCPMovieCurationResults : NSObject /usr/lib/libc++.1.dylib
 @property  PHAsset *phAsset
 @property  NSMutableArray *highlights

  // instance methods
  -[VCPMovieCurationResults .cxx_destruct]
  -[VCPMovieCurationResults phAsset]
  -[VCPMovieCurationResults initWithPHAsset:]
  -[VCPMovieCurationResults highlights]


VCPMovieHighlight : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score
 @property  float junkScore
 @property  float qualityScore
 @property  float expressionScore
 @property  float actionScore
 @property  float voiceScore
 @property  float humanActionScore
 @property  float humanPoseScore
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bestPlaybackCrop
 @property  BOOL isAutoPlayable
 @property  BOOL isTrimmed
 @property  VCPImageDescriptor *descriptor
 @property  VCPVideoKeyFrame *keyFrame

  // instance methods
  -[VCPMovieHighlight setScore:]
  -[VCPMovieHighlight setDescriptor:]
  -[VCPMovieHighlight initWithTimeRange:]
  -[VCPMovieHighlight .cxx_destruct]
  -[VCPMovieHighlight timerange]
  -[VCPMovieHighlight isTrimmed]
  -[VCPMovieHighlight isShort]
  -[VCPMovieHighlight bestPlaybackCrop]
  -[VCPMovieHighlight isAutoPlayable]
  -[VCPMovieHighlight junkScore]
  -[VCPMovieHighlight expressionScore]
  -[VCPMovieHighlight voiceScore]
  -[VCPMovieHighlight humanActionScore]
  -[VCPMovieHighlight humanPoseScore]
  -[VCPMovieHighlight mergeSegment:]
  -[VCPMovieHighlight copyScoresFrom:]
  -[VCPMovieHighlight setTimerange:]
  -[VCPMovieHighlight checkAutoPlayable]
  -[VCPMovieHighlight setJunkScore:]
  -[VCPMovieHighlight setExpressionScore:]
  -[VCPMovieHighlight setVoiceScore:]
  -[VCPMovieHighlight setHumanActionScore:]
  -[VCPMovieHighlight setHumanPoseScore:]
  -[VCPMovieHighlight setBestPlaybackCrop:]
  -[VCPMovieHighlight setIsAutoPlayable:]
  -[VCPMovieHighlight setIsTrimmed:]
  -[VCPMovieHighlight setKeyFrame:]
  -[VCPMovieHighlight descriptor]
  -[VCPMovieHighlight score]
  -[VCPMovieHighlight setActionScore:]
  -[VCPMovieHighlight actionScore]
  -[VCPMovieHighlight keyFrame]
  -[VCPMovieHighlight qualityScore]
  -[VCPMovieHighlight setQualityScore:]


VCPExpressionSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  float score

  // instance methods
  -[VCPExpressionSegment setTimeRange:]
  -[VCPExpressionSegment setScore:]
  -[VCPExpressionSegment timeRange]
  -[VCPExpressionSegment score]


VCPMovieHighlightAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPMovieHighlightAnalyzer prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:frameSize:]
  -[VCPMovieHighlightAnalyzer results]
  -[VCPMovieHighlightAnalyzer .cxx_destruct]
  -[VCPMovieHighlightAnalyzer addSegment:]
  -[VCPMovieHighlightAnalyzer initWithAnalysisType:isLivePhoto:hadFlash:hadZoom:]
  -[VCPMovieHighlightAnalyzer setMaxHighlightDuration:]
  -[VCPMovieHighlightAnalyzer generateHighlights]
  -[VCPMovieHighlightAnalyzer movieSummary]
  -[VCPMovieHighlightAnalyzer generateInitialSegments]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreWithConstraint]
  -[VCPMovieHighlightAnalyzer computeQualityTrimFor:withKeyFrame:]
  -[VCPMovieHighlightAnalyzer computeActionFaceTrimFor:]
  -[VCPMovieHighlightAnalyzer computeSteadyTranslationTrimFor:]
  -[VCPMovieHighlightAnalyzer checkCameraZoom:]
  -[VCPMovieHighlightAnalyzer pickHighlightsFrom:]
  -[VCPMovieHighlightAnalyzer generateExpressionSegments:]
  -[VCPMovieHighlightAnalyzer analyzeOverallQuality:]
  -[VCPMovieHighlightAnalyzer pickKeyFramesInRange:]
  -[VCPMovieHighlightAnalyzer computeBestPlaybackCrop:]
  -[VCPMovieHighlightAnalyzer junkScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer qualityScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer SetKeyFramesForSegments:]
  -[VCPMovieHighlightAnalyzer computeExpressionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeActionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeVoiceScoreInTimeRange:]
  -[VCPMovieHighlightAnalyzer searchFeatureVectorOfSegment:]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreOfSegment:]
  -[VCPMovieHighlightAnalyzer evaluateSegment:]
  -[VCPMovieHighlightAnalyzer computeHumanActionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeHumanPoseScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer actionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer subtleMotionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer expressionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer voiceScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer cameraMotionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer visualPleasingScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreOfRange:]
  -[VCPMovieHighlightAnalyzer mergeShortSegments]
  -[VCPMovieHighlightAnalyzer mergeSimilarSegments]


VCPMediaAnalysisService : NSObject /usr/lib/libc++.1.dylib <VCPMediaAnalysisClientProtocol>
  // class methods
  +[VCPMediaAnalysisService queryProgressDetail:forPhotoLibrary:andTaskID:]
  +[VCPMediaAnalysisService errorWithDescription:]
  +[VCPMediaAnalysisService queryProgressDetail:forPhotoLibraryURL:andTaskID:]
  +[VCPMediaAnalysisService analysisService]
  +[VCPMediaAnalysisService queryProgress:forPhotoLibrary:andTaskID:]
  +[VCPMediaAnalysisService sharedAnalysisService]

  // instance methods
  -[VCPMediaAnalysisService requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService init]
  -[VCPMediaAnalysisService requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:]
  -[VCPMediaAnalysisService requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService .cxx_destruct]
  -[VCPMediaAnalysisService requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService notifyLibraryAvailableAtURL:]
  -[VCPMediaAnalysisService requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService cancelAllRequests]
  -[VCPMediaAnalysisService requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService cancelBackgroundActivity]
  -[VCPMediaAnalysisService connection]
  -[VCPMediaAnalysisService reportProgress:forRequest:]
  -[VCPMediaAnalysisService invalidate]
  -[VCPMediaAnalysisService requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService cancelRequest:]


VCPMediaAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPMediaAnalyzer sharedMediaAnalyzer]
  +[VCPMediaAnalyzer _getDistanceDescriptorClass]

  // instance methods
  -[VCPMediaAnalyzer init]
  -[VCPMediaAnalyzer dealloc]
  -[VCPMediaAnalyzer .cxx_destruct]
  -[VCPMediaAnalyzer _addClassificationResults:analysis:]
  -[VCPMediaAnalyzer _metaAnalysisTypesForAsset:]
  -[VCPMediaAnalyzer _analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:]
  -[VCPMediaAnalyzer _databaseForPhotoLibrary:]
  -[VCPMediaAnalyzer requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:]
  -[VCPMediaAnalyzer assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:]
  -[VCPMediaAnalyzer _getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:]
  -[VCPMediaAnalyzer _checkDuplicate:withAsset:duplicate:]
  -[VCPMediaAnalyzer _queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:]
  -[VCPMediaAnalyzer _typesToRemove:requested:]
  -[VCPMediaAnalyzer requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssets:withOptions:andProgressHandler:analyses:]
  -[VCPMediaAnalyzer requestAnalysis:forAssets:withOptions:andProgressHandler:andError:]
  -[VCPMediaAnalyzer _getDatabaseSandboxExtensionForPhotoLibraryURL:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:]
  -[VCPMediaAnalyzer analyzeOndemand:pairedURL:forAnalysisTypes:error:]
  -[VCPMediaAnalyzer requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:]
  -[VCPMediaAnalyzer cancelAnalysisWithRequestID:]
  -[VCPMediaAnalyzer assetsAnalyzedSinceDate:completionHandler:]
  -[VCPMediaAnalyzer distanceFromAsset:toAsset:duplicate:distance:]
  -[VCPMediaAnalyzer requestCallerIdentificationForFaces:]
  -[VCPMediaAnalyzer completeStorage]
  -[VCPMediaAnalyzer distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:]
  -[VCPMediaAnalyzer requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:]
  -[VCPMediaAnalyzer curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:]
  -[VCPMediaAnalyzer requestMovieHighlightsForAssets:withOptions:]
  -[VCPMediaAnalyzer requestLivePhotoEffectsForAssets:allowOnDemand:flags:]
  -[VCPMediaAnalyzer connection]


VCPMetaSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames

  // instance methods
  -[VCPMetaSegment init]
  -[VCPMetaSegment timeRange]
  -[VCPMetaSegment mergeSegment:]
  -[VCPMetaSegment numOfFrames]
  -[VCPMetaSegment updateSegment:]
  -[VCPMetaSegment resetSegment:]
  -[VCPMetaSegment finalizeAtTime:]


VCPMetaTrackDecoder : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPMetaTrackDecoder initWithTrack:]
  -[VCPMetaTrackDecoder dealloc]
  -[VCPMetaTrackDecoder .cxx_destruct]
  -[VCPMetaTrackDecoder copyNextMetadataGroup]
  -[VCPMetaTrackDecoder status]


VCPMovieAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL allowStreaming
 @property  float maxHighlightDuration
 @property  BOOL faceDominated
 @property  long long status

  // class methods
  +[VCPMovieAnalyzer canAnalyzeUndegraded:withResources:]
  +[VCPMovieAnalyzer analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  +[VCPMovieAnalyzer getMaximumHighlightInSec]

  // instance methods
  -[VCPMovieAnalyzer analyzeAsset:streamed:]
  -[VCPMovieAnalyzer initWithPHAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer .cxx_destruct]
  -[VCPMovieAnalyzer setMaxHighlightDuration:]
  -[VCPMovieAnalyzer setAllowStreaming:]
  -[VCPMovieAnalyzer initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer processExistingAnalysisForTimeRange:analysisTypes:]
  -[VCPMovieAnalyzer createDecoderForTrack:timerange:forAnalysisTypes:]
  -[VCPMovieAnalyzer createVideoAnalyzer:withFrameStats:]
  -[VCPMovieAnalyzer allowStreaming]
  -[VCPMovieAnalyzer analyzeVideoSegment:timerange:forAnalysisTypes:cancel:]
  -[VCPMovieAnalyzer loadPropertiesForAsset:]
  -[VCPMovieAnalyzer performMetadataAnalysisOnAsset:withCancelBlock:]
  -[VCPMovieAnalyzer analyzeVideoTrack:start:forAnalysisTypes:cancel:]
  -[VCPMovieAnalyzer generateKeyFrameResource:]
  -[VCPMovieAnalyzer initWithPHAsset:withPausedAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer maxHighlightDuration]
  -[VCPMovieAnalyzer faceDominated]
  -[VCPMovieAnalyzer setFaceDominated:]
  -[VCPMovieAnalyzer status]
  -[VCPMovieAnalyzer privateResults]


VCPProtoImageHumanPoseResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds
 @property  int flags

  // class methods
  +[VCPProtoImageHumanPoseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageHumanPoseResult copyWithZone:]
  -[VCPProtoImageHumanPoseResult exportToLegacyDictionary]
  -[VCPProtoImageHumanPoseResult setFlags:]
  -[VCPProtoImageHumanPoseResult setConfidence:]
  -[VCPProtoImageHumanPoseResult .cxx_destruct]
  -[VCPProtoImageHumanPoseResult confidence]
  -[VCPProtoImageHumanPoseResult setBounds:]
  -[VCPProtoImageHumanPoseResult readFrom:]
  -[VCPProtoImageHumanPoseResult bounds]
  -[VCPProtoImageHumanPoseResult writeTo:]
  -[VCPProtoImageHumanPoseResult isEqual:]
  -[VCPProtoImageHumanPoseResult flags]
  -[VCPProtoImageHumanPoseResult copyTo:]
  -[VCPProtoImageHumanPoseResult dictionaryRepresentation]
  -[VCPProtoImageHumanPoseResult mergeFrom:]


VCPLivePhotoKeyFrameAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPLivePhotoKeyFrameAnalyzer dealloc]
  -[VCPLivePhotoKeyFrameAnalyzer createFaceHeatMap:imageFaces:]
  -[VCPLivePhotoKeyFrameAnalyzer computeOverallFaceQualityScore:]
  -[VCPLivePhotoKeyFrameAnalyzer selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:]
  -[VCPLivePhotoKeyFrameAnalyzer fetchAndComputeScoreForKeyFrame:withResult:]
  -[VCPLivePhotoKeyFrameAnalyzer computeScoreForPhoto:withRefKeyFrame:]
  -[VCPLivePhotoKeyFrameAnalyzer reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:]
  -[VCPLivePhotoKeyFrameAnalyzer getFaceHeat:]
  -[VCPLivePhotoKeyFrameAnalyzer updateFaceHeatMap:]
  -[VCPLivePhotoKeyFrameAnalyzer analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:]
  -[VCPLivePhotoKeyFrameAnalyzer initWithWidth:height:]


VCPPhotosQuickFaceIdentificationManager : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPPhotosQuickFaceIdentificationManager initWithPhotoLibrary:]
  -[VCPPhotosQuickFaceIdentificationManager init]
  -[VCPPhotosQuickFaceIdentificationManager .cxx_destruct]
  -[VCPPhotosQuickFaceIdentificationManager fetchPersonsForFaceIDModel]
  -[VCPPhotosQuickFaceIdentificationManager _needToGeneratePersonsModel]
  -[VCPPhotosQuickFaceIdentificationManager _personsModelLastGenerationDidExceedTimeInterval]
  -[VCPPhotosQuickFaceIdentificationManager _detectFacesWithPVImage:forAsset:withAnalysis:]
  -[VCPPhotosQuickFaceIdentificationManager _generatePersonsModelShouldForce:extendTimeoutBlock:cancel:]
  -[VCPPhotosQuickFaceIdentificationManager _persistResults:withFaces:forAsset:]
  -[VCPPhotosQuickFaceIdentificationManager generatePersonsModelWithExtendTimeout:cancel:]
  -[VCPPhotosQuickFaceIdentificationManager _persistPersonsModel:error:]
  -[VCPPhotosQuickFaceIdentificationManager processAsset:]
  -[VCPPhotosQuickFaceIdentificationManager _classifyFaces:forAsset:withResults:]
  -[VCPPhotosQuickFaceIdentificationManager _loadPersonsModel]
  -[VCPPhotosQuickFaceIdentificationManager _loadPVImage:forAsset:]


VCPPhotoAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL allowStreaming
 @property  long long status

  // class methods
  +[VCPPhotoAnalyzer canAnalyzeUndegraded:withResources:]
  +[VCPPhotoAnalyzer analyzerWithVCPAsset:forAnalysisTypes:]
  +[VCPPhotoAnalyzer resourceForAsset:withResources:]

  // instance methods
  -[VCPPhotoAnalyzer initWithPHAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPPhotoAnalyzer .cxx_destruct]
  -[VCPPhotoAnalyzer setAllowStreaming:]
  -[VCPPhotoAnalyzer analyzeAsset:]
  -[VCPPhotoAnalyzer initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPPhotoAnalyzer allowStreaming]
  -[VCPPhotoAnalyzer processExistingAnalyses:]
  -[VCPPhotoAnalyzer updateDegradedFlagForMajorDimension:]
  -[VCPPhotoAnalyzer downscaleImage:scaledImage:majorDimension:]
  -[VCPPhotoAnalyzer existingAnalysisForMovieAnalyzer]
  -[VCPPhotoAnalyzer checkFaceDominant]
  -[VCPPhotoAnalyzer analyzeImage:performedAnalyses:cancel:]
  -[VCPPhotoAnalyzer status]


VCPPnPSolver : NSObject /usr/lib/libc++.1.dylib
 @property  {?=[4]} pose

  // instance methods
  -[VCPPnPSolver pose]
  -[VCPPnPSolver dealloc]
  -[VCPPnPSolver setPose:]
  -[VCPPnPSolver computeControlPointsCamera:Vt:]
  -[VCPPnPSolver computePoints3DCamera]
  -[VCPPnPSolver correctSigns]
  -[VCPPnPSolver computeRT:T:]
  -[VCPPnPSolver computeProjectionError:T:]
  -[VCPPnPSolver configureGaussNewton:R6x1:betas:jacobian:residual:]
  -[VCPPnPSolver getControlPoints]
  -[VCPPnPSolver computeBarycentricCoordinates]
  -[VCPPnPSolver computeSVDVt:Vt:]
  -[VCPPnPSolver computeL6x10:L6x10:]
  -[VCPPnPSolver computeR6x1:]
  -[VCPPnPSolver estimateBetasN1:R6x1:betas:]
  -[VCPPnPSolver estimateBetasN2:R6x1:betas:]
  -[VCPPnPSolver estimateBetasN3:R6x1:betas:]
  -[VCPPnPSolver optimizeBetas:R6x1:betas:]
  -[VCPPnPSolver estimateRT:betas:R:T:projectionError:]
  -[VCPPnPSolver estimatePose:]
  -[VCPPnPSolver initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:]
  -[VCPPnPSolver updateIntrinsic:vc:]
  -[VCPPnPSolver updateFocalLengthInPixels:]
  -[VCPPnPSolver estimateExtrinsicsWith:andPoints3D:andNumPoints:]


VCPSceneprintDescriptor : NSObject /usr/lib/libc++.1.dylib <VCPDistanceDescriptorProtocol>
  // class methods
  +[VCPSceneprintDescriptor usePHAssetData]
  +[VCPSceneprintDescriptor descriptorWithImage:]
  +[VCPSceneprintDescriptor descriptorWithData:]
  +[VCPSceneprintDescriptor preferredPixelFormat]

  // instance methods
  -[VCPSceneprintDescriptor serialize]
  -[VCPSceneprintDescriptor initWithImage:]
  -[VCPSceneprintDescriptor computeDistance:toDescriptor:]
  -[VCPSceneprintDescriptor .cxx_destruct]
  -[VCPSceneprintDescriptor initWithData:]


VCPSceneChangeAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPSceneChangeAnalyzer init]
  -[VCPSceneChangeAnalyzer results]
  -[VCPSceneChangeAnalyzer .cxx_construct]
  -[VCPSceneChangeAnalyzer .cxx_destruct]
  -[VCPSceneChangeAnalyzer ComputeSceneDelta:]
  -[VCPSceneChangeAnalyzer decideLensSwitchPoint:]
  -[VCPSceneChangeAnalyzer PrintSegments]
  -[VCPSceneChangeAnalyzer finalizeAnalysisPass:]
  -[VCPSceneChangeAnalyzer isSegmentPoint]
  -[VCPSceneChangeAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]


VCPSceneChangeSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames

  // instance methods
  -[VCPSceneChangeSegment init]
  -[VCPSceneChangeSegment timeRange]
  -[VCPSceneChangeSegment mergeSegment:]
  -[VCPSceneChangeSegment numOfFrames]
  -[VCPSceneChangeSegment updateSegment:]
  -[VCPSceneChangeSegment resetSegment:]
  -[VCPSceneChangeSegment finalizeAtTime:]


VCPVideoPixelStabilizer : VCPVideoStabilizer
  // instance methods
  -[VCPVideoPixelStabilizer init]
  -[VCPVideoPixelStabilizer dealloc]
  -[VCPVideoPixelStabilizer convertAnalysisResult]
  -[VCPVideoPixelStabilizer analyzeFrame:withTimestamp:andDuration:flags:]


VCPTaskProcessingService : NSObject /usr/lib/libc++.1.dylib <VCPTaskProcessingClientProtocol>
  // class methods
  +[VCPTaskProcessingService service]

  // instance methods
  -[VCPTaskProcessingService .cxx_destruct]
  -[VCPTaskProcessingService sandboxExtensionForURL:error:]
  -[VCPTaskProcessingService connection]
  -[VCPTaskProcessingService requestImageProcessingTask:forPixelBuffer:withOptions:andCompletionHandler:]
  -[VCPTaskProcessingService requestImageProcessingTask:forAssetURL:withOptions:andCompletionHandler:]


VCPVoiceOverAssetProcessingTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
  // class methods
  +[VCPVoiceOverAssetProcessingTask taskWithProcessingTypes:forPixelBuffer:withOptions:andCompletionHandler:]

  // instance methods
  -[VCPVoiceOverAssetProcessingTask run]
  -[VCPVoiceOverAssetProcessingTask .cxx_construct]
  -[VCPVoiceOverAssetProcessingTask dealloc]
  -[VCPVoiceOverAssetProcessingTask .cxx_destruct]
  -[VCPVoiceOverAssetProcessingTask resourceRequirement]
  -[VCPVoiceOverAssetProcessingTask cancel]
  -[VCPVoiceOverAssetProcessingTask initWithProcessingTypes:forPixelBuffer:withOptions:andCompletionHandler:]
  -[VCPVoiceOverAssetProcessingTask _analyzeFace:error:]
  -[VCPVoiceOverAssetProcessingTask _analyzeScene:error:]


VCPFaceShapeModel : NSObject /usr/lib/libc++.1.dylib
 @property  int processingMode
 @property  BOOL identityInit
 @property  * meshVertices
 @property  unsigned long vertexCount
 @property  int detectionModeCounterShapeModel

  // instance methods
  -[VCPFaceShapeModel initWithMode:]
  -[VCPFaceShapeModel vertexCount]
  -[VCPFaceShapeModel dealloc]
  -[VCPFaceShapeModel .cxx_destruct]
  -[VCPFaceShapeModel getPose]
  -[VCPFaceShapeModel setupModel:]
  -[VCPFaceShapeModel updateIntrinsic:vc:]
  -[VCPFaceShapeModel updateFocalLengthInPixels:]
  -[VCPFaceShapeModel getInternal3dLandmarksCoordinates:lm3dPos:]
  -[VCPFaceShapeModel getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:]
  -[VCPFaceShapeModel projectAndUpdateBoundary]
  -[VCPFaceShapeModel updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:]
  -[VCPFaceShapeModel project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:]
  -[VCPFaceShapeModel updateBoundaryLmForShapeOptimization]
  -[VCPFaceShapeModel moveBoundaryLandmarks:output:isInput:]
  -[VCPFaceShapeModel updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:]
  -[VCPFaceShapeModel optimizeProjectionMatrix:tracking:firstPass:]
  -[VCPFaceShapeModel updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:]
  -[VCPFaceShapeModel updateMeshAndLm3dAfterExpressionChange]
  -[VCPFaceShapeModel getPoseParam]
  -[VCPFaceShapeModel calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:]
  -[VCPFaceShapeModel calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:]
  -[VCPFaceShapeModel calculatePosePnpSolver:]
  -[VCPFaceShapeModel reestimateProjectionMatrixPnP]
  -[VCPFaceShapeModel updateIdentityShape:]
  -[VCPFaceShapeModel setCameraIntrinsics:uc:vc:]
  -[VCPFaceShapeModel getEulerAngle:]
  -[VCPFaceShapeModel resetIdentityAndExpressions]
  -[VCPFaceShapeModel trackFaceMesh:]
  -[VCPFaceShapeModel fitOneImage:]
  -[VCPFaceShapeModel blendShapes]
  -[VCPFaceShapeModel updateMeshVertices]
  -[VCPFaceShapeModel processingMode]
  -[VCPFaceShapeModel setProcessingMode:]
  -[VCPFaceShapeModel identityInit]
  -[VCPFaceShapeModel setIdentityInit:]
  -[VCPFaceShapeModel meshVertices]
  -[VCPFaceShapeModel detectionModeCounterShapeModel]
  -[VCPFaceShapeModel setDetectionModeCounterShapeModel:]


VCPMotionFlowSubtleMotionAnalyzer : VCPVideoAnalyzer
 @property  float subtleMotionScore

  // instance methods
  -[VCPMotionFlowSubtleMotionAnalyzer init]
  -[VCPMotionFlowSubtleMotionAnalyzer createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPMotionFlowSubtleMotionAnalyzer .cxx_construct]
  -[VCPMotionFlowSubtleMotionAnalyzer dealloc]
  -[VCPMotionFlowSubtleMotionAnalyzer .cxx_destruct]
  -[VCPMotionFlowSubtleMotionAnalyzer convertPixelBuffer:toPixelBuffer:withPixelFormat:]
  -[VCPMotionFlowSubtleMotionAnalyzer prepareAnalyzerWithCVPixelBuffer:]
  -[VCPMotionFlowSubtleMotionAnalyzer preProcessing:]
  -[VCPMotionFlowSubtleMotionAnalyzer generateMotionFlow]
  -[VCPMotionFlowSubtleMotionAnalyzer generateSubleMotionScore:]
  -[VCPMotionFlowSubtleMotionAnalyzer subtleMotionScore]
  -[VCPMotionFlowSubtleMotionAnalyzer analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:]


VCPVideoProcessorNode : NSObject /usr/lib/libc++.1.dylib
 @property  VNRequest *request
 @property  {?=qiIq} timeInterval
 @property  unsigned long frameInterval

  // class methods
  +[VCPVideoProcessorNode validateConfiguration:withError:]
  +[VCPVideoProcessorNode nodeWithRequest:andConfiguration:]

  // instance methods
  -[VCPVideoProcessorNode timeInterval]
  -[VCPVideoProcessorNode frameInterval]
  -[VCPVideoProcessorNode .cxx_destruct]
  -[VCPVideoProcessorNode initWithRequest:andConfiguration:]
  -[VCPVideoProcessorNode request]


VCPFaceTensorModel : NSObject /usr/lib/libc++.1.dylib
 @property  int numVertices
 @property  ^f meanBlendshape
 @property  ^f tensorCoeff
 @property  ^f componentsBlendshape
 @property  ^i blendshapeComponentIndex

  // instance methods
  -[VCPFaceTensorModel dealloc]
  -[VCPFaceTensorModel initWithModelFile:]
  -[VCPFaceTensorModel numVertices]
  -[VCPFaceTensorModel meanBlendshape]
  -[VCPFaceTensorModel componentsBlendshape]
  -[VCPFaceTensorModel calculateMesh:numVertices:blendshapes:outputMesh:]
  -[VCPFaceTensorModel tensorCoeff]
  -[VCPFaceTensorModel calculateModelBlendshapes:outputBlendshapes:]
  -[VCPFaceTensorModel blendshapeComponentIndex]


VCPVanishingPointDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVanishingPointDetector initWithImage:]
  -[VCPVanishingPointDetector detect:withConfidence:dominantLine:]
  -[VCPVanishingPointDetector dealloc]
  -[VCPVanishingPointDetector .cxx_destruct]
  -[VCPVanishingPointDetector prepareImage:]
  -[VCPVanishingPointDetector calculateOrientationResponses]
  -[VCPVanishingPointDetector generateOrientationMap]
  -[VCPVanishingPointDetector generateLineWeightMap:weightMap:]
  -[VCPVanishingPointDetector voteVanishingPoint:]
  -[VCPVanishingPointDetector searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:]
  -[VCPVanishingPointDetector extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:]
  -[VCPVanishingPointDetector averageOrientationResponses:withCurrentMap:]
  -[VCPVanishingPointDetector smoothFiltering:width:height:]
  -[VCPVanishingPointDetector calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:]
  -[VCPVanishingPointDetector isVerticalOrHorizontal:]


VCPActionAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPActionAnalyzer segments]
  -[VCPActionAnalyzer init]
  -[VCPActionAnalyzer dealloc]
  -[VCPActionAnalyzer .cxx_destruct]
  -[VCPActionAnalyzer isActive:]
  -[VCPActionAnalyzer isScoreValid:]
  -[VCPActionAnalyzer decideSegmentPointUsingHinkleyDetector:]
  -[VCPActionAnalyzer updateActiveThreshold]
  -[VCPActionAnalyzer mergeSameTypeSegments]
  -[VCPActionAnalyzer printSegments:]
  -[VCPActionAnalyzer prepareTrimmingWithTrimStart:andTrimEnd:]
  -[VCPActionAnalyzer mergeConsecutiveShortSegments]
  -[VCPActionAnalyzer mergeSparseShortSegments]
  -[VCPActionAnalyzer activeSegment]
  -[VCPActionAnalyzer analyzeFrameWithTimeRange:andActionScore:]
  -[VCPActionAnalyzer decideSegmentPointBasedOnActionScore:]
  -[VCPActionAnalyzer finalizeWithDestructiveTrimStart:trimEnd:]
  -[VCPActionAnalyzer postProcessSegmentsWithCaptureTime:trimStart:]


VCPAsset : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL isPano
 @property  BOOL isLivePhoto
 @property  BOOL isScreenshot
 @property  BOOL isHDR
 @property  BOOL isSDOF
 @property  NSDictionary *exif
 @property  BOOL hadFlash
 @property  float exposureTimeSeconds
 @property  float photoOffsetSeconds
 @property  float originalPhotoOffsetSeconds
 @property  BOOL isSlowmo
 @property  BOOL isTimelapse
 @property  double duration
 @property  float slowmoRate
 @property  float timelapseRate
 @property  long long mediaType
 @property  unsigned long mediaSubtypes
 @property  unsigned long pixelWidth
 @property  unsigned long pixelHeight
 @property  NSDate *modificationDate
 @property  VCPFingerprint *fingerprint
 @property  BOOL isImage
 @property  BOOL isMovie
 @property  NSString *localIdentifier
 @property  NSURL *mainFileURL
 @property  NSDictionary *scenes

  // class methods
  +[VCPAsset unimplementedExceptionForMethodName:]

  // instance methods
  -[VCPAsset scenes]
  -[VCPAsset pixelHeight]
  -[VCPAsset localIdentifier]
  -[VCPAsset mediaType]
  -[VCPAsset exif]
  -[VCPAsset movie]
  -[VCPAsset fingerprint]
  -[VCPAsset isPano]
  -[VCPAsset isImage]
  -[VCPAsset isMovie]
  -[VCPAsset isLivePhoto]
  -[VCPAsset mediaSubtypes]
  -[VCPAsset isTimelapse]
  -[VCPAsset isHDR]
  -[VCPAsset isSDOF]
  -[VCPAsset pixelWidth]
  -[VCPAsset mainFileURL]
  -[VCPAsset hadFlash]
  -[VCPAsset isSlowmo]
  -[VCPAsset slowmoRate]
  -[VCPAsset isScreenshot]
  -[VCPAsset imageWithPreferredDimension:]
  -[VCPAsset exposureTimeSeconds]
  -[VCPAsset photoOffsetSeconds]
  -[VCPAsset originalPhotoOffsetSeconds]
  -[VCPAsset timelapseRate]
  -[VCPAsset streamedMovie]
  -[VCPAsset originalMovie]
  -[VCPAsset originalMovieSize]
  -[VCPAsset modificationDate]
  -[VCPAsset duration]
  -[VCPAsset typeDescription]


VCPFaceGeometry : NSObject /usr/lib/libc++.1.dylib <NSSecureCoding>
 @property  unsigned long vertexCount
 @property  r^ vertices

  // class methods
  +[VCPFaceGeometry supportsSecureCoding]

  // instance methods
  -[VCPFaceGeometry vertexCount]
  -[VCPFaceGeometry dealloc]
  -[VCPFaceGeometry encodeWithCoder:]
  -[VCPFaceGeometry vertices]
  -[VCPFaceGeometry initWithVertices:vertexCount:]
  -[VCPFaceGeometry initWithCoder:]


VCPFaceAnchor : NSObject /usr/lib/libc++.1.dylib <NSSecureCoding>
 @property  {?=[4]} transform
 @property  NSDictionary *blendShapes
 @property  VCPFaceGeometry *geometry

  // class methods
  +[VCPFaceAnchor supportsSecureCoding]

  // instance methods
  -[VCPFaceAnchor geometry]
  -[VCPFaceAnchor .cxx_destruct]
  -[VCPFaceAnchor encodeWithCoder:]
  -[VCPFaceAnchor blendShapes]
  -[VCPFaceAnchor initWithTransform:blendShapes:geometry:]
  -[VCPFaceAnchor transform]
  -[VCPFaceAnchor initWithCoder:]


VCPCaptureAnalysisSession : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *aggregatedResults

  // class methods
  +[VCPCaptureAnalysisSession analyzerForAnalysisTypes:withPreferredTransform:properties:]
  +[VCPCaptureAnalysisSession aggregateAnalysisForTypes:withFramesMeta:properties:]

  // instance methods
  -[VCPCaptureAnalysisSession init]
  -[VCPCaptureAnalysisSession dealloc]
  -[VCPCaptureAnalysisSession .cxx_destruct]
  -[VCPCaptureAnalysisSession finalizeAnalysis]
  -[VCPCaptureAnalysisSession initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:]
  -[VCPCaptureAnalysisSession transformForAngle:pixelBuffer:]
  -[VCPCaptureAnalysisSession flipTransform:]
  -[VCPCaptureAnalysisSession rotateTransform:byAngle:]
  -[VCPCaptureAnalysisSession shouldCutAt:stillPTS:withCut:]
  -[VCPCaptureAnalysisSession analyzeFrameWithTimeRange:analysisData:]
  -[VCPCaptureAnalysisSession prewarmWithProperties:]
  -[VCPCaptureAnalysisSession updatePreferredTransform:properties:]
  -[VCPCaptureAnalysisSession analyzeAudioBuffer:]
  -[VCPCaptureAnalysisSession analyzePixelBuffer:withTimestamp:andDuration:properties:error:]
  -[VCPCaptureAnalysisSession analyzePixelBuffer:withTimestamp:andDuration:properties:completion:]
  -[VCPCaptureAnalysisSession aggregatedResults]


VCPClientDatabaseManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPClientDatabaseManager sharedDatabaseForPhotoLibrary:]
  +[VCPClientDatabaseManager sharedDatabaseManager]

  // instance methods
  -[VCPClientDatabaseManager init]
  -[VCPClientDatabaseManager .cxx_destruct]
  -[VCPClientDatabaseManager sharedDatabaseForPhotoLibrary:]


VCPContentAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPContentAnalysis contentAnalysis]

  // instance methods
  -[VCPContentAnalysis init]
  -[VCPContentAnalysis dealloc]
  -[VCPContentAnalysis .cxx_destruct]
  -[VCPContentAnalysis copyBlock:withStride:toBlock:]
  -[VCPContentAnalysis blockContentDetection:]
  -[VCPContentAnalysis detectPixelBuffer:contentType:]


VCPDefaultPhotoLibraryManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPDefaultPhotoLibraryManager sharedManager]

  // instance methods
  -[VCPDefaultPhotoLibraryManager init]
  -[VCPDefaultPhotoLibraryManager defaultPhotoLibrary]


VCPDownloadManager : NSObject /usr/lib/libc++.1.dylib
 @property  @? cancel

  // class methods
  +[VCPDownloadManager sharedManager]
  +[VCPDownloadManager _reportDownload:]
  +[VCPDownloadManager maxSizeBytes]

  // instance methods
  -[VCPDownloadManager init]
  -[VCPDownloadManager setCancel:]
  -[VCPDownloadManager flush]
  -[VCPDownloadManager .cxx_destruct]
  -[VCPDownloadManager cancel]
  -[VCPDownloadManager requestDownloadOfResource:]


VCPVoteStats : NSObject /usr/lib/libc++.1.dylib
 @property  long long votes
 @property  long long count

  // instance methods
  -[VCPVoteStats rate]
  -[VCPVoteStats setCount:]
  -[VCPVoteStats votes]
  -[VCPVoteStats count]
  -[VCPVoteStats setVotes:]
  -[VCPVoteStats initWithVotes:andCount:]


VCPFaceRecognitionTask : NSOperation /System/Library/PrivateFrameworks/FTServices.framework/FTServices
  // instance methods
  -[VCPFaceRecognitionTask init]
  -[VCPFaceRecognitionTask .cxx_destruct]
  -[VCPFaceRecognitionTask recognizeFaces:]
  -[VCPFaceRecognitionTask recognizeFace:]


VCPFullAnalysisURLProcessingTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
  // class methods
  +[VCPFullAnalysisURLProcessingTask taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:]

  // instance methods
  -[VCPFullAnalysisURLProcessingTask run]
  -[VCPFullAnalysisURLProcessingTask .cxx_destruct]
  -[VCPFullAnalysisURLProcessingTask resourceRequirement]
  -[VCPFullAnalysisURLProcessingTask cancel]
  -[VCPFullAnalysisURLProcessingTask initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:]


VCPFaceTimeFace : NSObject /usr/lib/libc++.1.dylib
 @property  VNFaceprint *faceprint

  // class methods
  +[VCPFaceTimeFace face]
  +[VCPFaceTimeFace faceFromManagedObject:]

  // instance methods
  -[VCPFaceTimeFace .cxx_destruct]
  -[VCPFaceTimeFace faceprint]
  -[VCPFaceTimeFace setFaceprint:]
  -[VCPFaceTimeFace managedObjectForContext:]


VCPProcessingStatusEntry : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long taskID
 @property  NSString *localIdentifier
 @property  unsigned long status
 @property  unsigned long attempts
 @property  NSDate *nextRetryDate

  // class methods
  +[VCPProcessingStatusEntry entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:]

  // instance methods
  -[VCPProcessingStatusEntry localIdentifier]
  -[VCPProcessingStatusEntry taskID]
  -[VCPProcessingStatusEntry .cxx_destruct]
  -[VCPProcessingStatusEntry attempts]
  -[VCPProcessingStatusEntry status]
  -[VCPProcessingStatusEntry nextRetryDate]
  -[VCPProcessingStatusEntry initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:]


VCPCNNFastGestureRecognition : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNFastGestureRecognition detector]

  // instance methods
  -[VCPCNNFastGestureRecognition init]
  -[VCPCNNFastGestureRecognition dealloc]
  -[VCPCNNFastGestureRecognition .cxx_destruct]
  -[VCPCNNFastGestureRecognition getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNFastGestureRecognition planDestroy]
  -[VCPCNNFastGestureRecognition createInput:keypoints:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNFastGestureRecognition getDetectionScore:]
  -[VCPCNNFastGestureRecognition gestureDetection:score:]


VCPProtoMovieSceneprintResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTime *timestamp
 @property  NSData *sceneprintBlob

  // class methods
  +[VCPProtoMovieSceneprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSceneprintResult copyWithZone:]
  -[VCPProtoMovieSceneprintResult exportToLegacyDictionary]
  -[VCPProtoMovieSceneprintResult .cxx_destruct]
  -[VCPProtoMovieSceneprintResult timestamp]
  -[VCPProtoMovieSceneprintResult setTimestamp:]
  -[VCPProtoMovieSceneprintResult readFrom:]
  -[VCPProtoMovieSceneprintResult writeTo:]
  -[VCPProtoMovieSceneprintResult isEqual:]
  -[VCPProtoMovieSceneprintResult copyTo:]
  -[VCPProtoMovieSceneprintResult dictionaryRepresentation]
  -[VCPProtoMovieSceneprintResult mergeFrom:]
  -[VCPProtoMovieSceneprintResult setSceneprintBlob:]
  -[VCPProtoMovieSceneprintResult sceneprintBlob]


VCPFaceTimePersistentStore : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceTimePersistentStore sharedInstance]

  // instance methods
  -[VCPFaceTimePersistentStore init]
  -[VCPFaceTimePersistentStore .cxx_destruct]
  -[VCPFaceTimePersistentStore fetchAllFaceTimeSessions]
  -[VCPFaceTimePersistentStore storeFaceTimeSession:]


VCPFaceTimeSession : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *sessionID
 @property  NSString *callerID
 @property  NSDate *date
 @property  NSArray *faces

  // class methods
  +[VCPFaceTimeSession session]
  +[VCPFaceTimeSession sessionFromManagedObject:]
  +[VCPFaceTimeSession createWithSessionID:callerID:andDate:]

  // instance methods
  -[VCPFaceTimeSession faces]
  -[VCPFaceTimeSession setSessionID:]
  -[VCPFaceTimeSession sessionID]
  -[VCPFaceTimeSession .cxx_destruct]
  -[VCPFaceTimeSession date]
  -[VCPFaceTimeSession setCallerID:]
  -[VCPFaceTimeSession setDate:]
  -[VCPFaceTimeSession addFace:]
  -[VCPFaceTimeSession callerID]
  -[VCPFaceTimeSession managedObjectForContext:]
  -[VCPFaceTimeSession initWithSessionID:callerID:andDate:]


VCPProtoMoviePetsResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMoviePetsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePetsResult copyWithZone:]
  -[VCPProtoMoviePetsResult setTimeRange:]
  -[VCPProtoMoviePetsResult exportToLegacyDictionary]
  -[VCPProtoMoviePetsResult setConfidence:]
  -[VCPProtoMoviePetsResult .cxx_destruct]
  -[VCPProtoMoviePetsResult timeRange]
  -[VCPProtoMoviePetsResult confidence]
  -[VCPProtoMoviePetsResult setBounds:]
  -[VCPProtoMoviePetsResult readFrom:]
  -[VCPProtoMoviePetsResult bounds]
  -[VCPProtoMoviePetsResult writeTo:]
  -[VCPProtoMoviePetsResult isEqual:]
  -[VCPProtoMoviePetsResult copyTo:]
  -[VCPProtoMoviePetsResult dictionaryRepresentation]
  -[VCPProtoMoviePetsResult mergeFrom:]


VCPFrameAnalysisStats : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL frameProcessedByVideoAnalyzer
 @property  float cameraMotionScore
 @property  float subjectActionScore
 @property  float interestingnessScore
 @property  float obstructionScore
 @property  float exposureScore
 @property  float colorfulnessScore
 @property  BOOL subMbMotionAvailable
 @property  float frameExpressionScore
 @property  float faceArea
 @property  BOOL frameProcessedByHumanAnalyzer
 @property  float humanPoseScore
 @property  float humanActionScore
 @property  BOOL frameProcessedByFaceDetector
 @property  NSMutableArray *detectedFaces
 @property  VCPVideoActivityDescriptor *videoActivityDescriptor

  // instance methods
  -[VCPFrameAnalysisStats exposureScore]
  -[VCPFrameAnalysisStats init]
  -[VCPFrameAnalysisStats setDetectedFaces:]
  -[VCPFrameAnalysisStats detectedFaces]
  -[VCPFrameAnalysisStats .cxx_destruct]
  -[VCPFrameAnalysisStats setExposureScore:]
  -[VCPFrameAnalysisStats humanActionScore]
  -[VCPFrameAnalysisStats humanPoseScore]
  -[VCPFrameAnalysisStats setHumanActionScore:]
  -[VCPFrameAnalysisStats setHumanPoseScore:]
  -[VCPFrameAnalysisStats reset]
  -[VCPFrameAnalysisStats faceArea]
  -[VCPFrameAnalysisStats setVideoActivityDescriptor:]
  -[VCPFrameAnalysisStats videoActivityDescriptor]
  -[VCPFrameAnalysisStats frameExpressionScore]
  -[VCPFrameAnalysisStats setFrameExpressionScore:]
  -[VCPFrameAnalysisStats setCameraMotionScore:]
  -[VCPFrameAnalysisStats setSubjectActionScore:]
  -[VCPFrameAnalysisStats setInterestingnessScore:]
  -[VCPFrameAnalysisStats setColorfulnessScore:]
  -[VCPFrameAnalysisStats setFrameProcessedByVideoAnalyzer:]
  -[VCPFrameAnalysisStats setSubMbMotionAvailable:]
  -[VCPFrameAnalysisStats interestingnessScore]
  -[VCPFrameAnalysisStats frameProcessedByVideoAnalyzer]
  -[VCPFrameAnalysisStats cameraMotionScore]
  -[VCPFrameAnalysisStats subjectActionScore]
  -[VCPFrameAnalysisStats colorfulnessScore]
  -[VCPFrameAnalysisStats subMbMotionAvailable]
  -[VCPFrameAnalysisStats setFaceArea:]
  -[VCPFrameAnalysisStats frameProcessedByHumanAnalyzer]
  -[VCPFrameAnalysisStats obstructionScore]
  -[VCPFrameAnalysisStats setObstructionScore:]
  -[VCPFrameAnalysisStats setFrameProcessedByHumanAnalyzer:]
  -[VCPFrameAnalysisStats frameProcessedByFaceDetector]
  -[VCPFrameAnalysisStats setFrameProcessedByFaceDetector:]


VCPHomeKitAnalysisService : NSObject /usr/lib/libc++.1.dylib <VCPHomeKitAnalysisClientProtocol>
  // class methods
  +[VCPHomeKitAnalysisService analysisService]

  // instance methods
  -[VCPHomeKitAnalysisService requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:]
  -[VCPHomeKitAnalysisService requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:]
  -[VCPHomeKitAnalysisService requestIdentificationForFaceCrop:withOptions:andCompletionHandler:]
  -[VCPHomeKitAnalysisService requestResidentMaintenanceWithOptions:andCompletionHandler:]
  -[VCPHomeKitAnalysisService init]
  -[VCPHomeKitAnalysisService .cxx_destruct]
  -[VCPHomeKitAnalysisService cancelAllRequests]
  -[VCPHomeKitAnalysisService connection]
  -[VCPHomeKitAnalysisService reportProgress:forRequest:]
  -[VCPHomeKitAnalysisService cancelRequest:]


VCPInMemoryAVAsset : AVURLAsset /System/Library/PrivateFrameworks/CMCapture.framework/CMCapture <AVAssetResourceLoaderDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPInMemoryAVAsset assetWithData:]

  // instance methods
  -[VCPInMemoryAVAsset .cxx_destruct]
  -[VCPInMemoryAVAsset initWithData:]
  -[VCPInMemoryAVAsset resourceLoader:shouldWaitForLoadingOfRequestedResource:]


VCPInternetReachability : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL hasWifiOrEthernetConnection

  // class methods
  +[VCPInternetReachability sharedInstance]

  // instance methods
  -[VCPInternetReachability setReachabilityForFlags:update:]
  -[VCPInternetReachability init]
  -[VCPInternetReachability dealloc]
  -[VCPInternetReachability .cxx_destruct]
  -[VCPInternetReachability hasWifiOrEthernetConnection]


VCPGeneralCanceller : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL canceled
 @property  @? updateBlock

  // class methods
  +[VCPGeneralCanceller cancelerWithUpdateBlock:]

  // instance methods
  -[VCPGeneralCanceller setCanceled:]
  -[VCPGeneralCanceller canceled]
  -[VCPGeneralCanceller .cxx_destruct]
  -[VCPGeneralCanceller updateBlock]
  -[VCPGeneralCanceller setUpdateBlock:]


VCPFaceCropSourceDescriptor : NSObject /usr/lib/libc++.1.dylib <NSCopying>
  // class methods
  +[VCPFaceCropSourceDescriptor descriptorForFace:image:]

  // instance methods
  -[VCPFaceCropSourceDescriptor face]
  -[VCPFaceCropSourceDescriptor copyWithZone:]
  -[VCPFaceCropSourceDescriptor initWithFace:image:]
  -[VCPFaceCropSourceDescriptor .cxx_destruct]
  -[VCPFaceCropSourceDescriptor image]


VCPFaceCropGenerator : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceCropGenerator _faceCropDataForImage:andNormalizedFaceRect:error:]
  +[VCPFaceCropGenerator _generateFaceCropWithDescriptor:andCancelBlock:error:]
  +[VCPFaceCropGenerator _reportCancellationOfRemainingFaceCropSourceDescriptors:withStartingIndex:andFailureBlock:]
  +[VCPFaceCropGenerator generateFaceCropsFromSourceDescriptors:withProgressBlock:andFailureBlock:andCancelBlock:]


VCPFaceCropManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceCropManager _allowANE]

  // instance methods
  -[VCPFaceCropManager _bestFaceForFaceDetectionRequest:withRect:]
  -[VCPFaceCropManager _faceFromFaceCrop:error:]
  -[VCPFaceCropManager _clearDirtyStateOnFaceCrops:error:]
  -[VCPFaceCropManager _associateFace:withFaceCrop:error:]
  -[VCPFaceCropManager _updateFaceprint:ofPersistedFace:error:]
  -[VCPFaceCropManager _faceAssociatedWithFaceCrop:]
  -[VCPFaceCropManager _generateAndAssociateFaceprintedFaceForFaceCrop:error:]
  -[VCPFaceCropManager _updateFace:withFaceCrop:error:]
  -[VCPFaceCropManager _recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
  -[VCPFaceCropManager _pvFaceCropFromPHFaceCrop:]
  -[VCPFaceCropManager _persistGeneratedFaceCrops:forAsset:error:]
  -[VCPFaceCropManager _processDirtyFaceCrop:error:]
  -[VCPFaceCropManager initWithPhotoLibrary:andContext:]
  -[VCPFaceCropManager _persistFaceAnalysis:forPHAsset:]
  -[VCPFaceCropManager generateAndPersistFaceCropsForFaces:withAsset:andImage:error:]
  -[VCPFaceCropManager processDirtyFaceCropsWithCancelBlock:andExtendTimeoutBlock:]
  -[VCPFaceCropManager .cxx_destruct]
  -[VCPFaceCropManager _configureRequest:withRevision:]


VCPPhotosAsset : VCPAsset
 @property  NSArray *resources

  // class methods
  +[VCPPhotosAsset assetWithPHAsset:]

  // instance methods
  -[VCPPhotosAsset scenes]
  -[VCPPhotosAsset pixelHeight]
  -[VCPPhotosAsset localIdentifier]
  -[VCPPhotosAsset mediaType]
  -[VCPPhotosAsset exif]
  -[VCPPhotosAsset movie]
  -[VCPPhotosAsset resources]
  -[VCPPhotosAsset fingerprint]
  -[VCPPhotosAsset .cxx_destruct]
  -[VCPPhotosAsset mediaSubtypes]
  -[VCPPhotosAsset initWithPHAsset:]
  -[VCPPhotosAsset pixelWidth]
  -[VCPPhotosAsset mainFileURL]
  -[VCPPhotosAsset slowmoRate]
  -[VCPPhotosAsset imageWithPreferredDimension:]
  -[VCPPhotosAsset photoOffsetSeconds]
  -[VCPPhotosAsset originalPhotoOffsetSeconds]
  -[VCPPhotosAsset streamedMovie]
  -[VCPPhotosAsset originalMovie]
  -[VCPPhotosAsset originalMovieSize]
  -[VCPPhotosAsset modificationDate]
  -[VCPPhotosAsset duration]


VCPPriorityAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPPriorityAnalysis priorityAnalysis]

  // instance methods
  -[VCPPriorityAnalysis init]
  -[VCPPriorityAnalysis normalizeKeypoints:handCenter:]
  -[VCPPriorityAnalysis computeMaxMinDistance:prevFrameKeypoints:]
  -[VCPPriorityAnalysis maxPooling:]
  -[VCPPriorityAnalysis fastSignLanguageDetection:ofPixelBuffer:withMetadata:]
  -[VCPPriorityAnalysis majorityVoting:numClass:]
  -[VCPPriorityAnalysis minPooling:]
  -[VCPPriorityAnalysis computeIOU:boxB:]
  -[VCPPriorityAnalysis calculatePriorityScore:ofPixelBuffer:withMetadata:]
  -[VCPPriorityAnalysis dealloc]
  -[VCPPriorityAnalysis .cxx_destruct]


VCPProtoAssetAnalysis : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  unsigned int version
 @property  unsigned int types
 @property  unsigned int flags
 @property  double date
 @property  BOOL hasQuality
 @property  double quality
 @property  BOOL hasStatsFlags
 @property  unsigned long statsFlags
 @property  BOOL hasTypesWide
 @property  unsigned long typesWide
 @property  NSString *assetIdentifier
 @property  double assetModificationDate
 @property  NSString *assetMasterFingerprint
 @property  BOOL hasAssetAdjustedFingerprint
 @property  NSString *assetAdjustedFingerprint
 @property  NSMutableArray *imageBlurResults
 @property  NSMutableArray *imageCompositionResults
 @property  NSMutableArray *imageFaceResults
 @property  NSMutableArray *imageFeatureResults
 @property  NSMutableArray *imageJunkResults
 @property  NSMutableArray *imageSaliencyResults
 @property  NSMutableArray *imageShotTypeResults
 @property  NSMutableArray *imagePetsResults
 @property  NSMutableArray *imagePetsFaceResults
 @property  NSMutableArray *imageSceneprintResults
 @property  NSMutableArray *livePhotoEffectsResults
 @property  NSMutableArray *livePhotoRecommendationResults
 @property  NSMutableArray *livePhotoSharpnessResults
 @property  NSMutableArray *livePhotoKeyFrameResults
 @property  NSMutableArray *livePhotoKeyFrameStillResults
 @property  NSMutableArray *movieActivityLevelResults
 @property  NSMutableArray *movieCameraMotionResults
 @property  NSMutableArray *movieClassificationResults
 @property  NSMutableArray *movieFaceResults
 @property  NSMutableArray *movieFaceprintResults
 @property  NSMutableArray *movieFeatureResults
 @property  NSMutableArray *movieFineSubjectMotionResults
 @property  NSMutableArray *movieInterestingnessResults
 @property  NSMutableArray *movieMovingObjectResults
 @property  NSMutableArray *movieMusicResults
 @property  NSMutableArray *movieObstructionResults
 @property  NSMutableArray *movieOrientationResults
 @property  NSMutableArray *moviePreEncodeResults
 @property  NSMutableArray *movieQualityResults
 @property  NSMutableArray *movieSaliencyResults
 @property  NSMutableArray *movieSceneResults
 @property  NSMutableArray *movieSceneprintResults
 @property  NSMutableArray *movieSubjectMotionResults
 @property  NSMutableArray *movieSubtleMotionResults
 @property  NSMutableArray *movieUtteranceResults
 @property  NSMutableArray *movieVoiceResults
 @property  NSMutableArray *movieSummaryResults
 @property  NSMutableArray *movieHighlightResults
 @property  NSMutableArray *imageExposureResults
 @property  NSMutableArray *imageHumanPoseResults
 @property  NSMutableArray *movieHumanPoseResults
 @property  NSMutableArray *movieApplauseResults
 @property  NSMutableArray *movieBabbleResults
 @property  NSMutableArray *movieCheeringResults
 @property  NSMutableArray *movieLaughterResults
 @property  NSMutableArray *movieHumanActionResults
 @property  NSMutableArray *movieLoudnessResults
 @property  NSMutableArray *moviePetsResults
 @property  NSMutableArray *moviePetsFaceResults
 @property  NSMutableArray *movieStabilizationResults

  // class methods
  +[VCPProtoAssetAnalysis imageBlurResultsType]
  +[VCPProtoAssetAnalysis imageFaceResultsType]
  +[VCPProtoAssetAnalysis imageCompositionResultsType]
  +[VCPProtoAssetAnalysis imageFeatureResultsType]
  +[VCPProtoAssetAnalysis imageJunkResultsType]
  +[VCPProtoAssetAnalysis imageSaliencyResultsType]
  +[VCPProtoAssetAnalysis imageShotTypeResultsType]
  +[VCPProtoAssetAnalysis imagePetsResultsType]
  +[VCPProtoAssetAnalysis imagePetsFaceResultsType]
  +[VCPProtoAssetAnalysis imageSceneprintResultsType]
  +[VCPProtoAssetAnalysis livePhotoEffectsResultsType]
  +[VCPProtoAssetAnalysis movieFaceResultsType]
  +[VCPProtoAssetAnalysis livePhotoRecommendationResultsType]
  +[VCPProtoAssetAnalysis livePhotoSharpnessResultsType]
  +[VCPProtoAssetAnalysis livePhotoKeyFrameResultsType]
  +[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsType]
  +[VCPProtoAssetAnalysis movieActivityLevelResultsType]
  +[VCPProtoAssetAnalysis movieCameraMotionResultsType]
  +[VCPProtoAssetAnalysis movieClassificationResultsType]
  +[VCPProtoAssetAnalysis movieFaceprintResultsType]
  +[VCPProtoAssetAnalysis movieFeatureResultsType]
  +[VCPProtoAssetAnalysis movieFineSubjectMotionResultsType]
  +[VCPProtoAssetAnalysis movieInterestingnessResultsType]
  +[VCPProtoAssetAnalysis movieMovingObjectResultsType]
  +[VCPProtoAssetAnalysis movieMusicResultsType]
  +[VCPProtoAssetAnalysis movieObstructionResultsType]
  +[VCPProtoAssetAnalysis movieOrientationResultsType]
  +[VCPProtoAssetAnalysis moviePreEncodeResultsType]
  +[VCPProtoAssetAnalysis movieSceneResultsType]
  +[VCPProtoAssetAnalysis movieQualityResultsType]
  +[VCPProtoAssetAnalysis movieSaliencyResultsType]
  +[VCPProtoAssetAnalysis movieSceneprintResultsType]
  +[VCPProtoAssetAnalysis movieSubjectMotionResultsType]
  +[VCPProtoAssetAnalysis movieSubtleMotionResultsType]
  +[VCPProtoAssetAnalysis movieUtteranceResultsType]
  +[VCPProtoAssetAnalysis movieVoiceResultsType]
  +[VCPProtoAssetAnalysis movieSummaryResultsType]
  +[VCPProtoAssetAnalysis movieHighlightResultsType]
  +[VCPProtoAssetAnalysis imageExposureResultsType]
  +[VCPProtoAssetAnalysis imageHumanPoseResultsType]
  +[VCPProtoAssetAnalysis movieHumanPoseResultsType]
  +[VCPProtoAssetAnalysis movieApplauseResultsType]
  +[VCPProtoAssetAnalysis movieBabbleResultsType]
  +[VCPProtoAssetAnalysis movieCheeringResultsType]
  +[VCPProtoAssetAnalysis movieLaughterResultsType]
  +[VCPProtoAssetAnalysis movieHumanActionResultsType]
  +[VCPProtoAssetAnalysis movieLoudnessResultsType]
  +[VCPProtoAssetAnalysis moviePetsResultsType]
  +[VCPProtoAssetAnalysis moviePetsFaceResultsType]
  +[VCPProtoAssetAnalysis movieStabilizationResultsType]
  +[VCPProtoAssetAnalysis imageAnalysisFromLegacyDictionary:]
  +[VCPProtoAssetAnalysis movieAnalysisFromLegacyDictionary:]

  // instance methods
  -[VCPProtoAssetAnalysis setTypes:]
  -[VCPProtoAssetAnalysis copyWithZone:]
  -[VCPProtoAssetAnalysis types]
  -[VCPProtoAssetAnalysis hasQuality]
  -[VCPProtoAssetAnalysis statsFlags]
  -[VCPProtoAssetAnalysis typesWide]
  -[VCPProtoAssetAnalysis addImageBlurResults:]
  -[VCPProtoAssetAnalysis addImageCompositionResults:]
  -[VCPProtoAssetAnalysis addImageFaceResults:]
  -[VCPProtoAssetAnalysis addImageFeatureResults:]
  -[VCPProtoAssetAnalysis addImageJunkResults:]
  -[VCPProtoAssetAnalysis addImageSaliencyResults:]
  -[VCPProtoAssetAnalysis addImageShotTypeResults:]
  -[VCPProtoAssetAnalysis addLivePhotoRecommendationResults:]
  -[VCPProtoAssetAnalysis addLivePhotoSharpnessResults:]
  -[VCPProtoAssetAnalysis setHasQuality:]
  -[VCPProtoAssetAnalysis addMovieActivityLevelResults:]
  -[VCPProtoAssetAnalysis addMovieCameraMotionResults:]
  -[VCPProtoAssetAnalysis addMovieClassificationResults:]
  -[VCPProtoAssetAnalysis addMovieFaceResults:]
  -[VCPProtoAssetAnalysis addMovieFaceprintResults:]
  -[VCPProtoAssetAnalysis addMovieFeatureResults:]
  -[VCPProtoAssetAnalysis addMovieFineSubjectMotionResults:]
  -[VCPProtoAssetAnalysis addMovieInterestingnessResults:]
  -[VCPProtoAssetAnalysis setHasStatsFlags:]
  -[VCPProtoAssetAnalysis addMovieMovingObjectResults:]
  -[VCPProtoAssetAnalysis addMovieMusicResults:]
  -[VCPProtoAssetAnalysis addMovieObstructionResults:]
  -[VCPProtoAssetAnalysis addMovieOrientationResults:]
  -[VCPProtoAssetAnalysis addMoviePreEncodeResults:]
  -[VCPProtoAssetAnalysis addMovieQualityResults:]
  -[VCPProtoAssetAnalysis addMovieSaliencyResults:]
  -[VCPProtoAssetAnalysis addMovieSceneResults:]
  -[VCPProtoAssetAnalysis addMovieSubjectMotionResults:]
  -[VCPProtoAssetAnalysis addMovieUtteranceResults:]
  -[VCPProtoAssetAnalysis addMovieVoiceResults:]
  -[VCPProtoAssetAnalysis addImagePetsResults:]
  -[VCPProtoAssetAnalysis addMovieSummaryResults:]
  -[VCPProtoAssetAnalysis addMovieHighlightResults:]
  -[VCPProtoAssetAnalysis addImageExposureResults:]
  -[VCPProtoAssetAnalysis addLivePhotoEffectsResults:]
  -[VCPProtoAssetAnalysis addImagePetsFaceResults:]
  -[VCPProtoAssetAnalysis addImageSceneprintResults:]
  -[VCPProtoAssetAnalysis addMoviePetsResults:]
  -[VCPProtoAssetAnalysis addMovieSceneprintResults:]
  -[VCPProtoAssetAnalysis addImageHumanPoseResults:]
  -[VCPProtoAssetAnalysis addMovieHumanPoseResults:]
  -[VCPProtoAssetAnalysis addMovieApplauseResults:]
  -[VCPProtoAssetAnalysis addMovieBabbleResults:]
  -[VCPProtoAssetAnalysis addMovieCheeringResults:]
  -[VCPProtoAssetAnalysis addMovieLaughterResults:]
  -[VCPProtoAssetAnalysis addLivePhotoKeyFrameResults:]
  -[VCPProtoAssetAnalysis addLivePhotoKeyFrameStillResults:]
  -[VCPProtoAssetAnalysis setQuality:]
  -[VCPProtoAssetAnalysis addMovieHumanActionResults:]
  -[VCPProtoAssetAnalysis addMovieSubtleMotionResults:]
  -[VCPProtoAssetAnalysis addMovieLoudnessResults:]
  -[VCPProtoAssetAnalysis addMoviePetsFaceResults:]
  -[VCPProtoAssetAnalysis addMovieStabilizationResults:]
  -[VCPProtoAssetAnalysis setAssetMasterFingerprint:]
  -[VCPProtoAssetAnalysis setAssetAdjustedFingerprint:]
  -[VCPProtoAssetAnalysis imageBlurResultsCount]
  -[VCPProtoAssetAnalysis clearImageBlurResults]
  -[VCPProtoAssetAnalysis imageBlurResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageCompositionResultsCount]
  -[VCPProtoAssetAnalysis clearImageCompositionResults]
  -[VCPProtoAssetAnalysis imageCompositionResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageFaceResultsCount]
  -[VCPProtoAssetAnalysis clearImageFaceResults]
  -[VCPProtoAssetAnalysis imageFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageFeatureResultsCount]
  -[VCPProtoAssetAnalysis clearImageFeatureResults]
  -[VCPProtoAssetAnalysis exportToLegacyDictionary]
  -[VCPProtoAssetAnalysis imageFeatureResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageJunkResultsCount]
  -[VCPProtoAssetAnalysis clearImageJunkResults]
  -[VCPProtoAssetAnalysis imageJunkResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageSaliencyResultsCount]
  -[VCPProtoAssetAnalysis clearImageSaliencyResults]
  -[VCPProtoAssetAnalysis imageSaliencyResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageShotTypeResultsCount]
  -[VCPProtoAssetAnalysis clearImageShotTypeResults]
  -[VCPProtoAssetAnalysis setStatsFlags:]
  -[VCPProtoAssetAnalysis setFlags:]
  -[VCPProtoAssetAnalysis imageShotTypeResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoRecommendationResults]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoSharpnessResults]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieActivityLevelResultsCount]
  -[VCPProtoAssetAnalysis clearMovieActivityLevelResults]
  -[VCPProtoAssetAnalysis movieActivityLevelResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieCameraMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieCameraMotionResults]
  -[VCPProtoAssetAnalysis movieCameraMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieClassificationResultsCount]
  -[VCPProtoAssetAnalysis movieFaceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieClassificationResults]
  -[VCPProtoAssetAnalysis movieClassificationResultsAtIndex:]
  -[VCPProtoAssetAnalysis clearMovieFaceResults]
  -[VCPProtoAssetAnalysis movieFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFaceprintResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFaceprintResults]
  -[VCPProtoAssetAnalysis movieFaceprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFeatureResultsCount]
  -[VCPProtoAssetAnalysis imagePetsResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFeatureResults]
  -[VCPProtoAssetAnalysis movieFeatureResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFineSubjectMotionResults]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieInterestingnessResultsCount]
  -[VCPProtoAssetAnalysis clearMovieInterestingnessResults]
  -[VCPProtoAssetAnalysis imageBlurResults]
  -[VCPProtoAssetAnalysis movieInterestingnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieMovingObjectResultsCount]
  -[VCPProtoAssetAnalysis clearMovieMovingObjectResults]
  -[VCPProtoAssetAnalysis movieMovingObjectResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieMusicResultsCount]
  -[VCPProtoAssetAnalysis clearMovieMusicResults]
  -[VCPProtoAssetAnalysis movieMusicResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieObstructionResultsCount]
  -[VCPProtoAssetAnalysis setTypesWide:]
  -[VCPProtoAssetAnalysis clearMovieObstructionResults]
  -[VCPProtoAssetAnalysis movieObstructionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieOrientationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieOrientationResults]
  -[VCPProtoAssetAnalysis movieOrientationResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePreEncodeResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePreEncodeResults]
  -[VCPProtoAssetAnalysis moviePreEncodeResultsAtIndex:]
  -[VCPProtoAssetAnalysis .cxx_destruct]
  -[VCPProtoAssetAnalysis movieQualityResultsCount]
  -[VCPProtoAssetAnalysis clearMovieQualityResults]
  -[VCPProtoAssetAnalysis movieQualityResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSaliencyResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSaliencyResults]
  -[VCPProtoAssetAnalysis movieSaliencyResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSceneResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSceneResults]
  -[VCPProtoAssetAnalysis movieSceneResultsAtIndex:]
  -[VCPProtoAssetAnalysis hasStatsFlags]
  -[VCPProtoAssetAnalysis movieSubjectMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSubjectMotionResults]
  -[VCPProtoAssetAnalysis movieSubjectMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieUtteranceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieUtteranceResults]
  -[VCPProtoAssetAnalysis movieUtteranceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieVoiceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieVoiceResults]
  -[VCPProtoAssetAnalysis imageFaceResults]
  -[VCPProtoAssetAnalysis movieVoiceResultsAtIndex:]
  -[VCPProtoAssetAnalysis clearImagePetsResults]
  -[VCPProtoAssetAnalysis imagePetsResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSummaryResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSummaryResults]
  -[VCPProtoAssetAnalysis movieSummaryResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHighlightResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHighlightResults]
  -[VCPProtoAssetAnalysis movieHighlightResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageExposureResultsCount]
  -[VCPProtoAssetAnalysis clearImageExposureResults]
  -[VCPProtoAssetAnalysis imageExposureResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoEffectsResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoEffectsResults]
  -[VCPProtoAssetAnalysis livePhotoEffectsResultsAtIndex:]
  -[VCPProtoAssetAnalysis imagePetsFaceResultsCount]
  -[VCPProtoAssetAnalysis clearImagePetsFaceResults]
  -[VCPProtoAssetAnalysis moviePetsResultsCount]
  -[VCPProtoAssetAnalysis date]
  -[VCPProtoAssetAnalysis setDate:]
  -[VCPProtoAssetAnalysis imagePetsFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageSceneprintResultsCount]
  -[VCPProtoAssetAnalysis clearImageSceneprintResults]
  -[VCPProtoAssetAnalysis imageSceneprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSceneprintResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSceneprintResults]
  -[VCPProtoAssetAnalysis movieSceneprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageHumanPoseResultsCount]
  -[VCPProtoAssetAnalysis hasTypesWide]
  -[VCPProtoAssetAnalysis clearImageHumanPoseResults]
  -[VCPProtoAssetAnalysis imageHumanPoseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHumanPoseResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHumanPoseResults]
  -[VCPProtoAssetAnalysis movieHumanPoseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieApplauseResultsCount]
  -[VCPProtoAssetAnalysis clearMovieApplauseResults]
  -[VCPProtoAssetAnalysis movieApplauseResultsAtIndex:]
  -[VCPProtoAssetAnalysis clearMoviePetsResults]
  -[VCPProtoAssetAnalysis movieBabbleResultsCount]
  -[VCPProtoAssetAnalysis clearMovieBabbleResults]
  -[VCPProtoAssetAnalysis movieBabbleResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieCheeringResultsCount]
  -[VCPProtoAssetAnalysis clearMovieCheeringResults]
  -[VCPProtoAssetAnalysis movieCheeringResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieLaughterResultsCount]
  -[VCPProtoAssetAnalysis clearMovieLaughterResults]
  -[VCPProtoAssetAnalysis movieLaughterResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoKeyFrameResults]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoKeyFrameStillResults]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHumanActionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHumanActionResults]
  -[VCPProtoAssetAnalysis movieHumanActionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSubtleMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSubtleMotionResults]
  -[VCPProtoAssetAnalysis movieSubtleMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieLoudnessResultsCount]
  -[VCPProtoAssetAnalysis clearMovieLoudnessResults]
  -[VCPProtoAssetAnalysis movieLoudnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePetsResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePetsFaceResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePetsFaceResults]
  -[VCPProtoAssetAnalysis moviePetsFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieStabilizationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieStabilizationResults]
  -[VCPProtoAssetAnalysis movieStabilizationResultsAtIndex:]
  -[VCPProtoAssetAnalysis quality]
  -[VCPProtoAssetAnalysis setVersion:]
  -[VCPProtoAssetAnalysis setHasTypesWide:]
  -[VCPProtoAssetAnalysis hasAssetAdjustedFingerprint]
  -[VCPProtoAssetAnalysis assetModificationDate]
  -[VCPProtoAssetAnalysis setAssetModificationDate:]
  -[VCPProtoAssetAnalysis assetMasterFingerprint]
  -[VCPProtoAssetAnalysis assetAdjustedFingerprint]
  -[VCPProtoAssetAnalysis setImageBlurResults:]
  -[VCPProtoAssetAnalysis imageCompositionResults]
  -[VCPProtoAssetAnalysis setImageCompositionResults:]
  -[VCPProtoAssetAnalysis setImageFaceResults:]
  -[VCPProtoAssetAnalysis imageFeatureResults]
  -[VCPProtoAssetAnalysis setImageFeatureResults:]
  -[VCPProtoAssetAnalysis imageJunkResults]
  -[VCPProtoAssetAnalysis setImageJunkResults:]
  -[VCPProtoAssetAnalysis imageSaliencyResults]
  -[VCPProtoAssetAnalysis setImageSaliencyResults:]
  -[VCPProtoAssetAnalysis imageShotTypeResults]
  -[VCPProtoAssetAnalysis setImageShotTypeResults:]
  -[VCPProtoAssetAnalysis imagePetsResults]
  -[VCPProtoAssetAnalysis setImagePetsResults:]
  -[VCPProtoAssetAnalysis imagePetsFaceResults]
  -[VCPProtoAssetAnalysis setImagePetsFaceResults:]
  -[VCPProtoAssetAnalysis imageSceneprintResults]
  -[VCPProtoAssetAnalysis setImageSceneprintResults:]
  -[VCPProtoAssetAnalysis livePhotoEffectsResults]
  -[VCPProtoAssetAnalysis setLivePhotoEffectsResults:]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResults]
  -[VCPProtoAssetAnalysis setLivePhotoRecommendationResults:]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResults]
  -[VCPProtoAssetAnalysis setLivePhotoSharpnessResults:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResults]
  -[VCPProtoAssetAnalysis setLivePhotoKeyFrameResults:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResults]
  -[VCPProtoAssetAnalysis setLivePhotoKeyFrameStillResults:]
  -[VCPProtoAssetAnalysis movieActivityLevelResults]
  -[VCPProtoAssetAnalysis setMovieActivityLevelResults:]
  -[VCPProtoAssetAnalysis movieCameraMotionResults]
  -[VCPProtoAssetAnalysis setMovieCameraMotionResults:]
  -[VCPProtoAssetAnalysis movieClassificationResults]
  -[VCPProtoAssetAnalysis setMovieClassificationResults:]
  -[VCPProtoAssetAnalysis movieFaceResults]
  -[VCPProtoAssetAnalysis setMovieFaceResults:]
  -[VCPProtoAssetAnalysis movieFaceprintResults]
  -[VCPProtoAssetAnalysis setMovieFaceprintResults:]
  -[VCPProtoAssetAnalysis movieFeatureResults]
  -[VCPProtoAssetAnalysis setMovieFeatureResults:]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResults]
  -[VCPProtoAssetAnalysis setMovieFineSubjectMotionResults:]
  -[VCPProtoAssetAnalysis movieInterestingnessResults]
  -[VCPProtoAssetAnalysis setMovieInterestingnessResults:]
  -[VCPProtoAssetAnalysis movieMovingObjectResults]
  -[VCPProtoAssetAnalysis setMovieMovingObjectResults:]
  -[VCPProtoAssetAnalysis movieMusicResults]
  -[VCPProtoAssetAnalysis setMovieMusicResults:]
  -[VCPProtoAssetAnalysis movieObstructionResults]
  -[VCPProtoAssetAnalysis setMovieObstructionResults:]
  -[VCPProtoAssetAnalysis movieOrientationResults]
  -[VCPProtoAssetAnalysis setMovieOrientationResults:]
  -[VCPProtoAssetAnalysis moviePreEncodeResults]
  -[VCPProtoAssetAnalysis setMoviePreEncodeResults:]
  -[VCPProtoAssetAnalysis movieQualityResults]
  -[VCPProtoAssetAnalysis setMovieQualityResults:]
  -[VCPProtoAssetAnalysis movieSaliencyResults]
  -[VCPProtoAssetAnalysis setMovieSaliencyResults:]
  -[VCPProtoAssetAnalysis movieSceneResults]
  -[VCPProtoAssetAnalysis setMovieSceneResults:]
  -[VCPProtoAssetAnalysis movieSceneprintResults]
  -[VCPProtoAssetAnalysis setMovieSceneprintResults:]
  -[VCPProtoAssetAnalysis movieSubjectMotionResults]
  -[VCPProtoAssetAnalysis setMovieSubjectMotionResults:]
  -[VCPProtoAssetAnalysis movieSubtleMotionResults]
  -[VCPProtoAssetAnalysis setMovieSubtleMotionResults:]
  -[VCPProtoAssetAnalysis movieUtteranceResults]
  -[VCPProtoAssetAnalysis setMovieUtteranceResults:]
  -[VCPProtoAssetAnalysis movieVoiceResults]
  -[VCPProtoAssetAnalysis setMovieVoiceResults:]
  -[VCPProtoAssetAnalysis movieSummaryResults]
  -[VCPProtoAssetAnalysis setMovieSummaryResults:]
  -[VCPProtoAssetAnalysis movieHighlightResults]
  -[VCPProtoAssetAnalysis setMovieHighlightResults:]
  -[VCPProtoAssetAnalysis imageExposureResults]
  -[VCPProtoAssetAnalysis setImageExposureResults:]
  -[VCPProtoAssetAnalysis imageHumanPoseResults]
  -[VCPProtoAssetAnalysis setImageHumanPoseResults:]
  -[VCPProtoAssetAnalysis movieBabbleResults]
  -[VCPProtoAssetAnalysis movieHumanPoseResults]
  -[VCPProtoAssetAnalysis setMovieHumanPoseResults:]
  -[VCPProtoAssetAnalysis movieApplauseResults]
  -[VCPProtoAssetAnalysis setMovieApplauseResults:]
  -[VCPProtoAssetAnalysis setMovieBabbleResults:]
  -[VCPProtoAssetAnalysis movieCheeringResults]
  -[VCPProtoAssetAnalysis setMovieCheeringResults:]
  -[VCPProtoAssetAnalysis movieLaughterResults]
  -[VCPProtoAssetAnalysis setMovieLaughterResults:]
  -[VCPProtoAssetAnalysis movieHumanActionResults]
  -[VCPProtoAssetAnalysis setMovieHumanActionResults:]
  -[VCPProtoAssetAnalysis movieLoudnessResults]
  -[VCPProtoAssetAnalysis setMovieLoudnessResults:]
  -[VCPProtoAssetAnalysis moviePetsResults]
  -[VCPProtoAssetAnalysis setMoviePetsResults:]
  -[VCPProtoAssetAnalysis moviePetsFaceResults]
  -[VCPProtoAssetAnalysis setMoviePetsFaceResults:]
  -[VCPProtoAssetAnalysis movieStabilizationResults]
  -[VCPProtoAssetAnalysis setMovieStabilizationResults:]
  -[VCPProtoAssetAnalysis setAttributesFromLegacyDictionary:]
  -[VCPProtoAssetAnalysis setResults:withClass:forPropertyKey:]
  -[VCPProtoAssetAnalysis exportResultsWithPropertyKey:toLegacyDictionary:withKey:]
  -[VCPProtoAssetAnalysis readFrom:]
  -[VCPProtoAssetAnalysis writeTo:]
  -[VCPProtoAssetAnalysis isEqual:]
  -[VCPProtoAssetAnalysis version]
  -[VCPProtoAssetAnalysis flags]
  -[VCPProtoAssetAnalysis copyTo:]
  -[VCPProtoAssetAnalysis dictionaryRepresentation]
  -[VCPProtoAssetAnalysis mergeFrom:]
  -[VCPProtoAssetAnalysis assetIdentifier]
  -[VCPProtoAssetAnalysis setAssetIdentifier:]


VCPProtoBounds : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  double x0
 @property  double y0
 @property  double width
 @property  double height

  // class methods
  +[VCPProtoBounds boundsWithCGRect:]

  // instance methods
  -[VCPProtoBounds x0]
  -[VCPProtoBounds y0]
  -[VCPProtoBounds setHeight:]
  -[VCPProtoBounds copyWithZone:]
  -[VCPProtoBounds rectValue]
  -[VCPProtoBounds setX0:]
  -[VCPProtoBounds setY0:]
  -[VCPProtoBounds setWidth:]
  -[VCPProtoBounds width]
  -[VCPProtoBounds readFrom:]
  -[VCPProtoBounds height]
  -[VCPProtoBounds writeTo:]
  -[VCPProtoBounds isEqual:]
  -[VCPProtoBounds copyTo:]
  -[VCPProtoBounds dictionaryRepresentation]
  -[VCPProtoBounds mergeFrom:]


VCPImageMotionFlowAnalyzer : VCPImageAnalyzer
  // class methods
  +[VCPImageMotionFlowAnalyzer sharedModel:inputNames:]

  // instance methods
  -[VCPImageMotionFlowAnalyzer init]
  -[VCPImageMotionFlowAnalyzer creatModel]
  -[VCPImageMotionFlowAnalyzer .cxx_construct]
  -[VCPImageMotionFlowAnalyzer dealloc]
  -[VCPImageMotionFlowAnalyzer .cxx_destruct]
  -[VCPImageMotionFlowAnalyzer prepareModelWithAspectRatio:]
  -[VCPImageMotionFlowAnalyzer createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPImageMotionFlowAnalyzer copyImage:toData:withChannels:]
  -[VCPImageMotionFlowAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageMotionFlowAnalyzer analyzeImages:secondImage:cancel:]
  -[VCPImageMotionFlowAnalyzer getFlowWithHeight:andWidth:]


VCPSongDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPSongDetector init]
  -[VCPSongDetector results]
  -[VCPSongDetector .cxx_destruct]
  -[VCPSongDetector setupWithSample:andSampleBatchSize:]
  -[VCPSongDetector processAudioSamples:timestamp:]
  -[VCPSongDetector finalizeAnalysisAtTime:]


VCPProtoClassification : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  unsigned int identifier
 @property  float confidence

  // instance methods
  -[VCPProtoClassification copyWithZone:]
  -[VCPProtoClassification setConfidence:]
  -[VCPProtoClassification confidence]
  -[VCPProtoClassification setIdentifier:]
  -[VCPProtoClassification identifier]
  -[VCPProtoClassification readFrom:]
  -[VCPProtoClassification writeTo:]
  -[VCPProtoClassification isEqual:]
  -[VCPProtoClassification copyTo:]
  -[VCPProtoClassification dictionaryRepresentation]
  -[VCPProtoClassification mergeFrom:]


VCPProtoImageBlurResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness
 @property  BOOL hasFaceSharpness
 @property  float faceSharpness

  // class methods
  +[VCPProtoImageBlurResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageBlurResult copyWithZone:]
  -[VCPProtoImageBlurResult faceSharpness]
  -[VCPProtoImageBlurResult exportToLegacyDictionary]
  -[VCPProtoImageBlurResult setFaceSharpness:]
  -[VCPProtoImageBlurResult setHasFaceSharpness:]
  -[VCPProtoImageBlurResult hasFaceSharpness]
  -[VCPProtoImageBlurResult readFrom:]
  -[VCPProtoImageBlurResult sharpness]
  -[VCPProtoImageBlurResult writeTo:]
  -[VCPProtoImageBlurResult isEqual:]
  -[VCPProtoImageBlurResult copyTo:]
  -[VCPProtoImageBlurResult dictionaryRepresentation]
  -[VCPProtoImageBlurResult setSharpness:]
  -[VCPProtoImageBlurResult mergeFrom:]


VCPProtoImageCompositionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoPoint *vanishingPoint
 @property  VCPProtoLine *dominantLine

  // class methods
  +[VCPProtoImageCompositionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageCompositionResult copyWithZone:]
  -[VCPProtoImageCompositionResult exportToLegacyDictionary]
  -[VCPProtoImageCompositionResult setConfidence:]
  -[VCPProtoImageCompositionResult .cxx_destruct]
  -[VCPProtoImageCompositionResult confidence]
  -[VCPProtoImageCompositionResult vanishingPoint]
  -[VCPProtoImageCompositionResult dominantLine]
  -[VCPProtoImageCompositionResult setVanishingPoint:]
  -[VCPProtoImageCompositionResult setDominantLine:]
  -[VCPProtoImageCompositionResult readFrom:]
  -[VCPProtoImageCompositionResult writeTo:]
  -[VCPProtoImageCompositionResult isEqual:]
  -[VCPProtoImageCompositionResult copyTo:]
  -[VCPProtoImageCompositionResult dictionaryRepresentation]
  -[VCPProtoImageCompositionResult mergeFrom:]


VCPProtoImageExposureResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float exposure
 @property  BOOL hasUnderExpose
 @property  float underExpose

  // class methods
  +[VCPProtoImageExposureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageExposureResult copyWithZone:]
  -[VCPProtoImageExposureResult exposure]
  -[VCPProtoImageExposureResult exportToLegacyDictionary]
  -[VCPProtoImageExposureResult readFrom:]
  -[VCPProtoImageExposureResult setUnderExpose:]
  -[VCPProtoImageExposureResult setHasUnderExpose:]
  -[VCPProtoImageExposureResult hasUnderExpose]
  -[VCPProtoImageExposureResult setExposure:]
  -[VCPProtoImageExposureResult underExpose]
  -[VCPProtoImageExposureResult writeTo:]
  -[VCPProtoImageExposureResult isEqual:]
  -[VCPProtoImageExposureResult copyTo:]
  -[VCPProtoImageExposureResult dictionaryRepresentation]
  -[VCPProtoImageExposureResult mergeFrom:]


VCPLoudnessAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPLoudnessAnalyzer init]
  -[VCPLoudnessAnalyzer results]
  -[VCPLoudnessAnalyzer .cxx_construct]
  -[VCPLoudnessAnalyzer dealloc]
  -[VCPLoudnessAnalyzer .cxx_destruct]
  -[VCPLoudnessAnalyzer setupWithSample:andSampleBatchSize:]
  -[VCPLoudnessAnalyzer processAudioSamples:timestamp:]
  -[VCPLoudnessAnalyzer finalizeAnalysisAtTime:]


VCPProtoImageFaceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int eyeExpression
 @property  int mouthExpression
 @property  int yaw
 @property  int position
 @property  VCPProtoBounds *bounds
 @property  BOOL isCloseup
 @property  BOOL hasFaceQuality
 @property  float faceQuality

  // class methods
  +[VCPProtoImageFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageFaceResult copyWithZone:]
  -[VCPProtoImageFaceResult position]
  -[VCPProtoImageFaceResult setPosition:]
  -[VCPProtoImageFaceResult yaw]
  -[VCPProtoImageFaceResult exportToLegacyDictionary]
  -[VCPProtoImageFaceResult setYaw:]
  -[VCPProtoImageFaceResult .cxx_destruct]
  -[VCPProtoImageFaceResult setBounds:]
  -[VCPProtoImageFaceResult readFrom:]
  -[VCPProtoImageFaceResult bounds]
  -[VCPProtoImageFaceResult hasFaceQuality]
  -[VCPProtoImageFaceResult setHasFaceQuality:]
  -[VCPProtoImageFaceResult eyeExpression]
  -[VCPProtoImageFaceResult setEyeExpression:]
  -[VCPProtoImageFaceResult writeTo:]
  -[VCPProtoImageFaceResult isEqual:]
  -[VCPProtoImageFaceResult mouthExpression]
  -[VCPProtoImageFaceResult setMouthExpression:]
  -[VCPProtoImageFaceResult isCloseup]
  -[VCPProtoImageFaceResult setIsCloseup:]
  -[VCPProtoImageFaceResult copyTo:]
  -[VCPProtoImageFaceResult dictionaryRepresentation]
  -[VCPProtoImageFaceResult mergeFrom:]
  -[VCPProtoImageFaceResult faceQuality]
  -[VCPProtoImageFaceResult setFaceQuality:]


VCPProtoImageFeatureResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *featureBlob

  // class methods
  +[VCPProtoImageFeatureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageFeatureResult copyWithZone:]
  -[VCPProtoImageFeatureResult exportToLegacyDictionary]
  -[VCPProtoImageFeatureResult .cxx_destruct]
  -[VCPProtoImageFeatureResult readFrom:]
  -[VCPProtoImageFeatureResult setFeatureBlob:]
  -[VCPProtoImageFeatureResult featureBlob]
  -[VCPProtoImageFeatureResult writeTo:]
  -[VCPProtoImageFeatureResult isEqual:]
  -[VCPProtoImageFeatureResult copyTo:]
  -[VCPProtoImageFeatureResult dictionaryRepresentation]
  -[VCPProtoImageFeatureResult mergeFrom:]


VCPProtoImageJunkResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence

  // class methods
  +[VCPProtoImageJunkResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageJunkResult copyWithZone:]
  -[VCPProtoImageJunkResult exportToLegacyDictionary]
  -[VCPProtoImageJunkResult setConfidence:]
  -[VCPProtoImageJunkResult confidence]
  -[VCPProtoImageJunkResult readFrom:]
  -[VCPProtoImageJunkResult writeTo:]
  -[VCPProtoImageJunkResult isEqual:]
  -[VCPProtoImageJunkResult copyTo:]
  -[VCPProtoImageJunkResult dictionaryRepresentation]
  -[VCPProtoImageJunkResult mergeFrom:]


VCPProtoImagePetsFaceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImagePetsFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImagePetsFaceResult copyWithZone:]
  -[VCPProtoImagePetsFaceResult exportToLegacyDictionary]
  -[VCPProtoImagePetsFaceResult setConfidence:]
  -[VCPProtoImagePetsFaceResult .cxx_destruct]
  -[VCPProtoImagePetsFaceResult confidence]
  -[VCPProtoImagePetsFaceResult setBounds:]
  -[VCPProtoImagePetsFaceResult readFrom:]
  -[VCPProtoImagePetsFaceResult bounds]
  -[VCPProtoImagePetsFaceResult writeTo:]
  -[VCPProtoImagePetsFaceResult isEqual:]
  -[VCPProtoImagePetsFaceResult copyTo:]
  -[VCPProtoImagePetsFaceResult dictionaryRepresentation]
  -[VCPProtoImagePetsFaceResult mergeFrom:]


VCPVoiceOverService : NSObject /usr/lib/libc++.1.dylib <VCPVoiceOverClientProtocol>
  // class methods
  +[VCPVoiceOverService errorWithDescription:]
  +[VCPVoiceOverService service]

  // instance methods
  -[VCPVoiceOverService init]
  -[VCPVoiceOverService .cxx_destruct]
  -[VCPVoiceOverService requestProcessingViaXPC:ofPixelBuffer:withOptions:andCompletionHandler:]
  -[VCPVoiceOverService requestProcessing:ofPixelBuffer:withOptions:andCompletionHandler:]
  -[VCPVoiceOverService connection]
  -[VCPVoiceOverService invalidate]


VCPProtoMovieLaughterResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieLaughterResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieLaughterResult copyWithZone:]
  -[VCPProtoMovieLaughterResult setTimeRange:]
  -[VCPProtoMovieLaughterResult exportToLegacyDictionary]
  -[VCPProtoMovieLaughterResult setConfidence:]
  -[VCPProtoMovieLaughterResult .cxx_destruct]
  -[VCPProtoMovieLaughterResult timeRange]
  -[VCPProtoMovieLaughterResult confidence]
  -[VCPProtoMovieLaughterResult readFrom:]
  -[VCPProtoMovieLaughterResult writeTo:]
  -[VCPProtoMovieLaughterResult isEqual:]
  -[VCPProtoMovieLaughterResult copyTo:]
  -[VCPProtoMovieLaughterResult dictionaryRepresentation]
  -[VCPProtoMovieLaughterResult mergeFrom:]


VCPProtoImagePetsResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImagePetsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImagePetsResult copyWithZone:]
  -[VCPProtoImagePetsResult exportToLegacyDictionary]
  -[VCPProtoImagePetsResult setConfidence:]
  -[VCPProtoImagePetsResult .cxx_destruct]
  -[VCPProtoImagePetsResult confidence]
  -[VCPProtoImagePetsResult setBounds:]
  -[VCPProtoImagePetsResult readFrom:]
  -[VCPProtoImagePetsResult bounds]
  -[VCPProtoImagePetsResult writeTo:]
  -[VCPProtoImagePetsResult isEqual:]
  -[VCPProtoImagePetsResult copyTo:]
  -[VCPProtoImagePetsResult dictionaryRepresentation]
  -[VCPProtoImagePetsResult mergeFrom:]


VCPHandPoseVideoRequest : VCPRequest
  // instance methods
  -[VCPHandPoseVideoRequest initWithOptions:]
  -[VCPHandPoseVideoRequest init]
  -[VCPHandPoseVideoRequest .cxx_destruct]
  -[VCPHandPoseVideoRequest associateHands:withExisingHands:]
  -[VCPHandPoseVideoRequest handDistance:withhandB:]
  -[VCPHandPoseVideoRequest processSampleBuffer:withOptions:error:]
  -[VCPHandPoseVideoRequest preferredInputSizeWithOptions:error:]
  -[VCPHandPoseVideoRequest preferredPixelFormat]
  -[VCPHandPoseVideoRequest cleanupWithOptions:error:]


VCPLoaned : NSObject /usr/lib/libc++.1.dylib
 @property  id object

  // instance methods
  -[VCPLoaned object]
  -[VCPLoaned dealloc]
  -[VCPLoaned .cxx_destruct]
  -[VCPLoaned initWithObject:fromPool:]


VCPObjectPool : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPObjectPool objectPoolWithAllocator:]

  // instance methods
  -[VCPObjectPool .cxx_destruct]
  -[VCPObjectPool returnObject:]
  -[VCPObjectPool initWithAllocator:]
  -[VCPObjectPool getObject]


VCPProtoImageSaliencyResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImageSaliencyResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageSaliencyResult copyWithZone:]
  -[VCPProtoImageSaliencyResult exportToLegacyDictionary]
  -[VCPProtoImageSaliencyResult setConfidence:]
  -[VCPProtoImageSaliencyResult .cxx_destruct]
  -[VCPProtoImageSaliencyResult confidence]
  -[VCPProtoImageSaliencyResult setBounds:]
  -[VCPProtoImageSaliencyResult readFrom:]
  -[VCPProtoImageSaliencyResult bounds]
  -[VCPProtoImageSaliencyResult writeTo:]
  -[VCPProtoImageSaliencyResult isEqual:]
  -[VCPProtoImageSaliencyResult copyTo:]
  -[VCPProtoImageSaliencyResult dictionaryRepresentation]
  -[VCPProtoImageSaliencyResult mergeFrom:]


VCPProtoImageShotTypeResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int shotType

  // class methods
  +[VCPProtoImageShotTypeResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageShotTypeResult copyWithZone:]
  -[VCPProtoImageShotTypeResult exportToLegacyDictionary]
  -[VCPProtoImageShotTypeResult shotType]
  -[VCPProtoImageShotTypeResult readFrom:]
  -[VCPProtoImageShotTypeResult setShotType:]
  -[VCPProtoImageShotTypeResult writeTo:]
  -[VCPProtoImageShotTypeResult isEqual:]
  -[VCPProtoImageShotTypeResult copyTo:]
  -[VCPProtoImageShotTypeResult dictionaryRepresentation]
  -[VCPProtoImageShotTypeResult mergeFrom:]


VCPProtoLine : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  VCPProtoPoint *start
 @property  VCPProtoPoint *end

  // class methods
  +[VCPProtoLine lineFromPoint:toPoint:]

  // instance methods
  -[VCPProtoLine copyWithZone:]
  -[VCPProtoLine end]
  -[VCPProtoLine .cxx_destruct]
  -[VCPProtoLine setStart:]
  -[VCPProtoLine setEnd:]
  -[VCPProtoLine readFrom:]
  -[VCPProtoLine startPointValue]
  -[VCPProtoLine endPointValue]
  -[VCPProtoLine writeTo:]
  -[VCPProtoLine isEqual:]
  -[VCPProtoLine copyTo:]
  -[VCPProtoLine dictionaryRepresentation]
  -[VCPProtoLine mergeFrom:]
  -[VCPProtoLine start]


VCPProtoMovieCheeringResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieCheeringResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieCheeringResult copyWithZone:]
  -[VCPProtoMovieCheeringResult setTimeRange:]
  -[VCPProtoMovieCheeringResult exportToLegacyDictionary]
  -[VCPProtoMovieCheeringResult setConfidence:]
  -[VCPProtoMovieCheeringResult .cxx_destruct]
  -[VCPProtoMovieCheeringResult timeRange]
  -[VCPProtoMovieCheeringResult confidence]
  -[VCPProtoMovieCheeringResult readFrom:]
  -[VCPProtoMovieCheeringResult writeTo:]
  -[VCPProtoMovieCheeringResult isEqual:]
  -[VCPProtoMovieCheeringResult copyTo:]
  -[VCPProtoMovieCheeringResult dictionaryRepresentation]
  -[VCPProtoMovieCheeringResult mergeFrom:]


VCPProtoLivePhotoEffectsRecipe : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int stabilizeResult
 @property  long long outputFrameDurValue
 @property  int cropRectX
 @property  int cropRectY
 @property  int cropRectHeight
 @property  int cropRectWidth
 @property  int timeScale
 @property  BOOL hasEpoch
 @property  long long epoch
 @property  BOOL hasFlags
 @property  int flags
 @property  NSMutableArray *frameInstructions
 @property  VCPProtoLivePhotoVariationParams *autoloop
 @property  VCPProtoLivePhotoVariationParams *bounce
 @property  VCPProtoLivePhotoVariationParams *longexposure
 @property  VCPProtoLivePhotoVariationParams *stabilize
 @property  int minVersion
 @property  int version

  // class methods
  +[VCPProtoLivePhotoEffectsRecipe frameInstructionsType]
  +[VCPProtoLivePhotoEffectsRecipe resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoEffectsRecipe setHasFlags:]
  -[VCPProtoLivePhotoEffectsRecipe copyWithZone:]
  -[VCPProtoLivePhotoEffectsRecipe bounce]
  -[VCPProtoLivePhotoEffectsRecipe epoch]
  -[VCPProtoLivePhotoEffectsRecipe timeScale]
  -[VCPProtoLivePhotoEffectsRecipe setBounce:]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionary]
  -[VCPProtoLivePhotoEffectsRecipe setFlags:]
  -[VCPProtoLivePhotoEffectsRecipe hasEpoch]
  -[VCPProtoLivePhotoEffectsRecipe setEpoch:]
  -[VCPProtoLivePhotoEffectsRecipe .cxx_destruct]
  -[VCPProtoLivePhotoEffectsRecipe cropRectX]
  -[VCPProtoLivePhotoEffectsRecipe setVersion:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectY]
  -[VCPProtoLivePhotoEffectsRecipe autoloop]
  -[VCPProtoLivePhotoEffectsRecipe stabilize]
  -[VCPProtoLivePhotoEffectsRecipe hasFlags]
  -[VCPProtoLivePhotoEffectsRecipe readFrom:]
  -[VCPProtoLivePhotoEffectsRecipe minVersion]
  -[VCPProtoLivePhotoEffectsRecipe addFrameInstructions:]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructionsCount]
  -[VCPProtoLivePhotoEffectsRecipe clearFrameInstructions]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructionsAtIndex:]
  -[VCPProtoLivePhotoEffectsRecipe setAutoloop:]
  -[VCPProtoLivePhotoEffectsRecipe setLongexposure:]
  -[VCPProtoLivePhotoEffectsRecipe setStabilize:]
  -[VCPProtoLivePhotoEffectsRecipe setHasEpoch:]
  -[VCPProtoLivePhotoEffectsRecipe stabilizeResult]
  -[VCPProtoLivePhotoEffectsRecipe setStabilizeResult:]
  -[VCPProtoLivePhotoEffectsRecipe outputFrameDurValue]
  -[VCPProtoLivePhotoEffectsRecipe setOutputFrameDurValue:]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectX:]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectY:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectHeight]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectHeight:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectWidth]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectWidth:]
  -[VCPProtoLivePhotoEffectsRecipe setTimeScale:]
  -[VCPProtoLivePhotoEffectsRecipe writeTo:]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructions]
  -[VCPProtoLivePhotoEffectsRecipe setFrameInstructions:]
  -[VCPProtoLivePhotoEffectsRecipe longexposure]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionaryFromFrameInstruction:]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionaryFromParam:withLoopFlavor:]
  -[VCPProtoLivePhotoEffectsRecipe isEqual:]
  -[VCPProtoLivePhotoEffectsRecipe version]
  -[VCPProtoLivePhotoEffectsRecipe flags]
  -[VCPProtoLivePhotoEffectsRecipe copyTo:]
  -[VCPProtoLivePhotoEffectsRecipe dictionaryRepresentation]
  -[VCPProtoLivePhotoEffectsRecipe setMinVersion:]
  -[VCPProtoLivePhotoEffectsRecipe mergeFrom:]


VCPProtoLivePhotoEffectsResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  unsigned long loopSuggestionState
 @property  unsigned long longExposureSuggestionState
 @property  BOOL hasRecipeBlob
 @property  NSData *recipeBlob

  // class methods
  +[VCPProtoLivePhotoEffectsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoEffectsResult copyWithZone:]
  -[VCPProtoLivePhotoEffectsResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoEffectsResult .cxx_destruct]
  -[VCPProtoLivePhotoEffectsResult readFrom:]
  -[VCPProtoLivePhotoEffectsResult writeTo:]
  -[VCPProtoLivePhotoEffectsResult setRecipeBlob:]
  -[VCPProtoLivePhotoEffectsResult hasRecipeBlob]
  -[VCPProtoLivePhotoEffectsResult loopSuggestionState]
  -[VCPProtoLivePhotoEffectsResult setLoopSuggestionState:]
  -[VCPProtoLivePhotoEffectsResult longExposureSuggestionState]
  -[VCPProtoLivePhotoEffectsResult setLongExposureSuggestionState:]
  -[VCPProtoLivePhotoEffectsResult recipeBlob]
  -[VCPProtoLivePhotoEffectsResult isEqual:]
  -[VCPProtoLivePhotoEffectsResult copyTo:]
  -[VCPProtoLivePhotoEffectsResult dictionaryRepresentation]
  -[VCPProtoLivePhotoEffectsResult mergeFrom:]


VCPHumanPoseImageRequest : VCPRequest
  // class methods
  +[VCPHumanPoseImageRequest parseResults:observations:]

  // instance methods
  -[VCPHumanPoseImageRequest initWithOptions:]
  -[VCPHumanPoseImageRequest init]
  -[VCPHumanPoseImageRequest .cxx_destruct]
  -[VCPHumanPoseImageRequest updateWithOptions:error:]
  -[VCPHumanPoseImageRequest processImage:withOptions:error:]
  -[VCPHumanPoseImageRequest preferredInputSizeWithOptions:error:]
  -[VCPHumanPoseImageRequest preferredPixelFormat]
  -[VCPHumanPoseImageRequest cleanupWithOptions:error:]


VCPProtoLivePhotoFrameInstruction : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  long long timeValue
 @property  unsigned long homographyParamsCount
 @property  ^f homographyParams
 @property  int timeScale
 @property  long long epoch
 @property  int flags

  // class methods
  +[VCPProtoLivePhotoFrameInstruction resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoFrameInstruction copyWithZone:]
  -[VCPProtoLivePhotoFrameInstruction epoch]
  -[VCPProtoLivePhotoFrameInstruction timeScale]
  -[VCPProtoLivePhotoFrameInstruction exportToLegacyDictionary]
  -[VCPProtoLivePhotoFrameInstruction setFlags:]
  -[VCPProtoLivePhotoFrameInstruction dealloc]
  -[VCPProtoLivePhotoFrameInstruction setEpoch:]
  -[VCPProtoLivePhotoFrameInstruction setTimeValue:]
  -[VCPProtoLivePhotoFrameInstruction readFrom:]
  -[VCPProtoLivePhotoFrameInstruction setTimeScale:]
  -[VCPProtoLivePhotoFrameInstruction writeTo:]
  -[VCPProtoLivePhotoFrameInstruction homographyParamsCount]
  -[VCPProtoLivePhotoFrameInstruction clearHomographyParams]
  -[VCPProtoLivePhotoFrameInstruction homographyParamAtIndex:]
  -[VCPProtoLivePhotoFrameInstruction addHomographyParam:]
  -[VCPProtoLivePhotoFrameInstruction homographyParams]
  -[VCPProtoLivePhotoFrameInstruction setHomographyParams:count:]
  -[VCPProtoLivePhotoFrameInstruction isEqual:]
  -[VCPProtoLivePhotoFrameInstruction flags]
  -[VCPProtoLivePhotoFrameInstruction copyTo:]
  -[VCPProtoLivePhotoFrameInstruction dictionaryRepresentation]
  -[VCPProtoLivePhotoFrameInstruction timeValue]
  -[VCPProtoLivePhotoFrameInstruction mergeFrom:]


VCPProtoLivePhotoRecommendationResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore

  // class methods
  +[VCPProtoLivePhotoRecommendationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoRecommendationResult copyWithZone:]
  -[VCPProtoLivePhotoRecommendationResult setTimeRange:]
  -[VCPProtoLivePhotoRecommendationResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoRecommendationResult .cxx_destruct]
  -[VCPProtoLivePhotoRecommendationResult timeRange]
  -[VCPProtoLivePhotoRecommendationResult readFrom:]
  -[VCPProtoLivePhotoRecommendationResult writeTo:]
  -[VCPProtoLivePhotoRecommendationResult isEqual:]
  -[VCPProtoLivePhotoRecommendationResult copyTo:]
  -[VCPProtoLivePhotoRecommendationResult dictionaryRepresentation]
  -[VCPProtoLivePhotoRecommendationResult mergeFrom:]
  -[VCPProtoLivePhotoRecommendationResult qualityScore]
  -[VCPProtoLivePhotoRecommendationResult setQualityScore:]


VCPProtoLivePhotoSharpnessResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness

  // class methods
  +[VCPProtoLivePhotoSharpnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoSharpnessResult copyWithZone:]
  -[VCPProtoLivePhotoSharpnessResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoSharpnessResult readFrom:]
  -[VCPProtoLivePhotoSharpnessResult sharpness]
  -[VCPProtoLivePhotoSharpnessResult writeTo:]
  -[VCPProtoLivePhotoSharpnessResult isEqual:]
  -[VCPProtoLivePhotoSharpnessResult copyTo:]
  -[VCPProtoLivePhotoSharpnessResult dictionaryRepresentation]
  -[VCPProtoLivePhotoSharpnessResult setSharpness:]
  -[VCPProtoLivePhotoSharpnessResult mergeFrom:]


VCPImageHandsAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageHandsAnalyzer init]
  -[VCPImageHandsAnalyzer .cxx_destruct]
  -[VCPImageHandsAnalyzer initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:]
  -[VCPImageHandsAnalyzer getClosestAspectRatio:]
  -[VCPImageHandsAnalyzer convertSingleResultToDict:keypointConfidence:box:results:]
  -[VCPImageHandsAnalyzer configForAspectRatio:]
  -[VCPImageHandsAnalyzer updateModelForAspectRatio:]
  -[VCPImageHandsAnalyzer preferredInputFormat:height:format:]
  -[VCPImageHandsAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPHomeResidentMaintenanceTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
 @property  @? cancelBlock

  // class methods
  +[VCPHomeResidentMaintenanceTask taskWithOptions:andCompletionHandler:]

  // instance methods
  -[VCPHomeResidentMaintenanceTask run]
  -[VCPHomeResidentMaintenanceTask isCanceled]
  -[VCPHomeResidentMaintenanceTask dealloc]
  -[VCPHomeResidentMaintenanceTask .cxx_destruct]
  -[VCPHomeResidentMaintenanceTask resourceRequirement]
  -[VCPHomeResidentMaintenanceTask cancel]
  -[VCPHomeResidentMaintenanceTask initWithOptions:andCompletionHandler:]
  -[VCPHomeResidentMaintenanceTask setCancelBlock:]
  -[VCPHomeResidentMaintenanceTask cancelBlock]


VCPProtoLivePhotoVariationParams : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int errorCode
 @property  BOOL hasLoopFadeLen
 @property  int loopFadeLen
 @property  BOOL hasLoopPeriod
 @property  int loopPeriod
 @property  BOOL hasLoopStart
 @property  int loopStart

  // class methods
  +[VCPProtoLivePhotoVariationParams resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoVariationParams setErrorCode:]
  -[VCPProtoLivePhotoVariationParams copyWithZone:]
  -[VCPProtoLivePhotoVariationParams errorCode]
  -[VCPProtoLivePhotoVariationParams exportToLegacyDictionary]
  -[VCPProtoLivePhotoVariationParams readFrom:]
  -[VCPProtoLivePhotoVariationParams writeTo:]
  -[VCPProtoLivePhotoVariationParams loopStart]
  -[VCPProtoLivePhotoVariationParams setLoopFadeLen:]
  -[VCPProtoLivePhotoVariationParams setHasLoopFadeLen:]
  -[VCPProtoLivePhotoVariationParams hasLoopFadeLen]
  -[VCPProtoLivePhotoVariationParams setLoopPeriod:]
  -[VCPProtoLivePhotoVariationParams setHasLoopPeriod:]
  -[VCPProtoLivePhotoVariationParams isEqual:]
  -[VCPProtoLivePhotoVariationParams hasLoopPeriod]
  -[VCPProtoLivePhotoVariationParams setLoopStart:]
  -[VCPProtoLivePhotoVariationParams setHasLoopStart:]
  -[VCPProtoLivePhotoVariationParams hasLoopStart]
  -[VCPProtoLivePhotoVariationParams loopFadeLen]
  -[VCPProtoLivePhotoVariationParams loopPeriod]
  -[VCPProtoLivePhotoVariationParams copyTo:]
  -[VCPProtoLivePhotoVariationParams dictionaryRepresentation]
  -[VCPProtoLivePhotoVariationParams mergeFrom:]


VCPProtoMovieActivityLevelResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float activityScore

  // class methods
  +[VCPProtoMovieActivityLevelResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieActivityLevelResult copyWithZone:]
  -[VCPProtoMovieActivityLevelResult setTimeRange:]
  -[VCPProtoMovieActivityLevelResult exportToLegacyDictionary]
  -[VCPProtoMovieActivityLevelResult .cxx_destruct]
  -[VCPProtoMovieActivityLevelResult timeRange]
  -[VCPProtoMovieActivityLevelResult activityScore]
  -[VCPProtoMovieActivityLevelResult readFrom:]
  -[VCPProtoMovieActivityLevelResult writeTo:]
  -[VCPProtoMovieActivityLevelResult isEqual:]
  -[VCPProtoMovieActivityLevelResult copyTo:]
  -[VCPProtoMovieActivityLevelResult dictionaryRepresentation]
  -[VCPProtoMovieActivityLevelResult mergeFrom:]
  -[VCPProtoMovieActivityLevelResult setActivityScore:]


VCPProtoMovieCameraMotionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int motionType
 @property  BOOL isFast

  // class methods
  +[VCPProtoMovieCameraMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieCameraMotionResult copyWithZone:]
  -[VCPProtoMovieCameraMotionResult setTimeRange:]
  -[VCPProtoMovieCameraMotionResult exportToLegacyDictionary]
  -[VCPProtoMovieCameraMotionResult isFast]
  -[VCPProtoMovieCameraMotionResult .cxx_destruct]
  -[VCPProtoMovieCameraMotionResult timeRange]
  -[VCPProtoMovieCameraMotionResult motionType]
  -[VCPProtoMovieCameraMotionResult readFrom:]
  -[VCPProtoMovieCameraMotionResult writeTo:]
  -[VCPProtoMovieCameraMotionResult isEqual:]
  -[VCPProtoMovieCameraMotionResult setMotionType:]
  -[VCPProtoMovieCameraMotionResult setIsFast:]
  -[VCPProtoMovieCameraMotionResult copyTo:]
  -[VCPProtoMovieCameraMotionResult dictionaryRepresentation]
  -[VCPProtoMovieCameraMotionResult mergeFrom:]


VCPHomeKitAnalysisSession : NSObject /usr/lib/libc++.1.dylib <VCPHomeKitAnalysisSessionClientProtocol>
  // class methods
  +[VCPHomeKitAnalysisSession sessionWithProperties:andResultsHandler:]

  // instance methods
  -[VCPHomeKitAnalysisSession .cxx_construct]
  -[VCPHomeKitAnalysisSession .cxx_destruct]
  -[VCPHomeKitAnalysisSession initWithProperties:andResultsHandler:]
  -[VCPHomeKitAnalysisSession processResults:withReply:]
  -[VCPHomeKitAnalysisSession processVideoFragmentAssetData:withOptions:andErrorHandler:]
  -[VCPHomeKitAnalysisSession processVideoFragmentAssetData:withOptions:andCompletionHandler:]
  -[VCPHomeKitAnalysisSession processMessageWithOptions:andCompletionHandler:]
  -[VCPHomeKitAnalysisSession connection]
  -[VCPHomeKitAnalysisSession invalidate]


VCPHomeKitSessionExportedObject : NSObject /usr/lib/libc++.1.dylib <VCPHomeKitAnalysisSessionClientProtocol>
 @property  VCPHomeKitAnalysisSession *weakSession

  // instance methods
  -[VCPHomeKitSessionExportedObject .cxx_destruct]
  -[VCPHomeKitSessionExportedObject setWeakSession:]
  -[VCPHomeKitSessionExportedObject processResults:withReply:]
  -[VCPHomeKitSessionExportedObject weakSession]


VCPHomeKitMotionAnalyzer : VCPVideoAnalyzer
 @property  float actionScore

  // instance methods
  -[VCPHomeKitMotionAnalyzer init]
  -[VCPHomeKitMotionAnalyzer .cxx_construct]
  -[VCPHomeKitMotionAnalyzer dealloc]
  -[VCPHomeKitMotionAnalyzer .cxx_destruct]
  -[VCPHomeKitMotionAnalyzer actionScore]
  -[VCPHomeKitMotionAnalyzer setPixelBuffer:]
  -[VCPHomeKitMotionAnalyzer calculateFrameDifference:]
  -[VCPHomeKitMotionAnalyzer computeRegionsofInterest]
  -[VCPHomeKitMotionAnalyzer regionsOfInterest]
  -[VCPHomeKitMotionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]


VCPProtoMovieClassificationResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *classifications

  // class methods
  +[VCPProtoMovieClassificationResult classificationType]
  +[VCPProtoMovieClassificationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieClassificationResult copyWithZone:]
  -[VCPProtoMovieClassificationResult setTimeRange:]
  -[VCPProtoMovieClassificationResult exportToLegacyDictionary]
  -[VCPProtoMovieClassificationResult .cxx_destruct]
  -[VCPProtoMovieClassificationResult timeRange]
  -[VCPProtoMovieClassificationResult readFrom:]
  -[VCPProtoMovieClassificationResult writeTo:]
  -[VCPProtoMovieClassificationResult addClassification:]
  -[VCPProtoMovieClassificationResult isEqual:]
  -[VCPProtoMovieClassificationResult classificationsCount]
  -[VCPProtoMovieClassificationResult clearClassifications]
  -[VCPProtoMovieClassificationResult classificationAtIndex:]
  -[VCPProtoMovieClassificationResult classifications]
  -[VCPProtoMovieClassificationResult setClassifications:]
  -[VCPProtoMovieClassificationResult copyTo:]
  -[VCPProtoMovieClassificationResult dictionaryRepresentation]
  -[VCPProtoMovieClassificationResult mergeFrom:]


VCPHandPoseImageRequest : VCPRequest
  // class methods
  +[VCPHandPoseImageRequest parseResults:observations:]

  // instance methods
  -[VCPHandPoseImageRequest initWithOptions:]
  -[VCPHandPoseImageRequest init]
  -[VCPHandPoseImageRequest .cxx_destruct]
  -[VCPHandPoseImageRequest updateWithOptions:error:]
  -[VCPHandPoseImageRequest processImage:withOptions:error:]
  -[VCPHandPoseImageRequest preferredInputSizeWithOptions:error:]
  -[VCPHandPoseImageRequest preferredPixelFormat]
  -[VCPHandPoseImageRequest cleanupWithOptions:error:]


VCPProtoMovieFaceprintResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  unsigned int faceID
 @property  NSData *faceprintBlob

  // class methods
  +[VCPProtoMovieFaceprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFaceprintResult copyWithZone:]
  -[VCPProtoMovieFaceprintResult exportToLegacyDictionary]
  -[VCPProtoMovieFaceprintResult faceID]
  -[VCPProtoMovieFaceprintResult .cxx_destruct]
  -[VCPProtoMovieFaceprintResult readFrom:]
  -[VCPProtoMovieFaceprintResult writeTo:]
  -[VCPProtoMovieFaceprintResult isEqual:]
  -[VCPProtoMovieFaceprintResult faceprintBlob]
  -[VCPProtoMovieFaceprintResult setFaceprintBlob:]
  -[VCPProtoMovieFaceprintResult copyTo:]
  -[VCPProtoMovieFaceprintResult dictionaryRepresentation]
  -[VCPProtoMovieFaceprintResult mergeFrom:]
  -[VCPProtoMovieFaceprintResult setFaceID:]


VCPRequest : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL useCPUOnly
 @property  unsigned int revision

  // instance methods
  -[VCPRequest initWithOptions:]
  -[VCPRequest init]
  -[VCPRequest revision]
  -[VCPRequest updateWithOptions:error:]
  -[VCPRequest useCPUOnly]
  -[VCPRequest preferredInputSizeWithOptions:error:]
  -[VCPRequest preferredPixelFormat]
  -[VCPRequest cleanupWithOptions:error:]


VCPProtoMovieFaceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int mouthExpression
 @property  int position
 @property  VCPProtoBounds *bounds
 @property  BOOL isCloseup
 @property  int faceID

  // class methods
  +[VCPProtoMovieFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFaceResult copyWithZone:]
  -[VCPProtoMovieFaceResult setTimeRange:]
  -[VCPProtoMovieFaceResult position]
  -[VCPProtoMovieFaceResult setPosition:]
  -[VCPProtoMovieFaceResult exportToLegacyDictionary]
  -[VCPProtoMovieFaceResult faceID]
  -[VCPProtoMovieFaceResult .cxx_destruct]
  -[VCPProtoMovieFaceResult timeRange]
  -[VCPProtoMovieFaceResult setBounds:]
  -[VCPProtoMovieFaceResult readFrom:]
  -[VCPProtoMovieFaceResult bounds]
  -[VCPProtoMovieFaceResult writeTo:]
  -[VCPProtoMovieFaceResult isEqual:]
  -[VCPProtoMovieFaceResult mouthExpression]
  -[VCPProtoMovieFaceResult setMouthExpression:]
  -[VCPProtoMovieFaceResult isCloseup]
  -[VCPProtoMovieFaceResult setIsCloseup:]
  -[VCPProtoMovieFaceResult copyTo:]
  -[VCPProtoMovieFaceResult dictionaryRepresentation]
  -[VCPProtoMovieFaceResult mergeFrom:]
  -[VCPProtoMovieFaceResult setFaceID:]


VCPProtoMovieFeatureResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTime *timestamp
 @property  NSData *featureBlob

  // class methods
  +[VCPProtoMovieFeatureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFeatureResult copyWithZone:]
  -[VCPProtoMovieFeatureResult exportToLegacyDictionary]
  -[VCPProtoMovieFeatureResult .cxx_destruct]
  -[VCPProtoMovieFeatureResult timestamp]
  -[VCPProtoMovieFeatureResult setTimestamp:]
  -[VCPProtoMovieFeatureResult readFrom:]
  -[VCPProtoMovieFeatureResult setFeatureBlob:]
  -[VCPProtoMovieFeatureResult featureBlob]
  -[VCPProtoMovieFeatureResult writeTo:]
  -[VCPProtoMovieFeatureResult isEqual:]
  -[VCPProtoMovieFeatureResult copyTo:]
  -[VCPProtoMovieFeatureResult dictionaryRepresentation]
  -[VCPProtoMovieFeatureResult mergeFrom:]


VCPProtoMovieFineSubjectMotionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float actionScore

  // class methods
  +[VCPProtoMovieFineSubjectMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFineSubjectMotionResult copyWithZone:]
  -[VCPProtoMovieFineSubjectMotionResult setTimeRange:]
  -[VCPProtoMovieFineSubjectMotionResult exportToLegacyDictionary]
  -[VCPProtoMovieFineSubjectMotionResult .cxx_destruct]
  -[VCPProtoMovieFineSubjectMotionResult timeRange]
  -[VCPProtoMovieFineSubjectMotionResult readFrom:]
  -[VCPProtoMovieFineSubjectMotionResult setActionScore:]
  -[VCPProtoMovieFineSubjectMotionResult actionScore]
  -[VCPProtoMovieFineSubjectMotionResult writeTo:]
  -[VCPProtoMovieFineSubjectMotionResult isEqual:]
  -[VCPProtoMovieFineSubjectMotionResult copyTo:]
  -[VCPProtoMovieFineSubjectMotionResult dictionaryRepresentation]
  -[VCPProtoMovieFineSubjectMotionResult mergeFrom:]


VCPProtoMovieHighlightResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float curationScore
 @property  VCPProtoVideoKeyFrame *keyFrame

  // class methods
  +[VCPProtoMovieHighlightResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHighlightResult copyWithZone:]
  -[VCPProtoMovieHighlightResult setTimeRange:]
  -[VCPProtoMovieHighlightResult exportToLegacyDictionary]
  -[VCPProtoMovieHighlightResult .cxx_destruct]
  -[VCPProtoMovieHighlightResult timeRange]
  -[VCPProtoMovieHighlightResult setKeyFrame:]
  -[VCPProtoMovieHighlightResult readFrom:]
  -[VCPProtoMovieHighlightResult setCurationScore:]
  -[VCPProtoMovieHighlightResult writeTo:]
  -[VCPProtoMovieHighlightResult isEqual:]
  -[VCPProtoMovieHighlightResult keyFrame]
  -[VCPProtoMovieHighlightResult curationScore]
  -[VCPProtoMovieHighlightResult copyTo:]
  -[VCPProtoMovieHighlightResult dictionaryRepresentation]
  -[VCPProtoMovieHighlightResult mergeFrom:]


VCPProtoMovieInterestingnessResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float interestScore

  // class methods
  +[VCPProtoMovieInterestingnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieInterestingnessResult copyWithZone:]
  -[VCPProtoMovieInterestingnessResult setTimeRange:]
  -[VCPProtoMovieInterestingnessResult exportToLegacyDictionary]
  -[VCPProtoMovieInterestingnessResult .cxx_destruct]
  -[VCPProtoMovieInterestingnessResult timeRange]
  -[VCPProtoMovieInterestingnessResult readFrom:]
  -[VCPProtoMovieInterestingnessResult writeTo:]
  -[VCPProtoMovieInterestingnessResult isEqual:]
  -[VCPProtoMovieInterestingnessResult interestScore]
  -[VCPProtoMovieInterestingnessResult setInterestScore:]
  -[VCPProtoMovieInterestingnessResult copyTo:]
  -[VCPProtoMovieInterestingnessResult dictionaryRepresentation]
  -[VCPProtoMovieInterestingnessResult mergeFrom:]


VCPImageHumanPoseAnalyzerTopDown : VCPImageAnalyzer
  // instance methods
  -[VCPImageHumanPoseAnalyzerTopDown .cxx_destruct]
  -[VCPImageHumanPoseAnalyzerTopDown preferredInputFormat:height:format:]
  -[VCPImageHumanPoseAnalyzerTopDown analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageHumanPoseAnalyzerTopDown initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:]


VCPProtoMovieLoudnessResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  double energy
 @property  double peak

  // class methods
  +[VCPProtoMovieLoudnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieLoudnessResult copyWithZone:]
  -[VCPProtoMovieLoudnessResult setTimeRange:]
  -[VCPProtoMovieLoudnessResult peak]
  -[VCPProtoMovieLoudnessResult exportToLegacyDictionary]
  -[VCPProtoMovieLoudnessResult .cxx_destruct]
  -[VCPProtoMovieLoudnessResult timeRange]
  -[VCPProtoMovieLoudnessResult readFrom:]
  -[VCPProtoMovieLoudnessResult writeTo:]
  -[VCPProtoMovieLoudnessResult isEqual:]
  -[VCPProtoMovieLoudnessResult setEnergy:]
  -[VCPProtoMovieLoudnessResult setPeak:]
  -[VCPProtoMovieLoudnessResult copyTo:]
  -[VCPProtoMovieLoudnessResult dictionaryRepresentation]
  -[VCPProtoMovieLoudnessResult mergeFrom:]
  -[VCPProtoMovieLoudnessResult energy]


VCPProtoMovieMovingObjectResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *bounds

  // class methods
  +[VCPProtoMovieMovingObjectResult boundsType]
  +[VCPProtoMovieMovingObjectResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieMovingObjectResult copyWithZone:]
  -[VCPProtoMovieMovingObjectResult setTimeRange:]
  -[VCPProtoMovieMovingObjectResult exportToLegacyDictionary]
  -[VCPProtoMovieMovingObjectResult .cxx_destruct]
  -[VCPProtoMovieMovingObjectResult timeRange]
  -[VCPProtoMovieMovingObjectResult setBounds:]
  -[VCPProtoMovieMovingObjectResult readFrom:]
  -[VCPProtoMovieMovingObjectResult bounds]
  -[VCPProtoMovieMovingObjectResult writeTo:]
  -[VCPProtoMovieMovingObjectResult isEqual:]
  -[VCPProtoMovieMovingObjectResult addBounds:]
  -[VCPProtoMovieMovingObjectResult boundsCount]
  -[VCPProtoMovieMovingObjectResult clearBounds]
  -[VCPProtoMovieMovingObjectResult boundsAtIndex:]
  -[VCPProtoMovieMovingObjectResult copyTo:]
  -[VCPProtoMovieMovingObjectResult dictionaryRepresentation]
  -[VCPProtoMovieMovingObjectResult mergeFrom:]


VCPProtoMovieMusicResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieMusicResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieMusicResult copyWithZone:]
  -[VCPProtoMovieMusicResult setTimeRange:]
  -[VCPProtoMovieMusicResult exportToLegacyDictionary]
  -[VCPProtoMovieMusicResult setConfidence:]
  -[VCPProtoMovieMusicResult .cxx_destruct]
  -[VCPProtoMovieMusicResult timeRange]
  -[VCPProtoMovieMusicResult confidence]
  -[VCPProtoMovieMusicResult readFrom:]
  -[VCPProtoMovieMusicResult writeTo:]
  -[VCPProtoMovieMusicResult isEqual:]
  -[VCPProtoMovieMusicResult copyTo:]
  -[VCPProtoMovieMusicResult dictionaryRepresentation]
  -[VCPProtoMovieMusicResult mergeFrom:]


VCPProtoMovieObstructionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float obstructionScore

  // class methods
  +[VCPProtoMovieObstructionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieObstructionResult copyWithZone:]
  -[VCPProtoMovieObstructionResult setTimeRange:]
  -[VCPProtoMovieObstructionResult exportToLegacyDictionary]
  -[VCPProtoMovieObstructionResult .cxx_destruct]
  -[VCPProtoMovieObstructionResult timeRange]
  -[VCPProtoMovieObstructionResult readFrom:]
  -[VCPProtoMovieObstructionResult writeTo:]
  -[VCPProtoMovieObstructionResult isEqual:]
  -[VCPProtoMovieObstructionResult copyTo:]
  -[VCPProtoMovieObstructionResult dictionaryRepresentation]
  -[VCPProtoMovieObstructionResult mergeFrom:]
  -[VCPProtoMovieObstructionResult obstructionScore]
  -[VCPProtoMovieObstructionResult setObstructionScore:]


VCPCNNHandsDetector : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPCNNHandsDetector detector:forceCPU:sharedModel:inputConfig:]

  // instance methods
  -[VCPCNNHandsDetector handsDetection:handsRegions:cancel:]
  -[VCPCNNHandsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandsDetector updateModelWithResConfig:]
  -[VCPCNNHandsDetector retrieveBoxes:outHeight:outWidth:boxes:anchorBox:]
  -[VCPCNNHandsDetector nonMaxSuppression:]
  -[VCPCNNHandsDetector drawLine:width:height:stride:point0:point1:drawPoint:]
  -[VCPCNNHandsDetector generateHandsBoxes:]
  -[VCPCNNHandsDetector generateHandsRegions:boxes:maxNumRegions:]
  -[VCPCNNHandsDetector drawRectangle:width:height:stride:keypoints:]
  -[VCPCNNHandsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNHandsDetector copyImage:toData:]


VCPFaceProcessingServiceWorker : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceProcessingServiceWorker newAllFacesFetchOptionsWithPhotoLibrary:]
  +[VCPFaceProcessingServiceWorker newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:]
  +[VCPFaceProcessingServiceWorker workerWithPhotoLibrary:andContext:]

  // instance methods
  -[VCPFaceProcessingServiceWorker initWithPhotoLibrary:andContext:]
  -[VCPFaceProcessingServiceWorker .cxx_destruct]
  -[VCPFaceProcessingServiceWorker _copyImageAtURLToSuggestionsLoggingSession:]
  -[VCPFaceProcessingServiceWorker _logFaceToSuggestionsLog:]
  -[VCPFaceProcessingServiceWorker _appendToSuggestionsLog:]
  -[VCPFaceProcessingServiceWorker personPromoterStatusWithContext:reply:]
  -[VCPFaceProcessingServiceWorker faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:]
  -[VCPFaceProcessingServiceWorker requestSuggestedMePersonIdentifierWithContext:reply:]
  -[VCPFaceProcessingServiceWorker _startAndSyncClusterCacheWithLibrary:reply:]
  -[VCPFaceProcessingServiceWorker _suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:]
  -[VCPFaceProcessingServiceWorker _suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:]
  -[VCPFaceProcessingServiceWorker suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:]
  -[VCPFaceProcessingServiceWorker resetPersonsModelWithContext:reply:]
  -[VCPFaceProcessingServiceWorker reclusterFacesWithContext:reply:extendTimeout:cancel:]
  -[VCPFaceProcessingServiceWorker rebuildPersonsWithContext:reply:extendTimeout:cancel:]
  -[VCPFaceProcessingServiceWorker _finalizeSuggestionsLog]
  -[VCPFaceProcessingServiceWorker updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:]
  -[VCPFaceProcessingServiceWorker resetFaceClusteringStateWithContext:reply:]
  -[VCPFaceProcessingServiceWorker validateClusterCacheWithContext:reply:]
  -[VCPFaceProcessingServiceWorker _closeSuggestionsLoggingSession]
  -[VCPFaceProcessingServiceWorker _openSuggestionsLoggingSession]
  -[VCPFaceProcessingServiceWorker _deleteAllVerifiedPersonsWithError:]


VCPFaceUtils : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceUtils phFaceFromPVFace:withFetchOptions:]
  +[VCPFaceUtils phFacesFromPVFaces:withFetchOptions:]
  +[VCPFaceUtils assignPropertiesOfPVFace:toPHFaceChangeRequest:]
  +[VCPFaceUtils _vnFaceAttributeAgeToPHFaceAgeTypeMap]
  +[VCPFaceUtils _vnFaceAttributeSexToPHFaceSexTypeMap]
  +[VCPFaceUtils _vnFaceAttributeEyesToPHEyesStateMap]
  +[VCPFaceUtils _vnFaceAttributeSmileToPHFaceSmileTypeMap]
  +[VCPFaceUtils _vnFaceAttributeFacialHairToPHFacialHairTypeMap]
  +[VCPFaceUtils _vnFaceAttributeHairColorToPHFaceHairColorTypeMap]
  +[VCPFaceUtils _vnFaceAttributeBaldToPHFaceBaldTypeMap]
  +[VCPFaceUtils _vnFaceAttributeGlassesToPHFaceGlassesTypeMap]
  +[VCPFaceUtils _phFaceAgeTypeFromPVFace:]
  +[VCPFaceUtils _phFaceSexFromPVFace:]
  +[VCPFaceUtils _phFaceEyesStateFromPVFace:]
  +[VCPFaceUtils _phFaceSmileTypeFromPVFace:]
  +[VCPFaceUtils _phFaceFacialHairTypeFromPVFace:]
  +[VCPFaceUtils _phFaceHairColorTypeFromPVFace:]
  +[VCPFaceUtils _phFaceBaldTypeFromPVFace:]
  +[VCPFaceUtils _phFaceGlassesTypeFromPVFace:]
  +[VCPFaceUtils _firstLocallyAvailableResourceFromResources:]
  +[VCPFaceUtils _assetResourceLargestToSmallestComparator]
  +[VCPFaceUtils pvImageCreationOptions]
  +[VCPFaceUtils preferredResourcesForFaceProcessingWithAsset:]
  +[VCPFaceUtils resourceForFaceProcessing:allowStreaming:]
  +[VCPFaceUtils resourceForFaceProcessingWithAsset:allowStreaming:]
  +[VCPFaceUtils pvFaceFromPHFace:copyPropertiesOption:]

  // instance methods
  -[VCPFaceUtils _pvFacesArrayFromPHFetchResult:copyPropertiesOption:]


VCPFaceVisionIntegrating : NSObject /usr/lib/libc++.1.dylib <PVVisionIntegrating>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPFaceVisionIntegrating configureRequest:algorithmUmbrellaVersion:]


VCPPersonBuilder : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPPersonBuilder .cxx_destruct]
  -[VCPPersonBuilder _setAllFaceGroupsNeedPersonBuilding]
  -[VCPPersonBuilder setLastMinimumFaceGroupSizeForCreatingMergeCandidate:]
  -[VCPPersonBuilder _readFaceAnalysisState]
  -[VCPPersonBuilder _setFaceAnalysisStateValue:forKey:]
  -[VCPPersonBuilder initWithPhotoLibrary:andFaceClusterer:andContext:]
  -[VCPPersonBuilder performPersonBuildingWithCanceler:extendTimeoutBlock:error:]
  -[VCPPersonBuilder setPersonBuilderMergeCandidatesEnabled:]


VCPVideoHumanActionAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoHumanActionAnalyzer results]
  -[VCPVideoHumanActionAnalyzer .cxx_destruct]
  -[VCPVideoHumanActionAnalyzer computeActionScore]
  -[VCPVideoHumanActionAnalyzer normDistance:point2:]
  -[VCPVideoHumanActionAnalyzer computeVar:index2:interVar:intraVar:]
  -[VCPVideoHumanActionAnalyzer scaleRect:scaleX:scaleY:]
  -[VCPVideoHumanActionAnalyzer intersectionOverUnion:rect:]
  -[VCPVideoHumanActionAnalyzer addActiveResults:]
  -[VCPVideoHumanActionAnalyzer processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:]
  -[VCPVideoHumanActionAnalyzer initWithFrameStats:]
  -[VCPVideoHumanActionAnalyzer privateResults]
  -[VCPVideoHumanActionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoHumanActionAnalyzer finishAnalysisPass:]


VCPPhotosSceneprintAssetProcessingTask : NSObject /usr/lib/libc++.1.dylib <VCPMADTaskProtocol>
  // class methods
  +[VCPPhotosSceneprintAssetProcessingTask _panoVNRequestMethod]
  +[VCPPhotosSceneprintAssetProcessingTask taskWithAssets:andCompletionHandler:]

  // instance methods
  -[VCPPhotosSceneprintAssetProcessingTask run]
  -[VCPPhotosSceneprintAssetProcessingTask dealloc]
  -[VCPPhotosSceneprintAssetProcessingTask .cxx_destruct]
  -[VCPPhotosSceneprintAssetProcessingTask run:]
  -[VCPPhotosSceneprintAssetProcessingTask resourceRequirement]
  -[VCPPhotosSceneprintAssetProcessingTask cancel]
  -[VCPPhotosSceneprintAssetProcessingTask initWithAssets:andCompletionHandler:]


VCPProtoMovieOrientationResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int orientation

  // class methods
  +[VCPProtoMovieOrientationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieOrientationResult copyWithZone:]
  -[VCPProtoMovieOrientationResult setTimeRange:]
  -[VCPProtoMovieOrientationResult exportToLegacyDictionary]
  -[VCPProtoMovieOrientationResult .cxx_destruct]
  -[VCPProtoMovieOrientationResult timeRange]
  -[VCPProtoMovieOrientationResult readFrom:]
  -[VCPProtoMovieOrientationResult writeTo:]
  -[VCPProtoMovieOrientationResult isEqual:]
  -[VCPProtoMovieOrientationResult setOrientation:]
  -[VCPProtoMovieOrientationResult orientation]
  -[VCPProtoMovieOrientationResult copyTo:]
  -[VCPProtoMovieOrientationResult dictionaryRepresentation]
  -[VCPProtoMovieOrientationResult mergeFrom:]


VCPProtoMoviePreEncodeResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *statisticsBlob

  // class methods
  +[VCPProtoMoviePreEncodeResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePreEncodeResult copyWithZone:]
  -[VCPProtoMoviePreEncodeResult exportToLegacyDictionary]
  -[VCPProtoMoviePreEncodeResult .cxx_destruct]
  -[VCPProtoMoviePreEncodeResult readFrom:]
  -[VCPProtoMoviePreEncodeResult writeTo:]
  -[VCPProtoMoviePreEncodeResult isEqual:]
  -[VCPProtoMoviePreEncodeResult setStatisticsBlob:]
  -[VCPProtoMoviePreEncodeResult statisticsBlob]
  -[VCPProtoMoviePreEncodeResult copyTo:]
  -[VCPProtoMoviePreEncodeResult dictionaryRepresentation]
  -[VCPProtoMoviePreEncodeResult mergeFrom:]


VCPProtoMovieQualityResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore

  // class methods
  +[VCPProtoMovieQualityResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieQualityResult copyWithZone:]
  -[VCPProtoMovieQualityResult setTimeRange:]
  -[VCPProtoMovieQualityResult exportToLegacyDictionary]
  -[VCPProtoMovieQualityResult .cxx_destruct]
  -[VCPProtoMovieQualityResult timeRange]
  -[VCPProtoMovieQualityResult readFrom:]
  -[VCPProtoMovieQualityResult writeTo:]
  -[VCPProtoMovieQualityResult isEqual:]
  -[VCPProtoMovieQualityResult copyTo:]
  -[VCPProtoMovieQualityResult dictionaryRepresentation]
  -[VCPProtoMovieQualityResult mergeFrom:]
  -[VCPProtoMovieQualityResult qualityScore]
  -[VCPProtoMovieQualityResult setQualityScore:]


VCPProtoMovieSaliencyResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMovieSaliencyResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSaliencyResult copyWithZone:]
  -[VCPProtoMovieSaliencyResult setTimeRange:]
  -[VCPProtoMovieSaliencyResult exportToLegacyDictionary]
  -[VCPProtoMovieSaliencyResult setConfidence:]
  -[VCPProtoMovieSaliencyResult .cxx_destruct]
  -[VCPProtoMovieSaliencyResult timeRange]
  -[VCPProtoMovieSaliencyResult confidence]
  -[VCPProtoMovieSaliencyResult setBounds:]
  -[VCPProtoMovieSaliencyResult readFrom:]
  -[VCPProtoMovieSaliencyResult bounds]
  -[VCPProtoMovieSaliencyResult writeTo:]
  -[VCPProtoMovieSaliencyResult isEqual:]
  -[VCPProtoMovieSaliencyResult copyTo:]
  -[VCPProtoMovieSaliencyResult dictionaryRepresentation]
  -[VCPProtoMovieSaliencyResult mergeFrom:]


VCPProtoMovieSceneResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore
 @property  BOOL hasDistanceToPreviousScene
 @property  float distanceToPreviousScene
 @property  BOOL hasFlickerScore
 @property  float flickerScore
 @property  BOOL hasSceneprintDistanceToPreviousScene
 @property  float sceneprintDistanceToPreviousScene

  // class methods
  +[VCPProtoMovieSceneResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSceneResult copyWithZone:]
  -[VCPProtoMovieSceneResult setTimeRange:]
  -[VCPProtoMovieSceneResult exportToLegacyDictionary]
  -[VCPProtoMovieSceneResult .cxx_destruct]
  -[VCPProtoMovieSceneResult timeRange]
  -[VCPProtoMovieSceneResult readFrom:]
  -[VCPProtoMovieSceneResult writeTo:]
  -[VCPProtoMovieSceneResult isEqual:]
  -[VCPProtoMovieSceneResult copyTo:]
  -[VCPProtoMovieSceneResult setDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult setHasDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult hasDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult setFlickerScore:]
  -[VCPProtoMovieSceneResult setHasFlickerScore:]
  -[VCPProtoMovieSceneResult hasFlickerScore]
  -[VCPProtoMovieSceneResult setSceneprintDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult setHasSceneprintDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult dictionaryRepresentation]
  -[VCPProtoMovieSceneResult hasSceneprintDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult distanceToPreviousScene]
  -[VCPProtoMovieSceneResult flickerScore]
  -[VCPProtoMovieSceneResult sceneprintDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult mergeFrom:]
  -[VCPProtoMovieSceneResult qualityScore]
  -[VCPProtoMovieSceneResult setQualityScore:]


VCPProtoMovieSubjectMotionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  BOOL hasAction

  // class methods
  +[VCPProtoMovieSubjectMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSubjectMotionResult copyWithZone:]
  -[VCPProtoMovieSubjectMotionResult setTimeRange:]
  -[VCPProtoMovieSubjectMotionResult exportToLegacyDictionary]
  -[VCPProtoMovieSubjectMotionResult .cxx_destruct]
  -[VCPProtoMovieSubjectMotionResult timeRange]
  -[VCPProtoMovieSubjectMotionResult hasAction]
  -[VCPProtoMovieSubjectMotionResult readFrom:]
  -[VCPProtoMovieSubjectMotionResult writeTo:]
  -[VCPProtoMovieSubjectMotionResult isEqual:]
  -[VCPProtoMovieSubjectMotionResult copyTo:]
  -[VCPProtoMovieSubjectMotionResult dictionaryRepresentation]
  -[VCPProtoMovieSubjectMotionResult mergeFrom:]
  -[VCPProtoMovieSubjectMotionResult setHasAction:]


VCPFaceClusterer : NSObject /usr/lib/libc++.1.dylib
 @property  @? updateBlock

  // instance methods
  -[VCPFaceClusterer initWithPhotoLibrary:andContext:]
  -[VCPFaceClusterer resetFaceClusteringState:]
  -[VCPFaceClusterer .cxx_destruct]
  -[VCPFaceClusterer stop]
  -[VCPFaceClusterer updateBlock]
  -[VCPFaceClusterer setUpdateBlock:]
  -[VCPFaceClusterer reclusterFacesWithThreshold:shouldRecluster:withContext:extendTimeout:cancel:error:]
  -[VCPFaceClusterer clusterer]
  -[VCPFaceClusterer startAndSyncClusterCacheWithLibrary:reply:]
  -[VCPFaceClusterer performFaceClusteringAndWait]
  -[VCPFaceClusterer clustererState]
  -[VCPFaceClusterer clusterFacesWithExtendTimeoutBlock:andCancelBlock:]
  -[VCPFaceClusterer performFaceClusteringWithCompletion:]
  -[VCPFaceClusterer cancelFaceClustering]
  -[VCPFaceClusterer performFaceClusteringIfNecessaryAndWait]
  -[VCPFaceClusterer scheduleClusteringOfFacesWithLocalIdentifiers:]
  -[VCPFaceClusterer numberOfFacesPendingClustering]
  -[VCPFaceClusterer scheduleUnclusteringOfFacesWithClusterSequenceNumbers:]
  -[VCPFaceClusterer clusteringStatus]
  -[VCPFaceClusterer reclusterFacesWithThreshold:shouldRecluster:error:]
  -[VCPFaceClusterer getFaceClusters:clusteringThreshold:utilizingGPU:error:]
  -[VCPFaceClusterer clustererIsReadyToReturnSuggestions]
  -[VCPFaceClusterer resetClusterer]
  -[VCPFaceClusterer clusterFacesIfNecessaryWithExtendTimeoutBlock:andCancelBlock:]
  -[VCPFaceClusterer differencesBetweenClustersInClusterCacheAndLibrary:]
  -[VCPFaceClusterer _resetFaceClusteringStateWithContext:error:]


VCPProtoMovieSummaryResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float curationScore
 @property  BOOL hasKeyFrame
 @property  VCPProtoVideoKeyFrame *keyFrame
 @property  BOOL autoPlayable
 @property  BOOL hasPlaybackCrop
 @property  VCPProtoBounds *playbackCrop

  // class methods
  +[VCPProtoMovieSummaryResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSummaryResult copyWithZone:]
  -[VCPProtoMovieSummaryResult setTimeRange:]
  -[VCPProtoMovieSummaryResult exportToLegacyDictionary]
  -[VCPProtoMovieSummaryResult .cxx_destruct]
  -[VCPProtoMovieSummaryResult timeRange]
  -[VCPProtoMovieSummaryResult setKeyFrame:]
  -[VCPProtoMovieSummaryResult readFrom:]
  -[VCPProtoMovieSummaryResult setCurationScore:]
  -[VCPProtoMovieSummaryResult writeTo:]
  -[VCPProtoMovieSummaryResult isEqual:]
  -[VCPProtoMovieSummaryResult keyFrame]
  -[VCPProtoMovieSummaryResult curationScore]
  -[VCPProtoMovieSummaryResult copyTo:]
  -[VCPProtoMovieSummaryResult dictionaryRepresentation]
  -[VCPProtoMovieSummaryResult hasKeyFrame]
  -[VCPProtoMovieSummaryResult setPlaybackCrop:]
  -[VCPProtoMovieSummaryResult hasPlaybackCrop]
  -[VCPProtoMovieSummaryResult autoPlayable]
  -[VCPProtoMovieSummaryResult setAutoPlayable:]
  -[VCPProtoMovieSummaryResult playbackCrop]
  -[VCPProtoMovieSummaryResult mergeFrom:]


VCPProtoMovieUtteranceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange

  // class methods
  +[VCPProtoMovieUtteranceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieUtteranceResult copyWithZone:]
  -[VCPProtoMovieUtteranceResult setTimeRange:]
  -[VCPProtoMovieUtteranceResult exportToLegacyDictionary]
  -[VCPProtoMovieUtteranceResult .cxx_destruct]
  -[VCPProtoMovieUtteranceResult timeRange]
  -[VCPProtoMovieUtteranceResult readFrom:]
  -[VCPProtoMovieUtteranceResult writeTo:]
  -[VCPProtoMovieUtteranceResult isEqual:]
  -[VCPProtoMovieUtteranceResult copyTo:]
  -[VCPProtoMovieUtteranceResult dictionaryRepresentation]
  -[VCPProtoMovieUtteranceResult mergeFrom:]


VCPProtoMovieVoiceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieVoiceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieVoiceResult copyWithZone:]
  -[VCPProtoMovieVoiceResult setTimeRange:]
  -[VCPProtoMovieVoiceResult exportToLegacyDictionary]
  -[VCPProtoMovieVoiceResult setConfidence:]
  -[VCPProtoMovieVoiceResult .cxx_destruct]
  -[VCPProtoMovieVoiceResult timeRange]
  -[VCPProtoMovieVoiceResult confidence]
  -[VCPProtoMovieVoiceResult readFrom:]
  -[VCPProtoMovieVoiceResult writeTo:]
  -[VCPProtoMovieVoiceResult isEqual:]
  -[VCPProtoMovieVoiceResult copyTo:]
  -[VCPProtoMovieVoiceResult dictionaryRepresentation]
  -[VCPProtoMovieVoiceResult mergeFrom:]


VCPProtoPoint : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  double x
 @property  double y

  // class methods
  +[VCPProtoPoint pointWithPoint:]

  // instance methods
  -[VCPProtoPoint copyWithZone:]
  -[VCPProtoPoint x]
  -[VCPProtoPoint setY:]
  -[VCPProtoPoint setX:]
  -[VCPProtoPoint y]
  -[VCPProtoPoint readFrom:]
  -[VCPProtoPoint writeTo:]
  -[VCPProtoPoint pointValue]
  -[VCPProtoPoint isEqual:]
  -[VCPProtoPoint copyTo:]
  -[VCPProtoPoint dictionaryRepresentation]
  -[VCPProtoPoint mergeFrom:]


VCPProtoMoviePetsFaceResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMoviePetsFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePetsFaceResult copyWithZone:]
  -[VCPProtoMoviePetsFaceResult setTimeRange:]
  -[VCPProtoMoviePetsFaceResult exportToLegacyDictionary]
  -[VCPProtoMoviePetsFaceResult setConfidence:]
  -[VCPProtoMoviePetsFaceResult .cxx_destruct]
  -[VCPProtoMoviePetsFaceResult timeRange]
  -[VCPProtoMoviePetsFaceResult confidence]
  -[VCPProtoMoviePetsFaceResult setBounds:]
  -[VCPProtoMoviePetsFaceResult readFrom:]
  -[VCPProtoMoviePetsFaceResult bounds]
  -[VCPProtoMoviePetsFaceResult writeTo:]
  -[VCPProtoMoviePetsFaceResult isEqual:]
  -[VCPProtoMoviePetsFaceResult copyTo:]
  -[VCPProtoMoviePetsFaceResult dictionaryRepresentation]
  -[VCPProtoMoviePetsFaceResult mergeFrom:]


VCPProtoTime : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  long long value
 @property  int timescale
 @property  unsigned int flags
 @property  long long epoch

  // class methods
  +[VCPProtoTime timeWithCMTime:]

  // instance methods
  -[VCPProtoTime copyWithZone:]
  -[VCPProtoTime epoch]
  -[VCPProtoTime setFlags:]
  -[VCPProtoTime setEpoch:]
  -[VCPProtoTime timescale]
  -[VCPProtoTime setTimescale:]
  -[VCPProtoTime readFrom:]
  -[VCPProtoTime writeTo:]
  -[VCPProtoTime setValue:]
  -[VCPProtoTime isEqual:]
  -[VCPProtoTime value]
  -[VCPProtoTime flags]
  -[VCPProtoTime copyTo:]
  -[VCPProtoTime dictionaryRepresentation]
  -[VCPProtoTime timeValue]
  -[VCPProtoTime mergeFrom:]


VCPProtoTimeRange : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  VCPProtoTime *start
 @property  VCPProtoTime *duration

  // class methods
  +[VCPProtoTimeRange timeRangeWithCMTimeRange:]

  // instance methods
  -[VCPProtoTimeRange copyWithZone:]
  -[VCPProtoTimeRange .cxx_destruct]
  -[VCPProtoTimeRange setStart:]
  -[VCPProtoTimeRange readFrom:]
  -[VCPProtoTimeRange writeTo:]
  -[VCPProtoTimeRange isEqual:]
  -[VCPProtoTimeRange setDuration:]
  -[VCPProtoTimeRange timeRangeValue]
  -[VCPProtoTimeRange copyTo:]
  -[VCPProtoTimeRange dictionaryRepresentation]
  -[VCPProtoTimeRange mergeFrom:]
  -[VCPProtoTimeRange duration]
  -[VCPProtoTimeRange start]


VCPProtoVideoKeyFrame : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <NSCopying>
 @property  VCPProtoTime *timestamp
 @property  float curationScore

  // instance methods
  -[VCPProtoVideoKeyFrame copyWithZone:]
  -[VCPProtoVideoKeyFrame .cxx_destruct]
  -[VCPProtoVideoKeyFrame timestamp]
  -[VCPProtoVideoKeyFrame setTimestamp:]
  -[VCPProtoVideoKeyFrame readFrom:]
  -[VCPProtoVideoKeyFrame setCurationScore:]
  -[VCPProtoVideoKeyFrame writeTo:]
  -[VCPProtoVideoKeyFrame isEqual:]
  -[VCPProtoVideoKeyFrame curationScore]
  -[VCPProtoVideoKeyFrame copyTo:]
  -[VCPProtoVideoKeyFrame dictionaryRepresentation]
  -[VCPProtoVideoKeyFrame mergeFrom:]


VCPCallerIdentificationResult : NSObject /usr/lib/libc++.1.dylib
 @property  PHFace *face
 @property  NSString *callerIdentifier
 @property  float confidence

  // instance methods
  -[VCPCallerIdentificationResult face]
  -[VCPCallerIdentificationResult .cxx_destruct]
  -[VCPCallerIdentificationResult confidence]
  -[VCPCallerIdentificationResult callerIdentifier]
  -[VCPCallerIdentificationResult initWithCallerIdentifier:face:andConfidence:]


VCPRealTimeAnalysisService : NSObject /usr/lib/libc++.1.dylib <VCPRealTimeAnalysisClientProtocol>
  // class methods
  +[VCPRealTimeAnalysisService analysisService]
  +[VCPRealTimeAnalysisService errorWithStatus:andDescription:]

  // instance methods
  -[VCPRealTimeAnalysisService init]
  -[VCPRealTimeAnalysisService dealloc]
  -[VCPRealTimeAnalysisService .cxx_destruct]
  -[VCPRealTimeAnalysisService connection]
  -[VCPRealTimeAnalysisService requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:]
  -[VCPRealTimeAnalysisService invalidate]


VCPRTLandmarkDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPRTLandmarkDetector dealloc]
  -[VCPRTLandmarkDetector initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:]
  -[VCPRTLandmarkDetector detectLandmark:width:height:stride:facerect:prevResult:result:]
  -[VCPRTLandmarkDetector calculateFaceRectFromPrevLM:result:numOfLandmarks:]


VCPProtoMovieStabilizationRecipe : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float cropRectX
 @property  float cropRectY
 @property  float cropRectHeight
 @property  float cropRectWidth
 @property  float inputBoundsX
 @property  float inputBoundsY
 @property  float inputBoundsHeight
 @property  float inputBoundsWidth
 @property  float sourceSizeHeight
 @property  float sourceSizeWidth
 @property  int timeScale
 @property  unsigned long timeValuesCount
 @property  ^q timeValues
 @property  unsigned long homographyParamsCount
 @property  ^f homographyParams

  // class methods
  +[VCPProtoMovieStabilizationRecipe resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieStabilizationRecipe copyWithZone:]
  -[VCPProtoMovieStabilizationRecipe timeScale]
  -[VCPProtoMovieStabilizationRecipe exportToLegacyDictionary]
  -[VCPProtoMovieStabilizationRecipe dealloc]
  -[VCPProtoMovieStabilizationRecipe cropRectX]
  -[VCPProtoMovieStabilizationRecipe cropRectY]
  -[VCPProtoMovieStabilizationRecipe readFrom:]
  -[VCPProtoMovieStabilizationRecipe setCropRectX:]
  -[VCPProtoMovieStabilizationRecipe setCropRectY:]
  -[VCPProtoMovieStabilizationRecipe cropRectHeight]
  -[VCPProtoMovieStabilizationRecipe setCropRectHeight:]
  -[VCPProtoMovieStabilizationRecipe cropRectWidth]
  -[VCPProtoMovieStabilizationRecipe setCropRectWidth:]
  -[VCPProtoMovieStabilizationRecipe setTimeScale:]
  -[VCPProtoMovieStabilizationRecipe writeTo:]
  -[VCPProtoMovieStabilizationRecipe homographyParamsCount]
  -[VCPProtoMovieStabilizationRecipe clearHomographyParams]
  -[VCPProtoMovieStabilizationRecipe homographyParams]
  -[VCPProtoMovieStabilizationRecipe setHomographyParams:count:]
  -[VCPProtoMovieStabilizationRecipe isEqual:]
  -[VCPProtoMovieStabilizationRecipe copyTo:]
  -[VCPProtoMovieStabilizationRecipe dictionaryRepresentation]
  -[VCPProtoMovieStabilizationRecipe timeValues]
  -[VCPProtoMovieStabilizationRecipe timeValuesCount]
  -[VCPProtoMovieStabilizationRecipe clearTimeValues]
  -[VCPProtoMovieStabilizationRecipe mergeFrom:]
  -[VCPProtoMovieStabilizationRecipe timeValueAtIndex:]
  -[VCPProtoMovieStabilizationRecipe addTimeValue:]
  -[VCPProtoMovieStabilizationRecipe homographyParamsAtIndex:]
  -[VCPProtoMovieStabilizationRecipe addHomographyParams:]
  -[VCPProtoMovieStabilizationRecipe setTimeValues:count:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsX]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsX:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsY]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsY:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsHeight]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsHeight:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsWidth]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsWidth:]
  -[VCPProtoMovieStabilizationRecipe sourceSizeHeight]
  -[VCPProtoMovieStabilizationRecipe setSourceSizeHeight:]
  -[VCPProtoMovieStabilizationRecipe sourceSizeWidth]
  -[VCPProtoMovieStabilizationRecipe setSourceSizeWidth:]


VCPSceneTaxonomy : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPSceneTaxonomy sharedTaxonomy]

  // instance methods
  -[VCPSceneTaxonomy init]
  -[VCPSceneTaxonomy sceneNameFromSceneId:]
  -[VCPSceneTaxonomy .cxx_destruct]
  -[VCPSceneTaxonomy sceneIdFromSceneName:]


VCPSegment : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames
 @property  unsigned long numOfValidFrames
 @property  float curationScore

  // instance methods
  -[VCPSegment setTimeRange:]
  -[VCPSegment init]
  -[VCPSegment timeRange]
  -[VCPSegment mergeSegment:]
  -[VCPSegment score]
  -[VCPSegment setCurationScore:]
  -[VCPSegment copyFrom:]
  -[VCPSegment numOfFrames]
  -[VCPSegment curationScore]
  -[VCPSegment numOfValidFrames]
  -[VCPSegment sumOfScore]
  -[VCPSegment initWithTimestamp:score:valid:]
  -[VCPSegment updateWithFirstFrame:score:valid:]
  -[VCPSegment updateSegment:score:valid:]
  -[VCPSegment updateDuration:]
  -[VCPSegment trimSegment:fromStart:]
  -[VCPSegment isContentTooShort]


VCPMovieAssetWriter : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPMovieAssetWriter assetWriterWithURL:andTrack:]

  // instance methods
  -[VCPMovieAssetWriter .cxx_construct]
  -[VCPMovieAssetWriter dealloc]
  -[VCPMovieAssetWriter .cxx_destruct]
  -[VCPMovieAssetWriter finish]
  -[VCPMovieAssetWriter setupMetadataTrack]
  -[VCPMovieAssetWriter initWithURL:andTrack:]
  -[VCPMovieAssetWriter popSample]
  -[VCPMovieAssetWriter pushSample:]
  -[VCPMovieAssetWriter processMediaRequest]
  -[VCPMovieAssetWriter createAssetWriterInputWithFormatDescription:]
  -[VCPMovieAssetWriter copyPixelBuffer:toPixelBuffer:]
  -[VCPMovieAssetWriter appendMetadataTrack]
  -[VCPMovieAssetWriter addPixelBuffer:withTime:]


VCPSharedInstanceManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPSharedInstanceManager sharedManager]

  // instance methods
  -[VCPSharedInstanceManager init]
  -[VCPSharedInstanceManager .cxx_destruct]
  -[VCPSharedInstanceManager reset]
  -[VCPSharedInstanceManager sharedInstanceWithIdentifier:andCreationBlock:]


VCPTrimAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPTrimAnalyzer isReady]
  -[VCPTrimAnalyzer init]
  -[VCPTrimAnalyzer .cxx_destruct]
  -[VCPTrimAnalyzer printSegments:]
  -[VCPTrimAnalyzer prepareTrimmingWithTrimStart:andTrimEnd:]
  -[VCPTrimAnalyzer shouldCutAt:stillPTS:withCut:]
  -[VCPTrimAnalyzer analyzeFrameWithTimeRange:analysisData:]
  -[VCPTrimAnalyzer generateCurationSegment]
  -[VCPTrimAnalyzer generateInterestingTrimBasedOnCaptureTime:]
  -[VCPTrimAnalyzer updateCurationThreshold]
  -[VCPTrimAnalyzer calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:]
  -[VCPTrimAnalyzer isCurated:]
  -[VCPTrimAnalyzer isTimestampSkipable:]
  -[VCPTrimAnalyzer checkTrimAt:captureTime:]
  -[VCPTrimAnalyzer finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:]
  -[VCPTrimAnalyzer bestTrimTimeRange]


VCPURLAsset : VCPAsset
  // class methods
  +[VCPURLAsset movieAssetWithURL:]
  +[VCPURLAsset livePhotoAssetWithImageURL:andMovieURL:]
  +[VCPURLAsset imageAssetWithURL:]
  +[VCPURLAsset sdofImageAssetWithURL:]

  // instance methods
  -[VCPURLAsset scenes]
  -[VCPURLAsset pixelHeight]
  -[VCPURLAsset mediaType]
  -[VCPURLAsset exif]
  -[VCPURLAsset movie]
  -[VCPURLAsset .cxx_destruct]
  -[VCPURLAsset mediaSubtypes]
  -[VCPURLAsset pixelWidth]
  -[VCPURLAsset mainFileURL]
  -[VCPURLAsset slowmoRate]
  -[VCPURLAsset imageWithPreferredDimension:]
  -[VCPURLAsset photoOffsetSeconds]
  -[VCPURLAsset originalPhotoOffsetSeconds]
  -[VCPURLAsset originalMovie]
  -[VCPURLAsset initWithImageURL:isSDOF:]
  -[VCPURLAsset initWithMovieURL:]
  -[VCPURLAsset initWithImageURL:andMovieURL:]
  -[VCPURLAsset modificationDate]
  -[VCPURLAsset duration]


VCPVideoChatAnalysis : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVideoChatAnalysis videoChatAnalysis]

  // instance methods
  -[VCPVideoChatAnalysis init]
  -[VCPVideoChatAnalysis .cxx_destruct]
  -[VCPVideoChatAnalysis detectFaces:]
  -[VCPVideoChatAnalysis checkAddFaces]
  -[VCPVideoChatAnalysis analyzeFrame:]
  -[VCPVideoChatAnalysis persistAnalysis]


VCPVideoActivityAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoActivityAnalyzer results]
  -[VCPVideoActivityAnalyzer .cxx_destruct]
  -[VCPVideoActivityAnalyzer normalizeActivityDescriptor]
  -[VCPVideoActivityAnalyzer prepareActivityStats]
  -[VCPVideoActivityAnalyzer generateActivityDescriptor]
  -[VCPVideoActivityAnalyzer computeActivityScoreAtTime:]
  -[VCPVideoActivityAnalyzer resetActivityStatsAtTime:]
  -[VCPVideoActivityAnalyzer extractRequiredInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer extractRequiredClassificationInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer extractRequiredFaceInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer actionScoreInTimeRange:]
  -[VCPVideoActivityAnalyzer validateActivityScores]
  -[VCPVideoActivityAnalyzer validationScoreOfTimeRange:fromResult:startIdx:]
  -[VCPVideoActivityAnalyzer scaleBasedOnFaceForTimeRange:]
  -[VCPVideoActivityAnalyzer addSceneSwitchFrequencyConstributionToActivityLevel:]
  -[VCPVideoActivityAnalyzer addSceneClassificationContributionToActivityLevel:]
  -[VCPVideoActivityAnalyzer initWithFrameStats:]
  -[VCPVideoActivityAnalyzer finishAnalysisPass:fpsRate:]
  -[VCPVideoActivityAnalyzer preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:]
  -[VCPVideoActivityAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]


VCPCompactResult : NSObject /usr/lib/libc++.1.dylib
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score

  // instance methods
  -[VCPCompactResult setScore:]
  -[VCPCompactResult timerange]
  -[VCPCompactResult setTimerange:]
  -[VCPCompactResult score]
  -[VCPCompactResult initWithTimerange:andScore:]


VCPVideoActivityDescriptor : NSObject /usr/lib/libc++.1.dylib
 @property  ^f descriptors

  // instance methods
  -[VCPVideoActivityDescriptor descriptors]
  -[VCPVideoActivityDescriptor dealloc]
  -[VCPVideoActivityDescriptor reset]
  -[VCPVideoActivityDescriptor initWithFrameWidthInMb:heightInMb:]
  -[VCPVideoActivityDescriptor spatialDescriptorWithMvMagnitudeMean:]
  -[VCPVideoActivityDescriptor ExtractActivityDescriptorFromStats:]


VCPVideoHumanActionClassifier : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoHumanActionClassifier init]
  -[VCPVideoHumanActionClassifier results]
  -[VCPVideoHumanActionClassifier dealloc]
  -[VCPVideoHumanActionClassifier detect]
  -[VCPVideoHumanActionClassifier .cxx_destruct]
  -[VCPVideoHumanActionClassifier createModel]
  -[VCPVideoHumanActionClassifier prepareData:]
  -[VCPVideoHumanActionClassifier analyzeBodyArray:]
  -[VCPVideoHumanActionClassifier privateResults]
  -[VCPVideoHumanActionClassifier keypointsFromObservations:]
  -[VCPVideoHumanActionClassifier analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoHumanActionClassifier finishAnalysisPass:]


VCPProtoMovieSubtleMotionResult : PBCodable /System/Library/PrivateFrameworks/SoftLinking.framework/SoftLinking <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float actionScore

  // class methods
  +[VCPProtoMovieSubtleMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSubtleMotionResult copyWithZone:]
  -[VCPProtoMovieSubtleMotionResult setTimeRange:]
  -[VCPProtoMovieSubtleMotionResult exportToLegacyDictionary]
  -[VCPProtoMovieSubtleMotionResult .cxx_destruct]
  -[VCPProtoMovieSubtleMotionResult timeRange]
  -[VCPProtoMovieSubtleMotionResult readFrom:]
  -[VCPProtoMovieSubtleMotionResult setActionScore:]
  -[VCPProtoMovieSubtleMotionResult actionScore]
  -[VCPProtoMovieSubtleMotionResult writeTo:]
  -[VCPProtoMovieSubtleMotionResult isEqual:]
  -[VCPProtoMovieSubtleMotionResult copyTo:]
  -[VCPProtoMovieSubtleMotionResult dictionaryRepresentation]
  -[VCPProtoMovieSubtleMotionResult mergeFrom:]


VCPVideoAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVideoAnalyzer dependencies]

  // instance methods
  -[VCPVideoAnalyzer results]
  -[VCPVideoAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoAnalyzer finishAnalysisPass:]


VCPVideoFaceDetector : VCPVideoAnalyzer
  // class methods
  +[VCPVideoFaceDetector faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:]

  // instance methods
  -[VCPVideoFaceDetector results]
  -[VCPVideoFaceDetector .cxx_destruct]
  -[VCPVideoFaceDetector faceRanges]


VCPVideoFaceMeshAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  {?=[4]} pose
 @property  NSDictionary *blendShapes
 @property  unsigned long vertexCount
 @property  r^ vertices
 @property  r^f landmarks
 @property  BOOL bufferRotated

  // instance methods
  -[VCPVideoFaceMeshAnalyzer pose]
  -[VCPVideoFaceMeshAnalyzer vertexCount]
  -[VCPVideoFaceMeshAnalyzer dealloc]
  -[VCPVideoFaceMeshAnalyzer .cxx_destruct]
  -[VCPVideoFaceMeshAnalyzer setFrame:]
  -[VCPVideoFaceMeshAnalyzer landmarks]
  -[VCPVideoFaceMeshAnalyzer updateFocalLengthInPixels:]
  -[VCPVideoFaceMeshAnalyzer blendShapes]
  -[VCPVideoFaceMeshAnalyzer vertices]
  -[VCPVideoFaceMeshAnalyzer initWithFocalLengthInPixels:offline:]
  -[VCPVideoFaceMeshAnalyzer isTracked]
  -[VCPVideoFaceMeshAnalyzer analyzeFrame:withFaceRect:withRotation:withTimestamp:]
  -[VCPVideoFaceMeshAnalyzer makeValidationDecision]
  -[VCPVideoFaceMeshAnalyzer updateIntrinsicWhenRotated]
  -[VCPVideoFaceMeshAnalyzer checkResolutionChange:withRotation:]
  -[VCPVideoFaceMeshAnalyzer validateFace:eulerAngles:]
  -[VCPVideoFaceMeshAnalyzer rotateLandmarks:width:height:landmarks:numLandmarks:]
  -[VCPVideoFaceMeshAnalyzer mapToCameraNegativeZ]
  -[VCPVideoFaceMeshAnalyzer bufferRotated]


VCPFacePair : NSObject /usr/lib/libc++.1.dylib
 @property  PVFace *face1
 @property  PVFace *face2
 @property  double score

  // instance methods
  -[VCPFacePair face1]
  -[VCPFacePair face2]
  -[VCPFacePair .cxx_destruct]
  -[VCPFacePair score]
  -[VCPFacePair initWithFace:andFace:andScore:]


VCPFaceMerger : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPFaceMerger _allowANE]

  // instance methods
  -[VCPFaceMerger mergeExistingFaces:withDetectedFaces:forImage:]
  -[VCPFaceMerger initWithContext:]
  -[VCPFaceMerger .cxx_destruct]
  -[VCPFaceMerger _bboxAlignedFaceObservationsFromFaceObservations:inImage:withError:]
  -[VCPFaceMerger _configureRequest:withRevision:]
  -[VCPFaceMerger _sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:]
  -[VCPFaceMerger _alignBBoxForPVFaces:forImage:]
  -[VCPFaceMerger _faceObservationsWithBBoxFromPVFaces:mapping:]


VCPPetsRegion : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bound
 @property  float confidence

  // instance methods
  -[VCPPetsRegion bound]
  -[VCPPetsRegion setConfidence:]
  -[VCPPetsRegion confidence]
  -[VCPPetsRegion initWith:confidence:]
  -[VCPPetsRegion setBound:]


VCPVideoPetsAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoPetsAnalyzer results]
  -[VCPVideoPetsAnalyzer .cxx_destruct]
  -[VCPVideoPetsAnalyzer initWithTransform:]
  -[VCPVideoPetsAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoPetsAnalyzer finishAnalysisPass:]
  -[VCPVideoPetsAnalyzer parseResults:toDetections:atTime:fromTime:addActiveRegions:]
  -[VCPVideoPetsAnalyzer addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:]


VCPVideoFacePoseAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  {?=[4]} pose

  // instance methods
  -[VCPVideoFacePoseAnalyzer pose]
  -[VCPVideoFacePoseAnalyzer init]
  -[VCPVideoFacePoseAnalyzer setPose:]
  -[VCPVideoFacePoseAnalyzer .cxx_destruct]
  -[VCPVideoFacePoseAnalyzer updateFocalLengthInPixels:]
  -[VCPVideoFacePoseAnalyzer initWithFocalLengthInPixels:]
  -[VCPVideoFacePoseAnalyzer analyzeFrameForPose:withFaceRect:withTimestamp:]


VCPVideoFacePoseFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVideoFacePoseFilter .cxx_construct]
  -[VCPVideoFacePoseFilter reset]
  -[VCPVideoFacePoseFilter rotationToEulerAngles:angles:]
  -[VCPVideoFacePoseFilter kalmanFiltering:T:]
  -[VCPVideoFacePoseFilter eulerAnglesToRotation:R:]
  -[VCPVideoFacePoseFilter filteringPose:]


VCPVideoFullFaceDetector : VCPVideoFaceDetector
  // instance methods
  -[VCPVideoFullFaceDetector minProcessTimeIntervalInSecs]
  -[VCPVideoFullFaceDetector detectFaces:faces:]
  -[VCPVideoFullFaceDetector compareFace:withFace:]
  -[VCPVideoFullFaceDetector removeSmallestKeyFace]
  -[VCPVideoFullFaceDetector detectTrackFacesInFrame:withTimestamp:faces:]
  -[VCPVideoFullFaceDetector clusterFaces]
  -[VCPVideoFullFaceDetector updateWithExistingFaces]
  -[VCPVideoFullFaceDetector locationChange:relativeTo:landscape:]
  -[VCPVideoFullFaceDetector dealloc]
  -[VCPVideoFullFaceDetector .cxx_destruct]
  -[VCPVideoFullFaceDetector initWithTransform:]
  -[VCPVideoFullFaceDetector frameFaceResults]
  -[VCPVideoFullFaceDetector initWithTransform:withExistingFaceprints:frameStats:]
  -[VCPVideoFullFaceDetector faceRanges]
  -[VCPVideoFullFaceDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoFullFaceDetector finishAnalysisPass:]


VCPCNNHandKeypointsDetectorEspresso : VCPCNNHandKeypointsDetector
  // instance methods
  -[VCPCNNHandKeypointsDetectorEspresso dealloc]
  -[VCPCNNHandKeypointsDetectorEspresso .cxx_destruct]
  -[VCPCNNHandKeypointsDetectorEspresso init:sharedModel:modelName:]
  -[VCPCNNHandKeypointsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:]
  -[VCPCNNHandKeypointsDetectorEspresso generateHandKeypoints:keypointConfidence:offset:]


VCPVideoGlobalAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVideoGlobalAnalyzer hasMeaningfulSceneSegment:withFpsRate:]
  -[VCPVideoGlobalAnalyzer assetQualityScoreFromAnalysis:withFpsRate:]
  -[VCPVideoGlobalAnalyzer assetActionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetExpressionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetVoiceScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetJunkScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetCameraMotionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer scaleForTimeRange:basedOnFace:]
  -[VCPVideoGlobalAnalyzer isJunkTimeRange:basedOnResults:]
  -[VCPVideoGlobalAnalyzer subjectActivityInTimeRange:fromResults:]
  -[VCPVideoGlobalAnalyzer cameraActivityfromQuality:]
  -[VCPVideoGlobalAnalyzer assetActivityLevelFromAnalysisResults:]
  -[VCPVideoGlobalAnalyzer analyzeOverallQuality:withFpsRate:]
  -[VCPVideoGlobalAnalyzer setActivityLevel:]
  -[VCPVideoGlobalAnalyzer generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:]


VCPVideoKeyFrame : NSObject /usr/lib/libc++.1.dylib
 @property  {?=qiIq} timestamp
 @property  float score
 @property  float semanticScore
 @property  float sharpness
 @property  float faceSharpness
 @property  float exposureScore
 @property  BOOL isHeadingFrame
 @property  float textureScore
 @property  float expressionChangeScore
 @property  unsigned long statsFlags
 @property  NSMutableArray *detectedFaces
 @property  NSMutableArray *faceQualityScores
 @property  NSMutableDictionary *frameResults
 @property  float overallFaceQualityScore
 @property  float qualityScoreForLivePhoto
 @property  float globalQualityScore
 @property  float visualPleasingScore
 @property  float penaltyScore
 @property  float contentScore
 @property  float humanPoseScore
 @property  float humanActionScore

  // instance methods
  -[VCPVideoKeyFrame exposureScore]
  -[VCPVideoKeyFrame contentScore]
  -[VCPVideoKeyFrame setScore:]
  -[VCPVideoKeyFrame statsFlags]
  -[VCPVideoKeyFrame setDetectedFaces:]
  -[VCPVideoKeyFrame faceSharpness]
  -[VCPVideoKeyFrame isHeadingFrame]
  -[VCPVideoKeyFrame printStats]
  -[VCPVideoKeyFrame faceQualityScores]
  -[VCPVideoKeyFrame setFaceQualityScores:]
  -[VCPVideoKeyFrame setStatsFlags:]
  -[VCPVideoKeyFrame computeGlobalQuality]
  -[VCPVideoKeyFrame computeScoreFromColorfulness]
  -[VCPVideoKeyFrame computeScoreFromExposure]
  -[VCPVideoKeyFrame computeExpressionScore]
  -[VCPVideoKeyFrame computeScoreFromAction]
  -[VCPVideoKeyFrame computeGlobalQualityForLivePhoto]
  -[VCPVideoKeyFrame computeVisualPleasingScore]
  -[VCPVideoKeyFrame computePenaltyScore]
  -[VCPVideoKeyFrame computeContentScore]
  -[VCPVideoKeyFrame storeFrameResults]
  -[VCPVideoKeyFrame detectedFaces]
  -[VCPVideoKeyFrame computeCurationScoreComponents]
  -[VCPVideoKeyFrame setFrameResults:]
  -[VCPVideoKeyFrame loadKeyFrameResult:timestamp:]
  -[VCPVideoKeyFrame setFaceSharpness:]
  -[VCPVideoKeyFrame computeCurationScore]
  -[VCPVideoKeyFrame frameResults]
  -[VCPVideoKeyFrame hasGoodSubjectAction]
  -[VCPVideoKeyFrame setIsHeadingFrame:]
  -[VCPVideoKeyFrame resetStatsFlag]
  -[VCPVideoKeyFrame setFaceStatsFlag:detectedFaces:]
  -[VCPVideoKeyFrame setExpressionChangeScore:]
  -[VCPVideoKeyFrame setContentScore:]
  -[VCPVideoKeyFrame .cxx_destruct]
  -[VCPVideoKeyFrame setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:]
  -[VCPVideoKeyFrame timestamp]
  -[VCPVideoKeyFrame setTimestamp:]
  -[VCPVideoKeyFrame setExposureScore:]
  -[VCPVideoKeyFrame semanticScore]
  -[VCPVideoKeyFrame humanActionScore]
  -[VCPVideoKeyFrame humanPoseScore]
  -[VCPVideoKeyFrame setHumanActionScore:]
  -[VCPVideoKeyFrame setHumanPoseScore:]
  -[VCPVideoKeyFrame expressionChangeScore]
  -[VCPVideoKeyFrame score]
  -[VCPVideoKeyFrame initWithLivePhoto:]
  -[VCPVideoKeyFrame sharpness]
  -[VCPVideoKeyFrame copyFrom:]
  -[VCPVideoKeyFrame setSemanticScore:]
  -[VCPVideoKeyFrame setGlobalQualityScore:]
  -[VCPVideoKeyFrame qualityScoreForLivePhoto]
  -[VCPVideoKeyFrame setQualityScoreForLivePhoto:]
  -[VCPVideoKeyFrame visualPleasingScore]
  -[VCPVideoKeyFrame setVisualPleasingScore:]
  -[VCPVideoKeyFrame overallFaceQualityScore]
  -[VCPVideoKeyFrame setOverallFaceQualityScore:]
  -[VCPVideoKeyFrame penaltyScore]
  -[VCPVideoKeyFrame setPenaltyScore:]
  -[VCPVideoKeyFrame textureScore]
  -[VCPVideoKeyFrame setTextureScore:]
  -[VCPVideoKeyFrame globalQualityScore]
  -[VCPVideoKeyFrame setSharpness:]


VCPVideoKeyFrameAnalyzer : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPVideoKeyFrameAnalyzer setKeyFrameTime:isHeadingFrame:]
  -[VCPVideoKeyFrameAnalyzer prepareFrameStats:]
  -[VCPVideoKeyFrameAnalyzer computeSharpnessOfFrame:]
  -[VCPVideoKeyFrameAnalyzer computeFaceQualityOfFrame:]
  -[VCPVideoKeyFrameAnalyzer finalizeKeyFrame]
  -[VCPVideoKeyFrameAnalyzer adjustScoreByFace]
  -[VCPVideoKeyFrameAnalyzer modulateByJunk]
  -[VCPVideoKeyFrameAnalyzer modulateByTimeRange]
  -[VCPVideoKeyFrameAnalyzer setBlurAnalyzerFaceResults:]
  -[VCPVideoKeyFrameAnalyzer loadKeyFrameResults:]
  -[VCPVideoKeyFrameAnalyzer .cxx_destruct]
  -[VCPVideoKeyFrameAnalyzer modulateByExposure]
  -[VCPVideoKeyFrameAnalyzer computeMinDistanceBetween:withSet:]
  -[VCPVideoKeyFrameAnalyzer keyFrames]
  -[VCPVideoKeyFrameAnalyzer initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:]
  -[VCPVideoKeyFrameAnalyzer analyzeFrame:withTimestamp:]
  -[VCPVideoKeyFrameAnalyzer postProcess]
  -[VCPVideoKeyFrameAnalyzer preparePostProcessingStatsFromFaceRange:junkResults:]
  -[VCPVideoKeyFrameAnalyzer keyFrameScores]


VCPVideoLightFaceDetector : VCPVideoFaceDetector
  // instance methods
  -[VCPVideoLightFaceDetector minProcessTimeIntervalInSecs]
  -[VCPVideoLightFaceDetector detectFaces:faces:]
  -[VCPVideoLightFaceDetector dealloc]
  -[VCPVideoLightFaceDetector .cxx_destruct]
  -[VCPVideoLightFaceDetector initWithTransform:frameStats:faceDominated:]
  -[VCPVideoLightFaceDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoLightFaceDetector finishAnalysisPass:]


VCPVideoMetaAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *publicResults
 @property  NSDictionary *privateResults

  // class methods
  +[VCPVideoMetaAnalyzer analyzerForTrackType:withTransform:requestAnalyses:formatDescription:]

  // instance methods
  -[VCPVideoMetaAnalyzer publicResults]
  -[VCPVideoMetaAnalyzer finalizeAnalysis]
  -[VCPVideoMetaAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaAnalyzer privateResults]


VCPVideoMetaFaceAnalyzer : VCPVideoMetaAnalyzer
  // instance methods
  -[VCPVideoMetaFaceAnalyzer .cxx_destruct]
  -[VCPVideoMetaFaceAnalyzer publicResults]
  -[VCPVideoMetaFaceAnalyzer finalizeAnalysis]
  -[VCPVideoMetaFaceAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaFaceAnalyzer initWithTransform:]
  -[VCPVideoMetaFaceAnalyzer flipTransform:]


VCPVideoMetaFocusAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *results

  // instance methods
  -[VCPVideoMetaFocusAnalyzer init]
  -[VCPVideoMetaFocusAnalyzer results]
  -[VCPVideoMetaFocusAnalyzer .cxx_destruct]
  -[VCPVideoMetaFocusAnalyzer addSegmentToResults]
  -[VCPVideoMetaFocusAnalyzer processFrameMetadata:]
  -[VCPVideoMetaFocusAnalyzer finalizeAnalysis]


VCPVideoMetaFocusSegment : VCPMetaSegment
 @property  long long focusStatus

  // instance methods
  -[VCPVideoMetaFocusSegment resetSegment:atTime:]
  -[VCPVideoMetaFocusSegment focusStatus]
  -[VCPVideoMetaFocusSegment initWithFocusStatus:atTime:]
  -[VCPVideoMetaFocusSegment updateSegment:atTime:]
  -[VCPVideoMetaFocusSegment setFocusStatus:]


VCPVideoMetaLensSwitchAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL hadZoom
 @property  float minZoom
 @property  float maxZoom

  // instance methods
  -[VCPVideoMetaLensSwitchAnalyzer maxZoom]
  -[VCPVideoMetaLensSwitchAnalyzer minZoom]
  -[VCPVideoMetaLensSwitchAnalyzer setMinZoom:]
  -[VCPVideoMetaLensSwitchAnalyzer init]
  -[VCPVideoMetaLensSwitchAnalyzer results]
  -[VCPVideoMetaLensSwitchAnalyzer setHadZoom:]
  -[VCPVideoMetaLensSwitchAnalyzer setMaxZoom:]
  -[VCPVideoMetaLensSwitchAnalyzer hadZoom]


VCPVideoMetaLivePhotoMetaAnalyzer : VCPVideoMetaAnalyzer
  // class methods
  +[VCPVideoMetaLivePhotoMetaAnalyzer referenceSoftwareStackVersion]
  +[VCPVideoMetaLivePhotoMetaAnalyzer defaultDesiredKeys]

  // instance methods
  -[VCPVideoMetaLivePhotoMetaAnalyzer init]
  -[VCPVideoMetaLivePhotoMetaAnalyzer .cxx_destruct]
  -[VCPVideoMetaLivePhotoMetaAnalyzer initWithRequestAnalyses:formatDescription:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer getSetupDataFrom:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer readGyroHomographyDimension:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer gyroHomographyVersionIsValid:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer readSoftwareStackVersion:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer compareSoftwareStackVersion:withReferenceVersion:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer getFirstAtomWithFourCharCode:fromSetupData:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer convertLivePhotoStruct:toDictionary:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer compareNumericVersion:withReferenceVersion:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer convertLivePhotoBinary:toDictionary:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer finalizeAnalysis]
  -[VCPVideoMetaLivePhotoMetaAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer privateResults]


VCPVideoMetaMotionAnalyzer : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *results

  // instance methods
  -[VCPVideoMetaMotionAnalyzer init]
  -[VCPVideoMetaMotionAnalyzer results]
  -[VCPVideoMetaMotionAnalyzer .cxx_construct]
  -[VCPVideoMetaMotionAnalyzer .cxx_destruct]
  -[VCPVideoMetaMotionAnalyzer processFrameMetadata:]
  -[VCPVideoMetaMotionAnalyzer decideSegmentPointBasedOn:]
  -[VCPVideoMetaMotionAnalyzer finalizeAnalysis]
  -[VCPVideoMetaMotionAnalyzer mergeSimilarSegments]


VCPVideoMetaMotionSegment : VCPMetaSegment
 @property  float absMotion
 @property  float stabilityScore

  // instance methods
  -[VCPVideoMetaMotionSegment absMotion]
  -[VCPVideoMetaMotionSegment resetSegment:atTime:]
  -[VCPVideoMetaMotionSegment updateSegment:atTime:]
  -[VCPVideoMetaMotionSegment stabilityScore]
  -[VCPVideoMetaMotionSegment initWithAbsMotion:atTime:]
  -[VCPVideoMetaMotionSegment setAbsMotion:]
  -[VCPVideoMetaMotionSegment setStabilityScore:]
  -[VCPVideoMetaMotionSegment mergeSegment:]
  -[VCPVideoMetaMotionSegment finalizeAtTime:]


VCPVideMetaOrientationAnalyzer : VCPVideoMetaAnalyzer
  // instance methods
  -[VCPVideMetaOrientationAnalyzer init]
  -[VCPVideMetaOrientationAnalyzer .cxx_destruct]
  -[VCPVideMetaOrientationAnalyzer processMetadataGroup:flags:]
  -[VCPVideMetaOrientationAnalyzer privateResults]


VCPVideoObjectTracker : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} objectBoundsInitial
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} objectBounds
 @property  float confidence
 @property  {?=qiIq} start
 @property  int lostCount

  // instance methods
  -[VCPVideoObjectTracker .cxx_destruct]
  -[VCPVideoObjectTracker lostCount]
  -[VCPVideoObjectTracker confidence]
  -[VCPVideoObjectTracker initWithObjectBounds:inFrame:timestamp:]
  -[VCPVideoObjectTracker trackObjectInFrame:]
  -[VCPVideoObjectTracker objectBoundsInitial]
  -[VCPVideoObjectTracker objectBounds]
  -[VCPVideoObjectTracker start]


VCPSaliencyRegion : NSObject /usr/lib/libc++.1.dylib
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bound
 @property  float confidence

  // class methods
  +[VCPSaliencyRegion attachSalientRegions:toPixelBuffer:]
  +[VCPSaliencyRegion salientRegionsFromPixelBuffer:]

  // instance methods
  -[VCPSaliencyRegion bound]
  -[VCPSaliencyRegion setConfidence:]
  -[VCPSaliencyRegion confidence]
  -[VCPSaliencyRegion plistRepresentation]
  -[VCPSaliencyRegion initWithPlistRepresentation:]
  -[VCPSaliencyRegion initWith:confidence:]
  -[VCPSaliencyRegion setBound:]


VCPVideoSaliencyAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoSaliencyAnalyzer results]
  -[VCPVideoSaliencyAnalyzer .cxx_destruct]
  -[VCPVideoSaliencyAnalyzer isOutOfBoundary:]
  -[VCPVideoSaliencyAnalyzer updateConfidence:prevBound:newBound:width:height:]
  -[VCPVideoSaliencyAnalyzer pruneRegions:withOverlapRatio:]
  -[VCPVideoSaliencyAnalyzer boundDistance:relativeTo:landscape:]
  -[VCPVideoSaliencyAnalyzer initWithTransform:]
  -[VCPVideoSaliencyAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoSaliencyAnalyzer finishAnalysisPass:]


VCPClassification : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *sceneId
 @property  float duration
 @property  float sumConfidence

  // instance methods
  -[VCPClassification .cxx_destruct]
  -[VCPClassification initWithSceneId:withDuration:withConfidence:]
  -[VCPClassification setSceneId:]
  -[VCPClassification sumConfidence]
  -[VCPClassification setSumConfidence:]
  -[VCPClassification sceneId]
  -[VCPClassification setDuration:]
  -[VCPClassification duration]


VCPVideoSceneClassifier : VCPVideoAnalyzer
 @property  NSDictionary *frameScenes
 @property  NSArray *sceneResults

  // instance methods
  -[VCPVideoSceneClassifier init]
  -[VCPVideoSceneClassifier results]
  -[VCPVideoSceneClassifier dealloc]
  -[VCPVideoSceneClassifier .cxx_destruct]
  -[VCPVideoSceneClassifier addResult:start:duration:keyIsName:]
  -[VCPVideoSceneClassifier compareObjectsOfInterest:withScenes:]
  -[VCPVideoSceneClassifier addAggregatedScenes:timerange:]
  -[VCPVideoSceneClassifier frameScenes]
  -[VCPVideoSceneClassifier sceneResults]
  -[VCPVideoSceneClassifier setSceneResults:]
  -[VCPVideoSceneClassifier analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoSceneClassifier finishAnalysisPass:]


VCPVideoTrackDecoder : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[VCPVideoTrackDecoder decodeDimensionsForTrack:]

  // instance methods
  -[VCPVideoTrackDecoder init]
  -[VCPVideoTrackDecoder initWithTrack:]
  -[VCPVideoTrackDecoder .cxx_destruct]
  -[VCPVideoTrackDecoder getNextCaptureSampleBuffer]
  -[VCPVideoTrackDecoder settings]
  -[VCPVideoTrackDecoder copyNextSampleBuffer]
  -[VCPVideoTrackDecoder status]


VCPVideoTrackStandardDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackStandardDecoder dealloc]
  -[VCPVideoTrackStandardDecoder .cxx_destruct]
  -[VCPVideoTrackStandardDecoder initWithTrack:timerange:withSettings:applyTransform:]
  -[VCPVideoTrackStandardDecoder initWithTrack:timerange:]
  -[VCPVideoTrackStandardDecoder copyNextSampleBuffer]
  -[VCPVideoTrackStandardDecoder status]


VCPVideoTrackSubsamplingDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackSubsamplingDecoder dealloc]
  -[VCPVideoTrackSubsamplingDecoder .cxx_destruct]
  -[VCPVideoTrackSubsamplingDecoder getNextCaptureSampleBuffer]
  -[VCPVideoTrackSubsamplingDecoder initWithTrack:timerange:atInterval:]
  -[VCPVideoTrackSubsamplingDecoder copyNextSampleBuffer]
  -[VCPVideoTrackSubsamplingDecoder status]


VCPVideoTrackSyncDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackSyncDecoder dealloc]
  -[VCPVideoTrackSyncDecoder .cxx_destruct]
  -[VCPVideoTrackSyncDecoder initWithTrack:timerange:]
  -[VCPVideoTrackSyncDecoder findNextSample:timerange:]
  -[VCPVideoTrackSyncDecoder decodeSample:sample:]
  -[VCPVideoTrackSyncDecoder decodeTask]
  -[VCPVideoTrackSyncDecoder copyNextSampleBuffer]
  -[VCPVideoTrackSyncDecoder status]


VCPVoiceDetector : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *voiceDetections

  // class methods
  +[VCPVoiceDetector detector]

  // instance methods
  -[VCPVoiceDetector init]
  -[VCPVoiceDetector results]
  -[VCPVoiceDetector .cxx_destruct]
  -[VCPVoiceDetector loadModel]
  -[VCPVoiceDetector setVoiceDetections:]
  -[VCPVoiceDetector addDetectionFromTime:toTime:result:]
  -[VCPVoiceDetector setupWithAudioStream:]
  -[VCPVoiceDetector setupWithSample:andSampleBatchSize:]
  -[VCPVoiceDetector processAudioSamples:timestamp:]
  -[VCPVoiceDetector finalizeAnalysisAtTime:]
  -[VCPVoiceDetector audioFormatRequirements]
  -[VCPVoiceDetector voiceDetections]


VCPVoiceDetectorV2 : VCPVoiceDetector
  // instance methods
  -[VCPVoiceDetectorV2 init]
  -[VCPVoiceDetectorV2 results]
  -[VCPVoiceDetectorV2 dealloc]
  -[VCPVoiceDetectorV2 loadModel]
  -[VCPVoiceDetectorV2 setupWithAudioStream:]
  -[VCPVoiceDetectorV2 processAudioSamples:timestamp:]
  -[VCPVoiceDetectorV2 finalizeAnalysisAtTime:]


Face : NSManagedObject /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation
 @property  NSData *facePrintBlob

  // class methods
  +[Face fetchRequest]


VCPCtrTracker : NSObject /usr/lib/libc++.1.dylib <VCPBaseTracker>
 @property  ^{CGPoint=dd} box
 @property  BOOL stableInd
 @property  BOOL lostTrackInd
 @property  float confidence

  // instance methods
  -[VCPCtrTracker init]
  -[VCPCtrTracker dealloc]
  -[VCPCtrTracker setConfidence:]
  -[VCPCtrTracker confidence]
  -[VCPCtrTracker setupTrackerWithReferenceFrame:withROI:]
  -[VCPCtrTracker trackInFrame:]
  -[VCPCtrTracker lostTrackInd]
  -[VCPCtrTracker stableInd]
  -[VCPCtrTracker setStableInd:]
  -[VCPCtrTracker setLostTrackInd:]
  -[VCPCtrTracker setBox:]
  -[VCPCtrTracker box]


VCPSideCarMetal : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[VCPSideCarMetal init]
  -[VCPSideCarMetal .cxx_construct]
  -[VCPSideCarMetal .cxx_destruct]
  -[VCPSideCarMetal setPacketLayout:]
  -[VCPSideCarMetal selectGPUForFrame:]
  -[VCPSideCarMetal cachedTexture:forPlane:withAttributes:]
  -[VCPSideCarMetal rgbaUnormTextureForLuma:withAttributes:]
  -[VCPSideCarMetal rgbaUintTextureForLuma:withAttributes:]
  -[VCPSideCarMetal rgbaUintTextureForChroma:withAttributes:]
  -[VCPSideCarMetal temporalTransitionScore:previousFrame:forRegion:]
  -[VCPSideCarMetal copyFromFrame:toTile:origin:size:withFence:]
  -[VCPSideCarMetal createEncodePacket:forRegion:instance:sequenceNumber:frameIndex:pts:duration:frameProperties:]


AVAsset(MediaAnalysis)
	// instance methods
	-[AVAsset(MediaAnalysis) vcp_livePhotoStillDisplayTime]
	-[AVAsset(MediaAnalysis) vcp_assetWithoutAdjustments:duration:]
	-[AVAsset(MediaAnalysis) vcp_firstEnabledTrackWithMediaType:]
	-[AVAsset(MediaAnalysis) vcp_enabledTracksWithMediaType:]
	-[AVAsset(MediaAnalysis) vcp_isShortMovie]
	-[AVAsset(MediaAnalysis) vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:]
	-[AVAsset(MediaAnalysis) vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:]

PFVideoAVObjectBuilder(CMTimerange)
	// instance methods
	-[PFVideoAVObjectBuilder(CMTimerange) vcp_convertToOriginalTimerangeFromScaledTimerange:]

AVAssetTrack(MediaAnalysis)
	// instance methods
	-[AVAssetTrack(MediaAnalysis) vcp_endTime]
	-[AVAssetTrack(MediaAnalysis) vcp_fullFrameSize]
	-[AVAssetTrack(MediaAnalysis) vcp_startTime]
	-[AVAssetTrack(MediaAnalysis) vcp_cleanApertureRect]
	-[AVAssetTrack(MediaAnalysis) vcp_imageOrientation]
	-[AVAssetTrack(MediaAnalysis) vcp_orientation]

PHPerson(PVPersonProtocol)
	// instance methods
	-[PHPerson(PVPersonProtocol) setKeyFace:]
	-[PHPerson(PVPersonProtocol) setIsVerified:]
	-[PHPerson(PVPersonProtocol) keyFace]
	-[PHPerson(PVPersonProtocol) favorite]
	-[PHPerson(PVPersonProtocol) hidden]
	-[PHPerson(PVPersonProtocol) anonymizedName]
	-[PHPerson(PVPersonProtocol) pv_addMergeCandidatePersons:]
	-[PHPerson(PVPersonProtocol) personLocalIdentifiers]
	-[PHPerson(PVPersonProtocol) setManualOrder:]

PHPhotoLibrary(PVPhotoLibraryProtocol)
	// class methods
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_defaultURL]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_defaultPhotoLibrary]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultAssetPropertySets]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _phPeopleSortDescriptors]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultFacePropertySets]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _phFaceSortDescriptors]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_defaultMediaAnalysisDatabaseFilepath]

	// instance methods
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_assetCountForTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_assetCountWithInternalPredicate:forTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_url]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_eligibleForStreaming:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_analysisPreferences]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_persistentStorageDirectoryURL]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_setAnalysisPreferencesValue:forKey:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_personsModelFilepath]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_mediaAnalysisDirectory]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isCPLEnabled]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isCPLDownloadComplete]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _vcp_analysisPreferencesURL]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _vcp_updateAnalysisPreferencesWithEntries:keysToRemove:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_assetCountWithMediaType:forTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isCPLSyncComplete]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_canStreamingForFaceAnalysis]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_faceAnalysisStateFilepath]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_faceProcessingProgress]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_mediaAnalysisDatabaseFilepath]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultFetchOptions]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForPersonLocalIdentifiers:inMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultAssetFetchOptions]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _progressFromWorkerStatesDictionary:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_performChangesAndWait:error:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_persistentStorageDirectoryURL]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsWithType:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsInMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchCandidatePersonsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchInvalidCandidatePersonsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_numberOfFacesWithFaceprints]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForPerson:inMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForFaceGroup:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMoments]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMomentsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMomentsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMomentsForAssetsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsInMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsForFaceGroup:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFaceGroups]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFaceGroupsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_lastAssetDate]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchInvalidAssetIdentifiersForCommonComparison]

PHAsset(FullAnalysis)
	// class methods
	+[PHAsset(FullAnalysis) vcp_fetchOptionsForLibrary:forTaskID:]
	+[PHAsset(FullAnalysis) vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:]
	+[PHAsset(FullAnalysis) vcp_usePHFace]
	+[PHAsset(FullAnalysis) vcp_usePHFaceExpression]
	+[PHAsset(FullAnalysis) vcp_fullAnalysisTypesForAssetType:]

	// instance methods
	-[PHAsset(FullAnalysis) vcp_modificationDate]
	-[PHAsset(FullAnalysis) vcp_needSceneProcessing]
	-[PHAsset(FullAnalysis) vcp_hasAdjustments:]
	-[PHAsset(FullAnalysis) vcp_isVideoSlowmo]
	-[PHAsset(FullAnalysis) vcp_fingerprint:]
	-[PHAsset(FullAnalysis) vcp_fullAnalysisTypesForResources:]
	-[PHAsset(FullAnalysis) vcp_eligibleForVideoDownload:]
	-[PHAsset(FullAnalysis) vcp_queryPHFaces:results:]
	-[PHAsset(FullAnalysis) vcp_isShortMovie]
	-[PHAsset(FullAnalysis) clsDistanceIdentity]
	-[PHAsset(FullAnalysis) vcp_faceRectFrom:]
	-[PHAsset(FullAnalysis) vcp_flagsForPHFace:withFaceRect:]
	-[PHAsset(FullAnalysis) vcp_typeDescription]
	-[PHAsset(FullAnalysis) vcp_isSdofPhoto]
	-[PHAsset(FullAnalysis) vcp_isVideoTimelapse]
	-[PHAsset(FullAnalysis) vcp_originalSize]
	-[PHAsset(FullAnalysis) vcp_needFaceProcessing]
	-[PHAsset(FullAnalysis) vcp_isPano]
	-[PHAsset(FullAnalysis) vcp_isLivePhoto]
	-[PHAsset(FullAnalysis) vcp_fullAnalysisTypes]

PHFace(PFPhotosFaceRepresentation)
	// instance methods
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationLocalIdentifier]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationSourceHeight]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationSourceWidth]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationIsLeftEyeClosed]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationCenterY]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationQuality]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationClusterSequenceNumber]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationQualityMeasure]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationHasSmile]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationSize]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationCenterX]
	-[PHFace(PFPhotosFaceRepresentation) faceprintData]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationIsRightEyeClosed]
	-[PHFace(PFPhotosFaceRepresentation) setQualityMeasure:]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationBlurScore]
	-[PHFace(PFPhotosFaceRepresentation) photosFaceRepresentationRoll]

(VCPPhotosPersistenceDelegateAdditions)
	// instance methods
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_originalResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_originalVideoResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_getFpsRate]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalSlowmo:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_adjustmentsResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_smallMovieDerivativeResource]
	-[(VCPPhotosPersistenceDelegateAdditions) persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalMovie:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_thumbnailResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_avAsset:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_localPhotoResourcesSorted:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalPhoto:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_isOriginalLocal]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalAdjustments]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_resourceWithType:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_smallResourceMeetingCriteria:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_localMovieResourcesSorted:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_photoResourcesSorted:]

PHFetchResult(MediaAnalysis)
	// instance methods
	-[PHFetchResult(MediaAnalysis) resultsAsSet]
	-[PHFetchResult(MediaAnalysis) resultsAsArray]
	-[PHFetchResult(MediaAnalysis) allObjects]

NSMutableArray(PHAssetResource)
	// instance methods
	-[NSMutableArray(PHAssetResource) vcp_sortBySize]

NSBundle(VCPMediaAnalysis)
	// class methods
	+[NSBundle(VCPMediaAnalysis) vcp_mediaAnalysisBundle]

(Exif)
	// class methods
	+[(Exif) vcp_exifFromImageURL:]

	// instance methods
	-[(Exif) vcp_dateModified]
	-[(Exif) vcp_version]
	-[(Exif) vcp_results]
	-[(Exif) vcp_quality]
	-[(Exif) vcp_types]
	-[(Exif) vcp_time]
	-[(Exif) vcp_degraded]
	-[(Exif) vcp_flags]
	-[(Exif) vcp_statsFlags]
	-[(Exif) vcp_syncPoint]
	-[(Exif) vcp_dateAnalyzed]
	-[(Exif) vcp_fingerprint]
	-[(Exif) vcp_streamedVideo]
	-[(Exif) vcp_timerange]
	-[(Exif) vcp_flashFired]
	-[(Exif) vcp_scaledExposureTime]

NSMutableDictionary(MediaAnalysis)
	// instance methods
	-[NSMutableDictionary(MediaAnalysis) vcp_setVersion:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setDateModified:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setDateAnalyzed:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setFingerprint:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setResult:forKey:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addTypes:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setStatsFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setTypes:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addEntriesFromResults:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setSyncPoint:]
	-[NSMutableDictionary(MediaAnalysis) vcp_addFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_appendResults:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setQuality:]
	-[NSMutableDictionary(MediaAnalysis) vcp_removeSyncPoint]
	-[NSMutableDictionary(MediaAnalysis) vcp_addStatsFlags:]
	-[NSMutableDictionary(MediaAnalysis) vcp_appendResult:forKey:]
	-[NSMutableDictionary(MediaAnalysis) vcp_mutableResults]
	-[NSMutableDictionary(MediaAnalysis) vcp_setResults:]
	-[NSMutableDictionary(MediaAnalysis) vcp_setTimerange:]
	-[NSMutableDictionary(MediaAnalysis) vcp_removeResultForKey:]

NSPredicate(MediaAnalysis)
	// class methods
	+[NSPredicate(MediaAnalysis) vcp_imagesPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_stillImagesPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_livePhotosPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_moviesPredicate:]

PHAssetResource(MediaAnalysis)
	// class methods
	+[PHAssetResource(MediaAnalysis) vcp_allResourcesForAsset:]

	// instance methods
	-[PHAssetResource(MediaAnalysis) vcp_isDecodable]
	-[PHAssetResource(MediaAnalysis) vcp_fileSize]
	-[PHAssetResource(MediaAnalysis) vcp_avAsset]
	-[PHAssetResource(MediaAnalysis) vcp_isLocallyAvailable]
	-[PHAssetResource(MediaAnalysis) vcp_isPhotoResourceUsable:]
	-[PHAssetResource(MediaAnalysis) vcp_isMovie]
	-[PHAssetResource(MediaAnalysis) vcp_isVideoResourceUsable:]
	-[PHAssetResource(MediaAnalysis) vcp_isPhoto]
	-[PHAssetResource(MediaAnalysis) vcp_size]

PHAssetCollection(PVMomentProtocol)
	// instance methods
	-[PHAssetCollection(PVMomentProtocol) isCoarse]
	-[PHAssetCollection(PVMomentProtocol) approximateCoordinate]

PHAssetResourceManager(MediaAnalysis)
	// class methods
	+[PHAssetResourceManager(MediaAnalysis) vcp_reportDownload:]
	+[PHAssetResourceManager(MediaAnalysis) vcp_inMemoryDownload:toData:cancel:]

PHFaceGroup(PVFaceGroupProtocol)
	// instance methods
	-[PHFaceGroup(PVFaceGroupProtocol) isDirty]
	-[PHFaceGroup(PVFaceGroupProtocol) faceCountInFaceGroup]

VNClustererBuilder(BackwardCompatability)
	// instance methods
	-[VNClustererBuilder(BackwardCompatability) vcp_updateModelByAddingFaces:]

01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAsset 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetImageGenerator 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReader 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderOutputMetadataAdaptor 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderSampleReferenceOutput 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderTrackOutput 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetTrack 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetWriter 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetWriterInput 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetWriterInputMetadataAdaptor 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioFormat 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioPCMBuffer 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMetadataItem 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMutableComposition 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVTimedMetadataGroup 
01 00 0d00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVURLAsset 
01 00 1500 /System/Library/PrivateFrameworks/DataDetectorsCore.framework/DataDetectorsCore: DDScannerService 
01 00 1500 /System/Library/PrivateFrameworks/DataDetectorsCore.framework/DataDetectorsCore: DDScannerServiceConfiguration 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNBinaryConvolution 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNConvolution 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNConvolutionDescriptor 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNDepthWiseConvolutionDescriptor 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNFullyConnected 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNPoolingMax 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImage 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImageDescriptor 
01 00 0700 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSTemporaryImage 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSArray 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSBundle 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSCompoundPredicate 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSConstantArray 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantDoubleNumber 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantFloatNumber 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantIntegerNumber 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSCountedSet 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSData 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDate 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSDateFormatter 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDictionary 
01 00 1000 /System/Library/Frameworks/CoreData.framework/CoreData: NSEntityDescription 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSError 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSException 
01 00 1000 /System/Library/Frameworks/CoreData.framework/CoreData: NSFetchRequest 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileManager 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSIndexSet 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedArchiver 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedUnarchiver 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSLocale 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSLock 
01 00 1000 /System/Library/Frameworks/CoreData.framework/CoreData: NSManagedObject 
01 00 1000 /System/Library/Frameworks/CoreData.framework/CoreData: NSManagedObjectModel 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSMapTable 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableArray 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableData 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableDictionary 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableSet 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSMutableString 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSNull 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumber 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumberFormatter 
01 00 2b00 /usr/lib/libobjc.A.dylib: NSObject 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSOperation 
01 00 1000 /System/Library/Frameworks/CoreData.framework/CoreData: NSPersistentContainer 
01 00 1000 /System/Library/Frameworks/CoreData.framework/CoreData: NSPersistentStoreDescription 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSPredicate 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSProcessInfo 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSProgress 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSPropertyListSerialization 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSSet 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSSortDescriptor 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSString 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSTimeZone 
01 00 1100 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSURL 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSUUID 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSValue 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSXPCConnection 
01 00 1a00 /System/Library/Frameworks/Foundation.framework/Foundation: NSXPCInterface 
01 00 2500 /System/Library/PrivateFrameworks/ProtocolBuffer.framework/ProtocolBuffer: PBCodable 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFPhotosFaceUtilities 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFSlowMotionConfiguration 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFVideoAVObjectBuilder 
01 00 2400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFVideoAdjustments 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAsset 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetChangeRequest 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetCollection 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResource 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResourceManager 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResourceRequestOptions 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFace 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFaceChangeRequest 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFaceCrop 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFaceCropChangeRequest 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFaceGroup 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFaceGroupChangeRequest 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFaceprint 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFetchOptions 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHFetchResult 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHMoment 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHObject 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHPerson 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHPersonChangeRequest 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHPhotoLibrary 
01 00 2300 /System/Library/Frameworks/Photos.framework/Photos: PHSceneClassification 
01 00 2700 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNAudioStreamAnalyzer 
01 00 2700 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectSoundRequest 
01 00 2700 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectionResult 
01 00 0800 /System/Library/PrivateFrameworks/TelephonyUtilities.framework/TelephonyUtilities: TUCallCenter 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VN5kJNH3eYuyaLxNpZr5Z7zi 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VN6Mb1ME89lyW3HpahkEygIG 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNAlignFaceRectangleRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyFaceAttributesRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyImageAestheticsRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyJunkImageRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyPotentialLandmarkRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClustererBuilder 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClustererBuilderOptions 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNClustererQuery 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNCreateFaceTorsoprintRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNCreateFaceprintRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNCreateImageprintRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNCreateSceneprintRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceCaptureQualityRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceExpressionsRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceLandmarksRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFacePoseRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceRectanglesRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNFaceObservation 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNFaceTorsoprint 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNFaceprint 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNGenerateAttentionBasedSaliencyImageRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNGenerateObjectnessBasedSaliencyImageRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNIdentifyJunkRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNImageBlurScoreRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNImageExposureScoreRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNImageRequestHandler 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNImageprint 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNProcessingDevice 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNRecognizeObjectsRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNRecognizeTextRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNSceneClassificationRequest 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNSceneObservation 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNSceneprint 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNSession 
01 00 2a00 /System/Library/Frameworks/Vision.framework/Vision: VNVYvzEtX1JlUdu8xx5qhDI 
