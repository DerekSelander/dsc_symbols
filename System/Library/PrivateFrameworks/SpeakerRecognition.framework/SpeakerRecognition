|| __DATA.__data _SSRLoggingSubsystem
|| __DATA.__data _kSSRLoggingContextFramework
|| __DATA.__data _kXPCEncodeKeyIsRemoteDevice
|| __DATA.__data _kXPCEncodeKeyRemoteDeviceProductIdentifier
|| __DATA.__data _kXPCEncodeKeyRemoteDeviceUID
|| __DATA.__data _kXPCEncodeKeyRoute
|| __DATA.__objc_data _OBJC_CLASS_$_CSAVVoiceTriggerClientManager
|| __DATA.__objc_data _OBJC_CLASS_$_CSAsset
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioChunk
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioChunkForTV
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioCircularBuffer
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioDecoder
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioFileManager
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioFileReader
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioPowerMeter
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioRecordContext
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioRecordDeviceInfo
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioRecorder
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioStartStreamOption
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioStreamRequest
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioTimeConverter
|| __DATA.__objc_data _OBJC_CLASS_$_CSAudioZeroFilter
|| __DATA.__objc_data _OBJC_CLASS_$_CSConfig
|| __DATA.__objc_data _OBJC_CLASS_$_CSDiagnosticReporter
|| __DATA.__objc_data _OBJC_CLASS_$_CSDispatchGroup
|| __DATA.__objc_data _OBJC_CLASS_$_CSNNVADEndpointAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_CSOSTransaction
|| __DATA.__objc_data _OBJC_CLASS_$_CSPlainAudioFileWriter
|| __DATA.__objc_data _OBJC_CLASS_$_CSPolicy
|| __DATA.__objc_data _OBJC_CLASS_$_CSPowerAssertionGibraltar
|| __DATA.__objc_data _OBJC_CLASS_$_CSPreferences
|| __DATA.__objc_data _OBJC_CLASS_$_CSRemoteControlClient
|| __DATA.__objc_data _OBJC_CLASS_$_CSRemoteRecordClient
|| __DATA.__objc_data _OBJC_CLASS_$_CSSelectiveChannelAudioFileWriter
|| __DATA.__objc_data _OBJC_CLASS_$_CSServerEndpointFeatures
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIASRGrammars
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIAudioSessionRecorder
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIKeywordDetector
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIRegularExpressionMatcher
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUITrainingSession
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUITrainingSessionWithPayload
|| __DATA.__objc_data _OBJC_CLASS_$_CSVoiceIdXPCClient
|| __DATA.__objc_data _OBJC_CLASS_$_CSVoiceTriggerEventInfoProvider
|| __DATA.__objc_data _OBJC_CLASS_$_SSRAESKeyManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRBiometricMatch
|| __DATA.__objc_data _OBJC_CLASS_$_SSRDESRecordWriter
|| __DATA.__objc_data _OBJC_CLASS_$_SSREnrollmentDataManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRLoggingAggregator
|| __DATA.__objc_data _OBJC_CLASS_$_SSRPitchExtractor
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerAnalyzerPSR
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerAnalyzerSAT
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionController
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionModelContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionOrchestrator
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionScorer
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognizerPSR
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognizerSAT
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetector
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetectorNDAPI
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetectorNDAPIResult
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetectorQuasar
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVTUITrainingManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceActivityDetector
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfile
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileComposer
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileMetaContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileMetadataManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileModelContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfilePruner
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainerFactory
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainerPSR
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainerSAT
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainingContext
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAVVoiceTriggerClientManager
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAsset
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioChunk
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioChunkForTV
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioCircularBuffer
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioDecoder
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioFileManager
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioFileReader
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioPowerMeter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioRecordContext
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioRecordDeviceInfo
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioRecorder
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioStartStreamOption
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioStreamRequest
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioTimeConverter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSAudioZeroFilter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSConfig
|| __DATA.__objc_data _OBJC_METACLASS_$_CSDiagnosticReporter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSDispatchGroup
|| __DATA.__objc_data _OBJC_METACLASS_$_CSNNVADEndpointAnalyzer
|| __DATA.__objc_data _OBJC_METACLASS_$_CSOSTransaction
|| __DATA.__objc_data _OBJC_METACLASS_$_CSPlainAudioFileWriter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSPolicy
|| __DATA.__objc_data _OBJC_METACLASS_$_CSPowerAssertionGibraltar
|| __DATA.__objc_data _OBJC_METACLASS_$_CSPreferences
|| __DATA.__objc_data _OBJC_METACLASS_$_CSRemoteControlClient
|| __DATA.__objc_data _OBJC_METACLASS_$_CSRemoteRecordClient
|| __DATA.__objc_data _OBJC_METACLASS_$_CSSelectiveChannelAudioFileWriter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSServerEndpointFeatures
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIASRGrammars
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIAudioSessionRecorder
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIKeywordDetector
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIRegularExpressionMatcher
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUITrainingSession
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUITrainingSessionWithPayload
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVoiceIdXPCClient
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVoiceTriggerEventInfoProvider
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRAESKeyManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRBiometricMatch
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRDESRecordWriter
|| __DATA.__objc_data _OBJC_METACLASS_$_SSREnrollmentDataManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRLoggingAggregator
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRPitchExtractor
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerAnalyzerPSR
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerAnalyzerSAT
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionController
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionModelContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionOrchestrator
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionScorer
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognizerPSR
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognizerSAT
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetector
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetectorNDAPI
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetectorNDAPIResult
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetectorQuasar
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVTUITrainingManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceActivityDetector
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfile
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileComposer
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileMetaContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileMetadataManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileModelContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfilePruner
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainerFactory
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainerPSR
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainerSAT
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainingContext
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._ASRErrorOccured
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._audioSession
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._keywordDetector
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._locale
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._masterTimer
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._pcmBufArray
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._queue
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._resultReported
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionDelegate
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionNumber
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionProcess
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionSuspended
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._speechRecognitionRequest
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._speechRecognitionTask
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._speechRecognizer
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._status
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._trainingCompletion
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._utteranceId
|| __DATA_CONST.__const _CSErrorDomain
|| __DATA_CONST.__const _CSVTUI_AVAudioSessionPortBorealisInput
|| __DATA_CONST.__const _CSVoiceProfileAvailabilityMetaBlobVersion
|| __DATA_CONST.__const _KSSRDeviceBuildVersion
|| __DATA_CONST.__const _SSRErrorDomain
|| __DATA_CONST.__const _SSRRecognitionLoggingKey
|| __DATA_CONST.__const _SSRRetrainingLoggingKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionAssetArrayKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionAssetKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionLocaleKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionMaxAudioDurationSecs
|| __DATA_CONST.__const _SSRSpeakerRecognitionOSTransactionRequired
|| __DATA_CONST.__const _SSRSpeakerRecognitionProfileArrayKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionSiriAppDomain
|| __DATA_CONST.__const _SSRSpeakerRecognitionSiriDebugAppDomain
|| __DATA_CONST.__const _SSRSpeakerRecognitionStyleKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionUsePayloadProfileKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionVADAssetPathKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionVTEventInfoKey
|| __DATA_CONST.__const _SSRVoiceRetrainingAssetKey
|| __DATA_CONST.__const _SSRVoiceRetrainingCompareVoiceProfilesKey
|| __DATA_CONST.__const _SSRVoiceRetrainingCompareVoiceProfilesSpIdTypeKey
|| __DATA_CONST.__const _SSRVoiceRetrainingFilterToVoiceTriggerUtterancesKey
|| __DATA_CONST.__const _SSRVoiceRetrainingForceKey
|| __DATA_CONST.__const _SSRVoiceRetrainingPayloadProfileKey
|| __DATA_CONST.__const _SSRVoiceRetrainingSpIdTypeKey
|| __DATA_CONST.__const _SSRVoiceRetrainingVoiceProfileKey
|| __DATA_CONST.__const _kCSAssetFootprintKey
|| __DATA_CONST.__const _kCSAssetLanguageKey
|| __DATA_CONST.__const _kCSAssetPremiumKey
|| __DATA_CONST.__const _kCSAudioSyncedFileSuffix
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioDidStartWatchDogFire
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioDidStopWatchDogFire
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioInsufficientPriority
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioResourceNotAvailable
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioSessionInterrupted
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioStreamDeallocDuringStreaming
|| __DATA_CONST.__const _kCSDiagnosticReporterAudioTypeKey
|| __DATA_CONST.__const _kCSDiagnosticReporterDomainKey
|| __DATA_CONST.__const _kCSDiagnosticReporterEndpointerModelVersionIsNil
|| __DATA_CONST.__const _kCSDiagnosticReporterEndpointerTypeKey
|| __DATA_CONST.__const _kCSDiagnosticReporterTrialAssetFetchFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterTrialDownloadFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterTrialTypeKey
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdDelayedScores
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdExplicitUttRejected
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdMissingHomeId
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdRetrainSATVecFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdSATInitFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdSATModelFileFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdSATVectorFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdStaleProfileDetected
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdTDSRFailed
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdTDSRTimeout
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdTooLessAudioFiles
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdTypeKey
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceIdUnrecognizedMetaData
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceTriggerAPLeak
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceTriggerSecondPassCompleteWatchDogFire
|| __DATA_CONST.__const _kCSDiagnosticReporterVoiceTriggerTypeKey
|| __DATA_CONST.__const _kCSInitialContinousZerosMetricKey
|| __DATA_CONST.__const _kCSLiveOnHomePodKey
|| __DATA_CONST.__const _kCSMaxContinousZerosMetricKey
|| __DATA_CONST.__const _kCSMidSegmentContinousZerosMetricKey
|| __DATA_CONST.__const _kCSNotBackedupPreferencesDomain
|| __DATA_CONST.__const _kCSPreferencesDomain
|| __DATA_CONST.__const _kCSPreferencesJarvisTriggerModeDidChangeDarwinNotification
|| __DATA_CONST.__const _kCSSystemDomain
|| __DATA_CONST.__const _kCSVoiceTriggerEventInfoKey
|| __DATA_CONST.__const _kCSZeroRunLengthMetricKey
|| __DATA_CONST.__const _kCSZeroRunStartingSampleMetricKey
|| __DATA_CONST.__const _kSSRAnalyticsAssetVersion
|| __DATA_CONST.__const _kSSRAnalyticsLocale
|| __DATA_CONST.__const _kSSRAnalyticsPrefix
|| __DATA_CONST.__const _kSSRAudioRecordContextKey
|| __DATA_CONST.__const _kSSRAudioRecordDeviceInfoKey
|| __DATA_CONST.__const _kSSRContainsPayload
|| __DATA_CONST.__const _kSSRDateTrainedKey
|| __DATA_CONST.__const _kSSRDiscardImplicitUttScore
|| __DATA_CONST.__const _kSSREnrollmentCompletedFileName
|| __DATA_CONST.__const _kSSREnrollmentMigratedFileName
|| __DATA_CONST.__const _kSSREnrollmentVersionFileName
|| __DATA_CONST.__const _kSSRExplicitTrainingType
|| __DATA_CONST.__const _kSSRExplicitUttScore
|| __DATA_CONST.__const _kSSRFailedExplicitUttScore
|| __DATA_CONST.__const _kSSRFarField
|| __DATA_CONST.__const _kSSRImplicitTrainingType
|| __DATA_CONST.__const _kSSRImplicitUttScore
|| __DATA_CONST.__const _kSSRMetaHandheldKey
|| __DATA_CONST.__const _kSSRMetaProductTypeKey
|| __DATA_CONST.__const _kSSRMetaProductVersionKey
|| __DATA_CONST.__const _kSSRMetaTrainingTypeKey
|| __DATA_CONST.__const _kSSRMetaUtteranceWavKey
|| __DATA_CONST.__const _kSSRMetaVersionFileName
|| __DATA_CONST.__const _kSSRMetaVersionKey
|| __DATA_CONST.__const _kSSRNearField
|| __DATA_CONST.__const _kSSRNumDiscardedUttsPHS
|| __DATA_CONST.__const _kSSRNumPrunedUttsPHS
|| __DATA_CONST.__const _kSSRNumRetainedUttsPHS
|| __DATA_CONST.__const _kSSROtherBiometricResultKey
|| __DATA_CONST.__const _kSSRProfilePruneFailCode
|| __DATA_CONST.__const _kSSRPruningLoggingKey
|| __DATA_CONST.__const _kSSRPsrFailedDuringSATDetection
|| __DATA_CONST.__const _kSSRRecordingTimeStampKey
|| __DATA_CONST.__const _kSSRRetrainingStatusCode
|| __DATA_CONST.__const _kSSRRetrainingWaitTimeMs
|| __DATA_CONST.__const _kSSRScoreMSE
|| __DATA_CONST.__const _kSSRSpeakerModelRetrainRequired
|| __DATA_CONST.__const _kSSRSpeakerModelUpdated
|| __DATA_CONST.__const _kSSRSpeakerRecognitionAssetVersionKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionAudioProcessedDurationKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionBestVoiceTriggerScoreKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionCombinationWeight
|| __DATA_CONST.__const _kSSRSpeakerRecognitionDomain
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserPSRExpScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserPSRScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserSATExpScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserSATScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionMetaFilePathKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionMyriadKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNonVTInvocationScoreThresholdingType
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumEnrollmentUtterances
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumExplicitUtt
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumImplicitUtt
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumSpeakerVector
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNviDirectionalityArrKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionPSRAdditionalContextKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionProcessingStatus
|| __DATA_CONST.__const _kSSRSpeakerRecognitionProfileID
|| __DATA_CONST.__const _kSSRSpeakerRecognitionRecordUserAudioKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSATAdditionalContextKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionScoreThresholdKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionScoreThresholdingTypeKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionScoresVersion
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSegmentCounterKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSegmentStartTimeKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSessionIdKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSmartSiriVolumeKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionUnknownUserScoreKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionVTInvocationScoreThresholdingType
|| __DATA_CONST.__const _kSSRSpeakerRecognitionWaitTimeMs
|| __DATA_CONST.__const _kSSRSpeakerVoiceProfileSync
|| __DATA_CONST.__const _kSSRTdPsrExtraAudioSamplesProcessed
|| __DATA_CONST.__const _kSSRTdPsrSATRetrainingTimedOut
|| __DATA_CONST.__const _kSSRTriggerPHSProfileDownload
|| __DATA_CONST.__const _kSSRUserSiriProfileID
|| __DATA_CONST.__const _kSSRVoiceProfileAppDomainKey
|| __DATA_CONST.__const _kSSRVoiceProfileCategoryType
|| __DATA_CONST.__const _kSSRVoiceProfileCompatabilityVersion
|| __DATA_CONST.__const _kSSRVoiceProfileExpSatVecCountType
|| __DATA_CONST.__const _kSSRVoiceProfileID
|| __DATA_CONST.__const _kSSRVoiceProfileIdentifier
|| __DATA_CONST.__const _kSSRVoiceProfileLocaleKey
|| __DATA_CONST.__const _kSSRVoiceProfileOnboardType
|| __DATA_CONST.__const _kSSRVoiceProfilePath
|| __DATA_CONST.__const _kSSRVoiceProfilePitchKey
|| __DATA_CONST.__const _kSSRVoiceProfileProductType
|| __DATA_CONST.__const _kSSRVoiceProfilePruningCookie
|| __DATA_CONST.__const _kSSRVoiceProfileRecordPayloadAllowedKey
|| __DATA_CONST.__const _kSSRVoiceProfileSWVersion
|| __DATA_CONST.__const _kSSRVoiceProfileUserName
|| __DATA_DIRTY.__common _CSLogContextFacilityCoreSpeech
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_CSUtils
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRAssetManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRMobileAssetProvider
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRTrialAssetProvider
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileStore
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileStoreCleaner
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileStorePrefs
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_CSUtils
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRAssetManager
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRMobileAssetProvider
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRTrialAssetProvider
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileManager
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileStore
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileStoreCleaner
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileStorePrefs
|| __TEXT.__const _kCSAssetValueLanguageAny
|| __TEXT.__const _kCSDiagnosticReporterAudioSnapshotTime
|| __TEXT.__const _kCSDiagnosticReporterEndpointerSnapshotTime
|| __TEXT.__const _kCSDiagnosticReporterTrialSnapshotTime
|| __TEXT.__const _kCSDiagnosticReporterVoiceIdSnapshotTime
|| __TEXT.__const _kCSDiagnosticReporterVoiceTriggerSnapshotTime
|| __TEXT.__const _kCSLogitCeilDefaultScore
|| __TEXT.__const _kCSLogitFloorDefaultScore
|| __TEXT.__const _kCurrVTMetaVersion
|| __TEXT.__const _kDecay
|| __TEXT.__const _kDecay1
|| __TEXT.__const _kMinDecibelsPower
|| __TEXT.__const _kMinLinearPower
|| __TEXT.__const _kPeakDecay
|| __TEXT.__const _kPeakDecay1
|| __TEXT.__const _kPeakResetTime
|| __TEXT.__const _kSSRExplicitTrainingUtterancesCount
|| __TEXT.__const _kSSRMaxEnrollmentUtterancesDefault
|| __TEXT.__const _kSSRMinExplicitTrainingUtterancesCount
|| __TEXT.__const _kSSRVoiceProfilePrunerMaxWaitTimeMs
|| __TEXT.__text _CSAudioLogDirectory
|| __TEXT.__text _CSHasAOP
|| __TEXT.__text _CSInternalPreferencesSynchronize
|| __TEXT.__text _CSIsBridgeOS
|| __TEXT.__text _CSIsCommunalDevice
|| __TEXT.__text _CSIsEmbedded
|| __TEXT.__text _CSIsHorseman
|| __TEXT.__text _CSIsHorsemanLiveOn
|| __TEXT.__text _CSIsIOS
|| __TEXT.__text _CSIsIPad
|| __TEXT.__text _CSIsIPhone
|| __TEXT.__text _CSIsInternalBuild
|| __TEXT.__text _CSIsMac
|| __TEXT.__text _CSIsOSX
|| __TEXT.__text _CSIsSimulator
|| __TEXT.__text _CSIsTV
|| __TEXT.__text _CSIsTorpedo
|| __TEXT.__text _CSIsWatch
|| __TEXT.__text _CSLogDirectory
|| __TEXT.__text _CSLogInitIfNeeded
|| __TEXT.__text _CSMachAbsoluteTimeAddTimeInterval
|| __TEXT.__text _CSMachAbsoluteTimeGetTimeInterval
|| __TEXT.__text _CSMachAbsoluteTimeToMachContinuousTime
|| __TEXT.__text _CSMakeTimestampedAudioLogFilenameWithPrefixAndSuffix
|| __TEXT.__text _CSNotBackedupInternalPreferencesSynchronize
|| __TEXT.__text _CSRunsSimple
|| __TEXT.__text _CSSafeSetOutErrorWithNSError
|| __TEXT.__text _CSSupportsVibrator
|| __TEXT.__text _CSSystemRootDirectory
|| __TEXT.__text __CSNotBackedupPreferencesSetValueForKey
|| __TEXT.__text __CSNotBackedupPreferencesSetValueForKeyFromRoot
|| __TEXT.__text __CSNotBackedupPreferencesValueForKey
|| __TEXT.__text __CSPreferencesSetValueForKey
|| __TEXT.__text __CSPreferencesValueForKey
|| __TEXT.__text __CSPreferencesValueForKeyFromRoot
|| __TEXT.__text __SSRVoiceProfileStorePrefsSetValueForKey
|| __TEXT.__text __SSRVoiceProfileStorePrefsSynchronize
|| __TEXT.__text __SSRVoiceProfileStorePrefsValueForKey
|| __TEXT.__text __SSRVoiceProfileStorePrefsValueForKeyFromRoot
__ AVFoundation: _AVAudioSessionPortAirPlay
__ AVFoundation: _AVAudioSessionPortBluetoothA2DP
__ AVFoundation: _AVAudioSessionPortBluetoothHFP
__ AVFoundation: _AVAudioSessionPortBluetoothLE
__ AVFoundation: _AVAudioSessionPortBuiltInMic
__ AVFoundation: _AVAudioSessionPortCarAudio
__ AVFoundation: _AVAudioSessionPortHDMI
__ AVFoundation: _AVAudioSessionPortHeadphones
__ AVFoundation: _AVAudioSessionPortLineOut
__ AVFoundation: _AVAudioSessionPortUSBAudio
__ AVFoundation: _AVEncoderBitRateKey
__ AVFoundation: _AVFormatIDKey
__ AVFoundation: _AVLinearPCMBitDepthKey
__ AVFoundation: _AVLinearPCMIsFloatKey
__ AVFoundation: _AVNumberOfChannelsKey
__ AVFoundation: _AVSampleRateConverterAlgorithmKey
__ AVFoundation: _AVSampleRateConverterAlgorithm_Mastering
__ AVFoundation: _AVSampleRateKey
__ AVFoundation: _AVVoiceActivationDeviceIDKey
__ AVFoundation: _AVVoiceActivationModeKey
__ AVFoundation: _AVVoiceControllerAlertBehavior
__ AVFoundation: _AVVoiceControllerStartTimeKey
__ AVFoundation: _OBJC_CLASS_$_AVAudioFormat
__ AVFoundation: _OBJC_CLASS_$_AVAudioPCMBuffer
__ AVFoundation: _OBJC_CLASS_$_AVAudioSession
__ AVFoundation: _OBJC_CLASS_$_AVVCAudioBuffer
__ AVFoundation: _OBJC_CLASS_$_AVVCConfigureAlertBehaviorSettings
__ AVFoundation: _OBJC_CLASS_$_AVVCContextSettings
__ AVFoundation: _OBJC_CLASS_$_AVVCPrepareRecordSettings
__ AVFoundation: _OBJC_CLASS_$_AVVCStartRecordSettings
__ AVFoundation: _OBJC_CLASS_$_AVVoiceController
__ AVFoundation: _OBJC_CLASS_$_AVVoiceTriggerClient
__ Accelerate: _vDSP_vclip
__ Accelerate: _vDSP_vfix16
__ Accelerate: _vDSP_vflt16
__ Accelerate: _vDSP_vsmul
__ AppSupport: _CPSharedResourcesDirectory
__ AppSupport: _CPSystemRootDirectory
__ AssistantServices: _AFPreferencesMobileUserSessionLanguage
__ AssistantServices: _AFPreferencesStartAlertEnabled
__ AssistantServices: _AFPreferencesSupportedLanguages
__ AssistantServices: _OBJC_CLASS_$_AFAnalytics
__ AssistantServices: _OBJC_CLASS_$_AFMultiUserConnection
__ AssistantServices: _OBJC_CLASS_$_AFPreferences
__ AssistantServices: _OBJC_CLASS_$_AFSettingsConnection
__ AudioToolbox: _AudioConverterConvertComplexBuffer
__ AudioToolbox: _AudioConverterDispose
__ AudioToolbox: _AudioConverterFillComplexBuffer
__ AudioToolbox: _AudioConverterNew
__ AudioToolbox: _AudioFileClose
__ AudioToolbox: _AudioFileOpenURL
__ AudioToolbox: _ExtAudioFileCreateWithURL
__ AudioToolbox: _ExtAudioFileDispose
__ AudioToolbox: _ExtAudioFileOpenURL
__ AudioToolbox: _ExtAudioFileRead
__ AudioToolbox: _ExtAudioFileSeek
__ AudioToolbox: _ExtAudioFileSetProperty
__ AudioToolbox: _ExtAudioFileWrapAudioFileID
__ AudioToolbox: _ExtAudioFileWrite
__ CoreAnalytics: _AnalyticsSendEvent
__ CoreAnalytics: _AnalyticsSendEventLazy
__ CoreFoundation: _CFNotificationCenterGetDarwinNotifyCenter
__ CoreFoundation: _CFNotificationCenterPostNotification
__ CoreFoundation: _CFPreferencesAppSynchronize
__ CoreFoundation: _CFPreferencesCopyAppValue
__ CoreFoundation: _CFPreferencesCopyValue
__ CoreFoundation: _CFPreferencesSetAppValue
__ CoreFoundation: _CFPreferencesSetValue
__ CoreFoundation: _CFRelease
__ CoreFoundation: _NSURLCreationDateKey
__ CoreFoundation: _NSURLIsDirectoryKey
__ CoreFoundation: _NSURLNameKey
__ CoreFoundation: _OBJC_CLASS_$_NSArray
__ CoreFoundation: _OBJC_CLASS_$_NSCalendar
__ CoreFoundation: _OBJC_CLASS_$_NSData
__ CoreFoundation: _OBJC_CLASS_$_NSDate
__ CoreFoundation: _OBJC_CLASS_$_NSDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSLocale
__ CoreFoundation: _OBJC_CLASS_$_NSMutableArray
__ CoreFoundation: _OBJC_CLASS_$_NSMutableData
__ CoreFoundation: _OBJC_CLASS_$_NSMutableDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSMutableSet
__ CoreFoundation: _OBJC_CLASS_$_NSSet
__ CoreFoundation: _OBJC_CLASS_$_NSTimer
__ CoreFoundation: _OBJC_CLASS_$_NSURL
__ CoreFoundation: ___CFConstantStringClassReference
__ CoreFoundation: ___NSArray0__struct
__ CoreFoundation: ___NSDictionary0__struct
__ CoreFoundation: ___kCFBooleanFalse
__ CoreFoundation: ___kCFBooleanTrue
__ CoreFoundation: _kCFAllocatorDefault
__ CoreFoundation: _kCFPreferencesAnyHost
__ DistributedEvaluation: _OBJC_CLASS_$_DESRecordStore
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$_EARAudioResultsGenerator
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$_EARCaesuraSilencePosteriorGenerator
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$_EARSyncPSRAudioProcessor
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$__EAREndpointFeatures
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$__EAREndpointer
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$__EARSyncSpeechRecognizer
__ Foundation: _NSHomeDirectory
__ Foundation: _NSLocalizedDescriptionKey
__ Foundation: _NSLog
__ Foundation: _NSOSStatusErrorDomain
__ Foundation: _NSTemporaryDirectory
__ Foundation: _OBJC_CLASS_$_NSAssertionHandler
__ Foundation: _OBJC_CLASS_$_NSBundle
__ Foundation: _OBJC_CLASS_$_NSCharacterSet
__ Foundation: _OBJC_CLASS_$_NSConstantDoubleNumber
__ Foundation: _OBJC_CLASS_$_NSConstantFloatNumber
__ Foundation: _OBJC_CLASS_$_NSConstantIntegerNumber
__ Foundation: _OBJC_CLASS_$_NSDateFormatter
__ Foundation: _OBJC_CLASS_$_NSDistributedNotificationCenter
__ Foundation: _OBJC_CLASS_$_NSError
__ Foundation: _OBJC_CLASS_$_NSFileManager
__ Foundation: _OBJC_CLASS_$_NSHashTable
__ Foundation: _OBJC_CLASS_$_NSJSONSerialization
__ Foundation: _OBJC_CLASS_$_NSMutableString
__ Foundation: _OBJC_CLASS_$_NSNumber
__ Foundation: _OBJC_CLASS_$_NSPredicate
__ Foundation: _OBJC_CLASS_$_NSProcessInfo
__ Foundation: _OBJC_CLASS_$_NSRegularExpression
__ Foundation: _OBJC_CLASS_$_NSScanner
__ Foundation: _OBJC_CLASS_$_NSString
__ Foundation: _OBJC_CLASS_$_NSUUID
__ HealthKit: _OBJC_CLASS_$_HKHealthStore
__ HealthKit: _OBJC_CLASS_$_HKMedicalIDStore
__ IOKit: _IOObjectRelease
__ IOKit: _IORegistryEntryCreateCFProperty
__ IOKit: _IOServiceGetMatchingService
__ IOKit: _IOServiceMatching
__ IOKit: _kIOMasterPortDefault
__ MobileAsset: _ASAttributeCompatibilityVersion
__ MobileAsset: _ASAttributeContentVersion
__ MobileAsset: _OBJC_CLASS_$_MAAsset
__ MobileAsset: _OBJC_CLASS_$_MAAssetQuery
__ SoftLinking: __sl_dlopen_audited
__ SoundAnalysis: _OBJC_CLASS_$_SNAudioStreamAnalyzer
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectSpeechUtteranceRequest
__ Speech: _OBJC_CLASS_$_SFSpeechAudioBufferRecognitionRequest
__ Speech: _OBJC_CLASS_$_SFSpeechRecognizer
__ VoiceTrigger: _OBJC_CLASS_$_VTPreferences
__ VoiceTrigger: _nd_close
__ VoiceTrigger: _nd_create
__ VoiceTrigger: _nd_error
__ VoiceTrigger: _nd_getoption
__ VoiceTrigger: _nd_getphraseresults
__ VoiceTrigger: _nd_getresults
__ VoiceTrigger: _nd_getsupervector
__ VoiceTrigger: _nd_initialize
__ VoiceTrigger: _nd_phrasecount
__ VoiceTrigger: _nd_reset
__ VoiceTrigger: _nd_sat_analyze
__ VoiceTrigger: _nd_sat_deletevector
__ VoiceTrigger: _nd_sat_getspeakervector
__ VoiceTrigger: _nd_sat_initialize
__ VoiceTrigger: _nd_sat_update
__ VoiceTrigger: _nd_sat_vectorcount
__ VoiceTrigger: _nd_wavedata
__ libMobileGestalt.dylib: _MGCopyAnswer
__ libMobileGestalt.dylib: _MGGetBoolAnswer
__ libMobileGestalt.dylib: _MGGetSInt32Answer
__ libSystem.B.dylib: __Block_object_assign
__ libSystem.B.dylib: __Block_object_dispose
__ libSystem.B.dylib: __NSConcreteGlobalBlock
__ libSystem.B.dylib: __NSConcreteStackBlock
__ libSystem.B.dylib: __Unwind_Resume
__ libSystem.B.dylib: ___fpclassifyd
__ libSystem.B.dylib: ___stack_chk_fail
__ libSystem.B.dylib: ___stack_chk_guard
__ libSystem.B.dylib: __dispatch_main_q
__ libSystem.B.dylib: __dispatch_source_type_timer
__ libSystem.B.dylib: __os_feature_enabled_impl
__ libSystem.B.dylib: __os_log_debug_impl
__ libSystem.B.dylib: __os_log_error_impl
__ libSystem.B.dylib: __os_log_impl
__ libSystem.B.dylib: __xpc_error_connection_interrupted
__ libSystem.B.dylib: __xpc_error_connection_invalid
__ libSystem.B.dylib: __xpc_error_key_description
__ libSystem.B.dylib: __xpc_type_error
__ libSystem.B.dylib: _arc4random_uniform
__ libSystem.B.dylib: _bzero
__ libSystem.B.dylib: _dispatch_after
__ libSystem.B.dylib: _dispatch_async
__ libSystem.B.dylib: _dispatch_async_and_wait
__ libSystem.B.dylib: _dispatch_get_global_queue
__ libSystem.B.dylib: _dispatch_group_create
__ libSystem.B.dylib: _dispatch_group_enter
__ libSystem.B.dylib: _dispatch_group_leave
__ libSystem.B.dylib: _dispatch_group_wait
__ libSystem.B.dylib: _dispatch_once
__ libSystem.B.dylib: _dispatch_pthread_root_queue_create
__ libSystem.B.dylib: _dispatch_queue_attr_make_with_autorelease_frequency
__ libSystem.B.dylib: _dispatch_queue_attr_make_with_qos_class
__ libSystem.B.dylib: _dispatch_queue_create
__ libSystem.B.dylib: _dispatch_queue_create_with_target$V2
__ libSystem.B.dylib: _dispatch_resume
__ libSystem.B.dylib: _dispatch_semaphore_create
__ libSystem.B.dylib: _dispatch_semaphore_signal
__ libSystem.B.dylib: _dispatch_semaphore_wait
__ libSystem.B.dylib: _dispatch_source_cancel
__ libSystem.B.dylib: _dispatch_source_create
__ libSystem.B.dylib: _dispatch_source_set_event_handler
__ libSystem.B.dylib: _dispatch_source_set_timer
__ libSystem.B.dylib: _dispatch_sync
__ libSystem.B.dylib: _dispatch_time
__ libSystem.B.dylib: _dlerror
__ libSystem.B.dylib: _dlsym
__ libSystem.B.dylib: _exp
__ libSystem.B.dylib: _expf
__ libSystem.B.dylib: _free
__ libSystem.B.dylib: _gettimeofday
__ libSystem.B.dylib: _kdebug_trace
__ libSystem.B.dylib: _log10
__ libSystem.B.dylib: _mach_absolute_time
__ libSystem.B.dylib: _mach_get_times
__ libSystem.B.dylib: _mach_timebase_info
__ libSystem.B.dylib: _malloc
__ libSystem.B.dylib: _memcpy
__ libSystem.B.dylib: _memmove
__ libSystem.B.dylib: _memset
__ libSystem.B.dylib: _notify_post
__ libSystem.B.dylib: _os_log_create
__ libSystem.B.dylib: _os_log_type_enabled
__ libSystem.B.dylib: _os_transaction_create
__ libSystem.B.dylib: _pow
__ libSystem.B.dylib: _powf
__ libSystem.B.dylib: _pthread_attr_destroy
__ libSystem.B.dylib: _pthread_attr_getschedparam
__ libSystem.B.dylib: _pthread_attr_init
__ libSystem.B.dylib: _pthread_attr_setinheritsched
__ libSystem.B.dylib: _pthread_attr_setschedparam
__ libSystem.B.dylib: _pthread_attr_setschedpolicy
__ libSystem.B.dylib: _sysctl
__ libSystem.B.dylib: _xpc_bool_create
__ libSystem.B.dylib: _xpc_connection_activate
__ libSystem.B.dylib: _xpc_connection_cancel
__ libSystem.B.dylib: _xpc_connection_create_mach_service
__ libSystem.B.dylib: _xpc_connection_send_message_with_reply_sync
__ libSystem.B.dylib: _xpc_connection_set_event_handler
__ libSystem.B.dylib: _xpc_dictionary_create
__ libSystem.B.dylib: _xpc_dictionary_get_array
__ libSystem.B.dylib: _xpc_dictionary_get_bool
__ libSystem.B.dylib: _xpc_dictionary_get_data
__ libSystem.B.dylib: _xpc_dictionary_get_double
__ libSystem.B.dylib: _xpc_dictionary_get_int64
__ libSystem.B.dylib: _xpc_dictionary_get_string
__ libSystem.B.dylib: _xpc_dictionary_get_uint64
__ libSystem.B.dylib: _xpc_dictionary_get_value
__ libSystem.B.dylib: _xpc_dictionary_set_data
__ libSystem.B.dylib: _xpc_dictionary_set_string
__ libSystem.B.dylib: _xpc_dictionary_set_value
__ libSystem.B.dylib: _xpc_double_create
__ libSystem.B.dylib: _xpc_get_type
__ libSystem.B.dylib: _xpc_int64_create
__ libSystem.B.dylib: _xpc_string_create
__ libSystem.B.dylib: _xpc_uint64_create
__ libSystem.B.dylib: dyld_stub_binder
__ libc++.1.dylib: __ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNSt11logic_errorC2EPKc
__ libc++.1.dylib: __ZNSt12length_errorD1Ev
__ libc++.1.dylib: __ZSt9terminatev
__ libc++.1.dylib: __ZTISt12length_error
__ libc++.1.dylib: __ZTISt9exception
__ libc++.1.dylib: __ZTVSt12length_error
__ libc++.1.dylib: __ZdaPv
__ libc++.1.dylib: __ZdlPv
__ libc++.1.dylib: __Znam
__ libc++.1.dylib: __Znwm
__ libc++.1.dylib: ___cxa_allocate_exception
__ libc++.1.dylib: ___cxa_begin_catch
__ libc++.1.dylib: ___cxa_end_catch
__ libc++.1.dylib: ___cxa_free_exception
__ libc++.1.dylib: ___cxa_throw
__ libc++.1.dylib: ___gxx_personality_v0
__ libobjc.A.dylib: _OBJC_CLASS_$_NSObject
__ libobjc.A.dylib: _OBJC_METACLASS_$_NSObject
__ libobjc.A.dylib: ___objc_personality_v0
__ libobjc.A.dylib: __objc_empty_cache
__ libobjc.A.dylib: _objc_alloc
__ libobjc.A.dylib: _objc_alloc_init
__ libobjc.A.dylib: _objc_autorelease
__ libobjc.A.dylib: _objc_autoreleasePoolPop
__ libobjc.A.dylib: _objc_autoreleasePoolPush
__ libobjc.A.dylib: _objc_autoreleaseReturnValue
__ libobjc.A.dylib: _objc_begin_catch
__ libobjc.A.dylib: _objc_copyWeak
__ libobjc.A.dylib: _objc_destroyWeak
__ libobjc.A.dylib: _objc_end_catch
__ libobjc.A.dylib: _objc_enumerationMutation
__ libobjc.A.dylib: _objc_getClass
__ libobjc.A.dylib: _objc_getProperty
__ libobjc.A.dylib: _objc_initWeak
__ libobjc.A.dylib: _objc_loadWeakRetained
__ libobjc.A.dylib: _objc_msgSend
__ libobjc.A.dylib: _objc_msgSendSuper2
__ libobjc.A.dylib: _objc_opt_class
__ libobjc.A.dylib: _objc_opt_isKindOfClass
__ libobjc.A.dylib: _objc_opt_respondsToSelector
__ libobjc.A.dylib: _objc_release
__ libobjc.A.dylib: _objc_retain
__ libobjc.A.dylib: _objc_retainAutorelease
__ libobjc.A.dylib: _objc_retainAutoreleaseReturnValue
__ libobjc.A.dylib: _objc_retainAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_retainBlock
__ libobjc.A.dylib: _objc_setProperty_atomic
__ libobjc.A.dylib: _objc_setProperty_nonatomic_copy
__ libobjc.A.dylib: _objc_storeStrong
__ libobjc.A.dylib: _objc_storeWeak
__ libobjc.A.dylib: _objc_unsafeClaimAutoreleasedReturnValue
CSAudioChunkForTV : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *packets
 @property  float avgPower
 @property  float peakPower
 @property  unsigned long timeStamp
 @property  unsigned int numChannels
 @property  unsigned int audioFormat
 @property  unsigned long streamHandleID

  // instance methods
  -[CSAudioChunkForTV setPackets:]
  -[CSAudioChunkForTV .cxx_destruct]
  -[CSAudioChunkForTV timeStamp]
  -[CSAudioChunkForTV packets]
  -[CSAudioChunkForTV audioFormat]
  -[CSAudioChunkForTV setTimeStamp:]
  -[CSAudioChunkForTV peakPower]
  -[CSAudioChunkForTV initWithXPCObject:]
  -[CSAudioChunkForTV xpcObject]
  -[CSAudioChunkForTV avgPower]
  -[CSAudioChunkForTV setAudioFormat:]
  -[CSAudioChunkForTV streamHandleID]
  -[CSAudioChunkForTV numChannels]
  -[CSAudioChunkForTV setAvgPower:]
  -[CSAudioChunkForTV setPeakPower:]
  -[CSAudioChunkForTV setNumChannels:]
  -[CSAudioChunkForTV setStreamHandleID:]


CSPlainAudioFileWriter : NSObject /usr/lib/libc++.1.dylib <CSAudioFileWriter>
 @property  NSURL *fileURL
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[CSPlainAudioFileWriter saveAudioChunck:toURL:]

  // instance methods
  -[CSPlainAudioFileWriter fileURL]
  -[CSPlainAudioFileWriter initWithURL:]
  -[CSPlainAudioFileWriter dealloc]
  -[CSPlainAudioFileWriter .cxx_destruct]
  -[CSPlainAudioFileWriter endAudio]
  -[CSPlainAudioFileWriter addSamples:numSamples:]
  -[CSPlainAudioFileWriter initWithFilepath:]
  -[CSPlainAudioFileWriter initWithURL:inputFormat:outputFormat:]
  -[CSPlainAudioFileWriter addContextKey:withContext:]
  -[CSPlainAudioFileWriter addContextKey:fromMetaFile:]


CSPreferences : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[CSPreferences sharedPreferences]

  // instance methods
  -[CSPreferences phraseSpotterEnabled]
  -[CSPreferences _storeModeEnabled]
  -[CSPreferences secondPassAudioLoggingEnabled]
  -[CSPreferences fileLoggingLevel]
  -[CSPreferences fileLoggingIsEnabled]
  -[CSPreferences baseDir]
  -[CSPreferences setFileLoggingLevel:]
  -[CSPreferences setFileLoggingIsEnabled:]
  -[CSPreferences audioInjectionFilePath]
  -[CSPreferences useSiriActivationSPIForwatchOS]
  -[CSPreferences voiceTriggerInCoreSpeech]
  -[CSPreferences audioSessionActivationDelay]
  -[CSPreferences voiceTriggerEnabled]
  -[CSPreferences isMultiPhraseVTEnabled]
  -[CSPreferences assistantAudioFileLogDirectory]
  -[CSPreferences isAdBlockerAudioLoggingEnabled]
  -[CSPreferences voiceTriggerAudioLogDirectory]
  -[CSPreferences maxNumGradingFiles]
  -[CSPreferences maxNumLoggingFiles]
  -[CSPreferences isAttentiveSiriAudioLoggingEnabled]
  -[CSPreferences assistantLogDirectory]
  -[CSPreferences runningVoiceTriggerOnMac]
  -[CSPreferences shouldOverwriteRemoteVADScore]
  -[CSPreferences overwritingRemoteVADScore]
  -[CSPreferences opportuneSpeakListenerBypassEnabled]
  -[CSPreferences jarvisAudioLoggingEnabled]
  -[CSPreferences startOfSpeechAudioLoggingEnabled]
  -[CSPreferences getStartOfSpeechAudioLogFilePath]
  -[CSPreferences myriadHashFilePath]
  -[CSPreferences programmableAudioInjectionEnabled]
  -[CSPreferences twoShotNotificationEnabled]
  -[CSPreferences myriadHashDirectory]
  -[CSPreferences interstitialRelativeDirForLevel:]
  -[CSPreferences enableAudioInjection:withKey:]
  -[CSPreferences audioInjectionEnabledWithKey:]
  -[CSPreferences smartSiriVolumeContextAwareEnabled]
  -[CSPreferences isAttentiveSiriEnabled]
  -[CSPreferences ssvLogDirectory]
  -[CSPreferences getSSVLogFilePathWithSessionIdentifier:]
  -[CSPreferences trialBaseAssetDirectory]
  -[CSPreferences getCatAdBlockerAssetUpdateDirectory]
  -[CSPreferences setJarvisTriggerMode:]
  -[CSPreferences getJarvisTriggerMode]
  -[CSPreferences forceVoiceTriggerAPMode]
  -[CSPreferences forceVoiceTriggerAOPMode]
  -[CSPreferences _isDirectory:]
  -[CSPreferences remoteVoiceTriggerDelayTime]
  -[CSPreferences remoteVoiceTriggerEndpointTimeoutWithDefault:]
  -[CSPreferences interstitialAbsoluteDirForLevel:]
  -[CSPreferences myriadFileLoggingEnabled]
  -[CSPreferences enableAudioInjection:]
  -[CSPreferences audioInjectionEnabled]
  -[CSPreferences enableProgrammableAudioInjection:]
  -[CSPreferences setAudioInjectionFilePath:]
  -[CSPreferences isPHSSupported]
  -[CSPreferences _isRemoteVoiceTriggerAvailable]
  -[CSPreferences isSpeakerRecognitionAvailable]
  -[CSPreferences speakerIdScoreReportingType]
  -[CSPreferences smartSiriVolumeSoftVolumeEnabled]
  -[CSPreferences smartSiriVolumeContextAwareLoggingEnabled]
  -[CSPreferences useSiriActivationSPIForHomePod]
  -[CSPreferences iOSBargeInSupportEnabled]
  -[CSPreferences setHearstFirstPassModelVersion:]
  -[CSPreferences setHearstSecondPassModelVersion:]
  -[CSPreferences fakeHearstModelPath]
  -[CSPreferences companionSyncVoiceTriggerUtterancesEnabled]
  -[CSPreferences bypassPersonalizedHeySiri]
  -[CSPreferences isMultiChannelAudioLoggingEnabled]
  -[CSPreferences isSelfTriggerFileLoggingEnabled]


SSRVoiceActivityDetector : NSObject /usr/lib/libc++.1.dylib <EARCaesuraSilencePosteriorGeneratorDelegate>
 @property  SSRSpeakerRecognitionContext *context
 @property  <SSRVoiceActivityDetectorDelegate> *delegate
 @property  EARCaesuraSilencePosteriorGenerator *earSpg
 @property  _EAREndpointer *hybridClassifier
 @property  CSServerEndpointFeatures *defaultServerEpFeatures
 @property  long long segmentStartPointSampleCount
 @property  unsigned long numSamplesProcessed
 @property  BOOL endpointReported
 @property  BOOL startpointReported
 @property  NSObject<OS_dispatch_queue> *spgQueue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRVoiceActivityDetector context]
  -[SSRVoiceActivityDetector .cxx_destruct]
  -[SSRVoiceActivityDetector endAudio]
  -[SSRVoiceActivityDetector earSpg]
  -[SSRVoiceActivityDetector setContext:]
  -[SSRVoiceActivityDetector clientSilenceFeaturesAvailable:]
  -[SSRVoiceActivityDetector initWithContext:delegate:]
  -[SSRVoiceActivityDetector setDelegate:]
  -[SSRVoiceActivityDetector spgQueue]
  -[SSRVoiceActivityDetector delegate]
  -[SSRVoiceActivityDetector numSamplesProcessed]
  -[SSRVoiceActivityDetector setNumSamplesProcessed:]
  -[SSRVoiceActivityDetector resetWithContext:]
  -[SSRVoiceActivityDetector hybridClassifier]
  -[SSRVoiceActivityDetector setHybridClassifier:]
  -[SSRVoiceActivityDetector setSpgQueue:]
  -[SSRVoiceActivityDetector _initializeSPGWithContext:]
  -[SSRVoiceActivityDetector processAudioData:numSamples:]
  -[SSRVoiceActivityDetector setEarSpg:]
  -[SSRVoiceActivityDetector defaultServerEpFeatures]
  -[SSRVoiceActivityDetector setDefaultServerEpFeatures:]
  -[SSRVoiceActivityDetector segmentStartPointSampleCount]
  -[SSRVoiceActivityDetector setSegmentStartPointSampleCount:]
  -[SSRVoiceActivityDetector endpointReported]
  -[SSRVoiceActivityDetector setEndpointReported:]
  -[SSRVoiceActivityDetector startpointReported]
  -[SSRVoiceActivityDetector setStartpointReported:]


CSAudioFileReader : NSObject /usr/lib/libc++.1.dylib
 @property  <CSAudioFileReaderDelegate> *delegate

  // instance methods
  -[CSAudioFileReader startRecording]
  -[CSAudioFileReader stopRecording]
  -[CSAudioFileReader setRecordBufferDuration:]
  -[CSAudioFileReader initWithURL:]
  -[CSAudioFileReader dealloc]
  -[CSAudioFileReader .cxx_destruct]
  -[CSAudioFileReader close]
  -[CSAudioFileReader setDelegate:]
  -[CSAudioFileReader delegate]
  -[CSAudioFileReader _readAudioBufferAndFeed]
  -[CSAudioFileReader prepareRecording:]
  -[CSAudioFileReader readSamplesFromChannelIdx:]


CSAudioFileManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[CSAudioFileManager _sharedAudioLoggingQueue]
  +[CSAudioFileManager _readDataFromFileHandle:toFileHandle:]
  +[CSAudioFileManager _createAudioFileWriterForOpportuneSpeakListenerWithLoggingDir:inputFormat:outputFormat:]
  +[CSAudioFileManager _createAudioFileWriterForPHSTrainingWithLoggingDir:inputFormat:outputFormat:]
  +[CSAudioFileManager _createAudioFileWriterWithLoggingDir:withLoggingUUID:inputFormat:outputFormat:]
  +[CSAudioFileManager _getDateLabel]
  +[CSAudioFileManager _createAudioFileWriterForAdBlockerWithLoggingDir:inputFormat:outputFormat:]
  +[CSAudioFileManager pruneLogFiles]
  +[CSAudioFileManager pruneNumberOfGradingFilesTo:]
  +[CSAudioFileManager pruneNumberOfLogFilesTo:]
  +[CSAudioFileManager cleanupOrphanedGradingFiles]
  +[CSAudioFileManager generateDeviceAudioLogging:speechId:]
  +[CSAudioFileManager createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:]
  +[CSAudioFileManager createAudioFileWriterForPHSTrainingWithInputFormat:outputFormat:]
  +[CSAudioFileManager createAudioFileWriterForRemoteVADWithInputFormat:outputFormat:withLoggingUUID:]
  +[CSAudioFileManager createAudioFileWriterWithInputFormat:outputFormat:withLoggingUUID:]
  +[CSAudioFileManager createSelectiveChannelAudioFileWriterWithChannelBitset:]
  +[CSAudioFileManager createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:]
  +[CSAudioFileManager removeLogFilesOlderThanNDays:]
  +[CSAudioFileManager audioFileWriterForAttentiveSiri]


SSRSpeakerAnalyzerPSR : NSObject /usr/lib/libc++.1.dylib <EARSyncPSRAudioProcessorDelegate>
 @property  <SSRSpeakerAnalyzerPSRDelegate> *delegate
 @property  EARSyncPSRAudioProcessor *psrAudioProcessor
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  SSRSpeakerRecognitionContext *context
 @property  NSDictionary *voiceProfilesModelFilePaths
 @property  NSDictionary *voiceProfilesExpModelFilePaths
 @property  NSArray *psrScorers
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRSpeakerAnalyzerPSR context]
  -[SSRSpeakerAnalyzerPSR dealloc]
  -[SSRSpeakerAnalyzerPSR .cxx_destruct]
  -[SSRSpeakerAnalyzerPSR endAudio]
  -[SSRSpeakerAnalyzerPSR setContext:]
  -[SSRSpeakerAnalyzerPSR setQueue:]
  -[SSRSpeakerAnalyzerPSR queue]
  -[SSRSpeakerAnalyzerPSR setDelegate:]
  -[SSRSpeakerAnalyzerPSR delegate]
  -[SSRSpeakerAnalyzerPSR resetForNewRequest]
  -[SSRSpeakerAnalyzerPSR psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:]
  -[SSRSpeakerAnalyzerPSR psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:]
  -[SSRSpeakerAnalyzerPSR configFilePath]
  -[SSRSpeakerAnalyzerPSR resourceFilePath]
  -[SSRSpeakerAnalyzerPSR voiceProfilesModelFilePaths]
  -[SSRSpeakerAnalyzerPSR _isSpeakerVectorValid:speakerVectorSize:fromPsrAudioProcessor:]
  -[SSRSpeakerAnalyzerPSR _processSpeakerVector:withSize:processedAudioDurationMs:]
  -[SSRSpeakerAnalyzerPSR initWithVoiceRecognitionContext:delegate:queue:]
  -[SSRSpeakerAnalyzerPSR processAudioData:]
  -[SSRSpeakerAnalyzerPSR getVoiceRecognizerResults]
  -[SSRSpeakerAnalyzerPSR psrAudioProcessor]
  -[SSRSpeakerAnalyzerPSR setPsrAudioProcessor:]
  -[SSRSpeakerAnalyzerPSR setConfigFilePath:]
  -[SSRSpeakerAnalyzerPSR setResourceFilePath:]
  -[SSRSpeakerAnalyzerPSR setVoiceProfilesModelFilePaths:]
  -[SSRSpeakerAnalyzerPSR voiceProfilesExpModelFilePaths]
  -[SSRSpeakerAnalyzerPSR setVoiceProfilesExpModelFilePaths:]
  -[SSRSpeakerAnalyzerPSR psrScorers]
  -[SSRSpeakerAnalyzerPSR setPsrScorers:]


SSRSpeakerRecognizerPSR : NSObject /usr/lib/libc++.1.dylib <SSRSpeakerAnalyzerPSRDelegate, SSRSpeakerRecognizer>
 @property  SSRSpeakerRecognitionContext *spIdCtx
 @property  NSString *sessionId
 @property  NSDictionary *lastSpeakerInfo
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <SSRSpeakerRecognizerDelegate> *delegate
 @property  NSString *invocationStyleStr
 @property  unsigned long extraSamplesAtStart
 @property  unsigned long vtEndInSampleCount
 @property  unsigned long endInSampleCount
 @property  unsigned long numSamplesProcessed
 @property  BOOL processingEnded
 @property  unsigned long totalNumSamplesReceived
 @property  SSRSpeakerAnalyzerPSR *psrAnalyzer
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  NSDictionary *lastScoreCard

  // instance methods
  -[SSRSpeakerRecognizerPSR setSessionId:]
  -[SSRSpeakerRecognizerPSR sessionId]
  -[SSRSpeakerRecognizerPSR dealloc]
  -[SSRSpeakerRecognizerPSR .cxx_destruct]
  -[SSRSpeakerRecognizerPSR endAudio]
  -[SSRSpeakerRecognizerPSR setQueue:]
  -[SSRSpeakerRecognizerPSR spIdCtx]
  -[SSRSpeakerRecognizerPSR queue]
  -[SSRSpeakerRecognizerPSR initWithContext:delegate:]
  -[SSRSpeakerRecognizerPSR setDelegate:]
  -[SSRSpeakerRecognizerPSR delegate]
  -[SSRSpeakerRecognizerPSR vtEndInSampleCount]
  -[SSRSpeakerRecognizerPSR setVtEndInSampleCount:]
  -[SSRSpeakerRecognizerPSR numSamplesProcessed]
  -[SSRSpeakerRecognizerPSR setNumSamplesProcessed:]
  -[SSRSpeakerRecognizerPSR resetWithContext:]
  -[SSRSpeakerRecognizerPSR extraSamplesAtStart]
  -[SSRSpeakerRecognizerPSR setExtraSamplesAtStart:]
  -[SSRSpeakerRecognizerPSR processAudioData:numSamples:]
  -[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzer:hasVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzerFinishedProcessing:withVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerPSR _initializeWithContext:]
  -[SSRSpeakerRecognizerPSR lastScoreCard]
  -[SSRSpeakerRecognizerPSR setSpIdCtx:]
  -[SSRSpeakerRecognizerPSR lastSpeakerInfo]
  -[SSRSpeakerRecognizerPSR setLastSpeakerInfo:]
  -[SSRSpeakerRecognizerPSR invocationStyleStr]
  -[SSRSpeakerRecognizerPSR setInvocationStyleStr:]
  -[SSRSpeakerRecognizerPSR endInSampleCount]
  -[SSRSpeakerRecognizerPSR setEndInSampleCount:]
  -[SSRSpeakerRecognizerPSR processingEnded]
  -[SSRSpeakerRecognizerPSR setProcessingEnded:]
  -[SSRSpeakerRecognizerPSR totalNumSamplesReceived]
  -[SSRSpeakerRecognizerPSR setTotalNumSamplesReceived:]
  -[SSRSpeakerRecognizerPSR psrAnalyzer]
  -[SSRSpeakerRecognizerPSR setPsrAnalyzer:]


CSAudioChunk : NSObject /usr/lib/libc++.1.dylib
 @property  NSData *data
 @property  unsigned long numChannels
 @property  unsigned long numSamples
 @property  unsigned long sampleByteDepth
 @property  unsigned long startSampleCount
 @property  unsigned long hostTime
 @property  BOOL remoteVADAvailable
 @property  NSData *remoteVAD
 @property  NSObject<OS_xpc_object> *xpcObject

  // instance methods
  -[CSAudioChunk hostTime]
  -[CSAudioChunk .cxx_destruct]
  -[CSAudioChunk data]
  -[CSAudioChunk initWithXPCObject:]
  -[CSAudioChunk xpcObject]
  -[CSAudioChunk initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:]
  -[CSAudioChunk numSamples]
  -[CSAudioChunk subChunkFrom:numSamples:]
  -[CSAudioChunk gainCompensatedChunk]
  -[CSAudioChunk dataForChannel:]
  -[CSAudioChunk remoteVAD]
  -[CSAudioChunk dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:]
  -[CSAudioChunk sampleByteDepth]
  -[CSAudioChunk startSampleCount]
  -[CSAudioChunk skipSamplesAtStartSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:]
  -[CSAudioChunk remoteVADSubChunkFrom:numSamples:numAudioSamplesPerRemoteVAD:]
  -[CSAudioChunk setRemoteVAD:]
  -[CSAudioChunk numChannels]
  -[CSAudioChunk chunkForChannel:]
  -[CSAudioChunk remoteVADAvailable]
  -[CSAudioChunk subChunkFrom:numSamples:forChannel:]
  -[CSAudioChunk splitAudioChunkSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:]


CSAudioStartStreamOption : NSObject /usr/lib/libc++.1.dylib
 @property  BOOL requestHistoricalAudioDataWithHostTime
 @property  BOOL requestHistoricalAudioDataSampleCount
 @property  unsigned long startRecordingHostTime
 @property  unsigned long startRecordingSampleCount
 @property  BOOL useOpportunisticZLL
 @property  long long startAlertBehavior
 @property  long long stopAlertBehavior
 @property  long long errorAlertBehavior
 @property  BOOL skipAlertBehavior
 @property  NSObject<OS_xpc_object> *xpcObject
 @property  NSString *localizedDescription
 @property  BOOL requireSingleChannelLookup
 @property  unsigned int selectedChannel

  // class methods
  +[CSAudioStartStreamOption noAlertOption]

  // instance methods
  -[CSAudioStartStreamOption localizedDescription]
  -[CSAudioStartStreamOption initWithXPCObject:]
  -[CSAudioStartStreamOption xpcObject]
  -[CSAudioStartStreamOption requestHistoricalAudioDataWithHostTime]
  -[CSAudioStartStreamOption startRecordingHostTime]
  -[CSAudioStartStreamOption setRequestHistoricalAudioDataWithHostTime:]
  -[CSAudioStartStreamOption setStartRecordingHostTime:]
  -[CSAudioStartStreamOption setAVVCAlertBehavior:]
  -[CSAudioStartStreamOption setUseOpportunisticZLL:]
  -[CSAudioStartStreamOption setRequestHistoricalAudioDataSampleCount:]
  -[CSAudioStartStreamOption setStartRecordingSampleCount:]
  -[CSAudioStartStreamOption setRequireSingleChannelLookup:]
  -[CSAudioStartStreamOption setSelectedChannel:]
  -[CSAudioStartStreamOption avvcAlertBehavior]
  -[CSAudioStartStreamOption skipAlertBehavior]
  -[CSAudioStartStreamOption _alertBehaviorTypeFromAVVCOberrideType:]
  -[CSAudioStartStreamOption setStartAlertBehavior:]
  -[CSAudioStartStreamOption setStopAlertBehavior:]
  -[CSAudioStartStreamOption setErrorAlertBehavior:]
  -[CSAudioStartStreamOption startAlertBehavior]
  -[CSAudioStartStreamOption _avvcAlertOverrideType:]
  -[CSAudioStartStreamOption stopAlertBehavior]
  -[CSAudioStartStreamOption errorAlertBehavior]
  -[CSAudioStartStreamOption avvcStartRecordSettingsWithAudioStreamHandleId:]
  -[CSAudioStartStreamOption avvcSettings]
  -[CSAudioStartStreamOption setSkipAlertBehavior:]
  -[CSAudioStartStreamOption requestHistoricalAudioDataSampleCount]
  -[CSAudioStartStreamOption startRecordingSampleCount]
  -[CSAudioStartStreamOption useOpportunisticZLL]
  -[CSAudioStartStreamOption requireSingleChannelLookup]
  -[CSAudioStartStreamOption selectedChannel]


CSAudioPowerMeter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[CSAudioPowerMeter _reset]
  -[CSAudioPowerMeter .cxx_destruct]
  -[CSAudioPowerMeter reset]
  -[CSAudioPowerMeter initWithSampleRate:]
  -[CSAudioPowerMeter processFloatBuffer:stride:inFrameToProcess:]
  -[CSAudioPowerMeter processShortBuffer:stride:inFrameToProcess:]
  -[CSAudioPowerMeter getPeakPowerDB]
  -[CSAudioPowerMeter getAveragePowerDB]
  -[CSAudioPowerMeter _scaleDecayConstants:]
  -[CSAudioPowerMeter _savePeaks:averagePower:maxSample:]
  -[CSAudioPowerMeter _zapgremlins:]
  -[CSAudioPowerMeter _linearToDB:]
  -[CSAudioPowerMeter _ampToDB:]


SSRTriggerPhraseDetectorNDAPI : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[SSRTriggerPhraseDetectorNDAPI analyzeWavData:numSamples:]
  -[SSRTriggerPhraseDetectorNDAPI dealloc]
  -[SSRTriggerPhraseDetectorNDAPI getSuperVectorWithEndPoint:]
  -[SSRTriggerPhraseDetectorNDAPI reset]
  -[SSRTriggerPhraseDetectorNDAPI initWithConfigPath:resourcePath:phraseId:]


SSRTriggerPhraseDetectorNDAPIResult : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long phraseId
 @property  unsigned long samplesFed
 @property  unsigned long bestPhrase
 @property  unsigned long bestStart
 @property  unsigned long bestEnd
 @property  float bestScore
 @property  BOOL isEarlyWarning
 @property  BOOL isRescoring

  // instance methods
  -[SSRTriggerPhraseDetectorNDAPIResult bestEnd]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestScore:]
  -[SSRTriggerPhraseDetectorNDAPIResult bestScore]
  -[SSRTriggerPhraseDetectorNDAPIResult phraseId]
  -[SSRTriggerPhraseDetectorNDAPIResult bestStart]
  -[SSRTriggerPhraseDetectorNDAPIResult setPhraseId:]
  -[SSRTriggerPhraseDetectorNDAPIResult setSamplesFed:]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestPhrase:]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestStart:]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestEnd:]
  -[SSRTriggerPhraseDetectorNDAPIResult setIsEarlyWarning:]
  -[SSRTriggerPhraseDetectorNDAPIResult setIsRescoring:]
  -[SSRTriggerPhraseDetectorNDAPIResult samplesFed]
  -[SSRTriggerPhraseDetectorNDAPIResult bestPhrase]
  -[SSRTriggerPhraseDetectorNDAPIResult isEarlyWarning]
  -[SSRTriggerPhraseDetectorNDAPIResult isRescoring]


SSRSpeakerRecognitionOrchestrator : NSObject /usr/lib/libc++.1.dylib <SSRSpeakerRecognizerDelegate, SSRVoiceActivityDetectorDelegate>
 @property  SSRSpeakerRecognitionContext *context
 @property  <SSRSpeakerRecognitionOrchestratorDelegate> *delegate
 @property  <CSAudioFileWriter> *ssrUttLogger
 @property  unsigned long myriadResult
 @property  <SSRSpeakerRecognizer> *psrRecognizer
 @property  <SSRSpeakerRecognizer> *satRecognizer
 @property  SSRVoiceActivityDetector *vad
 @property  NSDictionary *psrLastSpeakerInfo
 @property  NSDictionary *satLastSpeakerInfo
 @property  NSDictionary *combinedScores
 @property  NSDictionary *psrFinalSpeakerInfo
 @property  NSDictionary *satFinalSpeakerInfo
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSString *debugUtteranceAudioFilePath
 @property  NSString *debugUtteranceJsonFilePath
 @property  NSObject<OS_os_transaction> *transaction
 @property  NSString *transDesc
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRSpeakerRecognitionOrchestrator context]
  -[SSRSpeakerRecognitionOrchestrator vad]
  -[SSRSpeakerRecognitionOrchestrator setTransaction:]
  -[SSRSpeakerRecognitionOrchestrator transaction]
  -[SSRSpeakerRecognitionOrchestrator dealloc]
  -[SSRSpeakerRecognitionOrchestrator .cxx_destruct]
  -[SSRSpeakerRecognitionOrchestrator endAudio]
  -[SSRSpeakerRecognitionOrchestrator setContext:]
  -[SSRSpeakerRecognitionOrchestrator setQueue:]
  -[SSRSpeakerRecognitionOrchestrator setVad:]
  -[SSRSpeakerRecognitionOrchestrator queue]
  -[SSRSpeakerRecognitionOrchestrator setDelegate:]
  -[SSRSpeakerRecognitionOrchestrator delegate]
  -[SSRSpeakerRecognitionOrchestrator initWithContext:withDelegate:error:]
  -[SSRSpeakerRecognitionOrchestrator resetWithContext:]
  -[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectEndPointAt:]
  -[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectStartPointAt:]
  -[SSRSpeakerRecognitionOrchestrator speakerRecognizer:hasSpeakerIdInfo:]
  -[SSRSpeakerRecognitionOrchestrator speakerRecognizerFinishedProcessing:withFinalSpeakerIdInfo:]
  -[SSRSpeakerRecognitionOrchestrator updateDebugFilePathsForSegment:]
  -[SSRSpeakerRecognitionOrchestrator _resetWithContext:]
  -[SSRSpeakerRecognitionOrchestrator orchestratorScoresWithPSRScores:withSATScores:withSegmentStartTime:]
  -[SSRSpeakerRecognitionOrchestrator _logSpeakerIdProcessorScoreDelayWithScoreInfo:hasFinished:]
  -[SSRSpeakerRecognitionOrchestrator processAudio:numSamples:]
  -[SSRSpeakerRecognitionOrchestrator getLatestVoiceRecognitionInfo]
  -[SSRSpeakerRecognitionOrchestrator ssrUttLogger]
  -[SSRSpeakerRecognitionOrchestrator setSsrUttLogger:]
  -[SSRSpeakerRecognitionOrchestrator myriadResult]
  -[SSRSpeakerRecognitionOrchestrator setMyriadResult:]
  -[SSRSpeakerRecognitionOrchestrator psrRecognizer]
  -[SSRSpeakerRecognitionOrchestrator setPsrRecognizer:]
  -[SSRSpeakerRecognitionOrchestrator satRecognizer]
  -[SSRSpeakerRecognitionOrchestrator setSatRecognizer:]
  -[SSRSpeakerRecognitionOrchestrator psrLastSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setPsrLastSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator satLastSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setSatLastSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator combinedScores]
  -[SSRSpeakerRecognitionOrchestrator setCombinedScores:]
  -[SSRSpeakerRecognitionOrchestrator psrFinalSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setPsrFinalSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator satFinalSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setSatFinalSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator debugUtteranceAudioFilePath]
  -[SSRSpeakerRecognitionOrchestrator setDebugUtteranceAudioFilePath:]
  -[SSRSpeakerRecognitionOrchestrator debugUtteranceJsonFilePath]
  -[SSRSpeakerRecognitionOrchestrator setDebugUtteranceJsonFilePath:]
  -[SSRSpeakerRecognitionOrchestrator transDesc]
  -[SSRSpeakerRecognitionOrchestrator setTransDesc:]


SSRVoiceProfileRetrainerSAT : NSObject /usr/lib/libc++.1.dylib <SSRVoiceProfileRetrainer>
 @property  SSRSpeakerRecognitionScorer *satScorer
 @property  SSRVoiceProfile *voiceProfile
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  NSURL *satModelFilePath
 @property  unsigned long spIdType
 @property  NSDictionary *comparativeModels
 @property  NSData *superVector
 @property  unsigned long superVectorSize
 @property  unsigned long processedAudioDurationMs
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSURL *modelFilePath
 @property  BOOL implicitTrainingRequired
 @property  unsigned long retrainerType
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRVoiceProfileRetrainerSAT modelFilePath]
  -[SSRVoiceProfileRetrainerSAT .cxx_destruct]
  -[SSRVoiceProfileRetrainerSAT setQueue:]
  -[SSRVoiceProfileRetrainerSAT processedAudioDurationMs]
  -[SSRVoiceProfileRetrainerSAT setProcessedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerSAT queue]
  -[SSRVoiceProfileRetrainerSAT spIdType]
  -[SSRVoiceProfileRetrainerSAT configFilePath]
  -[SSRVoiceProfileRetrainerSAT resourceFilePath]
  -[SSRVoiceProfileRetrainerSAT setConfigFilePath:]
  -[SSRVoiceProfileRetrainerSAT setResourceFilePath:]
  -[SSRVoiceProfileRetrainerSAT voiceProfile]
  -[SSRVoiceProfileRetrainerSAT _processAudioFile:withSATProcessor:]
  -[SSRVoiceProfileRetrainerSAT _processSuperVector:withSize:withScorers:processedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerSAT initWithVoiceRetrainingContext:]
  -[SSRVoiceProfileRetrainerSAT resetModelForRetraining]
  -[SSRVoiceProfileRetrainerSAT addUtterances:withPolicy:withCompletion:]
  -[SSRVoiceProfileRetrainerSAT needsRetrainingWithAudioFiles:]
  -[SSRVoiceProfileRetrainerSAT purgeLastSpeakerEmbedding]
  -[SSRVoiceProfileRetrainerSAT purgeConfusionInformationWithPolicy:]
  -[SSRVoiceProfileRetrainerSAT implicitTrainingRequired]
  -[SSRVoiceProfileRetrainerSAT retrainerType]
  -[SSRVoiceProfileRetrainerSAT satScorer]
  -[SSRVoiceProfileRetrainerSAT setSatScorer:]
  -[SSRVoiceProfileRetrainerSAT setVoiceProfile:]
  -[SSRVoiceProfileRetrainerSAT satModelFilePath]
  -[SSRVoiceProfileRetrainerSAT setSatModelFilePath:]
  -[SSRVoiceProfileRetrainerSAT setSpIdType:]
  -[SSRVoiceProfileRetrainerSAT comparativeModels]
  -[SSRVoiceProfileRetrainerSAT setComparativeModels:]
  -[SSRVoiceProfileRetrainerSAT superVector]
  -[SSRVoiceProfileRetrainerSAT setSuperVector:]
  -[SSRVoiceProfileRetrainerSAT superVectorSize]
  -[SSRVoiceProfileRetrainerSAT setSuperVectorSize:]


CSAudioStreamRequest : NSObject /usr/lib/libc++.1.dylib
 @property  NSObject<OS_xpc_object> *xpcObject
 @property  CSAudioRecordContext *recordContext
 @property  BOOL requiresHistoricalBuffer
 @property  BOOL useCustomizedRecordSettings
 @property  long long audioFormat
 @property  double sampleRate
 @property  unsigned int lpcmBitDepth
 @property  BOOL lpcmIsFloat
 @property  unsigned int numberOfChannels
 @property  unsigned int encoderBitRate
 @property  BOOL isSiri

  // class methods
  +[CSAudioStreamRequest defaultRequestWithContext:]
  +[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
  +[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
  +[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]

  // instance methods
  -[CSAudioStreamRequest .cxx_destruct]
  -[CSAudioStreamRequest isSiri]
  -[CSAudioStreamRequest audioFormat]
  -[CSAudioStreamRequest setSampleRate:]
  -[CSAudioStreamRequest initWithXPCObject:]
  -[CSAudioStreamRequest sampleRate]
  -[CSAudioStreamRequest xpcObject]
  -[CSAudioStreamRequest numberOfChannels]
  -[CSAudioStreamRequest setAudioFormat:]
  -[CSAudioStreamRequest setRequiresHistoricalBuffer:]
  -[CSAudioStreamRequest setIsSiri:]
  -[CSAudioStreamRequest setEncoderBitRate:]
  -[CSAudioStreamRequest setNumberOfChannels:]
  -[CSAudioStreamRequest setLpcmBitDepth:]
  -[CSAudioStreamRequest setLpcmIsFloat:]
  -[CSAudioStreamRequest setRecordContext:]
  -[CSAudioStreamRequest setUseCustomizedRecordSettings:]
  -[CSAudioStreamRequest recordContext]
  -[CSAudioStreamRequest requiresHistoricalBuffer]
  -[CSAudioStreamRequest useCustomizedRecordSettings]
  -[CSAudioStreamRequest lpcmBitDepth]
  -[CSAudioStreamRequest lpcmIsFloat]
  -[CSAudioStreamRequest encoderBitRate]


SSRDESRecordWriter : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[SSRDESRecordWriter createDESRecordWithSuperVector:withMetaInfo:]
  +[SSRDESRecordWriter fetchMedicalDataWithCompletion:]


SSRSpeakerRecognitionScorer : NSObject /usr/lib/libc++.1.dylib
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  NSURL *modelFilePath
 @property  NSString *profileID
 @property  NSString *sysConfigRoot
 @property  NSString *psrConfigFilePath
 @property  NSString *psrConfigRoot
 @property  BOOL satModelAvailable

  // class methods
  +[SSRSpeakerRecognitionScorer createVoiceScorersWithVoiceProfiles:withConfigFile:withResourceFile:withOffsetsType:]

  // instance methods
  -[SSRSpeakerRecognitionScorer modelFilePath]
  -[SSRSpeakerRecognitionScorer setModelFilePath:]
  -[SSRSpeakerRecognitionScorer profileID]
  -[SSRSpeakerRecognitionScorer dealloc]
  -[SSRSpeakerRecognitionScorer .cxx_destruct]
  -[SSRSpeakerRecognitionScorer resetForNewRequest]
  -[SSRSpeakerRecognitionScorer configFilePath]
  -[SSRSpeakerRecognitionScorer resourceFilePath]
  -[SSRSpeakerRecognitionScorer psrConfigFilePath]
  -[SSRSpeakerRecognitionScorer psrConfigRoot]
  -[SSRSpeakerRecognitionScorer scoreSpeakerVector:withDimensions:withThresholdType:]
  -[SSRSpeakerRecognitionScorer getSATVectorCount]
  -[SSRSpeakerRecognitionScorer resetScorerWithModelFilePath:]
  -[SSRSpeakerRecognitionScorer setConfigFilePath:]
  -[SSRSpeakerRecognitionScorer setResourceFilePath:]
  -[SSRSpeakerRecognitionScorer initWithProfileID:withModelFile:withConfigFile:withResourceFile:withOffsetsType:]
  -[SSRSpeakerRecognitionScorer satModelAvailable]
  -[SSRSpeakerRecognitionScorer deleteVectorAtIndex:]
  -[SSRSpeakerRecognitionScorer updateSAT]
  -[SSRSpeakerRecognitionScorer analyzeSuperVector:withDimensions:withThresholdType:]
  -[SSRSpeakerRecognitionScorer normalizedScoreFromRawScore:forScoreType:]
  -[SSRSpeakerRecognitionScorer _satScoreVTScale]
  -[SSRSpeakerRecognitionScorer _satScoreVTOffset]
  -[SSRSpeakerRecognitionScorer _satLogitCeilScore]
  -[SSRSpeakerRecognitionScorer _satLogitFloorScore]
  -[SSRSpeakerRecognitionScorer _satScoreNonVTScale]
  -[SSRSpeakerRecognitionScorer _satScoreNonVTOffset]
  -[SSRSpeakerRecognitionScorer _getValueForNDAPIConfigOption:]
  -[SSRSpeakerRecognitionScorer _getFloatValueForNDAPIConfigOption:defaultValue:]
  -[SSRSpeakerRecognitionScorer _getOptionValueFromConfigurationName:]
  -[SSRSpeakerRecognitionScorer analyzeSpeakerVector:withDimensions:withThresholdType:]
  -[SSRSpeakerRecognitionScorer sysConfigRoot]
  -[SSRSpeakerRecognitionScorer getSpeakerVectorAtIndex:]
  -[SSRSpeakerRecognitionScorer _getFloatValueFromConfigurationName:defaultTo:]
  -[SSRSpeakerRecognitionScorer _getIntValueFromConfigurationName:defaultTo:]
  -[SSRSpeakerRecognitionScorer _getStringValueFromConfigurationName:defaultTo:]


SSRVTUITrainingManager : NSObject /usr/lib/libc++.1.dylib <CSVTUITrainingSessionDelegate, CSVTUIAudioSessionDelegate, CSEndpointAnalyzerDelegate>
 @property  CSPlainAudioFileWriter *audioFileWriter
 @property  SSRVoiceProfile *voiceProfile
 @property  float rms
 @property  <SSRVTUITrainingManagerDelegate> *delegate
 @property  BOOL speechRecognizerAvailable
 @property  unsigned long audioSource
 @property  BOOL suspendAudio
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[SSRVTUITrainingManager sharedtrainingSessionQueue]
  +[SSRVTUITrainingManager trainingManagerWithLocaleID:withAppDomain:]

  // instance methods
  -[SSRVTUITrainingManager rms]
  -[SSRVTUITrainingManager setLocaleIdentifier:]
  -[SSRVTUITrainingManager .cxx_destruct]
  -[SSRVTUITrainingManager stopRMS]
  -[SSRVTUITrainingManager setRms:]
  -[SSRVTUITrainingManager _audioSource]
  -[SSRVTUITrainingManager reset]
  -[SSRVTUITrainingManager setDelegate:]
  -[SSRVTUITrainingManager prepareWithCompletion:]
  -[SSRVTUITrainingManager delegate]
  -[SSRVTUITrainingManager startRMS]
  -[SSRVTUITrainingManager audioSource]
  -[SSRVTUITrainingManager audioFileWriter]
  -[SSRVTUITrainingManager setAudioFileWriter:]
  -[SSRVTUITrainingManager endpointer:didDetectHardEndpointAtTime:withMetrics:]
  -[SSRVTUITrainingManager endpointer:didDetectStartpointAtTime:]
  -[SSRVTUITrainingManager audioSessionDidStopRecording:]
  -[SSRVTUITrainingManager audioSessionRecordBufferAvailable:]
  -[SSRVTUITrainingManager audioSessionDidStartRecording:error:]
  -[SSRVTUITrainingManager audioSessionErrorDidOccur:]
  -[SSRVTUITrainingManager audioSessionUnsupportedAudioRoute]
  -[SSRVTUITrainingManager _setupAudioSession]
  -[SSRVTUITrainingManager voiceProfile]
  -[SSRVTUITrainingManager initWithLocaleIdentifier:withAudioSession:withAppDomain:]
  -[SSRVTUITrainingManager createKeywordDetector]
  -[SSRVTUITrainingManager _stopAudioSession]
  -[SSRVTUITrainingManager destroySpeakerTrainer]
  -[SSRVTUITrainingManager _destroyAudioSession]
  -[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:withCompletion:]
  -[SSRVTUITrainingManager _createAudioAnalyzer]
  -[SSRVTUITrainingManager _shouldShowHeadsetDisconnectionMessage]
  -[SSRVTUITrainingManager _startAudioSession]
  -[SSRVTUITrainingManager createSpeechRecognizer]
  -[SSRVTUITrainingManager CSVTUITrainingSessionRMSAvailable:]
  -[SSRVTUITrainingManager CSVTUITrainingSessionStopListen]
  -[SSRVTUITrainingManager CSVTUITrainingSession:hasTrainUtterance:languageCode:payload:]
  -[SSRVTUITrainingManager _beginOfSpeechDetected]
  -[SSRVTUITrainingManager _endOfSpeechDetected]
  -[SSRVTUITrainingManager cleanupWithCompletion:]
  -[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]
  -[SSRVTUITrainingManager cancelTrainingForID:]
  -[SSRVTUITrainingManager suspendAudio]
  -[SSRVTUITrainingManager setSuspendAudio:]
  -[SSRVTUITrainingManager shouldPerformRMS]
  -[SSRVTUITrainingManager didDetectForceEndPoint]
  -[SSRVTUITrainingManager speechRecognizerAvailable]


SSRVoiceProfileRetrainerFactory : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[SSRVoiceProfileRetrainerFactory init]
  -[SSRVoiceProfileRetrainerFactory voiceRetrainersWithContext:]


CSOSTransaction : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[CSOSTransaction initWithDescription:]
  -[CSOSTransaction dealloc]
  -[CSOSTransaction .cxx_destruct]


CSAudioRecordDeviceInfo : NSObject /usr/lib/libc++.1.dylib <NSCopying, NSSecureCoding>
 @property  NSString *route
 @property  BOOL isRemoteDevice
 @property  NSUUID *remoteDeviceUID
 @property  NSString *remoteDeviceProductIdentifier

  // class methods
  +[CSAudioRecordDeviceInfo supportsSecureCoding]

  // instance methods
  -[CSAudioRecordDeviceInfo copyWithZone:]
  -[CSAudioRecordDeviceInfo route]
  -[CSAudioRecordDeviceInfo isRemoteDevice]
  -[CSAudioRecordDeviceInfo .cxx_destruct]
  -[CSAudioRecordDeviceInfo encodeWithCoder:]
  -[CSAudioRecordDeviceInfo initWithXPCObject:]
  -[CSAudioRecordDeviceInfo xpcObject]
  -[CSAudioRecordDeviceInfo remoteDeviceUID]
  -[CSAudioRecordDeviceInfo initWithCoder:]
  -[CSAudioRecordDeviceInfo initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:]
  -[CSAudioRecordDeviceInfo initWithAVVCRecordDeviceInfo:]
  -[CSAudioRecordDeviceInfo remoteDeviceProductIdentifier]


CSVTUIAudioSessionRecorder : NSObject /usr/lib/libc++.1.dylib <CSAudioRecorderDelegate, CSVTUIAudioSession>
 @property  CSAudioPowerMeter *powerMeter
 @property  unsigned long audioStreamHandleId
 @property  <CSVTUIAudioSessionDelegate> *delegate
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUIAudioSessionRecorder startRecording]
  -[CSVTUIAudioSessionRecorder stopRecording]
  -[CSVTUIAudioSessionRecorder setEndpointerDelegate:]
  -[CSVTUIAudioSessionRecorder releaseAudioSession]
  -[CSVTUIAudioSessionRecorder init]
  -[CSVTUIAudioSessionRecorder .cxx_destruct]
  -[CSVTUIAudioSessionRecorder updateMeters]
  -[CSVTUIAudioSessionRecorder isRecording]
  -[CSVTUIAudioSessionRecorder averagePower]
  -[CSVTUIAudioSessionRecorder hasAudioRoute]
  -[CSVTUIAudioSessionRecorder audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:]
  -[CSVTUIAudioSessionRecorder setDelegate:]
  -[CSVTUIAudioSessionRecorder audioRecorderBufferAvailable:audioStreamHandleId:buffer:]
  -[CSVTUIAudioSessionRecorder delegate]
  -[CSVTUIAudioSessionRecorder audioSource]
  -[CSVTUIAudioSessionRecorder audioStreamHandleId]
  -[CSVTUIAudioSessionRecorder audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:]
  -[CSVTUIAudioSessionRecorder audioRecorderDidStopRecord:audioStreamHandleId:reason:]
  -[CSVTUIAudioSessionRecorder audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:]
  -[CSVTUIAudioSessionRecorder audioRecorderDisconnected:]
  -[CSVTUIAudioSessionRecorder _audioRecorder]
  -[CSVTUIAudioSessionRecorder powerMeter]
  -[CSVTUIAudioSessionRecorder setPowerMeter:]
  -[CSVTUIAudioSessionRecorder setAudioStreamHandleId:]
  -[CSVTUIAudioSessionRecorder _hasCorrectInputAudioRoute]
  -[CSVTUIAudioSessionRecorder _hasCorrectOutputAudioRoute]
  -[CSVTUIAudioSessionRecorder convertStopReason:]
  -[CSVTUIAudioSessionRecorder _handleDidStopWithReason:]
  -[CSVTUIAudioSessionRecorder prepareRecord]
  -[CSVTUIAudioSessionRecorder resetEndPointer]
  -[CSVTUIAudioSessionRecorder hasCorrectAudioRoute]


SSRVoiceProfileMetaContext : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *appDomain
 @property  NSString *profileId
 @property  NSString *languageCode
 @property  NSString *productCategory
 @property  NSNumber *version
 @property  NSDate *dateAdded
 @property  NSNumber *pitch
 @property  NSString *sharedSiriId
 @property  NSString *homeId
 @property  NSString *userName

  // instance methods
  -[SSRVoiceProfileMetaContext pitch]
  -[SSRVoiceProfileMetaContext setLanguageCode:]
  -[SSRVoiceProfileMetaContext languageCode]
  -[SSRVoiceProfileMetaContext .cxx_destruct]
  -[SSRVoiceProfileMetaContext homeId]
  -[SSRVoiceProfileMetaContext setUserName:]
  -[SSRVoiceProfileMetaContext userName]
  -[SSRVoiceProfileMetaContext setVersion:]
  -[SSRVoiceProfileMetaContext dateAdded]
  -[SSRVoiceProfileMetaContext version]
  -[SSRVoiceProfileMetaContext setDateAdded:]
  -[SSRVoiceProfileMetaContext setPitch:]
  -[SSRVoiceProfileMetaContext appDomain]
  -[SSRVoiceProfileMetaContext profileId]
  -[SSRVoiceProfileMetaContext sharedSiriId]
  -[SSRVoiceProfileMetaContext setProfileId:]
  -[SSRVoiceProfileMetaContext productCategory]
  -[SSRVoiceProfileMetaContext setProductCategory:]
  -[SSRVoiceProfileMetaContext setHomeId:]
  -[SSRVoiceProfileMetaContext initWithVoiceProfile:]
  -[SSRVoiceProfileMetaContext initWithSharedSiriId:languageCode:productCategory:version:]
  -[SSRVoiceProfileMetaContext setAppDomain:]
  -[SSRVoiceProfileMetaContext setSharedSiriId:]


SSRTriggerPhraseDetector : NSObject /usr/lib/libc++.1.dylib
 @property  SSRTriggerPhraseDetectorNDAPI *detectorNDAPI
 @property  SSRTriggerPhraseDetectorQuasar *detectorQuasar
 @property  float recognizerScoreScaleFactor

  // class methods
  +[SSRTriggerPhraseDetector filterVTAudioFiles:withLocale:withAsset:]

  // instance methods
  -[SSRTriggerPhraseDetector .cxx_destruct]
  -[SSRTriggerPhraseDetector recognizerScoreScaleFactor]
  -[SSRTriggerPhraseDetector setRecognizerScoreScaleFactor:]
  -[SSRTriggerPhraseDetector initWithLocale:asset:]
  -[SSRTriggerPhraseDetector computeTriggerConfidenceForAudio:withCompletion:]
  -[SSRTriggerPhraseDetector detectorNDAPI]
  -[SSRTriggerPhraseDetector setDetectorNDAPI:]
  -[SSRTriggerPhraseDetector detectorQuasar]
  -[SSRTriggerPhraseDetector setDetectorQuasar:]


CSRemoteControlClient : NSObject /usr/lib/libc++.1.dylib
 @property  <CSRemoteControlClientDelegate> *delegate

  // instance methods
  -[CSRemoteControlClient isConnected]
  -[CSRemoteControlClient init]
  -[CSRemoteControlClient dealloc]
  -[CSRemoteControlClient .cxx_destruct]
  -[CSRemoteControlClient setDelegate:]
  -[CSRemoteControlClient delegate]
  -[CSRemoteControlClient waitingForConnection:error:]


CSAudioRecorder : NSObject /usr/lib/libc++.1.dylib <AVVoiceControllerRecordDelegate, CSAudioDecoderDelegate, CSAudioFileReaderDelegate, CSAudioServerCrashEventProviding, CSAudioSessionEventProviding>
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSObject<OS_dispatch_queue> *voiceControllerCreationQueue
 @property  NSHashTable *observers
 @property  <CSAudioServerCrashEventProvidingDelegate> *crashEventDelegate
 @property  <CSAudioSessionEventProvidingDelegate> *sessionEventDelegate
 @property  BOOL duckOthersOption
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[CSAudioRecorder createSharedAudioSession]
  +[CSAudioRecorder _convertDeactivateOption:]

  // instance methods
  -[CSAudioRecorder metrics]
  -[CSAudioRecorder deactivateAudioSession:error:]
  -[CSAudioRecorder voiceTriggerInfo]
  -[CSAudioRecorder unregisterObserver:]
  -[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
  -[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
  -[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
  -[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
  -[CSAudioRecorder voiceControllerBeginRecordInterruption:]
  -[CSAudioRecorder voiceControllerEndRecordInterruption:]
  -[CSAudioRecorder voiceControllerMediaServicesWereLost:]
  -[CSAudioRecorder voiceControllerMediaServicesWereReset:]
  -[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
  -[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
  -[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
  -[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
  -[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
  -[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
  -[CSAudioRecorder enableMiniDucking:]
  -[CSAudioRecorder registerObserver:]
  -[CSAudioRecorder setObservers:]
  -[CSAudioRecorder dealloc]
  -[CSAudioRecorder playAlertSoundForType:]
  -[CSAudioRecorder .cxx_destruct]
  -[CSAudioRecorder updateMeters]
  -[CSAudioRecorder observers]
  -[CSAudioRecorder setQueue:]
  -[CSAudioRecorder setDuckOthersOption:]
  -[CSAudioRecorder setAlertSoundFromURL:forType:]
  -[CSAudioRecorder duckOthersOption]
  -[CSAudioRecorder peakPowerForChannel:]
  -[CSAudioRecorder alertStartTime]
  -[CSAudioRecorder queue]
  -[CSAudioRecorder playbackRoute]
  -[CSAudioRecorder setMeteringEnabled:]
  -[CSAudioRecorder averagePowerForChannel:]
  -[CSAudioRecorder setContext:error:]
  -[CSAudioRecorder audioFileReaderDidStartRecording:successfully:error:]
  -[CSAudioRecorder audioFileReaderBufferAvailable:buffer:atTime:]
  -[CSAudioRecorder audioFileReaderDidStopRecording:forReason:]
  -[CSAudioRecorder willDestroy]
  -[CSAudioRecorder setAudioServerCrashEventDelegate:]
  -[CSAudioRecorder setAudioSessionEventDelegate:]
  -[CSAudioRecorder setCurrentContext:streamHandleId:error:]
  -[CSAudioRecorder prepareAudioStreamRecord:streamHandleId:error:]
  -[CSAudioRecorder startAudioStreamWithOption:streamHandleId:error:]
  -[CSAudioRecorder stopAudioStreamWithStreamHandleId:error:]
  -[CSAudioRecorder isRecordingWithStreamHandleId:]
  -[CSAudioRecorder recordRouteWithStreamHandleId:]
  -[CSAudioRecorder recordDeviceInfoWithStreamHandleId:]
  -[CSAudioRecorder recordSettingsWithStreamHandleId:]
  -[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
  -[CSAudioRecorder isNarrowBandWithStreamHandleId:]
  -[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
  -[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
  -[CSAudioRecorder setRecordMode:streamHandleId:error:]
  -[CSAudioRecorder playRecordStartingAlertAndResetEndpointerFromStream:]
  -[CSAudioRecorder isSessionCurrentlyActivated]
  -[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
  -[CSAudioRecorder initWithQueue:error:]
  -[CSAudioRecorder audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:receivedNumChannels:]
  -[CSAudioRecorder _createDeInterleaverIfNeeded]
  -[CSAudioRecorder _deinterleaveBufferIfNeeded:]
  -[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
  -[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
  -[CSAudioRecorder _voiceControllerWithError:]
  -[CSAudioRecorder _destroyVoiceController]
  -[CSAudioRecorder _audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:]
  -[CSAudioRecorder _getRecordSettingsWithRequest:]
  -[CSAudioRecorder _logResourceNotAvailableErrorIfNeeded:]
  -[CSAudioRecorder _shouldInjectAudio]
  -[CSAudioRecorder _needResetAudioInjectionIndex:]
  -[CSAudioRecorder _startAudioStreamForAudioInjection]
  -[CSAudioRecorder _shouldLogResourceNotAvailableError]
  -[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
  -[CSAudioRecorder _processAudioChain:audioStreamHandleId:remoteVAD:atTime:]
  -[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:]
  -[CSAudioRecorder _audioRecorderDidStopRecordingForReason:streamHandleID:]
  -[CSAudioRecorder _shouldUseRemoteRecordForContext:]
  -[CSAudioRecorder _shouldUseRemoteBuiltInMic:]
  -[CSAudioRecorder voiceControllerCreationQueue]
  -[CSAudioRecorder setVoiceControllerCreationQueue:]
  -[CSAudioRecorder crashEventDelegate]
  -[CSAudioRecorder setCrashEventDelegate:]
  -[CSAudioRecorder sessionEventDelegate]
  -[CSAudioRecorder setSessionEventDelegate:]


CSAsset : NSObject /usr/lib/libc++.1.dylib
 @property  NSString *CVTConfigPathNDAPI
 @property  float CVTThreshold
 @property  float CVTTwoShotThreshold
 @property  float CVTTwoShotDecisionWaitTime
 @property  BOOL containsSpeakerRecognitionCategory
 @property  float satScoreThreshold
 @property  long long multiUserLowScoreThreshold
 @property  long long multiUserHighScoreThreshold
 @property  long long multiUserConfidentScoreThreshold
 @property  long long multiUserDeltaScoreThreshold
 @property  float psrCombinationWeight
 @property  float satImplicitProfileThreshold
 @property  float satImplicitProfileDeltaThreshold
 @property  float satVTImplicitThreshold
 @property  BOOL satImplicitTrainingEnabled
 @property  float pruningExplicitUttThresholdSAT
 @property  float pruningExplicitUttThresholdPSR
 @property  float pruningThresholdSAT
 @property  float pruningThresholdPSR
 @property  unsigned long pruningNumRetentionUtterance
 @property  unsigned long maxAllowedEnrollmentUtterances
 @property  NSString *voiceProfilePruningCookie
 @property  NSString *keywordDetectorNDAPIConfigFilePath
 @property  NSString *keywordDetectorQuasarConfigFilePath
 @property  NSString *path
 @property  NSString *resourcePath
 @property  NSDictionary *dictionary
 @property  NSString *hashFromResourcePath
 @property  NSString *configVersion
 @property  unsigned long assetProvider

  // class methods
  +[CSAsset fallBackAssetResourcePath]
  +[CSAsset defaultFallBackAssetForVoiceTrigger]
  +[CSAsset assetForAssetType:resourcePath:configVersion:]
  +[CSAsset assetForAssetType:resourcePath:configVersion:assetProvider:]
  +[CSAsset hybridEndpointerAssetFilename]
  +[CSAsset getConfigFileNameForAssetType:]
  +[CSAsset defaultFallBackAssetForSmartSiriVolume]
  +[CSAsset defaultFallBackAssetForHearst]
  +[CSAsset defaultFallBackAssetForAdBlocker]

  // instance methods
  -[CSAsset path]
  -[CSAsset resourcePath]
  -[CSAsset configVersion]
  -[CSAsset .cxx_destruct]
  -[CSAsset dictionary]
  -[CSAsset getNumberForKey:category:default:]
  -[CSAsset CVTConfigPathNDAPI]
  -[CSAsset CVTThreshold]
  -[CSAsset CVTTwoShotDecisionWaitTime]
  -[CSAsset CVTTwoShotThreshold]
  -[CSAsset VTSecondPassCategoryForFirstPassSource:]
  -[CSAsset VTSecondPassRemoteVADThresholdFrom:]
  -[CSAsset VTSecondPassRemoteVADMyriadThresholdFrom:]
  -[CSAsset VTSecondPassMinimumPhraseLengthForVADGating:]
  -[CSAsset hashFromResourcePath]
  -[CSAsset getStringForKey:category:default:]
  -[CSAsset VTSecondPassConfigPathNDAPIFrom:]
  -[CSAsset containsCategory:]
  -[CSAsset containsKey:category:]
  -[CSAsset VTSecondPassThresholdFrom:]
  -[CSAsset VTSecondPass2ndChanceThresholdFrom:]
  -[CSAsset VTSecondPassLoggingThresholdFrom:]
  -[CSAsset VTSecondPassPreTriggerAudioTimeFrom:]
  -[CSAsset VTSecondPassAnalyzerPrependingAudioTimeFrom:]
  -[CSAsset VTSecondPassAnalyzerTrailingAudioTimeFrom:]
  -[CSAsset VTSecondPassConfigPathRecognizerExistFrom:]
  -[CSAsset VTSecondPassConfigPathRecognizerFrom:]
  -[CSAsset VTSecondPassUseKeywordSpottingFrom:]
  -[CSAsset VTSecondPassRecognizerThresholdOffsetFrom:]
  -[CSAsset VTSecondPassRecognizerScoreScaleFactorFrom:]
  -[CSAsset VTSecondPassRecognizerTokenFrom:]
  -[CSAsset VTSecondPassTwoShotFeedbackDelayFrom:]
  -[CSAsset VTSecondPassShadowMicScoreThresholdForVADGating:]
  -[CSAsset VTSecondPassRejectLoggingThresholdFrom:]
  -[CSAsset assetsRequireSecondPass]
  -[CSAsset VTSecondPassPHSRejectLoggingThresholdFrom:]
  -[CSAsset VTSecondPassPHSThresholdFrom:]
  -[CSAsset supportedVTPhrasesInfoForCategory:]
  -[CSAsset ctcKwdToPhraseIdMapForCategory:]
  -[CSAsset isEqualAsset:]
  -[CSAsset satScoreThreshold]
  -[CSAsset getBoolForKey:category:default:]
  -[CSAsset containsSpeakerRecognitionCategory]
  -[CSAsset multiUserLowScoreThreshold]
  -[CSAsset multiUserHighScoreThreshold]
  -[CSAsset multiUserConfidentScoreThreshold]
  -[CSAsset multiUserDeltaScoreThreshold]
  -[CSAsset psrCombinationWeight]
  -[CSAsset satImplicitProfileThreshold]
  -[CSAsset satImplicitProfileDeltaThreshold]
  -[CSAsset satVTImplicitThreshold]
  -[CSAsset pruningExplicitUttThresholdSAT]
  -[CSAsset pruningExplicitUttThresholdPSR]
  -[CSAsset pruningThresholdSAT]
  -[CSAsset pruningThresholdPSR]
  -[CSAsset pruningNumRetentionUtterance]
  -[CSAsset maxAllowedEnrollmentUtterances]
  -[CSAsset voiceProfilePruningCookie]
  -[CSAsset keywordDetectorQuasarConfigFilePath]
  -[CSAsset keywordDetectorNDAPIConfigFilePath]
  -[CSAsset satImplicitTrainingEnabled]
  -[CSAsset initWithResourcePath:configFile:configVersion:assetProvderType:]
  -[CSAsset _decodeJson:]
  -[CSAsset stringForCurrentAssetProviderType]
  -[CSAsset assetProvider]
  -[CSAsset _getContinuousVoiceTriggerAssetCategory]


SSRTrialAssetProvider : NSObject /usr/lib/libc++.1.dylib <SSRAssetProviding>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRTrialAssetProvider init]
  -[SSRTrialAssetProvider getAssetProviderType]
  -[SSRTrialAssetProvider installedAssetOfType:forLanguageCode:]
  -[SSRTrialAssetProvider reloadForLocale:]


CSVTUIKeywordDetector : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[CSVTUIKeywordDetector .cxx_destruct]
  -[CSVTUIKeywordDetector _sampleLengthFrom:To:]
  -[CSVTUIKeywordDetector initWithAsset:]
  -[CSVTUIKeywordDetector reset]
  -[CSVTUIKeywordDetector analyze:]
  -[CSVTUIKeywordDetector triggeredUtterance:]


CSPolicy : NSObject /usr/lib/libc++.1.dylib <CSEventMonitorDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSPolicy init]
  -[CSPolicy CSEventMonitorDidReceiveEvent:]
  -[CSPolicy dealloc]
  -[CSPolicy .cxx_destruct]
  -[CSPolicy addConditions:]
  -[CSPolicy isEnabled]
  -[CSPolicy setCallback:]
  -[CSPolicy notifyCallbackWithOption:]
  -[CSPolicy subscribeEventMonitor:]
  -[CSPolicy _checkAllConditionsEnabled]
  -[CSPolicy notifyCallback:option:]


CSRemoteRecordClient : NSObject /usr/lib/libc++.1.dylib
 @property  <CSRemoteRecordClientDelegate> *delegate

  // instance methods
  -[CSRemoteRecordClient isConnected]
  -[CSRemoteRecordClient init]
  -[CSRemoteRecordClient dealloc]
  -[CSRemoteRecordClient .cxx_destruct]
  -[CSRemoteRecordClient isRecording]
  -[CSRemoteRecordClient voiceTriggerEventInfo]
  -[CSRemoteRecordClient setDelegate:]
  -[CSRemoteRecordClient stopRecording:]
  -[CSRemoteRecordClient delegate]
  -[CSRemoteRecordClient waitingForConnection:error:]
  -[CSRemoteRecordClient startRecordingWithOptions:error:]
  -[CSRemoteRecordClient didPlayEndpointBeep]
  -[CSRemoteRecordClient hasPendingTwoShotBeep]


SSRVoiceProfileComposer : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[SSRVoiceProfileComposer sharedTrainer]

  // instance methods
  -[SSRVoiceProfileComposer addUtterance:toProfile:withAsset:]
  -[SSRVoiceProfileComposer addUtterance:toProfile:]


SSRVoiceProfileRetrainerPSR : NSObject /usr/lib/libc++.1.dylib <EARSyncPSRAudioProcessorDelegate, SSRVoiceProfileRetrainer>
 @property  SSRSpeakerRecognitionScorer *psrScorer
 @property  SSRVoiceProfile *voiceProfile
 @property  unsigned long spIdType
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  NSString *configVersion
 @property  NSURL *psrModelFilePath
 @property  NSDictionary *comparativeModels
 @property  unsigned long currUttLengthInMs
 @property  NSData *speakerVector
 @property  unsigned long speakerVectorSize
 @property  unsigned long processedAudioDurationMs
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  NSURL *modelFilePath
 @property  BOOL implicitTrainingRequired
 @property  unsigned long retrainerType

  // instance methods
  -[SSRVoiceProfileRetrainerPSR setConfigVersion:]
  -[SSRVoiceProfileRetrainerPSR modelFilePath]
  -[SSRVoiceProfileRetrainerPSR configVersion]
  -[SSRVoiceProfileRetrainerPSR dealloc]
  -[SSRVoiceProfileRetrainerPSR .cxx_destruct]
  -[SSRVoiceProfileRetrainerPSR setQueue:]
  -[SSRVoiceProfileRetrainerPSR processedAudioDurationMs]
  -[SSRVoiceProfileRetrainerPSR setProcessedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerPSR queue]
  -[SSRVoiceProfileRetrainerPSR spIdType]
  -[SSRVoiceProfileRetrainerPSR configFilePath]
  -[SSRVoiceProfileRetrainerPSR resourceFilePath]
  -[SSRVoiceProfileRetrainerPSR setConfigFilePath:]
  -[SSRVoiceProfileRetrainerPSR setResourceFilePath:]
  -[SSRVoiceProfileRetrainerPSR voiceProfile]
  -[SSRVoiceProfileRetrainerPSR initWithVoiceRetrainingContext:]
  -[SSRVoiceProfileRetrainerPSR resetModelForRetraining]
  -[SSRVoiceProfileRetrainerPSR addUtterances:withPolicy:withCompletion:]
  -[SSRVoiceProfileRetrainerPSR needsRetrainingWithAudioFiles:]
  -[SSRVoiceProfileRetrainerPSR purgeLastSpeakerEmbedding]
  -[SSRVoiceProfileRetrainerPSR purgeConfusionInformationWithPolicy:]
  -[SSRVoiceProfileRetrainerPSR implicitTrainingRequired]
  -[SSRVoiceProfileRetrainerPSR retrainerType]
  -[SSRVoiceProfileRetrainerPSR setVoiceProfile:]
  -[SSRVoiceProfileRetrainerPSR setSpIdType:]
  -[SSRVoiceProfileRetrainerPSR comparativeModels]
  -[SSRVoiceProfileRetrainerPSR setComparativeModels:]
  -[SSRVoiceProfileRetrainerPSR _processAudioFile:withPSRProcessor:]
  -[SSRVoiceProfileRetrainerPSR _processSpeakerVector:withSize:withScorers:processedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerPSR _logSpeakerConfusionWithExplicitScores:withImplicitScores:withPurgeUtterances:forProfile:forConfigVersion:]
  -[SSRVoiceProfileRetrainerPSR _composeSpeakerConfusionWithScores:forProfiles:]
  -[SSRVoiceProfileRetrainerPSR _logSpeakerConfusion:forProfileArray:withPrependString:]
  -[SSRVoiceProfileRetrainerPSR psrScorer]
  -[SSRVoiceProfileRetrainerPSR setPsrScorer:]
  -[SSRVoiceProfileRetrainerPSR psrModelFilePath]
  -[SSRVoiceProfileRetrainerPSR setPsrModelFilePath:]
  -[SSRVoiceProfileRetrainerPSR currUttLengthInMs]
  -[SSRVoiceProfileRetrainerPSR setCurrUttLengthInMs:]
  -[SSRVoiceProfileRetrainerPSR speakerVector]
  -[SSRVoiceProfileRetrainerPSR setSpeakerVector:]
  -[SSRVoiceProfileRetrainerPSR speakerVectorSize]
  -[SSRVoiceProfileRetrainerPSR setSpeakerVectorSize:]


SSRLoggingAggregator : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long voiceProfilePruningFailureReasonCode
 @property  float voiceProfileUpdateScoreMSE
 @property  unsigned long voiceProfileDiscardedUtteranceCount
 @property  unsigned long voiceProfilePrunedUtteranceCount
 @property  unsigned long voiceProfileRetainedUtteranceCount
 @property  unsigned long voiceProfileRetrainingFailureReasonCode
 @property  double retrainingWaitTime
 @property  unsigned long speakerRecognitionProcessingStatus
 @property  double speakerRecognitionWaitTime
 @property  unsigned long speakerRecognitionPSRProcessingStatus
 @property  unsigned long speakerRecognitionSATProcessingStatus

  // instance methods
  -[SSRLoggingAggregator .cxx_destruct]
  -[SSRLoggingAggregator setSpeakerRecognitionPSRProcessingStatus:]
  -[SSRLoggingAggregator setSpeakerRecognitionProcessingStatus:]
  -[SSRLoggingAggregator setSpeakerRecognitionWaitTime:]
  -[SSRLoggingAggregator initWithEvent:locale:configVersion:]
  -[SSRLoggingAggregator pushAnalyticsWithLazyBlock:]
  -[SSRLoggingAggregator setVoiceProfilePruningFailureReasonCode:]
  -[SSRLoggingAggregator setVoiceProfileUpdateScoreMSE:]
  -[SSRLoggingAggregator setVoiceProfileDiscardedUtteranceCount:]
  -[SSRLoggingAggregator setvoiceProfilePrunedUtteranceCount:]
  -[SSRLoggingAggregator setVoiceProfileRetainedUtteranceCount:]
  -[SSRLoggingAggregator appendVoiceProfileExplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator appendVoiceProfileImplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator appendVoiceProfileDiscardedImplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator appendVoiceProfileFailedExplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator setVoiceProfileRetrainingFailureReasonCode:]
  -[SSRLoggingAggregator setRetrainingWaitTime:]
  -[SSRLoggingAggregator pushAnalytics]
  -[SSRLoggingAggregator voiceProfilePruningFailureReasonCode]
  -[SSRLoggingAggregator voiceProfileUpdateScoreMSE]
  -[SSRLoggingAggregator voiceProfileDiscardedUtteranceCount]
  -[SSRLoggingAggregator voiceProfilePrunedUtteranceCount]
  -[SSRLoggingAggregator setVoiceProfilePrunedUtteranceCount:]
  -[SSRLoggingAggregator voiceProfileRetainedUtteranceCount]
  -[SSRLoggingAggregator voiceProfileRetrainingFailureReasonCode]
  -[SSRLoggingAggregator retrainingWaitTime]
  -[SSRLoggingAggregator speakerRecognitionProcessingStatus]
  -[SSRLoggingAggregator speakerRecognitionWaitTime]
  -[SSRLoggingAggregator speakerRecognitionPSRProcessingStatus]
  -[SSRLoggingAggregator speakerRecognitionSATProcessingStatus]
  -[SSRLoggingAggregator setSpeakerRecognitionSATProcessingStatus:]


SSRSpeakerRecognizerSAT : NSObject /usr/lib/libc++.1.dylib <SSRSpeakerAnalyzerSATDelegate, SSRSpeakerRecognizer>
 @property  SSRSpeakerRecognitionContext *spIdCtx
 @property  NSString *sessionId
 @property  NSDictionary *lastSpeakerInfo
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <SSRSpeakerRecognizerDelegate> *delegate
 @property  NSString *invocationStyleStr
 @property  unsigned long extraSamplesAtStart
 @property  unsigned long tdEndInSampleCount
 @property  unsigned long totalNumSamplesReceived
 @property  unsigned long numTdTiSamplesProcessed
 @property  BOOL processingEnded
 @property  SSRSpeakerAnalyzerSAT *satAnalyzer
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  NSDictionary *lastScoreCard

  // instance methods
  -[SSRSpeakerRecognizerSAT setSessionId:]
  -[SSRSpeakerRecognizerSAT sessionId]
  -[SSRSpeakerRecognizerSAT dealloc]
  -[SSRSpeakerRecognizerSAT .cxx_destruct]
  -[SSRSpeakerRecognizerSAT endAudio]
  -[SSRSpeakerRecognizerSAT setQueue:]
  -[SSRSpeakerRecognizerSAT spIdCtx]
  -[SSRSpeakerRecognizerSAT queue]
  -[SSRSpeakerRecognizerSAT initWithContext:delegate:]
  -[SSRSpeakerRecognizerSAT setDelegate:]
  -[SSRSpeakerRecognizerSAT delegate]
  -[SSRSpeakerRecognizerSAT resetWithContext:]
  -[SSRSpeakerRecognizerSAT extraSamplesAtStart]
  -[SSRSpeakerRecognizerSAT setExtraSamplesAtStart:]
  -[SSRSpeakerRecognizerSAT processAudioData:numSamples:]
  -[SSRSpeakerRecognizerSAT _initializeWithContext:]
  -[SSRSpeakerRecognizerSAT lastScoreCard]
  -[SSRSpeakerRecognizerSAT setSpIdCtx:]
  -[SSRSpeakerRecognizerSAT lastSpeakerInfo]
  -[SSRSpeakerRecognizerSAT setLastSpeakerInfo:]
  -[SSRSpeakerRecognizerSAT invocationStyleStr]
  -[SSRSpeakerRecognizerSAT setInvocationStyleStr:]
  -[SSRSpeakerRecognizerSAT processingEnded]
  -[SSRSpeakerRecognizerSAT setProcessingEnded:]
  -[SSRSpeakerRecognizerSAT totalNumSamplesReceived]
  -[SSRSpeakerRecognizerSAT setTotalNumSamplesReceived:]
  -[SSRSpeakerRecognizerSAT voiceRecognitionSATAnalyzer:hasVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerSAT voiceRecognitionSATAnalyzerFinishedProcessing:withVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerSAT tdEndInSampleCount]
  -[SSRSpeakerRecognizerSAT setTdEndInSampleCount:]
  -[SSRSpeakerRecognizerSAT numTdTiSamplesProcessed]
  -[SSRSpeakerRecognizerSAT setNumTdTiSamplesProcessed:]
  -[SSRSpeakerRecognizerSAT satAnalyzer]
  -[SSRSpeakerRecognizerSAT setSatAnalyzer:]


CSVoiceIdXPCClient : NSObject /usr/lib/libc++.1.dylib
 @property  NSObject<OS_xpc_object> *xpcConnection

  // instance methods
  -[CSVoiceIdXPCClient _decodeError:]
  -[CSVoiceIdXPCClient disconnect]
  -[CSVoiceIdXPCClient setXpcConnection:]
  -[CSVoiceIdXPCClient connect]
  -[CSVoiceIdXPCClient init]
  -[CSVoiceIdXPCClient xpcConnection]
  -[CSVoiceIdXPCClient dealloc]
  -[CSVoiceIdXPCClient .cxx_destruct]
  -[CSVoiceIdXPCClient _handleListenerEvent:]
  -[CSVoiceIdXPCClient _sendMessage:connection:completion:]
  -[CSVoiceIdXPCClient _handleListenerError:]
  -[CSVoiceIdXPCClient notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:]


SSRVoiceProfileStoreCleaner : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[SSRVoiceProfileStoreCleaner _cleanupAppDomain:]
  -[SSRVoiceProfileStoreCleaner _cleanuplanguageCodePath:forAppDomain:]
  -[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesForProfile:payloadUtteranceLifeTimeInDays:]
  -[SSRVoiceProfileStoreCleaner _cleanupImplicitUtteranceCacheForProfile:]
  -[SSRVoiceProfileStoreCleaner _cleanupContentsOfSatFolder:]
  -[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesAtURL:]
  -[SSRVoiceProfileStoreCleaner _cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:]
  -[SSRVoiceProfileStoreCleaner _cleanupInvalidAudioFiles:]
  -[SSRVoiceProfileStoreCleaner _cleanupModelFilesAtDir:forAssetArray:]
  -[SSRVoiceProfileStoreCleaner filterDuplicatedSiriProfilesFrom:]
  -[SSRVoiceProfileStoreCleaner filterInvalidSiriProfilesFrom:]
  -[SSRVoiceProfileStoreCleaner cleanupProfileStore]
  -[SSRVoiceProfileStoreCleaner cleanupInvalidModelsForProfile:withAssetArray:]


SSRVoiceProfile : NSObject /usr/lib/libc++.1.dylib <NSSecureCoding>
 @property  NSString *profileBasePath
 @property  NSString *voiceProfileBasePath
 @property  NSString *voiceProfileImplicitCacheDirPath
 @property  NSString *voiceProfileIdentity
 @property  unsigned long voiceProfileVersion
 @property  unsigned long productCategory
 @property  NSString *pruningCookie
 @property  BOOL profileLocallyAvailable
 @property  NSNumber *profilePitch
 @property  NSString *userName
 @property  NSString *locale
 @property  NSString *appDomain
 @property  NSDate *dateAdded
 @property  NSString *profileID
 @property  NSString *siriProfileId

  // class methods
  +[SSRVoiceProfile supportsSecureCoding]

  // instance methods
  -[SSRVoiceProfile profileID]
  -[SSRVoiceProfile locale]
  -[SSRVoiceProfile .cxx_destruct]
  -[SSRVoiceProfile setUserName:]
  -[SSRVoiceProfile userName]
  -[SSRVoiceProfile encodeWithCoder:]
  -[SSRVoiceProfile initWithDictionary:]
  -[SSRVoiceProfile dateAdded]
  -[SSRVoiceProfile dictionaryRepresentation]
  -[SSRVoiceProfile initWithCoder:]
  -[SSRVoiceProfile siriProfileId]
  -[SSRVoiceProfile appDomain]
  -[SSRVoiceProfile productCategory]
  -[SSRVoiceProfile voiceProfileBasePath]
  -[SSRVoiceProfile initNewVoiceProfileWithLocale:withAppDomain:]
  -[SSRVoiceProfile profilePitch]
  -[SSRVoiceProfile voiceProfileAudioDirPathForSpidType:]
  -[SSRVoiceProfile getExplicitEnrollmentUtterancesForType:]
  -[SSRVoiceProfile isMarkedSATEnrolled]
  -[SSRVoiceProfile voiceProfileImplicitCacheDirPath]
  -[SSRVoiceProfile voiceProfileIdentity]
  -[SSRVoiceProfile voiceProfileVersion]
  -[SSRVoiceProfile getImplicitEnrollmentUtterancesPriorTo:forType:]
  -[SSRVoiceProfile voiceProfileModelDirForSpidType:recognizerType:]
  -[SSRVoiceProfile addUtterances:spIdType:]
  -[SSRVoiceProfile getEnrollmentUtterancesForModelType:]
  -[SSRVoiceProfile _voiceProfilePathForSpidType:]
  -[SSRVoiceProfile _getProfileVersionFilePath]
  -[SSRVoiceProfile _updateVoiceProfileVersionFile]
  -[SSRVoiceProfile _markSATEnrollmentWithMarker:]
  -[SSRVoiceProfile _isSATMarkedWithMarker:]
  -[SSRVoiceProfile setSharedSiriProfileId:]
  -[SSRVoiceProfile voiceProfileModelFilePathForRecognizerType:spIdType:]
  -[SSRVoiceProfile importVoiceProfileAtPath:]
  -[SSRVoiceProfile getExplicitMarkedEnrollmentUtterancesForType:]
  -[SSRVoiceProfile getImplicitEnrollmentUtterancesForType:]
  -[SSRVoiceProfile profileLocallyAvailable]
  -[SSRVoiceProfile deleteModelForSpidType:recognizerType:]
  -[SSRVoiceProfile markSATEnrollmentSuccess]
  -[SSRVoiceProfile markSATEnrollmentMigrated]
  -[SSRVoiceProfile isMarkedSATMigrated]
  -[SSRVoiceProfile pruningCookie]
  -[SSRVoiceProfile updatePruningCookie:]
  -[SSRVoiceProfile profileBasePath]
  -[SSRVoiceProfile setProfileBasePath:]
  -[SSRVoiceProfile setProfilePitch:]


SSRTriggerPhraseDetectorQuasar : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[SSRTriggerPhraseDetectorQuasar analyzeWavData:numSamples:]
  -[SSRTriggerPhraseDetectorQuasar .cxx_destruct]
  -[SSRTriggerPhraseDetectorQuasar endAudio]
  -[SSRTriggerPhraseDetectorQuasar reset]
  -[SSRTriggerPhraseDetectorQuasar initWithLocale:configPath:resourcePath:]


CSPowerAssertionGibraltar : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[CSPowerAssertionGibraltar init]
  -[CSPowerAssertionGibraltar invalidate]
  -[CSPowerAssertionGibraltar initWithName:timeout:]


CSDiagnosticReporter : NSObject /usr/lib/libc++.1.dylib
 @property  SDRDiagnosticReporter *reporter
 @property  NSObject<OS_dispatch_queue> *queue

  // class methods
  +[CSDiagnosticReporter sharedInstance]

  // instance methods
  -[CSDiagnosticReporter init]
  -[CSDiagnosticReporter reporter]
  -[CSDiagnosticReporter .cxx_destruct]
  -[CSDiagnosticReporter setQueue:]
  -[CSDiagnosticReporter queue]
  -[CSDiagnosticReporter submitAudioIssueReport:]
  -[CSDiagnosticReporter submitDiagnosticReportWithType:withSubType:withDuration:withContext:]
  -[CSDiagnosticReporter submitTrialIssueReport:]
  -[CSDiagnosticReporter submitVoiceIdIssueReport:]
  -[CSDiagnosticReporter submitVoiceTriggerIssueReport:]
  -[CSDiagnosticReporter submitEndpointerIssueReport:]
  -[CSDiagnosticReporter setReporter:]


CSServerEndpointFeatures : NSObject /usr/lib/libc++.1.dylib
 @property  long long wordCount
 @property  long long trailingSilenceDuration
 @property  double eosLikelihood
 @property  NSArray *pauseCounts
 @property  double silencePosterior
 @property  long long processedAudioDurationInMilliseconds
 @property  NSString *taskName

  // instance methods
  -[CSServerEndpointFeatures .cxx_destruct]
  -[CSServerEndpointFeatures dictionary]
  -[CSServerEndpointFeatures eosLikelihood]
  -[CSServerEndpointFeatures setEosLikelihood:]
  -[CSServerEndpointFeatures pauseCounts]
  -[CSServerEndpointFeatures setPauseCounts:]
  -[CSServerEndpointFeatures setTaskName:]
  -[CSServerEndpointFeatures trailingSilenceDuration]
  -[CSServerEndpointFeatures setTrailingSilenceDuration:]
  -[CSServerEndpointFeatures taskName]
  -[CSServerEndpointFeatures wordCount]
  -[CSServerEndpointFeatures setWordCount:]
  -[CSServerEndpointFeatures silencePosterior]
  -[CSServerEndpointFeatures setSilencePosterior:]
  -[CSServerEndpointFeatures setProcessedAudioDurationInMilliseconds:]
  -[CSServerEndpointFeatures processedAudioDurationInMilliseconds]
  -[CSServerEndpointFeatures initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:]
  -[CSServerEndpointFeatures initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:]


CSAVVoiceTriggerClientManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[CSAVVoiceTriggerClientManager sharedVoiceTriggerClient]


CSAudioTimeConverter : NSObject /usr/lib/libc++.1.dylib
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long anchorSampleCount
 @property  unsigned long anchorHostTime

  // class methods
  +[CSAudioTimeConverter sharedInstance]

  // instance methods
  -[CSAudioTimeConverter init]
  -[CSAudioTimeConverter .cxx_destruct]
  -[CSAudioTimeConverter setQueue:]
  -[CSAudioTimeConverter queue]
  -[CSAudioTimeConverter hostTimeFromSampleCount:]
  -[CSAudioTimeConverter sampleCountFromHostTime:]
  -[CSAudioTimeConverter processSampleCount:hostTime:]
  -[CSAudioTimeConverter anchorSampleCount]
  -[CSAudioTimeConverter setAnchorSampleCount:]
  -[CSAudioTimeConverter anchorHostTime]
  -[CSAudioTimeConverter setAnchorHostTime:]


SSRVoiceProfilePruner : NSObject /usr/lib/libc++.1.dylib <SSRSpeakerRecognitionControllerDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRVoiceProfilePruner _retrainVoiceProfile:withAsset:]
  -[SSRVoiceProfilePruner _getScoresForAudio:withController:withDetector:forProfile:withCompletion:]
  -[SSRVoiceProfilePruner _deleteUtterances:]
  -[SSRVoiceProfilePruner pruneVoiceProfile:forSpIdType:withAsset:]


SSRVoiceProfileRetrainingContext : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *compareVoiceProfileArray
 @property  SSRVoiceProfile *voiceProfile
 @property  unsigned long spIdType
 @property  NSURL *resourceFilePath
 @property  NSString *configVersion
 @property  BOOL filterToVoiceTriggerUtterances
 @property  BOOL forceRetrain
 @property  unsigned long maxAllowedSpeakerVectors
 @property  NSDictionary *modelsContext
 @property  float combinationWeight
 @property  CSAsset *asset
 @property  SSRLoggingAggregator *logAggregator
 @property  NSString *sessionId

  // instance methods
  -[SSRVoiceProfileRetrainingContext setAsset:]
  -[SSRVoiceProfileRetrainingContext asset]
  -[SSRVoiceProfileRetrainingContext sessionId]
  -[SSRVoiceProfileRetrainingContext configVersion]
  -[SSRVoiceProfileRetrainingContext .cxx_destruct]
  -[SSRVoiceProfileRetrainingContext spIdType]
  -[SSRVoiceProfileRetrainingContext initWithVoiceRetrainingContext:error:]
  -[SSRVoiceProfileRetrainingContext modelsContext]
  -[SSRVoiceProfileRetrainingContext resourceFilePath]
  -[SSRVoiceProfileRetrainingContext logAggregator]
  -[SSRVoiceProfileRetrainingContext combinationWeight]
  -[SSRVoiceProfileRetrainingContext forceRetrain]
  -[SSRVoiceProfileRetrainingContext voiceProfile]
  -[SSRVoiceProfileRetrainingContext maxAllowedSpeakerVectors]
  -[SSRVoiceProfileRetrainingContext setVoiceProfile:]
  -[SSRVoiceProfileRetrainingContext compareVoiceProfileArray]
  -[SSRVoiceProfileRetrainingContext setCompareVoiceProfileArray:]
  -[SSRVoiceProfileRetrainingContext filterToVoiceTriggerUtterances]
  -[SSRVoiceProfileRetrainingContext setLogAggregator:]


SSRVoiceProfileModelContext : NSObject /usr/lib/libc++.1.dylib
 @property  NSURL *configFilePath
 @property  NSURL *voiceProfileModelFilePath
 @property  NSDictionary *compareModelFilePaths

  // instance methods
  -[SSRVoiceProfileModelContext .cxx_destruct]
  -[SSRVoiceProfileModelContext configFilePath]
  -[SSRVoiceProfileModelContext voiceProfileModelFilePath]
  -[SSRVoiceProfileModelContext compareModelFilePaths]
  -[SSRVoiceProfileModelContext initWithConfigFilePath:withModelPath:withCompareModelFilePaths:]


CSVoiceTriggerEventInfoProvider : NSObject /usr/lib/libc++.1.dylib
 @property  NSDictionary *voiceTriggerInfo
 @property  NSDictionary *rtsTriggerInfo
 @property  unsigned long triggerNotifiedMachTime

  // class methods
  +[CSVoiceTriggerEventInfoProvider sharedInstance]

  // instance methods
  -[CSVoiceTriggerEventInfoProvider voiceTriggerInfo]
  -[CSVoiceTriggerEventInfoProvider .cxx_destruct]
  -[CSVoiceTriggerEventInfoProvider setVoiceTriggerInfo:]
  -[CSVoiceTriggerEventInfoProvider rtsTriggerInfo]
  -[CSVoiceTriggerEventInfoProvider setRtsTriggerInfo:]
  -[CSVoiceTriggerEventInfoProvider triggerNotifiedMachTime]
  -[CSVoiceTriggerEventInfoProvider setTriggerNotifiedMachTime:]


SSRVoiceProfileMetadataManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[SSRVoiceProfileMetadataManager _getBaseMetaDictionaryForUtterancePath:]
  +[SSRVoiceProfileMetadataManager isUtteranceImplicitlyTrained:]
  +[SSRVoiceProfileMetadataManager getUtteranceEnrollmentType:]
  +[SSRVoiceProfileMetadataManager recordedTimeStampFromFileName:]
  +[SSRVoiceProfileMetadataManager recordedTimeStampOfFile:]
  +[SSRVoiceProfileMetadataManager _writeMetaDict:forUtterancePath:]
  +[SSRVoiceProfileMetadataManager saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:]


CSVTUIRegularExpressionMatcher : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[CSVTUIRegularExpressionMatcher matchWithString:TrailingStr:LeadingStr:Pattern:]


CSVTUITrainingSessionWithPayload : CSVTUITrainingSession <SFSpeechRecognitionTaskDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndPointDelegate>
 @property  NSDictionary *voiceTriggerEventInfo
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUITrainingSessionWithPayload .cxx_destruct]
  -[CSVTUITrainingSessionWithPayload voiceTriggerEventInfo]
  -[CSVTUITrainingSessionWithPayload setVoiceTriggerEventInfo:]
  -[CSVTUITrainingSessionWithPayload audioSessionDidStopRecording:]
  -[CSVTUITrainingSessionWithPayload audioSessionRecordBufferAvailable:]
  -[CSVTUITrainingSessionWithPayload audioSessionDidStartRecording:error:]
  -[CSVTUITrainingSessionWithPayload audioSessionErrorDidOccur:]
  -[CSVTUITrainingSessionWithPayload audioSessionUnsupportedAudioRoute]
  -[CSVTUITrainingSessionWithPayload startTraining]
  -[CSVTUITrainingSessionWithPayload didDetectBeginOfSpeech]
  -[CSVTUITrainingSessionWithPayload didDetectEndOfSpeech:]
  -[CSVTUITrainingSessionWithPayload _firedVoiceTriggerTimeout]
  -[CSVTUITrainingSessionWithPayload shouldHandleSession]
  -[CSVTUITrainingSessionWithPayload shouldMatchPayload]
  -[CSVTUITrainingSessionWithPayload closeSessionWithStatus:successfully:]
  -[CSVTUITrainingSessionWithPayload _firedEndPointTimeout]
  -[CSVTUITrainingSessionWithPayload _registerVoiceTriggerTimeout]
  -[CSVTUITrainingSessionWithPayload handleAudioInput:]
  -[CSVTUITrainingSessionWithPayload _reportStopListening]
  -[CSVTUITrainingSessionWithPayload _registerEndPointTimeout]
  -[CSVTUITrainingSessionWithPayload _registerForceEndPointTimeout]
  -[CSVTUITrainingSessionWithPayload matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:]
  -[CSVTUITrainingSessionWithPayload speechRecognitionTask:didHypothesizeTranscription:]
  -[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishRecognition:]
  -[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishSuccessfully:]


CSVTUITrainingSession : NSObject /usr/lib/libc++.1.dylib <SFSpeechRecognitionTaskDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndPointDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUITrainingSession .cxx_destruct]
  -[CSVTUITrainingSession audioSessionDidStopRecording:]
  -[CSVTUITrainingSession audioSessionRecordBufferAvailable:]
  -[CSVTUITrainingSession audioSessionDidStartRecording:error:]
  -[CSVTUITrainingSession audioSessionErrorDidOccur:]
  -[CSVTUITrainingSession audioSessionUnsupportedAudioRoute]
  -[CSVTUITrainingSession initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:completion:]
  -[CSVTUITrainingSession startTraining]
  -[CSVTUITrainingSession suspendTraining]
  -[CSVTUITrainingSession closeSessionWithStatus:successfully:complete:]
  -[CSVTUITrainingSession resumeTraining]
  -[CSVTUITrainingSession didDetectBeginOfSpeech]
  -[CSVTUITrainingSession didDetectEndOfSpeech:]
  -[CSVTUITrainingSession finishSpeechRecognitionTask]
  -[CSVTUITrainingSession closeSessionWithStatus:successfully:]
  -[CSVTUITrainingSession updateMeterAndForward]
  -[CSVTUITrainingSession pushAudioInputIntoPCMBuffer:]
  -[CSVTUITrainingSession setupSpeechRecognitionTaskWithVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession feedSpeechRecognitionWithPCMBuffer]
  -[CSVTUITrainingSession handleAudioBufferForVTWithAudioInput:withDetectedBlock:]
  -[CSVTUITrainingSession handleAudioInput:]
  -[CSVTUITrainingSession _registerEndPointTimeout]
  -[CSVTUITrainingSession requestTriggeredUtterance:]
  -[CSVTUITrainingSession speechRecognitionTask:didHypothesizeTranscription:]
  -[CSVTUITrainingSession setupPhraseSpotter]
  -[CSVTUITrainingSession startMasterTimerWithTimeout:]
  -[CSVTUITrainingSession resultAlreadyReported]
  -[CSVTUITrainingSession stopMasterTimer]
  -[CSVTUITrainingSession closeSessionWithCompletion:]
  -[CSVTUITrainingSession trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession computeRequiredTrailingSamples]
  -[CSVTUITrainingSession feedSpeechRecognitionTrailingSamplesWithCompletedBlock:]
  -[CSVTUITrainingSession numSamplesInPCMBuffer]
  -[CSVTUITrainingSession createAVAudioPCMBufferWithNSData:]
  -[CSVTUITrainingSession handleMasterTimeout:]


SSRVoiceProfileManager : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long currentDeviceCategory
 @property  CSVoiceIdXPCClient *xpcClient
 @property  NSObject<OS_dispatch_queue> *queue

  // class methods
  +[SSRVoiceProfileManager sharedInstance]

  // instance methods
  -[SSRVoiceProfileManager xpcClient]
  -[SSRVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]
  -[SSRVoiceProfileManager .cxx_destruct]
  -[SSRVoiceProfileManager setQueue:]
  -[SSRVoiceProfileManager isSATEnrolledForSiriProfileId:forLanguageCode:]
  -[SSRVoiceProfileManager baseDir]
  -[SSRVoiceProfileManager getSATEnrollmentPath]
  -[SSRVoiceProfileManager queue]
  -[SSRVoiceProfileManager SSRSpeakerProfilesBasePath]
  -[SSRVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]
  -[SSRVoiceProfileManager setXpcClient:]
  -[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:]
  -[SSRVoiceProfileManager enableVoiceTriggerUponVoiceProfileSyncForLanguage:]
  -[SSRVoiceProfileManager provisionedVoiceProfilesForAppDomain:withLocale:]
  -[SSRVoiceProfileManager voiceProfileForId:]
  -[SSRVoiceProfileManager _isDirectory:]
  -[SSRVoiceProfileManager _isRemoteVoiceTriggerAvailable]
  -[SSRVoiceProfileManager isSpeakerRecognitionAvailable]
  -[SSRVoiceProfileManager getVoiceProfileAnalyticsForAppDomain:withLocale:]
  -[SSRVoiceProfileManager isSATEnrollmentMigratedForSiriProfileId:forLanguageCode:]
  -[SSRVoiceProfileManager newVoiceProfileWithLocale:withAppDomain:]
  -[SSRVoiceProfileManager addUtterances:toProfile:withContext:withCompletion:]
  -[SSRVoiceProfileManager updateVoiceProfile:withUserName:]
  -[SSRVoiceProfileManager provisionedVoiceProfilesForLocale:]
  -[SSRVoiceProfileManager deleteUserVoiceProfile:]
  -[SSRVoiceProfileManager triggerVoiceProfileCleanupWithCompletion:]
  -[SSRVoiceProfileManager triggerVoiceProfileDuplicatesCleanup]
  -[SSRVoiceProfileManager triggerVoiceProfileMigrationWithCompletion:]
  -[SSRVoiceProfileManager cleanupVoiceProfileModelFilesForLocale:]
  -[SSRVoiceProfileManager pruneImplicitUtterancesOfProfile:withAsset:]
  -[SSRVoiceProfileManager triggerRetrainingVoiceProfile:withContext:withCompletion:]
  -[SSRVoiceProfileManager SSRBasePathForAppDomain:]
  -[SSRVoiceProfileManager setCurrentDeviceCategory:]
  -[SSRVoiceProfileManager discardSiriEnrollmentForProfileId:forLanguageCode:]
  -[SSRVoiceProfileManager _getVoiceProfilesForSiriProfileId:withLanguageCode:]
  -[SSRVoiceProfileManager _markVoiceProfileTrainingSyncForLanguage:]
  -[SSRVoiceProfileManager _CSSATDownloadPath]
  -[SSRVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:]
  -[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]
  -[SSRVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:]
  -[SSRVoiceProfileManager _downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:]
  -[SSRVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryForProfileId:forDeviceCategory:forVoiceProfileVersion:]
  -[SSRVoiceProfileManager _enableVoiceTriggerIfLanguageMatches:]
  -[SSRVoiceProfileManager _CSSATUploadPathForSiriProfileId:]
  -[SSRVoiceProfileManager _prepareVoiceProfileWithSiriProfileId:withUploadBlock:]
  -[SSRVoiceProfileManager _CSSATLegacyUploadPath]
  -[SSRVoiceProfileManager _getVoiceProfilePathsToBeUploadedForSiriProfileId:]
  -[SSRVoiceProfileManager _copyExplicitEnrollmentFilesFromPath:toPath:withCompletion:]
  -[SSRVoiceProfileManager _copyVoiceProfileAtPath:toPath:]
  -[SSRVoiceProfileManager _isMarkedForVoiceProfileTrainingSyncForLanguage:]
  -[SSRVoiceProfileManager _isLegacyEnrollmentMarkedWith:forLanguageCode:]
  -[SSRVoiceProfileManager _CSSATCachePath]
  -[SSRVoiceProfileManager modelDirectoryPathForProfile:]
  -[SSRVoiceProfileManager discardSiriEnrollmentForLanguageCode:]
  -[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:withCompletion:]
  -[SSRVoiceProfileManager getUserVoiceProfileUpdateDirectory]
  -[SSRVoiceProfileManager notifyUserVoiceProfileDownloadReadyForUser:getData:completion:]
  -[SSRVoiceProfileManager notifyUserVoiceProfileUpdateReady]
  -[SSRVoiceProfileManager notifyUserVoiceProfileUploadCompleteForSiriProfileId:withError:]
  -[SSRVoiceProfileManager uploadUserVoiceProfileForSiriProfileId:withUploadTrigger:completion:]
  -[SSRVoiceProfileManager getUserVoiceProfileUploadPathWithEnrolledLanguageList:]
  -[SSRVoiceProfileManager notifyUserVoiceProfileUploadComplete]
  -[SSRVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]
  -[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:]
  -[SSRVoiceProfileManager markSATEnrollmentSuccessForVoiceProfile:]
  -[SSRVoiceProfileManager deleteAllVoiceProfilesForAppDomain:]
  -[SSRVoiceProfileManager currentDeviceCategory]


CSAudioCircularBuffer : NSObject /usr/lib/libc++.1.dylib
 @property  unsigned long bufferLength

  // class methods
  +[CSAudioCircularBuffer createAudioCircularBufferWithDefaultSettings]

  // instance methods
  -[CSAudioCircularBuffer sampleCount]
  -[CSAudioCircularBuffer .cxx_construct]
  -[CSAudioCircularBuffer .cxx_destruct]
  -[CSAudioCircularBuffer addSamples:numSamples:]
  -[CSAudioCircularBuffer reset]
  -[CSAudioCircularBuffer initWithNumChannels:recordingDuration:samplingRate:]
  -[CSAudioCircularBuffer copybufferFrom:to:]
  -[CSAudioCircularBuffer bufferLength]
  -[CSAudioCircularBuffer copySamplesFrom:to:]
  -[CSAudioCircularBuffer copyBufferWithNumSamplesCopiedIn:]
  -[CSAudioCircularBuffer addSamples:numSamples:atHostTime:]
  -[CSAudioCircularBuffer copySamplesFromHostTime:]
  -[CSAudioCircularBuffer copySamplesFrom:to:channelIdx:]
  -[CSAudioCircularBuffer setBufferLength:]


CSAudioZeroFilter : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[CSAudioZeroFilter metrics]
  -[CSAudioZeroFilter .cxx_construct]
  -[CSAudioZeroFilter .cxx_destruct]
  -[CSAudioZeroFilter initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:]
  -[CSAudioZeroFilter filterZerosInAudioPacket:atBufferHostTime:filteredPacket:]
  -[CSAudioZeroFilter endAudioAndFetchAnyTrailingZerosPacket:]


CSNNVADEndpointAnalyzer : NSObject /usr/lib/libc++.1.dylib <SNResultsObserving, CSEndpointAnalyzerImpl>
 @property  SNAudioStreamAnalyzer *snAudioStreamAnalyzer
 @property  unsigned long framePosition
 @property  unsigned long nnvadState
 @property  unsigned long numSamplesReceived
 @property  unsigned long currentRequestSampleRate
 @property  AVAudioFormat *currentRequestAudioFormat
 @property  double vtEndInSecs
 @property  unsigned long vtEndInSampleCount
 @property  double vtExtraAudioAtStartInMs
 @property  double nnvadAudioOriginInMs
 @property  BOOL shouldDetectTwoShot
 @property  BOOL didEnterTwoshot
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <CSAudioFileWriter> *audioFileWriter
 @property  double firstAudioSampleSensorTimestamp
 @property  long long firstSampleId
 @property  unsigned long numSamplesSkippedForVT
 @property  BOOL finishedSkippingSamplesForVT
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  <CSEndpointAnalyzerDelegate> *delegate
 @property  <CSEndpointAnalyzerImplDelegate> *implDelegate
 @property  BOOL canProcessCurrentRequest
 @property  unsigned long activeChannel
 @property  NSString *endpointerModelVersion
 @property  double elapsedTimeWithNoSpeech
 @property  long long endpointStyle
 @property  double delay
 @property  double startWaitTime
 @property  double automaticEndpointingSuspensionEndTime
 @property  double minimumDurationForEndpointer
 @property  double lastEndOfVoiceActivityTime
 @property  double lastStartOfVoiceActivityTime
 @property  double bypassSamples
 @property  long long endpointMode
 @property  double interspeechWaitTime
 @property  double endWaitTime
 @property  BOOL saveSamplesSeenInReset

  // class methods
  +[CSNNVADEndpointAnalyzer timeStampString]

  // instance methods
  -[CSNNVADEndpointAnalyzer setDelay:]
  -[CSNNVADEndpointAnalyzer delay]
  -[CSNNVADEndpointAnalyzer preheat]
  -[CSNNVADEndpointAnalyzer init]
  -[CSNNVADEndpointAnalyzer .cxx_destruct]
  -[CSNNVADEndpointAnalyzer setActiveChannel:]
  -[CSNNVADEndpointAnalyzer setQueue:]
  -[CSNNVADEndpointAnalyzer framePosition]
  -[CSNNVADEndpointAnalyzer setFramePosition:]
  -[CSNNVADEndpointAnalyzer endpointMode]
  -[CSNNVADEndpointAnalyzer endWaitTime]
  -[CSNNVADEndpointAnalyzer setEndpointMode:]
  -[CSNNVADEndpointAnalyzer startWaitTime]
  -[CSNNVADEndpointAnalyzer setStartWaitTime:]
  -[CSNNVADEndpointAnalyzer setEndWaitTime:]
  -[CSNNVADEndpointAnalyzer interspeechWaitTime]
  -[CSNNVADEndpointAnalyzer setInterspeechWaitTime:]
  -[CSNNVADEndpointAnalyzer queue]
  -[CSNNVADEndpointAnalyzer lastStartOfVoiceActivityTime]
  -[CSNNVADEndpointAnalyzer lastEndOfVoiceActivityTime]
  -[CSNNVADEndpointAnalyzer setAutomaticEndpointingSuspensionEndTime:]
  -[CSNNVADEndpointAnalyzer automaticEndpointingSuspensionEndTime]
  -[CSNNVADEndpointAnalyzer minimumDurationForEndpointer]
  -[CSNNVADEndpointAnalyzer setMinimumDurationForEndpointer:]
  -[CSNNVADEndpointAnalyzer reset]
  -[CSNNVADEndpointAnalyzer request:didProduceResult:]
  -[CSNNVADEndpointAnalyzer setDelegate:]
  -[CSNNVADEndpointAnalyzer activeChannel]
  -[CSNNVADEndpointAnalyzer request:didFailWithError:]
  -[CSNNVADEndpointAnalyzer delegate]
  -[CSNNVADEndpointAnalyzer audioFileWriter]
  -[CSNNVADEndpointAnalyzer setAudioFileWriter:]
  -[CSNNVADEndpointAnalyzer _pcmBufferForAudioChunk:]
  -[CSNNVADEndpointAnalyzer _effectiveAudioTimeInSecsForSNObservation:]
  -[CSNNVADEndpointAnalyzer _reportStartpointAtTsInSecs:]
  -[CSNNVADEndpointAnalyzer _shouldEnterTwoShotAtAudioTimeInSecs:]
  -[CSNNVADEndpointAnalyzer _reportTwoShotAtTsInSecs:]
  -[CSNNVADEndpointAnalyzer _reportEndpointAtTsInSecs:]
  -[CSNNVADEndpointAnalyzer _checkSNObservationForStartpoint:]
  -[CSNNVADEndpointAnalyzer _checkSNObservationForEndpoint:]
  -[CSNNVADEndpointAnalyzer endpointStyle]
  -[CSNNVADEndpointAnalyzer setEndpointStyle:]
  -[CSNNVADEndpointAnalyzer saveSamplesSeenInReset]
  -[CSNNVADEndpointAnalyzer setSaveSamplesSeenInReset:]
  -[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:recordSettings:]
  -[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
  -[CSNNVADEndpointAnalyzer stopEndpointer]
  -[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
  -[CSNNVADEndpointAnalyzer trailingSilenceDurationAtEndpoint]
  -[CSNNVADEndpointAnalyzer implDelegate]
  -[CSNNVADEndpointAnalyzer setImplDelegate:]
  -[CSNNVADEndpointAnalyzer canProcessCurrentRequest]
  -[CSNNVADEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]
  -[CSNNVADEndpointAnalyzer snAudioStreamAnalyzer]
  -[CSNNVADEndpointAnalyzer setSnAudioStreamAnalyzer:]
  -[CSNNVADEndpointAnalyzer nnvadState]
  -[CSNNVADEndpointAnalyzer setNnvadState:]
  -[CSNNVADEndpointAnalyzer numSamplesReceived]
  -[CSNNVADEndpointAnalyzer setNumSamplesReceived:]
  -[CSNNVADEndpointAnalyzer currentRequestSampleRate]
  -[CSNNVADEndpointAnalyzer setCurrentRequestSampleRate:]
  -[CSNNVADEndpointAnalyzer currentRequestAudioFormat]
  -[CSNNVADEndpointAnalyzer setCurrentRequestAudioFormat:]
  -[CSNNVADEndpointAnalyzer vtEndInSecs]
  -[CSNNVADEndpointAnalyzer setVtEndInSecs:]
  -[CSNNVADEndpointAnalyzer vtEndInSampleCount]
  -[CSNNVADEndpointAnalyzer setVtEndInSampleCount:]
  -[CSNNVADEndpointAnalyzer vtExtraAudioAtStartInMs]
  -[CSNNVADEndpointAnalyzer setVtExtraAudioAtStartInMs:]
  -[CSNNVADEndpointAnalyzer nnvadAudioOriginInMs]
  -[CSNNVADEndpointAnalyzer setNnvadAudioOriginInMs:]
  -[CSNNVADEndpointAnalyzer shouldDetectTwoShot]
  -[CSNNVADEndpointAnalyzer setShouldDetectTwoShot:]
  -[CSNNVADEndpointAnalyzer didEnterTwoshot]
  -[CSNNVADEndpointAnalyzer setDidEnterTwoshot:]
  -[CSNNVADEndpointAnalyzer firstAudioSampleSensorTimestamp]
  -[CSNNVADEndpointAnalyzer setFirstAudioSampleSensorTimestamp:]
  -[CSNNVADEndpointAnalyzer firstSampleId]
  -[CSNNVADEndpointAnalyzer setFirstSampleId:]
  -[CSNNVADEndpointAnalyzer numSamplesSkippedForVT]
  -[CSNNVADEndpointAnalyzer setNumSamplesSkippedForVT:]
  -[CSNNVADEndpointAnalyzer finishedSkippingSamplesForVT]
  -[CSNNVADEndpointAnalyzer setFinishedSkippingSamplesForVT:]


CSAudioRecordContext : NSObject /usr/lib/libc++.1.dylib <NSCopying>
 @property  long long type
 @property  NSString *deviceId
 @property  BOOL alwaysUseRemoteBuiltInMic
 @property  NSObject<OS_xpc_object> *xpcObject

  // class methods
  +[CSAudioRecordContext defaultContext]
  +[CSAudioRecordContext contextForRemoraVoiceTriggerWithDeviceId:]
  +[CSAudioRecordContext contextForHearstVoiceTriggerWithDeviceId:]
  +[CSAudioRecordContext contextForOpportuneSpeakerListener]
  +[CSAudioRecordContext contextForJarvisWithDeviceId:]
  +[CSAudioRecordContext contextForServerInvoke]
  +[CSAudioRecordContext recordTypeString:]
  +[CSAudioRecordContext contextForBuiltInVoiceTrigger]
  +[CSAudioRecordContext contextForBTLEWithDeviceId:]
  +[CSAudioRecordContext contextForVoiceTriggerTraining]
  +[CSAudioRecordContext contextForHomeButton]

  // instance methods
  -[CSAudioRecordContext copyWithZone:]
  -[CSAudioRecordContext setDeviceId:]
  -[CSAudioRecordContext deviceId]
  -[CSAudioRecordContext setType:]
  -[CSAudioRecordContext .cxx_destruct]
  -[CSAudioRecordContext type]
  -[CSAudioRecordContext isEqual:]
  -[CSAudioRecordContext initWithXPCObject:]
  -[CSAudioRecordContext xpcObject]
  -[CSAudioRecordContext avvcContext]
  -[CSAudioRecordContext avvcContextSettings]
  -[CSAudioRecordContext isRTSTriggered]
  -[CSAudioRecordContext isHearstVoiceTriggered]
  -[CSAudioRecordContext isBuiltInVoiceTriggered]
  -[CSAudioRecordContext initWithRecordType:deviceId:]
  -[CSAudioRecordContext setAlwaysUseRemoteBuiltInMic:]
  -[CSAudioRecordContext recordTypeFromAVVCActivationMode:]
  -[CSAudioRecordContext _createAVVCContextWithType:deviceId:]
  -[CSAudioRecordContext avvcActivationMode:]
  -[CSAudioRecordContext isJarvisVoiceTriggered]
  -[CSAudioRecordContext isHearstDoubleTapTriggered]
  -[CSAudioRecordContext initWithAVVCContext:]
  -[CSAudioRecordContext isVoiceTriggered]
  -[CSAudioRecordContext isTriggeredFromHearst]
  -[CSAudioRecordContext isServerInvoked]
  -[CSAudioRecordContext isStarkTriggered]
  -[CSAudioRecordContext isDictation]
  -[CSAudioRecordContext alwaysUseRemoteBuiltInMic]


SSRAssetManager : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *assetProviders
 @property  NSString *currentLanguageCode
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <SSRAssetManagerDelegate> *delegate

  // class methods
  +[SSRAssetManager sharedManager]

  // instance methods
  -[SSRAssetManager init]
  -[SSRAssetManager currentLanguageCode]
  -[SSRAssetManager .cxx_destruct]
  -[SSRAssetManager setCurrentLanguageCode:]
  -[SSRAssetManager setQueue:]
  -[SSRAssetManager queue]
  -[SSRAssetManager setDelegate:]
  -[SSRAssetManager delegate]
  -[SSRAssetManager installedAssetOfType:forLanguage:]
  -[SSRAssetManager allInstalledAssetsOfType:forLanguage:]
  -[SSRAssetManager _latestVersionedAssetOfType:fromProviders:forLocale:]
  -[SSRAssetManager _convertVersionStringToFloat:]
  -[SSRAssetManager assetProviders]
  -[SSRAssetManager setAssetProviders:]


SSRSpeakerRecognitionController : NSObject /usr/lib/libc++.1.dylib <SSRSpeakerRecognitionOrchestratorDelegate>
 @property  SSRSpeakerRecognitionContext *context
 @property  <SSRSpeakerRecognitionControllerDelegate> *delegate
 @property  SSRSpeakerRecognitionOrchestrator *orchestrator
 @property  NSDictionary *lastScoreCard
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRSpeakerRecognitionController context]
  -[SSRSpeakerRecognitionController .cxx_destruct]
  -[SSRSpeakerRecognitionController endAudio]
  -[SSRSpeakerRecognitionController setContext:]
  -[SSRSpeakerRecognitionController setDelegate:]
  -[SSRSpeakerRecognitionController delegate]
  -[SSRSpeakerRecognitionController initWithContext:withDelegate:error:]
  -[SSRSpeakerRecognitionController processAudio:withNumberOfSamples:]
  -[SSRSpeakerRecognitionController resetWithContext:]
  -[SSRSpeakerRecognitionController getLatestSpeakerInfo]
  -[SSRSpeakerRecognitionController lastScoreCard]
  -[SSRSpeakerRecognitionController voiceRecognitionOrchestrator:hasVoiceRecognitionInfo:]
  -[SSRSpeakerRecognitionController voiceRecognitionOrchestratorFinishedProcessing:withFinalVoiceRecognitionInfo:]
  -[SSRSpeakerRecognitionController orchestrator]
  -[SSRSpeakerRecognitionController setOrchestrator:]
  -[SSRSpeakerRecognitionController setLastScoreCard:]


SSRMobileAssetProvider : NSObject /usr/lib/libc++.1.dylib <SSRAssetProviding>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRMobileAssetProvider _findLatestInstalledAsset:]
  -[SSRMobileAssetProvider getAssetProviderType]
  -[SSRMobileAssetProvider installedAssetOfType:forLanguageCode:]
  -[SSRMobileAssetProvider allInstalledAssetsOfType:forLanguage:]
  -[SSRMobileAssetProvider _installedMobileAssetOfType:forLanguage:]
  -[SSRMobileAssetProvider _buildAssetQueryForAssetType:]
  -[SSRMobileAssetProvider _filteredAssets:forLanguage:]
  -[SSRMobileAssetProvider _getSSRAssetTypeString]
  -[SSRMobileAssetProvider _getSSRAssetCurrentCompatibilityVersion]
  -[SSRMobileAssetProvider _getVoiceTriggerAssetTypeString]
  -[SSRMobileAssetProvider _getVoiceTriggerAssetCurrentCompatibilityVersion]
  -[SSRMobileAssetProvider _getEndpointAssetTypeString]
  -[SSRMobileAssetProvider _getEndpointAssetCurrentCompatibilityVersion]


SSRVoiceProfileStore : NSObject /usr/lib/libc++.1.dylib
 @property  NSMutableArray *voiceProfileArray
 @property  NSObject<OS_dispatch_queue> *queue
 @property  SSRVoiceProfileStorePrefs *storePrefs

  // class methods
  +[SSRVoiceProfileStore sharedInstance]

  // instance methods
  -[SSRVoiceProfileStore .cxx_destruct]
  -[SSRVoiceProfileStore setQueue:]
  -[SSRVoiceProfileStore queue]
  -[SSRVoiceProfileStore updateVoiceProfile:withUserName:]
  -[SSRVoiceProfileStore deleteUserVoiceProfile:]
  -[SSRVoiceProfileStore cleanupVoiceProfileModelFilesForLocale:]
  -[SSRVoiceProfileStore userVoiceProfilesForAppDomain:]
  -[SSRVoiceProfileStore userVoiceProfilesForAppDomain:forLocale:]
  -[SSRVoiceProfileStore addUserVoiceProfile:withContext:withCompletion:]
  -[SSRVoiceProfileStore addImplicitUtterance:toVoiceProfile:withAsset:withTriggerSource:withAudioInput:withCompletion:]
  -[SSRVoiceProfileStore checkIfVoiceProfile:needsUpdatedWith:withCategory:]
  -[SSRVoiceProfileStore userVoiceProfilesForLocale:]
  -[SSRVoiceProfileStore userVoiceProfileForVoiceProfileID:]
  -[SSRVoiceProfileStore migrateVoiceProfilesIfNeededWithCompletionBlock:]
  -[SSRVoiceProfileStore cleanupDuplicatedProfiles]
  -[SSRVoiceProfileStore cleanupVoiceProfileStore:]
  -[SSRVoiceProfileStore retrainVoiceProfile:withContext:withCompletion:]
  -[SSRVoiceProfileStore initStore]
  -[SSRVoiceProfileStore _loadVoiceProfiles]
  -[SSRVoiceProfileStore _updateTrainedUsersWithAction:UserVoiceProfile:]
  -[SSRVoiceProfileStore _deleteUserVoiceProfile:]
  -[SSRVoiceProfileStore _synchronizeSiriVoiceProfilesWithAssistant]
  -[SSRVoiceProfileStore _retrainLiveOnOnboardedProfilesForLanguage:withForceRetrain:withCompletion:]
  -[SSRVoiceProfileStore _logVoiceProfileConfusionWithCleanup:]
  -[SSRVoiceProfileStore evaluateImplicitAdditionPolicyWithScores:forProfile:withImplicitThreshold:withDeltaThreshold:]
  -[SSRVoiceProfileStore _getTopScoringProfileIdFromScores:]
  -[SSRVoiceProfileStore _retrainVoiceProfile:withContext:]
  -[SSRVoiceProfileStore _enrolledVoiceProfiles]
  -[SSRVoiceProfileStore _saveTrainedUsers:]
  -[SSRVoiceProfileStore _retrainVoiceProfile:withContext:withUtterances:]
  -[SSRVoiceProfileStore logVoiceProfileConfusionWithCleanup:]
  -[SSRVoiceProfileStore _checkIfRetrainingRequiredForProfile:]
  -[SSRVoiceProfileStore copyAudioFiles:toProfile:forModelType:]
  -[SSRVoiceProfileStore voiceProfileArray]
  -[SSRVoiceProfileStore setVoiceProfileArray:]
  -[SSRVoiceProfileStore storePrefs]
  -[SSRVoiceProfileStore setStorePrefs:]


CSSelectiveChannelAudioFileWriter : NSObject /usr/lib/libc++.1.dylib <CSAudioFileWriter>
 @property  NSURL *fileURL
 @property  unsigned int numberOfChannels
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSSelectiveChannelAudioFileWriter fileURL]
  -[CSSelectiveChannelAudioFileWriter dealloc]
  -[CSSelectiveChannelAudioFileWriter .cxx_destruct]
  -[CSSelectiveChannelAudioFileWriter endAudio]
  -[CSSelectiveChannelAudioFileWriter addSamples:numSamples:]
  -[CSSelectiveChannelAudioFileWriter numberOfChannels]
  -[CSSelectiveChannelAudioFileWriter initWithURL:inputFormat:outputFormat:channelBitset:]


CSAudioDecoder : NSObject /usr/lib/libc++.1.dylib
 @property  <CSAudioDecoderDelegate> *delegate

  // class methods
  +[CSAudioDecoder speexDecoder]
  +[CSAudioDecoder opusDecoder]

  // instance methods
  -[CSAudioDecoder .cxx_destruct]
  -[CSAudioDecoder setDelegate:]
  -[CSAudioDecoder delegate]
  -[CSAudioDecoder initWithInASBD:outASBD:]
  -[CSAudioDecoder addPackets:audioStreamHandleId:remoteVAD:timestamp:receivedNumChannels:]


SSRBiometricMatch : NSObject /usr/lib/libc++.1.dylib <BKDeviceDelegate>
 @property  BKDevice *biometricDevice
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[SSRBiometricMatch sharedInstance]

  // instance methods
  -[SSRBiometricMatch init]
  -[SSRBiometricMatch .cxx_destruct]
  -[SSRBiometricMatch biometricDevice]
  -[SSRBiometricMatch setBiometricDevice:]
  -[SSRBiometricMatch getLastBiometricMatchForVoiceTriggerTimeStamp:]
  -[SSRBiometricMatch _getLastBiometricMatchEvent:atTime:]


SSRSpeakerAnalyzerSAT : NSObject /usr/lib/libc++.1.dylib
 @property  <SSRSpeakerAnalyzerSATDelegate> *delegate
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  SSRSpeakerRecognitionContext *context
 @property  NSDictionary *voiceProfilesModelFilePaths
 @property  NSDictionary *voiceProfilesExpModelFilePaths
 @property  NSArray *satScorers
 @property  NSDictionary *scoreCard
 @property  NSObject<OS_dispatch_queue> *queue

  // instance methods
  -[SSRSpeakerAnalyzerSAT context]
  -[SSRSpeakerAnalyzerSAT dealloc]
  -[SSRSpeakerAnalyzerSAT .cxx_destruct]
  -[SSRSpeakerAnalyzerSAT endAudio]
  -[SSRSpeakerAnalyzerSAT setContext:]
  -[SSRSpeakerAnalyzerSAT setQueue:]
  -[SSRSpeakerAnalyzerSAT queue]
  -[SSRSpeakerAnalyzerSAT setDelegate:]
  -[SSRSpeakerAnalyzerSAT delegate]
  -[SSRSpeakerAnalyzerSAT resetForNewRequest]
  -[SSRSpeakerAnalyzerSAT processAudioData:numSamples:]
  -[SSRSpeakerAnalyzerSAT configFilePath]
  -[SSRSpeakerAnalyzerSAT resourceFilePath]
  -[SSRSpeakerAnalyzerSAT voiceProfilesModelFilePaths]
  -[SSRSpeakerAnalyzerSAT initWithVoiceRecognitionContext:delegate:queue:]
  -[SSRSpeakerAnalyzerSAT getVoiceRecognizerResults]
  -[SSRSpeakerAnalyzerSAT setConfigFilePath:]
  -[SSRSpeakerAnalyzerSAT setResourceFilePath:]
  -[SSRSpeakerAnalyzerSAT setVoiceProfilesModelFilePaths:]
  -[SSRSpeakerAnalyzerSAT voiceProfilesExpModelFilePaths]
  -[SSRSpeakerAnalyzerSAT setVoiceProfilesExpModelFilePaths:]
  -[SSRSpeakerAnalyzerSAT _updateScoreCardForFinalResult:]
  -[SSRSpeakerAnalyzerSAT _getAnalyzedResult]
  -[SSRSpeakerAnalyzerSAT _getSuperVectorWithEndPoint:]
  -[SSRSpeakerAnalyzerSAT _processSuperVector:withSize:processedAudioDurationMs:isFinal:]
  -[SSRSpeakerAnalyzerSAT satScorers]
  -[SSRSpeakerAnalyzerSAT setSatScorers:]
  -[SSRSpeakerAnalyzerSAT scoreCard]
  -[SSRSpeakerAnalyzerSAT setScoreCard:]


SSREnrollmentDataManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[SSREnrollmentDataManager saveMetadata:isExplicitEnrollment:]
  +[SSREnrollmentDataManager saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:]
  +[SSREnrollmentDataManager _getBaseMetaDictionaryForUtterancePath:]
  +[SSREnrollmentDataManager writeMetaDict:atMetaPath:]
  +[SSREnrollmentDataManager saveRawUtteranceAndMetadata:to:isExplicitEnrollment:]
  +[SSREnrollmentDataManager saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:]


SSRVoiceProfileStorePrefs : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[SSRVoiceProfileStorePrefs sharedStorePrefs]

  // instance methods
  -[SSRVoiceProfileStorePrefs getVoiceProfileStoreVersion]
  -[SSRVoiceProfileStorePrefs loadKnownUserVoiceProfiles]
  -[SSRVoiceProfileStorePrefs setVoiceProfileStoreVersion:]
  -[SSRVoiceProfileStorePrefs saveKnownUserVoiceProfiles:]


SSRSpeakerRecognitionContext : NSObject /usr/lib/libc++.1.dylib
 @property  NSArray *voiceProfileArray
 @property  unsigned long spIdType
 @property  CSAsset *asset
 @property  NSString *locale
 @property  unsigned long activeChannel
 @property  unsigned long scoreType
 @property  unsigned long recognitionStyle
 @property  float combinationWeight
 @property  NSDictionary *vtEventInfo
 @property  NSString *configVersion
 @property  NSURL *resourceFilePath
 @property  NSURL *vadResourcePath
 @property  NSDictionary *modelsContext
 @property  NSDictionary *expModelsContext
 @property  NSDictionary *numEnrollmentUtterances
 @property  unsigned long maxAllowedAudioSamples
 @property  BOOL osTransactionReqd
 @property  NSString *debugUtteranceAudioFile
 @property  NSString *debugUtteranceMetaFile
 @property  SSRLoggingAggregator *logAggregator
 @property  NSString *sessionId

  // instance methods
  -[SSRSpeakerRecognitionContext setAsset:]
  -[SSRSpeakerRecognitionContext asset]
  -[SSRSpeakerRecognitionContext sessionId]
  -[SSRSpeakerRecognitionContext setLocale:]
  -[SSRSpeakerRecognitionContext locale]
  -[SSRSpeakerRecognitionContext configVersion]
  -[SSRSpeakerRecognitionContext dealloc]
  -[SSRSpeakerRecognitionContext .cxx_destruct]
  -[SSRSpeakerRecognitionContext activeChannel]
  -[SSRSpeakerRecognitionContext spIdType]
  -[SSRSpeakerRecognitionContext initWithVoiceRecognitionContext:error:]
  -[SSRSpeakerRecognitionContext vadResourcePath]
  -[SSRSpeakerRecognitionContext modelsContext]
  -[SSRSpeakerRecognitionContext expModelsContext]
  -[SSRSpeakerRecognitionContext resourceFilePath]
  -[SSRSpeakerRecognitionContext recognitionStyle]
  -[SSRSpeakerRecognitionContext logAggregator]
  -[SSRSpeakerRecognitionContext vtEventInfo]
  -[SSRSpeakerRecognitionContext debugUtteranceAudioFile]
  -[SSRSpeakerRecognitionContext debugUtteranceMetaFile]
  -[SSRSpeakerRecognitionContext maxAllowedAudioSamples]
  -[SSRSpeakerRecognitionContext osTransactionReqd]
  -[SSRSpeakerRecognitionContext combinationWeight]
  -[SSRSpeakerRecognitionContext numEnrollmentUtterances]
  -[SSRSpeakerRecognitionContext scoreType]
  -[SSRSpeakerRecognitionContext setSpIdType:]
  -[SSRSpeakerRecognitionContext setLogAggregator:]
  -[SSRSpeakerRecognitionContext voiceProfileArray]
  -[SSRSpeakerRecognitionContext setVoiceProfileArray:]
  -[SSRSpeakerRecognitionContext pickAssetForProfiles:forSpIdType:withAssetArray:]
  -[SSRSpeakerRecognitionContext pickAssetForProfiles:forSpIdType:]
  -[SSRSpeakerRecognitionContext composeModelContextsForProfiles:forSpIdType:forAsset:completion:]
  -[SSRSpeakerRecognitionContext _checkIfModelsPresentForProfiles:forSpIdType:forAsset:]


SSRSpeakerRecognitionModelContext : NSObject /usr/lib/libc++.1.dylib
 @property  NSURL *configFilePath
 @property  NSDictionary *voiceProfilesModelFilePaths

  // instance methods
  -[SSRSpeakerRecognitionModelContext .cxx_destruct]
  -[SSRSpeakerRecognitionModelContext configFilePath]
  -[SSRSpeakerRecognitionModelContext voiceProfilesModelFilePaths]
  -[SSRSpeakerRecognitionModelContext initWithConfigFilePath:withModelFilePaths:]


CSVTUIASRGrammars : NSObject /usr/lib/libc++.1.dylib <NSURLSessionDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[CSVTUIASRGrammars sharedGrammars]

  // instance methods
  -[CSVTUIASRGrammars init]
  -[CSVTUIASRGrammars .cxx_destruct]
  -[CSVTUIASRGrammars getTrailingPatternsForUtt:Locale:]
  -[CSVTUIASRGrammars getLeadingPatternsForUtt:Locale:]
  -[CSVTUIASRGrammars getRegexPatternsForUtt:Locale:]
  -[CSVTUIASRGrammars getLMEforLocale:]
  -[CSVTUIASRGrammars createGrammars]
  -[CSVTUIASRGrammars _getTrailingPatternsWithGrammars:withLocale:]
  -[CSVTUIASRGrammars _getLeadingPatternsWithGrammars:withLocale:]
  -[CSVTUIASRGrammars _getRegexPatternsWithGrammars:withUtt:withLocale:]
  -[CSVTUIASRGrammars _getLMEWithGrammar:withLocale:]


SSRPitchExtractor : NSObject /usr/lib/libc++.1.dylib <EARAudioResultsGeneratorDelegate>
 @property  EARAudioResultsGenerator *resultsGenerator
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRPitchExtractor .cxx_destruct]
  -[SSRPitchExtractor setQueue:]
  -[SSRPitchExtractor initWithAsset:]
  -[SSRPitchExtractor queue]
  -[SSRPitchExtractor getPitchForUtteranceAudioFiles:]
  -[SSRPitchExtractor _processAudioFileURL:]
  -[SSRPitchExtractor _getVoicingWeightedPitchForResultMatrix:]
  -[SSRPitchExtractor _getVoicingProbFromRawData:]
  -[SSRPitchExtractor _getPitchHzFromRawData:]
  -[SSRPitchExtractor resultsGenerator]
  -[SSRPitchExtractor setResultsGenerator:]


CSUtils : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[CSUtils systemUpTime]
  +[CSUtils deviceProductType]
  +[CSUtils supportTTS]
  +[CSUtils deviceBuildVersion]
  +[CSUtils convertToShortLPCMBufFromFloatLPCMBuf:]
  +[CSUtils supportPremiumAssets]
  +[CSUtils deviceProductVersion]
  +[CSUtils deviceCategoryStringRepresentationForCategoryType:]
  +[CSUtils deviceCategoryForDeviceProductType:]
  +[CSUtils lpcmASBD]
  +[CSUtils opusASBD]
  +[CSUtils hostTimeToSeconds:]
  +[CSUtils getSiriLanguageWithFallback:]
  +[CSUtils applyNegative12dBGain:]
  +[CSUtils secondsToHostTime:]
  +[CSUtils shouldDeinterleaveAudioOnCS]
  +[CSUtils deviceHwRevision]
  +[CSUtils lpcmNonInterleavedASBDWithSampleRate:numberOfChannels:]
  +[CSUtils lpcmInterleavedASBDWithSampleRate:numberOfChannels:]
  +[CSUtils removeLogFilesInDirectory:matchingPattern:beforeDays:]
  +[CSUtils clearLogFilesInDirectory:matchingPattern:exceedNumber:]
  +[CSUtils utteranceFileASBD]
  +[CSUtils _sharedDisposeLoggingQueue]
  +[CSUtils URLsInDirectory:matchingPattern:completion:]
  +[CSUtils _sortedURLsInDirectory:matchingPattern:completion:]
  +[CSUtils _contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:]
  +[CSUtils supportZeroFilter]
  +[CSUtils supportBeepCanceller]
  +[CSUtils assetHashInResourcePath:]
  +[CSUtils supportCSTwoShotDecision]
  +[CSUtils lpcmNarrowBandASBD]
  +[CSUtils supportLanguageDetector]
  +[CSUtils lpcmNonInterleavedWithRemoteVADASBD]
  +[CSUtils lpcmInterleavedWithRemoteVADASBD]
  +[CSUtils getFixedHighPrioritySerialQueueWithLabel:]
  +[CSUtils isRecordContextVoiceTrigger:]
  +[CSUtils applyGain:toBuffer:]
  +[CSUtils convertToFloatLPCMBufFromShortLPCMBuf:]
  +[CSUtils apply12dBGain:]
  +[CSUtils shouldRunVTOnCS]
  +[CSUtils isIOSDeviceSupportingBargeIn]
  +[CSUtils supportHearstVoiceTrigger]
  +[CSUtils supportRemoraVoiceTrigger]
  +[CSUtils supportJarvisVoiceTrigger]
  +[CSUtils supportBluetoothDeviceVoiceTrigger]
  +[CSUtils supportSmartVolume]
  +[CSUtils supportsVoiceTriggerFides]
  +[CSUtils supportSelfTriggerSuppression]
  +[CSUtils supportHybridEndpointer]
  +[CSUtils supportAdBlocker]
  +[CSUtils supportsSpeakerRecognitionAssets]
  +[CSUtils supportPhatic]
  +[CSUtils supportContinuousVoiceTrigger]
  +[CSUtils supportLazySessionActivation]
  +[CSUtils supportSessionActivateDelay]
  +[CSUtils hostTimeToTimeInterval:]
  +[CSUtils lpcmInt16NarrowBandASBD]
  +[CSUtils lpcmInt16ASBD]
  +[CSUtils supportOpportunisticZLL]
  +[CSUtils lpcmMonoNonInterleavedWithRemoteVADASBD]
  +[CSUtils lpcmMonoInterleavedWithRemoteVADASBD]
  +[CSUtils shouldDelayPhaticForMyriadDecision]
  +[CSUtils hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:]
  +[CSUtils sampleCountFromHostTime:anchorHostTime:anchorSampleCount:]
  +[CSUtils lpcmNonInterleavedASBD]
  +[CSUtils lpcmInterleavedASBD]
  +[CSUtils supportCompactPlus]
  +[CSUtils speexASBD]
  +[CSUtils lpcmFloatASBD]
  +[CSUtils hasRemoteBuiltInMic]
  +[CSUtils supportHandsFree]
  +[CSUtils getHostClockFrequency]
  +[CSUtils supportRaiseToSpeak]
  +[CSUtils supportPremiumWatchAssets]
  +[CSUtils rootQueueWithFixedPriority:]
  +[CSUtils supportKeywordDetector]
  +[CSUtils supportSAT]
  +[CSUtils supportContinuousAudioFingerprint]
  +[CSUtils supportPremiumModel]
  +[CSUtils shouldDownloadVTAssetsOnDaemon]
  +[CSUtils hasRemoteCoreSpeech]
  +[CSUtils supportCircularBuffer]
  +[CSUtils getFixedPrioritySerialQueueWithLabel:fixedPriority:]
  +[CSUtils deviceUserAssignedName]
  +[CSUtils timeStampWithSaltGrain]
  +[CSUtils opusNarrowBandASBD]
  +[CSUtils aiffFileASBD]
  +[CSUtils isRecordContextHearstVoiceTrigger:]
  +[CSUtils isRecordContextJarvisVoiceTrigger:]
  +[CSUtils isRecordContextJarvisButtonPress:]
  +[CSUtils macHostTimeFromBridgeHostTime:]
  +[CSUtils isRecordContextRaiseToSpeak:]
  +[CSUtils isRecordContextHearstDoubleTap:]
  +[CSUtils isRecordContextAutoPrompt:]
  +[CSUtils isRecordContextHomeButtonPress:]
  +[CSUtils isRecordContextSpeakerIdTrainingTrigger:]
  +[CSUtils recordContextString:]
  +[CSUtils stringForSpeakerRecognizerType:]
  +[CSUtils stringForInvocationStyle:]
  +[CSUtils ssrAudioLogsCountWithinPrivacyLimit]
  +[CSUtils combineScoreFromPSR:fromSAT:withCombinedWt:]
  +[CSUtils logSpeakerRecognitionGradingMetadataAtFilepath:withScoreInfo:]
  +[CSUtils removeItemAtPath:]
  +[CSUtils stringForCSSpIdType:]
  +[CSUtils streamAudioFromFileUrl:audioStreamBasicDescriptor:samplesPerStreamChunk:audioDataAvailableHandler:]
  +[CSUtils createDirectoryIfDoesNotExist:]
  +[CSUtils ssrAudioLogsDir]
  +[CSUtils satConfigFileNameForCSSpIdType:forModelType:forAssetType:]
  +[CSUtils readJsonFileAtPath:]
  +[CSUtils getVoiceProfileProductCategoryFromVersionFilePath:]
  +[CSUtils getExplicitEnrollmentUtterancesFromDirectory:]
  +[CSUtils getImplicitEnrollmentUtterancesFromDirectory:]
  +[CSUtils _getUtterancesFromDirectory:]
  +[CSUtils explicitSpIdTypeForSpId:]
  +[CSUtils spIdTypeForString:]
  +[CSUtils stringForVoiceProfileRetrainerType:]
  +[CSUtils satConfigFileNameForCSSpIdType:]
  +[CSUtils psrConfigFileNameForCSSpIdType:]
  +[CSUtils spIdVoiceProfileImportRootDir]
  +[CSUtils cleanupOrphanedVoiceIdGradingFiles]
  +[CSUtils spidAudioTrainUtterancesDir]
  +[CSUtils isSpeakerRecognitionSupportedInLocale:]
  +[CSUtils getVoiceProfileIdentityFromVersionFilePath:]
  +[CSUtils isCurrentDeviceCompatibleWithNewerVoiceProfileAt:]
  +[CSUtils isCurrentDeviceCompatibleWithVoiceProfileAt:]
  +[CSUtils getImplicitUtteranceCacheDirectory]
  +[CSUtils getNumberOfAudioFilesInDirectory:]
  +[CSUtils dumpFilesInDirectory:]
  +[CSUtils getContentsOfDirectory:]
  +[CSUtils getHomeUserIdForVoiceProfile:withCompletion:]
  +[CSUtils getVoiceProfilesForSiriProfileId:]
  +[CSUtils getVoiceProfileForSiriProfileId:forLanguageCode:]
  +[CSUtils segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:]
  +[CSUtils getEnrollmentUtterancesFromDirectory:]
  +[CSUtils getExplicitMarkedEnrollmentUtterancesFromDirectory:]
  +[CSUtils getEnrollmentUtterancesCountFromDirectory:withCountBlock:]
  +[CSUtils moveContentsOfSrcDirectory:toDestDirectory:]
  +[CSUtils encryptFileAt:andSaveTo:error:]


SSRAESKeyManager : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[SSRAESKeyManager getVoiceTriggerProfilesAESKey]
  +[SSRAESKeyManager generateIfNecessaryVoiceTriggerProfilesAESKey]
  +[SSRAESKeyManager generateIfNecessaryAESKeyWithKeySizeInBits:applicationTag:keyLabel:shouldGenerateIfNecessary:]
  +[SSRAESKeyManager generateAESKeyWithKeySizeInBits:]
  +[SSRAESKeyManager storeAESKeyInKeychain:applicationTag:keyLabel:]
  +[SSRAESKeyManager getAESKeyFromKeychainWithApplicationTag:keyLabel:]
  +[SSRAESKeyManager deleteAESKeyWithApplicationTag:keyLabel:]
  +[SSRAESKeyManager getKeychainAttributesForAESKeyWithApplicationTag:keyLabel:]


CSConfig : NSObject /usr/lib/libc++.1.dylib
  // class methods
  +[CSConfig inputRecordingNumberOfChannels]
  +[CSConfig inputRecordingSampleRate]
  +[CSConfig inputRecordingSampleByteDepth]
  +[CSConfig inputRecordingBufferDuration]
  +[CSConfig zeroFilterWindowSizeInMs]
  +[CSConfig zeroFilterWindowSizeInMsForReport]
  +[CSConfig inputRecordingSampleRateNarrowBand]
  +[CSConfig channelForProcessedInput]
  +[CSConfig remoteVADDuration]
  +[CSConfig inputRecordingIsFloat]
  +[CSConfig inputRecordingFramesPerPacket]
  +[CSConfig inputRecordingBytesPerFrame]
  +[CSConfig inputRecordingBytesPerPacket]
  +[CSConfig hearstNumberOfBytesPerChunk]
  +[CSConfig hearstNumberOfSamplesPerChunk]
  +[CSConfig inputRecordingDurationInSecs]
  +[CSConfig inputRecordingSampleBitDepth]
  +[CSConfig EncryptionAudioSampleByteDepth]
  +[CSConfig inputRecordingEncoderAudioQuality]
  +[CSConfig inputRecordingSampleRateConverterAlgorithm]
  +[CSConfig audioConverterBitrate]
  +[CSConfig channelForOutputReference]
  +[CSConfig zeroFilterApproxAbsSpeechThreshold]
  +[CSConfig csAudioProcessingQueuePriority]
  +[CSConfig daysBeforeRemovingLogFiles]
  +[CSConfig serverLoggingChannelBitset]
  +[CSConfig continousFingerprintBufferDuration]


CSDispatchGroup : NSObject /usr/lib/libc++.1.dylib
  // instance methods
  -[CSDispatchGroup waitWithTimeout:]
  -[CSDispatchGroup init]
  -[CSDispatchGroup enter]
  -[CSDispatchGroup .cxx_destruct]
  -[CSDispatchGroup leave]


MAAsset(CSAsset)
	// instance methods
	-[MAAsset(CSAsset) path]
	-[MAAsset(CSAsset) isPremium]
	-[MAAsset(CSAsset) _footprint]
	-[MAAsset(CSAsset) canBePurged]
	-[MAAsset(CSAsset) _version]
	-[MAAsset(CSAsset) _compatibilityVersion]
	-[MAAsset(CSAsset) isDownloading]
	-[MAAsset(CSAsset) getCSAssetOfType:]
	-[MAAsset(CSAsset) isCSAssetInstalled]
	-[MAAsset(CSAsset) isLatestCompareTo:]

AVVCStartRecordSettings(debugDescription)
	// instance methods
	-[AVVCStartRecordSettings(debugDescription) debugDescription]

AVVCAudioBuffer(remoteVoiceActivityVADBuffer)
	// instance methods
	-[AVVCAudioBuffer(remoteVoiceActivityVADBuffer) remoteVoiceActivityVADBuffer]

(CSVTUIEditDistance)
	// instance methods
	-[(CSVTUIEditDistance) _stringByStrippingLeadingNoise:]
	-[(CSVTUIEditDistance) _stringByStrippingTrailingNoise:]
	-[(CSVTUIEditDistance) _firstMatchesForRegularExpression:]
	-[(CSVTUIEditDistance) _stringByFixingNamePattern:]
	-[(CSVTUIEditDistance) _stringByStrippingNoiseLeadingNoise:TrailingNoise:]
	-[(CSVTUIEditDistance) _hasSubstring:]
	-[(CSVTUIEditDistance) _matchesRegularExpression:]
	-[(CSVTUIEditDistance) _caseInsensitiveHasMatchInEnumeration:]
	-[(CSVTUIEditDistance) _firstMatchesForRegularExpressions:]

01 00 0b00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFAnalytics 
01 00 0b00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFMultiUserConnection 
01 00 0b00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFPreferences 
01 00 0b00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFSettingsConnection 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioFormat 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioPCMBuffer 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAudioSession 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVCAudioBuffer 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVCConfigureAlertBehaviorSettings 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVCContextSettings 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVCPrepareRecordSettings 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVCStartRecordSettings 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVoiceController 
01 00 0900 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVVoiceTriggerClient 
01 00 0800 /System/Library/PrivateFrameworks/DistributedEvaluation.framework/DistributedEvaluation: DESRecordStore 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: EARAudioResultsGenerator 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: EARCaesuraSilencePosteriorGenerator 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: EARSyncPSRAudioProcessor 
01 00 0700 /System/Library/Frameworks/HealthKit.framework/HealthKit: HKHealthStore 
01 00 0700 /System/Library/Frameworks/HealthKit.framework/HealthKit: HKMedicalIDStore 
01 00 0c00 /System/Library/PrivateFrameworks/MobileAsset.framework/MobileAsset: MAAsset 
01 00 0c00 /System/Library/PrivateFrameworks/MobileAsset.framework/MobileAsset: MAAssetQuery 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSArray 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSAssertionHandler 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSBundle 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSCalendar 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSCharacterSet 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantDoubleNumber 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantFloatNumber 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantIntegerNumber 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSData 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDate 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSDateFormatter 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDictionary 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSDistributedNotificationCenter 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSError 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileManager 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSHashTable 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSJSONSerialization 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSLocale 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableArray 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableData 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableDictionary 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableSet 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSMutableString 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumber 
01 00 1100 /usr/lib/libobjc.A.dylib: NSObject 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSPredicate 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSProcessInfo 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSRegularExpression 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSScanner 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSSet 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSString 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSTimer 
01 00 1400 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSURL 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSUUID 
01 00 0a40 /System/Library/Frameworks/Speech.framework/Speech: SFSpeechAudioBufferRecognitionRequest 
01 00 0a40 /System/Library/Frameworks/Speech.framework/Speech: SFSpeechRecognizer 
01 00 1000 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNAudioStreamAnalyzer 
01 00 1000 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectSpeechUtteranceRequest 
01 00 0f00 /System/Library/PrivateFrameworks/VoiceTrigger.framework/VoiceTrigger: VTPreferences 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: _EAREndpointFeatures 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: _EAREndpointer 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: _EARSyncSpeechRecognizer 
