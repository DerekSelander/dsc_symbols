|| __DATA.__data _CSLoggingSubsystem
|| __DATA.__data _SSRLoggingSubsystem
|| __DATA.__data _kCSLoggingContextFramework
|| __DATA.__data _kSSRLoggingContextFramework
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIASRGrammars
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIAudioRecorder
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIAudioRecorderRemoteDeviceContext
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIAudioSessionRecorder
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIEndpointAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIKeywordDetector
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIRegularExpressionMatcher
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUIRemoteRecordClient
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUISelfLoggingDigitalZeroReporter
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUITrainingResult
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUITrainingSession
|| __DATA.__objc_data _OBJC_CLASS_$_CSVTUITrainingSessionWithPayload
|| __DATA.__objc_data _OBJC_CLASS_$_SSRAESKeyManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRAssetManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRBiometricMatch
|| __DATA.__objc_data _OBJC_CLASS_$_SSRDESRecordWriter
|| __DATA.__objc_data _OBJC_CLASS_$_SSREnrollmentDataManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRLoggingAggregator
|| __DATA.__objc_data _OBJC_CLASS_$_SSRMobileAssetProvider
|| __DATA.__objc_data _OBJC_CLASS_$_SSRPitchExtractor
|| __DATA.__objc_data _OBJC_CLASS_$_SSRRemoteControlClient
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerAnalyzerPSR
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerAnalyzerSAT
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionController
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionModelContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionOrchestrator
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognitionScorer
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognizerPSR
|| __DATA.__objc_data _OBJC_CLASS_$_SSRSpeakerRecognizerSAT
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTrialAssetProvider
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetector
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetectorNDAPI
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetectorNDAPIResult
|| __DATA.__objc_data _OBJC_CLASS_$_SSRTriggerPhraseDetectorQuasar
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVTUITrainingManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceActivityDetector
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfile
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileComposer
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileMetaContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileMetadataManager
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileModelContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfilePruner
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainerFactory
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainerPSR
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainerSAT
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileRetrainingContext
|| __DATA.__objc_data _OBJC_CLASS_$_SSRVoiceProfileStoreCleaner
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIASRGrammars
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIAudioRecorder
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIAudioRecorderRemoteDeviceContext
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIAudioSessionRecorder
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIEndpointAnalyzer
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIKeywordDetector
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIRegularExpressionMatcher
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUIRemoteRecordClient
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUISelfLoggingDigitalZeroReporter
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUITrainingResult
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUITrainingSession
|| __DATA.__objc_data _OBJC_METACLASS_$_CSVTUITrainingSessionWithPayload
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRAESKeyManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRAssetManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRBiometricMatch
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRDESRecordWriter
|| __DATA.__objc_data _OBJC_METACLASS_$_SSREnrollmentDataManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRLoggingAggregator
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRMobileAssetProvider
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRPitchExtractor
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRRemoteControlClient
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerAnalyzerPSR
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerAnalyzerSAT
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionController
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionModelContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionOrchestrator
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognitionScorer
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognizerPSR
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRSpeakerRecognizerSAT
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTrialAssetProvider
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetector
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetectorNDAPI
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetectorNDAPIResult
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRTriggerPhraseDetectorQuasar
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVTUITrainingManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceActivityDetector
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfile
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileComposer
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileMetaContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileMetadataManager
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileModelContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfilePruner
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainerFactory
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainerPSR
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainerSAT
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileRetrainingContext
|| __DATA.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileStoreCleaner
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._ASRErrorOccured
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._audioSession
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._keywordDetector
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._locale
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._masterTimer
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._mhUUID
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._pcmBufArray
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._queue
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._resultReported
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionDelegate
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionNumber
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionProcess
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._sessionSuspended
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._speechRecognitionRequest
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._speechRecognitionTask
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._speechRecognizer
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._status
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._trainingCompletion
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._trainingCompletionWithResult
|| __DATA.__objc_ivar _OBJC_IVAR_$_CSVTUITrainingSession._utteranceId
|| __DATA_CONST.__const _CSErrorDomain
|| __DATA_CONST.__const _CSVTUI_AVAudioSessionPortBorealisInput
|| __DATA_CONST.__const _CSVoiceProfileAvailabilityMetaBlobVersion
|| __DATA_CONST.__const _KSSRDeviceBuildVersion
|| __DATA_CONST.__const _SSRErrorDomain
|| __DATA_CONST.__const _SSRRecognitionLoggingKey
|| __DATA_CONST.__const _SSRRetrainingLoggingKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionAssetArrayKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionAssetKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionEndpointId
|| __DATA_CONST.__const _SSRSpeakerRecognitionLocaleKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionMaxAudioDurationSecs
|| __DATA_CONST.__const _SSRSpeakerRecognitionOSTransactionRequired
|| __DATA_CONST.__const _SSRSpeakerRecognitionProfileArrayKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionSiriAppDomain
|| __DATA_CONST.__const _SSRSpeakerRecognitionSiriCCAppDomain
|| __DATA_CONST.__const _SSRSpeakerRecognitionSiriDebugAppDomain
|| __DATA_CONST.__const _SSRSpeakerRecognitionStyleKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionUsePayloadProfileKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionVADAssetPathKey
|| __DATA_CONST.__const _SSRSpeakerRecognitionVTEventInfoKey
|| __DATA_CONST.__const _SSRVoiceRetrainingAssetKey
|| __DATA_CONST.__const _SSRVoiceRetrainingCompareVoiceProfilesKey
|| __DATA_CONST.__const _SSRVoiceRetrainingCompareVoiceProfilesSpIdTypeKey
|| __DATA_CONST.__const _SSRVoiceRetrainingFilterToVoiceTriggerUtterancesKey
|| __DATA_CONST.__const _SSRVoiceRetrainingForceKey
|| __DATA_CONST.__const _SSRVoiceRetrainingPayloadProfileKey
|| __DATA_CONST.__const _SSRVoiceRetrainingSpIdTypeKey
|| __DATA_CONST.__const _SSRVoiceRetrainingVoiceProfileKey
|| __DATA_CONST.__const _kCSAssetFootprintKey
|| __DATA_CONST.__const _kCSAssetLanguageKey
|| __DATA_CONST.__const _kCSAssetPremiumKey
|| __DATA_CONST.__const _kCSVoiceTriggerEventInfoKey
|| __DATA_CONST.__const _kSSRAnalyticsAssetVersion
|| __DATA_CONST.__const _kSSRAnalyticsLocale
|| __DATA_CONST.__const _kSSRAnalyticsPrefix
|| __DATA_CONST.__const _kSSRAudioRecordContextKey
|| __DATA_CONST.__const _kSSRAudioRecordDeviceInfoKey
|| __DATA_CONST.__const _kSSRContainsPayload
|| __DATA_CONST.__const _kSSRDateTrainedKey
|| __DATA_CONST.__const _kSSRDiscardImplicitUttScore
|| __DATA_CONST.__const _kSSREnrollmentCompletedFileName
|| __DATA_CONST.__const _kSSREnrollmentMigratedFileName
|| __DATA_CONST.__const _kSSREnrollmentVersionFileName
|| __DATA_CONST.__const _kSSRExplicitTrainingType
|| __DATA_CONST.__const _kSSRExplicitUttScore
|| __DATA_CONST.__const _kSSRFailedExplicitUttScore
|| __DATA_CONST.__const _kSSRFarField
|| __DATA_CONST.__const _kSSRImplicitTrainingType
|| __DATA_CONST.__const _kSSRImplicitUttScore
|| __DATA_CONST.__const _kSSRMetaHandheldKey
|| __DATA_CONST.__const _kSSRMetaProductTypeKey
|| __DATA_CONST.__const _kSSRMetaProductVersionKey
|| __DATA_CONST.__const _kSSRMetaTrainingTypeKey
|| __DATA_CONST.__const _kSSRMetaUtteranceWavKey
|| __DATA_CONST.__const _kSSRMetaVersionFileName
|| __DATA_CONST.__const _kSSRMetaVersionKey
|| __DATA_CONST.__const _kSSRNearField
|| __DATA_CONST.__const _kSSRNumDiscardedUttsPHS
|| __DATA_CONST.__const _kSSRNumPrunedUttsPHS
|| __DATA_CONST.__const _kSSRNumRetainedUttsPHS
|| __DATA_CONST.__const _kSSROtherBiometricResultKey
|| __DATA_CONST.__const _kSSRProfilePruneFailCode
|| __DATA_CONST.__const _kSSRPruningLoggingKey
|| __DATA_CONST.__const _kSSRPsrFailedDuringSATDetection
|| __DATA_CONST.__const _kSSRRecordingTimeStampKey
|| __DATA_CONST.__const _kSSRRetrainingStatusCode
|| __DATA_CONST.__const _kSSRRetrainingWaitTimeMs
|| __DATA_CONST.__const _kSSRScoreMSE
|| __DATA_CONST.__const _kSSRSpeakerModelRetrainRequired
|| __DATA_CONST.__const _kSSRSpeakerModelUpdated
|| __DATA_CONST.__const _kSSRSpeakerRecognitionAssetVersionKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionAudioProcessedDurationKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionBestVoiceTriggerScoreKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionCombinationWeight
|| __DATA_CONST.__const _kSSRSpeakerRecognitionDomain
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserPSRExpScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserPSRScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserSATExpScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserSATScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionKnownUserScoresKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionLowScoreThresholdKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionMetaFilePathKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionMyriadKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNonVTInvocationScoreThresholdingType
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumEnrollmentUtterances
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumExplicitUtt
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumImplicitUtt
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNumSpeakerVector
|| __DATA_CONST.__const _kSSRSpeakerRecognitionNviDirectionalityArrKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionPSRAdditionalContextKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionProcessingStatus
|| __DATA_CONST.__const _kSSRSpeakerRecognitionProfileID
|| __DATA_CONST.__const _kSSRSpeakerRecognitionRecordUserAudioKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSATAdditionalContextKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionScoreThresholdKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionScoreThresholdingTypeKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionScoresVersion
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSegmentCounterKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSegmentStartTimeKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSessionIdKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionSmartSiriVolumeKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionUnknownUserScoreKey
|| __DATA_CONST.__const _kSSRSpeakerRecognitionVTInvocationScoreThresholdingType
|| __DATA_CONST.__const _kSSRSpeakerRecognitionWaitTimeMs
|| __DATA_CONST.__const _kSSRSpeakerVoiceProfileSync
|| __DATA_CONST.__const _kSSRTdPsrExtraAudioSamplesProcessed
|| __DATA_CONST.__const _kSSRTdPsrSATRetrainingTimedOut
|| __DATA_CONST.__const _kSSRTriggerPHSProfileDownload
|| __DATA_CONST.__const _kSSRUserSiriProfileID
|| __DATA_CONST.__const _kSSRVoiceProfileAppDomainKey
|| __DATA_CONST.__const _kSSRVoiceProfileCategoryType
|| __DATA_CONST.__const _kSSRVoiceProfileCompatabilityVersion
|| __DATA_CONST.__const _kSSRVoiceProfileExpSatVecCountType
|| __DATA_CONST.__const _kSSRVoiceProfileID
|| __DATA_CONST.__const _kSSRVoiceProfileIdentifier
|| __DATA_CONST.__const _kSSRVoiceProfileLocaleKey
|| __DATA_CONST.__const _kSSRVoiceProfileOnboardType
|| __DATA_CONST.__const _kSSRVoiceProfilePath
|| __DATA_CONST.__const _kSSRVoiceProfilePitchKey
|| __DATA_CONST.__const _kSSRVoiceProfileProductType
|| __DATA_CONST.__const _kSSRVoiceProfilePruningCookie
|| __DATA_CONST.__const _kSSRVoiceProfileRecordPayloadAllowedKey
|| __DATA_CONST.__const _kSSRVoiceProfileSWVersion
|| __DATA_CONST.__const _kSSRVoiceProfileUserName
|| __DATA_CONST.__const _kVTUIRemoteRecordGibraltarDeviceId
|| __DATA_DIRTY.__common _CSLogContextFacilityCoreSpeech
|| __DATA_DIRTY.__common _SSRLogContextFacilityCoreSpeech
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRUtils
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileStore
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_SSRVoiceProfileStorePrefs
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRUtils
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileManager
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileStore
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_SSRVoiceProfileStorePrefs
|| __TEXT.__const _kCSAssetValueLanguageAny
|| __TEXT.__const _kCSLogitCeilDefaultScore
|| __TEXT.__const _kCSLogitFloorDefaultScore
|| __TEXT.__const _kCurrVTMetaVersion
|| __TEXT.__const _kSSRExplicitTrainingUtterancesCount
|| __TEXT.__const _kSSRMaxEnrollmentUtterancesDefault
|| __TEXT.__const _kSSRMinExplicitTrainingUtterancesCount
|| __TEXT.__const _kSSRVoiceProfilePrunerMaxWaitTimeMs
|| __TEXT.__text _CSLogInitIfNeeded
|| __TEXT.__text _SSRLogInitIfNeeded
|| __TEXT.__text _SSRShouldUseTDTI
|| __TEXT.__text __SSRVoiceProfileStorePrefsSetValueForKey
|| __TEXT.__text __SSRVoiceProfileStorePrefsSynchronize
|| __TEXT.__text __SSRVoiceProfileStorePrefsValueForKey
|| __TEXT.__text __SSRVoiceProfileStorePrefsValueForKeyFromRoot
__ AVFAudio: _AVAudioSessionPortAirPlay
__ AVFAudio: _AVAudioSessionPortBluetoothA2DP
__ AVFAudio: _AVAudioSessionPortBluetoothHFP
__ AVFAudio: _AVAudioSessionPortBluetoothLE
__ AVFAudio: _AVAudioSessionPortBuiltInMic
__ AVFAudio: _AVAudioSessionPortCarAudio
__ AVFAudio: _AVAudioSessionPortHDMI
__ AVFAudio: _AVAudioSessionPortHeadphones
__ AVFAudio: _AVAudioSessionPortLineOut
__ AVFAudio: _AVAudioSessionPortUSBAudio
__ AVFAudio: _AVEncoderBitRateKey
__ AVFAudio: _AVFormatIDKey
__ AVFAudio: _AVLinearPCMBitDepthKey
__ AVFAudio: _AVLinearPCMIsFloatKey
__ AVFAudio: _AVLinearPCMIsNonInterleaved
__ AVFAudio: _AVNumberOfChannelsKey
__ AVFAudio: _AVSampleRateConverterAlgorithmKey
__ AVFAudio: _AVSampleRateConverterAlgorithm_Mastering
__ AVFAudio: _AVSampleRateKey
__ AVFAudio: _AVVoiceActivationDeviceIDKey
__ AVFAudio: _AVVoiceActivationModeKey
__ AVFAudio: _OBJC_CLASS_$_AVAudioFormat
__ AVFAudio: _OBJC_CLASS_$_AVAudioPCMBuffer
__ AVFAudio: _OBJC_CLASS_$_AVVCContextSettings
__ AVFAudio: _OBJC_CLASS_$_AVVCPrepareRecordSettings
__ AVFAudio: _OBJC_CLASS_$_AVVCStartRecordSettings
__ AVFAudio: _OBJC_CLASS_$_AVVoiceController
__ AppSupport: _CPSharedResourcesDirectory
__ AssistantServices: _AFPreferencesMobileUserSessionLanguage
__ AssistantServices: _AFPreferencesSupportedLanguages
__ AssistantServices: _OBJC_CLASS_$_AFAnalytics
__ AssistantServices: _OBJC_CLASS_$_AFMultiUserConnection
__ AssistantServices: _OBJC_CLASS_$_AFSettingsConnection
__ AudioToolbox: _AudioFileClose
__ AudioToolbox: _AudioFileOpenURL
__ AudioToolbox: _ExtAudioFileDispose
__ AudioToolbox: _ExtAudioFileRead
__ AudioToolbox: _ExtAudioFileSetProperty
__ AudioToolbox: _ExtAudioFileWrapAudioFileID
__ Celestial: _AVController_RouteDescriptionKey_RouteSubtype
__ Celestial: _OBJC_CLASS_$_AVSystemController
__ CoreAnalytics: _AnalyticsSendEvent
__ CoreAnalytics: _AnalyticsSendEventLazy
__ CoreFoundation: _CFPreferencesAppSynchronize
__ CoreFoundation: _CFPreferencesCopyAppValue
__ CoreFoundation: _CFPreferencesCopyValue
__ CoreFoundation: _CFPreferencesSetAppValue
__ CoreFoundation: _NSURLIsDirectoryKey
__ CoreFoundation: _NSURLNameKey
__ CoreFoundation: _OBJC_CLASS_$_NSArray
__ CoreFoundation: _OBJC_CLASS_$_NSCalendar
__ CoreFoundation: _OBJC_CLASS_$_NSConstantDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSData
__ CoreFoundation: _OBJC_CLASS_$_NSDate
__ CoreFoundation: _OBJC_CLASS_$_NSDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSLocale
__ CoreFoundation: _OBJC_CLASS_$_NSMutableArray
__ CoreFoundation: _OBJC_CLASS_$_NSMutableData
__ CoreFoundation: _OBJC_CLASS_$_NSMutableDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSMutableSet
__ CoreFoundation: _OBJC_CLASS_$_NSSet
__ CoreFoundation: _OBJC_CLASS_$_NSTimer
__ CoreFoundation: _OBJC_CLASS_$_NSURL
__ CoreFoundation: ___CFConstantStringClassReference
__ CoreFoundation: ___NSArray0__struct
__ CoreFoundation: ___NSDictionary0__struct
__ CoreFoundation: ___kCFBooleanFalse
__ CoreFoundation: ___kCFBooleanTrue
__ CoreFoundation: _kCFPreferencesAnyHost
__ CoreSpeechFoundation: _CSIsCommunalDevice
__ CoreSpeechFoundation: _CSIsHorseman
__ CoreSpeechFoundation: _CSIsIOS
__ CoreSpeechFoundation: _CSIsIPad
__ CoreSpeechFoundation: _CSIsInternalBuild
__ CoreSpeechFoundation: _CSIsMac
__ CoreSpeechFoundation: _CSIsOSX
__ CoreSpeechFoundation: _CSIsTV
__ CoreSpeechFoundation: _CSIsTorpedo
__ CoreSpeechFoundation: _CSIsWatch
__ CoreSpeechFoundation: _CSMachAbsoluteTimeGetTimeInterval
__ CoreSpeechFoundation: _CSMachAbsoluteTimeToMachContinuousTime
__ CoreSpeechFoundation: _CSNotBackedupInternalPreferencesSynchronize
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAsset
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAudioChunk
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAudioCircularBuffer
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAudioFileManager
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAudioPowerMeter
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAudioRecordContext
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSAudioZeroCounter
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSConfig
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSContinuousVoiceTriggerConfigDecoder
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSDiagnosticReporter
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSDispatchGroup
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSFAudioStreamBasicDescriptionFactory
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSFPreferences
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSFTimeUtils
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSMobileAssetVersions
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSOSTransaction
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSPlainAudioFileWriter
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSRemoteAssetManager
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSUtils
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSVTUITrainingSelfLogger
__ CoreSpeechFoundation: _OBJC_CLASS_$_CSVoiceTriggerSecondPassConfigDecoder
__ CoreSpeechFoundation: __CSNotBackedupPreferencesSetValueForKey
__ CoreSpeechFoundation: __CSNotBackedupPreferencesValueForKey
__ CoreSpeechFoundation: _kCSDiagnosticReporterVoiceIdDelayedScores
__ CoreSpeechFoundation: _kCSDiagnosticReporterVoiceIdRetrainSATVecFailed
__ CoreSpeechFoundation: _kCSDiagnosticReporterVoiceIdStaleProfileDetected
__ CoreSpeechFoundation: _kCSDiagnosticReporterVoiceIdTooLessAudioFiles
__ CoreSpeechFoundation: _kCSDiagnosticReporterVoiceIdUnrecognizedMetaData
__ DistributedEvaluation: _OBJC_CLASS_$_DESRecordStore
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$_EARAudioResultsGenerator
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$_EARCaesuraSilencePosteriorGenerator
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$_EARSyncPSRAudioProcessor
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$__EAREndpointFeatures
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$__EAREndpointer
__ EmbeddedAcousticRecognition: _OBJC_CLASS_$__EARSyncSpeechRecognizer
__ Foundation: _NSHomeDirectory
__ Foundation: _NSLocalizedDescriptionKey
__ Foundation: _NSLog
__ Foundation: _NSStringFromClass
__ Foundation: _NSTemporaryDirectory
__ Foundation: _OBJC_CLASS_$_NSAssertionHandler
__ Foundation: _OBJC_CLASS_$_NSBundle
__ Foundation: _OBJC_CLASS_$_NSCharacterSet
__ Foundation: _OBJC_CLASS_$_NSConstantDoubleNumber
__ Foundation: _OBJC_CLASS_$_NSConstantFloatNumber
__ Foundation: _OBJC_CLASS_$_NSConstantIntegerNumber
__ Foundation: _OBJC_CLASS_$_NSDateFormatter
__ Foundation: _OBJC_CLASS_$_NSDistributedNotificationCenter
__ Foundation: _OBJC_CLASS_$_NSError
__ Foundation: _OBJC_CLASS_$_NSFileManager
__ Foundation: _OBJC_CLASS_$_NSHashTable
__ Foundation: _OBJC_CLASS_$_NSJSONSerialization
__ Foundation: _OBJC_CLASS_$_NSMutableString
__ Foundation: _OBJC_CLASS_$_NSNumber
__ Foundation: _OBJC_CLASS_$_NSPredicate
__ Foundation: _OBJC_CLASS_$_NSRegularExpression
__ Foundation: _OBJC_CLASS_$_NSScanner
__ Foundation: _OBJC_CLASS_$_NSString
__ Foundation: _OBJC_CLASS_$_NSUUID
__ HealthKit: _OBJC_CLASS_$_HKHealthStore
__ HealthKit: _OBJC_CLASS_$_HKMedicalIDStore
__ MobileAsset: _ASAttributeCompatibilityVersion
__ MobileAsset: _ASAttributeContentVersion
__ MobileAsset: _OBJC_CLASS_$_MAAsset
__ MobileAsset: _OBJC_CLASS_$_MAAssetQuery
__ RemoteServiceDiscovery: _remote_device_cancel
__ RemoteServiceDiscovery: _remote_device_copy_device_with_uuid
__ RemoteServiceDiscovery: _remote_device_copy_service
__ RemoteServiceDiscovery: _remote_device_copy_unique_of_type
__ RemoteServiceDiscovery: _remote_device_get_type
__ RemoteServiceDiscovery: _remote_device_set_connected_callback
__ RemoteServiceDiscovery: _remote_device_set_disconnected_callback
__ RemoteXPC: _xpc_remote_connection_activate
__ RemoteXPC: _xpc_remote_connection_cancel
__ RemoteXPC: _xpc_remote_connection_create_with_remote_service
__ RemoteXPC: _xpc_remote_connection_send_message
__ RemoteXPC: _xpc_remote_connection_send_message_with_reply
__ RemoteXPC: _xpc_remote_connection_send_message_with_reply_sync
__ RemoteXPC: _xpc_remote_connection_set_event_handler
__ SoftLinking: __sl_dlopen
__ SoundAnalysis: _OBJC_CLASS_$_SNAudioStreamAnalyzer
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectSpeechUtteranceRequest
__ Speech: _OBJC_CLASS_$_SFSpeechAudioBufferRecognitionRequest
__ Speech: _OBJC_CLASS_$_SFSpeechRecognizer
__ VoiceTrigger: _OBJC_CLASS_$_VTPreferences
__ VoiceTrigger: _nd_close
__ VoiceTrigger: _nd_create
__ VoiceTrigger: _nd_error
__ VoiceTrigger: _nd_getoption
__ VoiceTrigger: _nd_getphraseresults
__ VoiceTrigger: _nd_getresults
__ VoiceTrigger: _nd_getsupervector
__ VoiceTrigger: _nd_initialize
__ VoiceTrigger: _nd_phrasecount
__ VoiceTrigger: _nd_reset
__ VoiceTrigger: _nd_sat_analyze
__ VoiceTrigger: _nd_sat_deletevector
__ VoiceTrigger: _nd_sat_getspeakervector
__ VoiceTrigger: _nd_sat_initialize
__ VoiceTrigger: _nd_sat_update
__ VoiceTrigger: _nd_sat_vectorcount
__ VoiceTrigger: _nd_wavedata
__ libSystem.B.dylib: __Block_object_dispose
__ libSystem.B.dylib: __NSConcreteGlobalBlock
__ libSystem.B.dylib: __NSConcreteStackBlock
__ libSystem.B.dylib: __Unwind_Resume
__ libSystem.B.dylib: ___error
__ libSystem.B.dylib: ___stack_chk_fail
__ libSystem.B.dylib: ___stack_chk_guard
__ libSystem.B.dylib: __dispatch_main_q
__ libSystem.B.dylib: __os_log_debug_impl
__ libSystem.B.dylib: __os_log_error_impl
__ libSystem.B.dylib: __os_log_fault_impl
__ libSystem.B.dylib: __os_log_impl
__ libSystem.B.dylib: __xpc_error_connection_interrupted
__ libSystem.B.dylib: __xpc_error_connection_invalid
__ libSystem.B.dylib: __xpc_error_key_description
__ libSystem.B.dylib: __xpc_type_dictionary
__ libSystem.B.dylib: __xpc_type_error
__ libSystem.B.dylib: _close
__ libSystem.B.dylib: _dispatch_after
__ libSystem.B.dylib: _dispatch_assert_queue$V2
__ libSystem.B.dylib: _dispatch_async
__ libSystem.B.dylib: _dispatch_async_and_wait
__ libSystem.B.dylib: _dispatch_get_global_queue
__ libSystem.B.dylib: _dispatch_group_create
__ libSystem.B.dylib: _dispatch_group_enter
__ libSystem.B.dylib: _dispatch_group_leave
__ libSystem.B.dylib: _dispatch_group_wait
__ libSystem.B.dylib: _dispatch_once
__ libSystem.B.dylib: _dispatch_queue_create
__ libSystem.B.dylib: _dispatch_queue_create_with_target$V2
__ libSystem.B.dylib: _dispatch_semaphore_create
__ libSystem.B.dylib: _dispatch_semaphore_signal
__ libSystem.B.dylib: _dispatch_semaphore_wait
__ libSystem.B.dylib: _dispatch_sync
__ libSystem.B.dylib: _dispatch_time
__ libSystem.B.dylib: _exp
__ libSystem.B.dylib: _expf
__ libSystem.B.dylib: _ffsctl
__ libSystem.B.dylib: _free
__ libSystem.B.dylib: _kdebug_trace
__ libSystem.B.dylib: _mach_absolute_time
__ libSystem.B.dylib: _memcpy
__ libSystem.B.dylib: _notify_post
__ libSystem.B.dylib: _open
__ libSystem.B.dylib: _os_log_create
__ libSystem.B.dylib: _os_log_type_enabled
__ libSystem.B.dylib: _os_transaction_create
__ libSystem.B.dylib: _powf
__ libSystem.B.dylib: _strerror
__ libSystem.B.dylib: _xpc_dictionary_create
__ libSystem.B.dylib: _xpc_dictionary_get_bool
__ libSystem.B.dylib: _xpc_dictionary_get_string
__ libSystem.B.dylib: _xpc_dictionary_set_string
__ libSystem.B.dylib: _xpc_dictionary_set_value
__ libSystem.B.dylib: _xpc_file_transfer_create_with_path
__ libSystem.B.dylib: _xpc_get_type
__ libc++.1.dylib: __ZSt9terminatev
__ libc++.1.dylib: __ZTISt9exception
__ libc++.1.dylib: ___cxa_begin_catch
__ libc++.1.dylib: ___cxa_end_catch
__ libc++.1.dylib: ___gxx_personality_v0
__ libobjc.A.dylib: _OBJC_CLASS_$_NSObject
__ libobjc.A.dylib: _OBJC_METACLASS_$_NSObject
__ libobjc.A.dylib: ___objc_personality_v0
__ libobjc.A.dylib: __objc_empty_cache
__ libobjc.A.dylib: _objc_alloc
__ libobjc.A.dylib: _objc_alloc_init
__ libobjc.A.dylib: _objc_autorelease
__ libobjc.A.dylib: _objc_autoreleasePoolPop
__ libobjc.A.dylib: _objc_autoreleasePoolPush
__ libobjc.A.dylib: _objc_autoreleaseReturnValue
__ libobjc.A.dylib: _objc_begin_catch
__ libobjc.A.dylib: _objc_claimAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_copyWeak
__ libobjc.A.dylib: _objc_destroyWeak
__ libobjc.A.dylib: _objc_end_catch
__ libobjc.A.dylib: _objc_enumerationMutation
__ libobjc.A.dylib: _objc_getClass
__ libobjc.A.dylib: _objc_getProperty
__ libobjc.A.dylib: _objc_initWeak
__ libobjc.A.dylib: _objc_loadWeakRetained
__ libobjc.A.dylib: _objc_msgSend
__ libobjc.A.dylib: _objc_msgSendSuper2
__ libobjc.A.dylib: _objc_opt_class
__ libobjc.A.dylib: _objc_opt_isKindOfClass
__ libobjc.A.dylib: _objc_opt_respondsToSelector
__ libobjc.A.dylib: _objc_release
__ libobjc.A.dylib: _objc_release_x1
__ libobjc.A.dylib: _objc_release_x19
__ libobjc.A.dylib: _objc_release_x20
__ libobjc.A.dylib: _objc_release_x21
__ libobjc.A.dylib: _objc_release_x22
__ libobjc.A.dylib: _objc_release_x23
__ libobjc.A.dylib: _objc_release_x24
__ libobjc.A.dylib: _objc_release_x25
__ libobjc.A.dylib: _objc_release_x26
__ libobjc.A.dylib: _objc_release_x27
__ libobjc.A.dylib: _objc_release_x28
__ libobjc.A.dylib: _objc_release_x8
__ libobjc.A.dylib: _objc_release_x9
__ libobjc.A.dylib: _objc_retain
__ libobjc.A.dylib: _objc_retainAutorelease
__ libobjc.A.dylib: _objc_retainAutoreleaseReturnValue
__ libobjc.A.dylib: _objc_retainBlock
__ libobjc.A.dylib: _objc_retain_x1
__ libobjc.A.dylib: _objc_retain_x10
__ libobjc.A.dylib: _objc_retain_x19
__ libobjc.A.dylib: _objc_retain_x2
__ libobjc.A.dylib: _objc_retain_x20
__ libobjc.A.dylib: _objc_retain_x21
__ libobjc.A.dylib: _objc_retain_x22
__ libobjc.A.dylib: _objc_retain_x23
__ libobjc.A.dylib: _objc_retain_x24
__ libobjc.A.dylib: _objc_retain_x25
__ libobjc.A.dylib: _objc_retain_x26
__ libobjc.A.dylib: _objc_retain_x27
__ libobjc.A.dylib: _objc_retain_x28
__ libobjc.A.dylib: _objc_retain_x3
__ libobjc.A.dylib: _objc_retain_x4
__ libobjc.A.dylib: _objc_retain_x5
__ libobjc.A.dylib: _objc_retain_x8
__ libobjc.A.dylib: _objc_retain_x9
__ libobjc.A.dylib: _objc_setProperty_atomic
__ libobjc.A.dylib: _objc_storeStrong
__ libobjc.A.dylib: _objc_storeWeak
__ libobjc.A.dylib: _objc_unsafeClaimAutoreleasedReturnValue
CSVTUIEndpointAnalyzer : NSObject <SNResultsObserving>
 @property  SNAudioStreamAnalyzer *snAudioStreamAnalyzer
 @property  unsigned long framePosition
 @property  unsigned long nnvadState
 @property  unsigned long numSamplesReceived
 @property  unsigned long numSamplesProcessedBeforeAnchorTime
 @property  unsigned long anchorMachAbsTime
 @property  BOOL isAnchorTimeBuffered
 @property  unsigned long currentRequestSampleRate
 @property  AVAudioFormat *currentRequestAudioFormat
 @property  double vtEndInSecs
 @property  unsigned long vtEndInSampleCount
 @property  double vtExtraAudioAtStartInMs
 @property  double nnvadAudioOriginInMs
 @property  BOOL shouldDetectTwoShot
 @property  BOOL didEnterTwoshot
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <CSAudioFileWriter> *audioFileWriter
 @property  double firstAudioSampleSensorTimestamp
 @property  long long firstSampleId
 @property  unsigned long numSamplesSkippedForVT
 @property  BOOL finishedSkippingSamplesForVT
 @property  double startWaitTime
 @property  double endWaitTime
 @property  <CSVTUIEndpointAnalyzerDelegate> *delegate
 @property  unsigned long activeChannel
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[CSVTUIEndpointAnalyzer timeStampString]

  // instance methods
  -[CSVTUIEndpointAnalyzer activeChannel]
  -[CSVTUIEndpointAnalyzer setActiveChannel:]
  -[CSVTUIEndpointAnalyzer setStartWaitTime:]
  -[CSVTUIEndpointAnalyzer request:didFailWithError:]
  -[CSVTUIEndpointAnalyzer stopEndpointer]
  -[CSVTUIEndpointAnalyzer startWaitTime]
  -[CSVTUIEndpointAnalyzer setEndWaitTime:]
  -[CSVTUIEndpointAnalyzer endWaitTime]
  -[CSVTUIEndpointAnalyzer recordingStoppedForReason:]
  -[CSVTUIEndpointAnalyzer processAudioSamplesAsynchronously:]
  -[CSVTUIEndpointAnalyzer firstAudioSampleSensorTimestamp]
  -[CSVTUIEndpointAnalyzer setDelegate:]
  -[CSVTUIEndpointAnalyzer setAudioFileWriter:]
  -[CSVTUIEndpointAnalyzer vtExtraAudioAtStartInMs]
  -[CSVTUIEndpointAnalyzer delegate]
  -[CSVTUIEndpointAnalyzer vtEndInSampleCount]
  -[CSVTUIEndpointAnalyzer setFirstAudioSampleSensorTimestamp:]
  -[CSVTUIEndpointAnalyzer setVtExtraAudioAtStartInMs:]
  -[CSVTUIEndpointAnalyzer .cxx_destruct]
  -[CSVTUIEndpointAnalyzer setNumSamplesProcessedBeforeAnchorTime:]
  -[CSVTUIEndpointAnalyzer setVtEndInSampleCount:]
  -[CSVTUIEndpointAnalyzer handleVoiceTriggerWithActivationInfo:]
  -[CSVTUIEndpointAnalyzer anchorMachAbsTime]
  -[CSVTUIEndpointAnalyzer setAnchorMachAbsTime:]
  -[CSVTUIEndpointAnalyzer currentRequestSampleRate]
  -[CSVTUIEndpointAnalyzer setQueue:]
  -[CSVTUIEndpointAnalyzer audioFileWriter]
  -[CSVTUIEndpointAnalyzer isAnchorTimeBuffered]
  -[CSVTUIEndpointAnalyzer queue]
  -[CSVTUIEndpointAnalyzer setCurrentRequestSampleRate:]
  -[CSVTUIEndpointAnalyzer setIsAnchorTimeBuffered:]
  -[CSVTUIEndpointAnalyzer init]
  -[CSVTUIEndpointAnalyzer numSamplesProcessedBeforeAnchorTime]
  -[CSVTUIEndpointAnalyzer framePosition]
  -[CSVTUIEndpointAnalyzer setFramePosition:]
  -[CSVTUIEndpointAnalyzer request:didProduceResult:]
  -[CSVTUIEndpointAnalyzer _pcmBufferForAudioChunk:]
  -[CSVTUIEndpointAnalyzer _effectiveAudioTimeInSecsForSNObservation:]
  -[CSVTUIEndpointAnalyzer _checkSNObservationForStartpoint:]
  -[CSVTUIEndpointAnalyzer _checkSNObservationForEndpoint:]
  -[CSVTUIEndpointAnalyzer _reportEndpointAtTsInSecs:]
  -[CSVTUIEndpointAnalyzer _reportStartpointAtTsInSecs:]
  -[CSVTUIEndpointAnalyzer snAudioStreamAnalyzer]
  -[CSVTUIEndpointAnalyzer setSnAudioStreamAnalyzer:]
  -[CSVTUIEndpointAnalyzer nnvadState]
  -[CSVTUIEndpointAnalyzer setNnvadState:]
  -[CSVTUIEndpointAnalyzer numSamplesReceived]
  -[CSVTUIEndpointAnalyzer setNumSamplesReceived:]
  -[CSVTUIEndpointAnalyzer currentRequestAudioFormat]
  -[CSVTUIEndpointAnalyzer setCurrentRequestAudioFormat:]
  -[CSVTUIEndpointAnalyzer vtEndInSecs]
  -[CSVTUIEndpointAnalyzer setVtEndInSecs:]
  -[CSVTUIEndpointAnalyzer nnvadAudioOriginInMs]
  -[CSVTUIEndpointAnalyzer setNnvadAudioOriginInMs:]
  -[CSVTUIEndpointAnalyzer shouldDetectTwoShot]
  -[CSVTUIEndpointAnalyzer setShouldDetectTwoShot:]
  -[CSVTUIEndpointAnalyzer didEnterTwoshot]
  -[CSVTUIEndpointAnalyzer setDidEnterTwoshot:]
  -[CSVTUIEndpointAnalyzer firstSampleId]
  -[CSVTUIEndpointAnalyzer setFirstSampleId:]
  -[CSVTUIEndpointAnalyzer numSamplesSkippedForVT]
  -[CSVTUIEndpointAnalyzer setNumSamplesSkippedForVT:]
  -[CSVTUIEndpointAnalyzer finishedSkippingSamplesForVT]
  -[CSVTUIEndpointAnalyzer setFinishedSkippingSamplesForVT:]
  -[CSVTUIEndpointAnalyzer resetForNewRequestWithSampleRate:]


SSRVoiceActivityDetector : NSObject <EARCaesuraSilencePosteriorGeneratorDelegate>
 @property  SSRSpeakerRecognitionContext *context
 @property  <SSRVoiceActivityDetectorDelegate> *delegate
 @property  EARCaesuraSilencePosteriorGenerator *earSpg
 @property  _EAREndpointer *hybridClassifier
 @property  _EARDefaultServerEndpointFeatures *defSepFeats
 @property  long long segmentStartPointSampleCount
 @property  unsigned long numSamplesProcessed
 @property  BOOL endpointReported
 @property  BOOL startpointReported
 @property  NSObject<OS_dispatch_queue> *spgQueue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRVoiceActivityDetector endAudio]
  -[SSRVoiceActivityDetector hybridClassifier]
  -[SSRVoiceActivityDetector setDelegate:]
  -[SSRVoiceActivityDetector delegate]
  -[SSRVoiceActivityDetector .cxx_destruct]
  -[SSRVoiceActivityDetector setHybridClassifier:]
  -[SSRVoiceActivityDetector setContext:]
  -[SSRVoiceActivityDetector context]
  -[SSRVoiceActivityDetector initWithContext:delegate:]
  -[SSRVoiceActivityDetector clientSilenceFeaturesAvailable:]
  -[SSRVoiceActivityDetector resetWithContext:]
  -[SSRVoiceActivityDetector numSamplesProcessed]
  -[SSRVoiceActivityDetector setNumSamplesProcessed:]
  -[SSRVoiceActivityDetector spgQueue]
  -[SSRVoiceActivityDetector setSpgQueue:]
  -[SSRVoiceActivityDetector processAudioData:numSamples:]
  -[SSRVoiceActivityDetector _initializeSPGWithContext:]
  -[SSRVoiceActivityDetector earSpg]
  -[SSRVoiceActivityDetector setEarSpg:]
  -[SSRVoiceActivityDetector defSepFeats]
  -[SSRVoiceActivityDetector setDefSepFeats:]
  -[SSRVoiceActivityDetector segmentStartPointSampleCount]
  -[SSRVoiceActivityDetector setSegmentStartPointSampleCount:]
  -[SSRVoiceActivityDetector endpointReported]
  -[SSRVoiceActivityDetector setEndpointReported:]
  -[SSRVoiceActivityDetector startpointReported]
  -[SSRVoiceActivityDetector setStartpointReported:]


SSRSpeakerAnalyzerPSR : NSObject <EARSyncPSRAudioProcessorDelegate>
 @property  <SSRSpeakerAnalyzerPSRDelegate> *delegate
 @property  EARSyncPSRAudioProcessor *psrAudioProcessor
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  SSRSpeakerRecognitionContext *context
 @property  NSDictionary *voiceProfilesModelFilePaths
 @property  NSDictionary *voiceProfilesExpModelFilePaths
 @property  NSArray *psrScorers
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRSpeakerAnalyzerPSR endAudio]
  -[SSRSpeakerAnalyzerPSR setDelegate:]
  -[SSRSpeakerAnalyzerPSR delegate]
  -[SSRSpeakerAnalyzerPSR dealloc]
  -[SSRSpeakerAnalyzerPSR .cxx_destruct]
  -[SSRSpeakerAnalyzerPSR setQueue:]
  -[SSRSpeakerAnalyzerPSR setContext:]
  -[SSRSpeakerAnalyzerPSR queue]
  -[SSRSpeakerAnalyzerPSR context]
  -[SSRSpeakerAnalyzerPSR psrAudioProcessor:hasSpeakerVector:speakerVectorSize:processedAudioDurationMs:]
  -[SSRSpeakerAnalyzerPSR psrAudioProcessor:finishedWithFinalSpeakerVector:speakerVectorSize:processedAudioDurationMs:]
  -[SSRSpeakerAnalyzerPSR resetForNewRequest]
  -[SSRSpeakerAnalyzerPSR configFilePath]
  -[SSRSpeakerAnalyzerPSR setConfigFilePath:]
  -[SSRSpeakerAnalyzerPSR initWithVoiceRecognitionContext:delegate:queue:]
  -[SSRSpeakerAnalyzerPSR processAudioData:]
  -[SSRSpeakerAnalyzerPSR getVoiceRecognizerResults]
  -[SSRSpeakerAnalyzerPSR _processSpeakerVector:withSize:processedAudioDurationMs:]
  -[SSRSpeakerAnalyzerPSR _isSpeakerVectorValid:speakerVectorSize:fromPsrAudioProcessor:]
  -[SSRSpeakerAnalyzerPSR psrAudioProcessor]
  -[SSRSpeakerAnalyzerPSR setPsrAudioProcessor:]
  -[SSRSpeakerAnalyzerPSR resourceFilePath]
  -[SSRSpeakerAnalyzerPSR setResourceFilePath:]
  -[SSRSpeakerAnalyzerPSR voiceProfilesModelFilePaths]
  -[SSRSpeakerAnalyzerPSR setVoiceProfilesModelFilePaths:]
  -[SSRSpeakerAnalyzerPSR voiceProfilesExpModelFilePaths]
  -[SSRSpeakerAnalyzerPSR setVoiceProfilesExpModelFilePaths:]
  -[SSRSpeakerAnalyzerPSR psrScorers]
  -[SSRSpeakerAnalyzerPSR setPsrScorers:]


SSRSpeakerRecognizerPSR : NSObject <SSRSpeakerAnalyzerPSRDelegate, SSRSpeakerRecognizer>
 @property  SSRSpeakerRecognitionContext *spIdCtx
 @property  NSString *sessionId
 @property  NSDictionary *lastSpeakerInfo
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <SSRSpeakerRecognizerDelegate> *delegate
 @property  NSString *invocationStyleStr
 @property  unsigned long extraSamplesAtStart
 @property  unsigned long vtEndInSampleCount
 @property  unsigned long endInSampleCount
 @property  unsigned long numSamplesProcessed
 @property  BOOL processingEnded
 @property  unsigned long totalNumSamplesReceived
 @property  SSRSpeakerAnalyzerPSR *psrAnalyzer
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  NSDictionary *lastScoreCard

  // instance methods
  -[SSRSpeakerRecognizerPSR endAudio]
  -[SSRSpeakerRecognizerPSR setSessionId:]
  -[SSRSpeakerRecognizerPSR sessionId]
  -[SSRSpeakerRecognizerPSR setDelegate:]
  -[SSRSpeakerRecognizerPSR delegate]
  -[SSRSpeakerRecognizerPSR vtEndInSampleCount]
  -[SSRSpeakerRecognizerPSR dealloc]
  -[SSRSpeakerRecognizerPSR .cxx_destruct]
  -[SSRSpeakerRecognizerPSR setVtEndInSampleCount:]
  -[SSRSpeakerRecognizerPSR setQueue:]
  -[SSRSpeakerRecognizerPSR queue]
  -[SSRSpeakerRecognizerPSR initWithContext:delegate:]
  -[SSRSpeakerRecognizerPSR setExtraSamplesAtStart:]
  -[SSRSpeakerRecognizerPSR extraSamplesAtStart]
  -[SSRSpeakerRecognizerPSR resetWithContext:]
  -[SSRSpeakerRecognizerPSR numSamplesProcessed]
  -[SSRSpeakerRecognizerPSR setNumSamplesProcessed:]
  -[SSRSpeakerRecognizerPSR processAudioData:numSamples:]
  -[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzer:hasVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerPSR voiceRecognitionPSRAnalyzerFinishedProcessing:withVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerPSR lastScoreCard]
  -[SSRSpeakerRecognizerPSR _initializeWithContext:]
  -[SSRSpeakerRecognizerPSR spIdCtx]
  -[SSRSpeakerRecognizerPSR setSpIdCtx:]
  -[SSRSpeakerRecognizerPSR lastSpeakerInfo]
  -[SSRSpeakerRecognizerPSR setLastSpeakerInfo:]
  -[SSRSpeakerRecognizerPSR invocationStyleStr]
  -[SSRSpeakerRecognizerPSR setInvocationStyleStr:]
  -[SSRSpeakerRecognizerPSR endInSampleCount]
  -[SSRSpeakerRecognizerPSR setEndInSampleCount:]
  -[SSRSpeakerRecognizerPSR processingEnded]
  -[SSRSpeakerRecognizerPSR setProcessingEnded:]
  -[SSRSpeakerRecognizerPSR totalNumSamplesReceived]
  -[SSRSpeakerRecognizerPSR setTotalNumSamplesReceived:]
  -[SSRSpeakerRecognizerPSR psrAnalyzer]
  -[SSRSpeakerRecognizerPSR setPsrAnalyzer:]


SSRTriggerPhraseDetectorNDAPI : NSObject
  // instance methods
  -[SSRTriggerPhraseDetectorNDAPI getSuperVectorWithEndPoint:]
  -[SSRTriggerPhraseDetectorNDAPI dealloc]
  -[SSRTriggerPhraseDetectorNDAPI reset]
  -[SSRTriggerPhraseDetectorNDAPI analyzeWavData:numSamples:]
  -[SSRTriggerPhraseDetectorNDAPI initWithConfigPath:resourcePath:phId:]


SSRTriggerPhraseDetectorNDAPIResult : NSObject
 @property  unsigned long phId
 @property  unsigned long samplesFed
 @property  unsigned long bestPhrase
 @property  unsigned long bestStart
 @property  unsigned long bestEnd
 @property  float bestScore
 @property  BOOL isEarlyWarning
 @property  BOOL isRescoring

  // instance methods
  -[SSRTriggerPhraseDetectorNDAPIResult bestScore]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestScore:]
  -[SSRTriggerPhraseDetectorNDAPIResult samplesFed]
  -[SSRTriggerPhraseDetectorNDAPIResult setSamplesFed:]
  -[SSRTriggerPhraseDetectorNDAPIResult bestStart]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestStart:]
  -[SSRTriggerPhraseDetectorNDAPIResult bestEnd]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestEnd:]
  -[SSRTriggerPhraseDetectorNDAPIResult phId]
  -[SSRTriggerPhraseDetectorNDAPIResult setPhId:]
  -[SSRTriggerPhraseDetectorNDAPIResult bestPhrase]
  -[SSRTriggerPhraseDetectorNDAPIResult setBestPhrase:]
  -[SSRTriggerPhraseDetectorNDAPIResult isEarlyWarning]
  -[SSRTriggerPhraseDetectorNDAPIResult setIsEarlyWarning:]
  -[SSRTriggerPhraseDetectorNDAPIResult isRescoring]
  -[SSRTriggerPhraseDetectorNDAPIResult setIsRescoring:]


SSRSpeakerRecognitionOrchestrator : NSObject <SSRSpeakerRecognizerDelegate, SSRVoiceActivityDetectorDelegate>
 @property  SSRSpeakerRecognitionContext *context
 @property  <SSRSpeakerRecognitionOrchestratorDelegate> *delegate
 @property  <CSAudioFileWriter> *ssrUttLogger
 @property  unsigned long myriadResult
 @property  <SSRSpeakerRecognizer> *psrRecognizer
 @property  <SSRSpeakerRecognizer> *satRecognizer
 @property  SSRVoiceActivityDetector *vad
 @property  NSDictionary *psrLastSpeakerInfo
 @property  NSDictionary *satLastSpeakerInfo
 @property  NSDictionary *combinedScores
 @property  NSDictionary *psrFinalSpeakerInfo
 @property  NSDictionary *satFinalSpeakerInfo
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSString *debugUtteranceAudioFilePath
 @property  NSString *debugUtteranceJsonFilePath
 @property  NSObject<OS_os_transaction> *transaction
 @property  NSString *transDesc
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRSpeakerRecognitionOrchestrator endAudio]
  -[SSRSpeakerRecognitionOrchestrator setDelegate:]
  -[SSRSpeakerRecognitionOrchestrator transaction]
  -[SSRSpeakerRecognitionOrchestrator delegate]
  -[SSRSpeakerRecognitionOrchestrator dealloc]
  -[SSRSpeakerRecognitionOrchestrator .cxx_destruct]
  -[SSRSpeakerRecognitionOrchestrator setTransaction:]
  -[SSRSpeakerRecognitionOrchestrator setQueue:]
  -[SSRSpeakerRecognitionOrchestrator setContext:]
  -[SSRSpeakerRecognitionOrchestrator queue]
  -[SSRSpeakerRecognitionOrchestrator context]
  -[SSRSpeakerRecognitionOrchestrator initWithContext:withDelegate:error:]
  -[SSRSpeakerRecognitionOrchestrator resetWithContext:]
  -[SSRSpeakerRecognitionOrchestrator processAudio:numSamples:]
  -[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectEndPointAt:]
  -[SSRSpeakerRecognitionOrchestrator SSRVoiceActivityDetector:didDetectStartPointAt:]
  -[SSRSpeakerRecognitionOrchestrator speakerRecognizer:hasSpeakerIdInfo:]
  -[SSRSpeakerRecognitionOrchestrator speakerRecognizerFinishedProcessing:withFinalSpeakerIdInfo:]
  -[SSRSpeakerRecognitionOrchestrator _logSpeakerIdProcessorScoreDelayWithScoreInfo:hasFinished:]
  -[SSRSpeakerRecognitionOrchestrator orchestratorScoresWithPSRScores:withSATScores:withSegmentStartTime:]
  -[SSRSpeakerRecognitionOrchestrator _resetWithContext:]
  -[SSRSpeakerRecognitionOrchestrator updateDebugFilePathsForSegment:]
  -[SSRSpeakerRecognitionOrchestrator getLatestVoiceRecognitionInfo]
  -[SSRSpeakerRecognitionOrchestrator ssrUttLogger]
  -[SSRSpeakerRecognitionOrchestrator setSsrUttLogger:]
  -[SSRSpeakerRecognitionOrchestrator myriadResult]
  -[SSRSpeakerRecognitionOrchestrator setMyriadResult:]
  -[SSRSpeakerRecognitionOrchestrator psrRecognizer]
  -[SSRSpeakerRecognitionOrchestrator setPsrRecognizer:]
  -[SSRSpeakerRecognitionOrchestrator satRecognizer]
  -[SSRSpeakerRecognitionOrchestrator setSatRecognizer:]
  -[SSRSpeakerRecognitionOrchestrator vad]
  -[SSRSpeakerRecognitionOrchestrator setVad:]
  -[SSRSpeakerRecognitionOrchestrator psrLastSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setPsrLastSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator satLastSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setSatLastSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator combinedScores]
  -[SSRSpeakerRecognitionOrchestrator setCombinedScores:]
  -[SSRSpeakerRecognitionOrchestrator psrFinalSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setPsrFinalSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator satFinalSpeakerInfo]
  -[SSRSpeakerRecognitionOrchestrator setSatFinalSpeakerInfo:]
  -[SSRSpeakerRecognitionOrchestrator debugUtteranceAudioFilePath]
  -[SSRSpeakerRecognitionOrchestrator setDebugUtteranceAudioFilePath:]
  -[SSRSpeakerRecognitionOrchestrator debugUtteranceJsonFilePath]
  -[SSRSpeakerRecognitionOrchestrator setDebugUtteranceJsonFilePath:]
  -[SSRSpeakerRecognitionOrchestrator transDesc]
  -[SSRSpeakerRecognitionOrchestrator setTransDesc:]


SSRVoiceProfileRetrainerSAT : NSObject <SSRVoiceProfileRetrainer>
 @property  SSRSpeakerRecognitionScorer *satScorer
 @property  SSRVoiceProfile *voiceProfile
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  NSURL *satModelFilePath
 @property  unsigned long spIdType
 @property  NSDictionary *comparativeModels
 @property  NSData *superVector
 @property  unsigned long superVectorSize
 @property  unsigned long processedAudioDurationMs
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSURL *modelFilePath
 @property  BOOL implicitTrainingRequired
 @property  unsigned long retrainerType
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRVoiceProfileRetrainerSAT modelFilePath]
  -[SSRVoiceProfileRetrainerSAT .cxx_destruct]
  -[SSRVoiceProfileRetrainerSAT setQueue:]
  -[SSRVoiceProfileRetrainerSAT queue]
  -[SSRVoiceProfileRetrainerSAT processedAudioDurationMs]
  -[SSRVoiceProfileRetrainerSAT setProcessedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerSAT configFilePath]
  -[SSRVoiceProfileRetrainerSAT setConfigFilePath:]
  -[SSRVoiceProfileRetrainerSAT resourceFilePath]
  -[SSRVoiceProfileRetrainerSAT setResourceFilePath:]
  -[SSRVoiceProfileRetrainerSAT initWithVoiceRetrainingContext:]
  -[SSRVoiceProfileRetrainerSAT resetModelForRetraining]
  -[SSRVoiceProfileRetrainerSAT addUtterances:withPolicy:withCompletion:]
  -[SSRVoiceProfileRetrainerSAT needsRetrainingWithAudioFiles:]
  -[SSRVoiceProfileRetrainerSAT purgeLastSpeakerEmbedding]
  -[SSRVoiceProfileRetrainerSAT purgeConfusionInformationWithPolicy:]
  -[SSRVoiceProfileRetrainerSAT implicitTrainingRequired]
  -[SSRVoiceProfileRetrainerSAT retrainerType]
  -[SSRVoiceProfileRetrainerSAT _processAudioFile:withSATProcessor:]
  -[SSRVoiceProfileRetrainerSAT _processSuperVector:withSize:withScorers:processedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerSAT satScorer]
  -[SSRVoiceProfileRetrainerSAT setSatScorer:]
  -[SSRVoiceProfileRetrainerSAT voiceProfile]
  -[SSRVoiceProfileRetrainerSAT setVoiceProfile:]
  -[SSRVoiceProfileRetrainerSAT satModelFilePath]
  -[SSRVoiceProfileRetrainerSAT setSatModelFilePath:]
  -[SSRVoiceProfileRetrainerSAT spIdType]
  -[SSRVoiceProfileRetrainerSAT setSpIdType:]
  -[SSRVoiceProfileRetrainerSAT comparativeModels]
  -[SSRVoiceProfileRetrainerSAT setComparativeModels:]
  -[SSRVoiceProfileRetrainerSAT superVector]
  -[SSRVoiceProfileRetrainerSAT setSuperVector:]
  -[SSRVoiceProfileRetrainerSAT superVectorSize]
  -[SSRVoiceProfileRetrainerSAT setSuperVectorSize:]


SSRDESRecordWriter : NSObject
  // class methods
  +[SSRDESRecordWriter createDESRecordWithSuperVector:withMetaInfo:]
  +[SSRDESRecordWriter fetchMedicalDataWithCompletion:]


SSRSpeakerRecognitionScorer : NSObject
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  NSURL *modelFilePath
 @property  NSString *profileID
 @property  NSString *sysConfigRoot
 @property  NSString *psrConfigFilePath
 @property  NSString *psrConfigRoot
 @property  BOOL satModelAvailable

  // class methods
  +[SSRSpeakerRecognitionScorer createVoiceScorersWithVoiceProfiles:withConfigFile:withResourceFile:withOffsetsType:]

  // instance methods
  -[SSRSpeakerRecognitionScorer setModelFilePath:]
  -[SSRSpeakerRecognitionScorer modelFilePath]
  -[SSRSpeakerRecognitionScorer dealloc]
  -[SSRSpeakerRecognitionScorer .cxx_destruct]
  -[SSRSpeakerRecognitionScorer profileID]
  -[SSRSpeakerRecognitionScorer resetForNewRequest]
  -[SSRSpeakerRecognitionScorer configFilePath]
  -[SSRSpeakerRecognitionScorer setConfigFilePath:]
  -[SSRSpeakerRecognitionScorer getSATVectorCount]
  -[SSRSpeakerRecognitionScorer updateSAT]
  -[SSRSpeakerRecognitionScorer deleteVectorAtIndex:]
  -[SSRSpeakerRecognitionScorer _getFloatValueForNDAPIConfigOption:defaultValue:]
  -[SSRSpeakerRecognitionScorer _getValueForNDAPIConfigOption:]
  -[SSRSpeakerRecognitionScorer _getStringValueFromConfigurationName:defaultTo:]
  -[SSRSpeakerRecognitionScorer _getIntValueFromConfigurationName:defaultTo:]
  -[SSRSpeakerRecognitionScorer _getFloatValueFromConfigurationName:defaultTo:]
  -[SSRSpeakerRecognitionScorer _getOptionValueFromConfigurationName:]
  -[SSRSpeakerRecognitionScorer resourceFilePath]
  -[SSRSpeakerRecognitionScorer setResourceFilePath:]
  -[SSRSpeakerRecognitionScorer initWithProfileID:withModelFile:withConfigFile:withResourceFile:withOffsetsType:]
  -[SSRSpeakerRecognitionScorer resetScorerWithModelFilePath:]
  -[SSRSpeakerRecognitionScorer analyzeSpeakerVector:withDimensions:withThresholdType:]
  -[SSRSpeakerRecognitionScorer analyzeSuperVector:withDimensions:withThresholdType:]
  -[SSRSpeakerRecognitionScorer scoreSpeakerVector:withDimensions:withThresholdType:]
  -[SSRSpeakerRecognitionScorer normalizedScoreFromRawScore:forScoreType:]
  -[SSRSpeakerRecognitionScorer sysConfigRoot]
  -[SSRSpeakerRecognitionScorer psrConfigFilePath]
  -[SSRSpeakerRecognitionScorer psrConfigRoot]
  -[SSRSpeakerRecognitionScorer getSpeakerVectorAtIndex:]
  -[SSRSpeakerRecognitionScorer _satScoreVTScale]
  -[SSRSpeakerRecognitionScorer _satScoreNonVTScale]
  -[SSRSpeakerRecognitionScorer _satScoreVTOffset]
  -[SSRSpeakerRecognitionScorer _satScoreNonVTOffset]
  -[SSRSpeakerRecognitionScorer _satLogitCeilScore]
  -[SSRSpeakerRecognitionScorer _satLogitFloorScore]
  -[SSRSpeakerRecognitionScorer satModelAvailable]


SSRVTUITrainingManager : NSObject <CSVTUITrainingSessionDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndpointAnalyzerDelegate>
 @property  CSPlainAudioFileWriter *audioFileWriter
 @property  SSRVoiceProfile *voiceProfile
 @property  float rms
 @property  <SSRVTUITrainingManagerDelegate> *delegate
 @property  BOOL speechRecognizerAvailable
 @property  unsigned long audioSource
 @property  BOOL suspendAudio
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[SSRVTUITrainingManager trainingManagerWithLocaleID:withAppDomain:]
  +[SSRVTUITrainingManager sharedtrainingSessionQueue]

  // instance methods
  -[SSRVTUITrainingManager setLocaleIdentifier:]
  -[SSRVTUITrainingManager endpointer:didDetectStartpointAtTime:]
  -[SSRVTUITrainingManager setDelegate:]
  -[SSRVTUITrainingManager setAudioFileWriter:]
  -[SSRVTUITrainingManager delegate]
  -[SSRVTUITrainingManager reset]
  -[SSRVTUITrainingManager .cxx_destruct]
  -[SSRVTUITrainingManager audioFileWriter]
  -[SSRVTUITrainingManager prepareWithCompletion:]
  -[SSRVTUITrainingManager audioSource]
  -[SSRVTUITrainingManager _audioSource]
  -[SSRVTUITrainingManager _setupAudioSession]
  -[SSRVTUITrainingManager _startAudioSession]
  -[SSRVTUITrainingManager _stopAudioSession]
  -[SSRVTUITrainingManager voiceProfile]
  -[SSRVTUITrainingManager audioSessionDidStartRecording:error:]
  -[SSRVTUITrainingManager audioSessionDidStopRecording:]
  -[SSRVTUITrainingManager audioSessionRecordBufferAvailable:]
  -[SSRVTUITrainingManager audioSessionErrorDidOccur:]
  -[SSRVTUITrainingManager audioSessionUnsupportedAudioRoute]
  -[SSRVTUITrainingManager CSVTUITrainingSessionRMSAvailable:]
  -[SSRVTUITrainingManager CSVTUITrainingSessionStopListen]
  -[SSRVTUITrainingManager CSVTUITrainingSession:hasTrainUtterance:languageCode:payload:]
  -[SSRVTUITrainingManager endpointer:didDetectHardEndpointAtTime:]
  -[SSRVTUITrainingManager initWithLocaleIdentifier:withAudioSession:withAppDomain:]
  -[SSRVTUITrainingManager updateTrainingManagerForDevice:trainingDeviceUUIDList:]
  -[SSRVTUITrainingManager createKeywordDetector]
  -[SSRVTUITrainingManager createSpeechRecognizer]
  -[SSRVTUITrainingManager _destroyAudioSession]
  -[SSRVTUITrainingManager _beginOfSpeechDetected]
  -[SSRVTUITrainingManager _endOfSpeechDetected]
  -[SSRVTUITrainingManager cleanupWithCompletion:]
  -[SSRVTUITrainingManager destroySpeakerTrainer]
  -[SSRVTUITrainingManager trainUtterance:shouldUseASR:completion:]
  -[SSRVTUITrainingManager trainUtterance:shouldUseASR:mhUUID:completionWithResult:]
  -[SSRVTUITrainingManager cancelTrainingForID:]
  -[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:withCompletion:]
  -[SSRVTUITrainingManager closeSessionBeforeStartWithStatus:successfully:completionWithResult:]
  -[SSRVTUITrainingManager _createAudioAnalyzer]
  -[SSRVTUITrainingManager _shouldShowHeadsetDisconnectionMessage]
  -[SSRVTUITrainingManager suspendAudio]
  -[SSRVTUITrainingManager setSuspendAudio:]
  -[SSRVTUITrainingManager startRMS]
  -[SSRVTUITrainingManager stopRMS]
  -[SSRVTUITrainingManager shouldPerformRMS]
  -[SSRVTUITrainingManager didDetectForceEndPoint]
  -[SSRVTUITrainingManager rms]
  -[SSRVTUITrainingManager setRms:]
  -[SSRVTUITrainingManager speechRecognizerAvailable]


SSRVoiceProfileRetrainerFactory : NSObject
  // instance methods
  -[SSRVoiceProfileRetrainerFactory init]
  -[SSRVoiceProfileRetrainerFactory voiceRetrainersWithContext:]


CSVTUIAudioSessionRecorder : NSObject <CSVTUIAudioRecorderDelegate, CSVTUIAudioSession>
 @property  CSAudioPowerMeter *powerMeter
 @property  unsigned long audioStreamHandleId
 @property  <CSVTUIAudioSessionDelegate> *delegate
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUIAudioSessionRecorder updateMeters]
  -[CSVTUIAudioSessionRecorder averagePower]
  -[CSVTUIAudioSessionRecorder audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:]
  -[CSVTUIAudioSessionRecorder setDelegate:]
  -[CSVTUIAudioSessionRecorder startRecording]
  -[CSVTUIAudioSessionRecorder isRecording]
  -[CSVTUIAudioSessionRecorder delegate]
  -[CSVTUIAudioSessionRecorder stopRecording]
  -[CSVTUIAudioSessionRecorder .cxx_destruct]
  -[CSVTUIAudioSessionRecorder powerMeter]
  -[CSVTUIAudioSessionRecorder hasAudioRoute]
  -[CSVTUIAudioSessionRecorder setEndpointerDelegate:]
  -[CSVTUIAudioSessionRecorder releaseAudioSession]
  -[CSVTUIAudioSessionRecorder setPowerMeter:]
  -[CSVTUIAudioSessionRecorder init]
  -[CSVTUIAudioSessionRecorder audioSource]
  -[CSVTUIAudioSessionRecorder _audioRecorder]
  -[CSVTUIAudioSessionRecorder audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:]
  -[CSVTUIAudioSessionRecorder audioRecorderDidStopRecord:audioStreamHandleId:reason:]
  -[CSVTUIAudioSessionRecorder audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:]
  -[CSVTUIAudioSessionRecorder audioRecorderDisconnected:]
  -[CSVTUIAudioSessionRecorder audioStreamHandleId]
  -[CSVTUIAudioSessionRecorder setAudioStreamHandleId:]
  -[CSVTUIAudioSessionRecorder prepareRecord]
  -[CSVTUIAudioSessionRecorder updateAudioRecorderForTrainingDevice:deviceUUIDs:]
  -[CSVTUIAudioSessionRecorder resetEndPointer]
  -[CSVTUIAudioSessionRecorder hasCorrectAudioRoute]
  -[CSVTUIAudioSessionRecorder initWithAudioRecorder:forceSupportsRemoteDarwinDisplay:]
  -[CSVTUIAudioSessionRecorder _hasCorrectInputAudioRoute]
  -[CSVTUIAudioSessionRecorder _hasCorrectOutputAudioRoute]
  -[CSVTUIAudioSessionRecorder convertStopReason:]
  -[CSVTUIAudioSessionRecorder _handleDidStopWithReason:]
  -[CSVTUIAudioSessionRecorder _updateRemoteDarwinDisplayConnectedIfNeeded]


SSRVoiceProfileMetaContext : NSObject
 @property  NSString *appDomain
 @property  NSString *profileId
 @property  NSString *languageCode
 @property  NSString *productCategory
 @property  NSNumber *version
 @property  NSDate *dateAdded
 @property  NSNumber *pitch
 @property  NSString *sharedSiriId
 @property  NSString *homeId
 @property  NSString *userName

  // instance methods
  -[SSRVoiceProfileMetaContext userName]
  -[SSRVoiceProfileMetaContext dateAdded]
  -[SSRVoiceProfileMetaContext setLanguageCode:]
  -[SSRVoiceProfileMetaContext .cxx_destruct]
  -[SSRVoiceProfileMetaContext pitch]
  -[SSRVoiceProfileMetaContext setPitch:]
  -[SSRVoiceProfileMetaContext languageCode]
  -[SSRVoiceProfileMetaContext version]
  -[SSRVoiceProfileMetaContext setDateAdded:]
  -[SSRVoiceProfileMetaContext setVersion:]
  -[SSRVoiceProfileMetaContext setUserName:]
  -[SSRVoiceProfileMetaContext homeId]
  -[SSRVoiceProfileMetaContext setHomeId:]
  -[SSRVoiceProfileMetaContext appDomain]
  -[SSRVoiceProfileMetaContext sharedSiriId]
  -[SSRVoiceProfileMetaContext profileId]
  -[SSRVoiceProfileMetaContext setProfileId:]
  -[SSRVoiceProfileMetaContext productCategory]
  -[SSRVoiceProfileMetaContext setProductCategory:]
  -[SSRVoiceProfileMetaContext initWithVoiceProfile:]
  -[SSRVoiceProfileMetaContext initWithSharedSiriId:languageCode:productCategory:version:]
  -[SSRVoiceProfileMetaContext setAppDomain:]
  -[SSRVoiceProfileMetaContext setSharedSiriId:]


SSRTriggerPhraseDetector : NSObject
 @property  SSRTriggerPhraseDetectorNDAPI *detectorNDAPI
 @property  SSRTriggerPhraseDetectorQuasar *detectorQuasar
 @property  float recognizerScoreScaleFactor

  // class methods
  +[SSRTriggerPhraseDetector filterVTAudioFiles:withLocale:withAsset:]

  // instance methods
  -[SSRTriggerPhraseDetector .cxx_destruct]
  -[SSRTriggerPhraseDetector recognizerScoreScaleFactor]
  -[SSRTriggerPhraseDetector initWithLocale:asset:]
  -[SSRTriggerPhraseDetector computeTriggerConfidenceForAudio:withCompletion:]
  -[SSRTriggerPhraseDetector detectorNDAPI]
  -[SSRTriggerPhraseDetector setDetectorNDAPI:]
  -[SSRTriggerPhraseDetector detectorQuasar]
  -[SSRTriggerPhraseDetector setDetectorQuasar:]
  -[SSRTriggerPhraseDetector setRecognizerScoreScaleFactor:]


SSRRemoteControlClient : NSObject
  // instance methods
  -[SSRRemoteControlClient isConnected]
  -[SSRRemoteControlClient dealloc]
  -[SSRRemoteControlClient .cxx_destruct]
  -[SSRRemoteControlClient didDeviceConnect:]
  -[SSRRemoteControlClient didDeviceDisconnect:]
  -[SSRRemoteControlClient waitingForConnection:error:]
  -[SSRRemoteControlClient _handleServerEvent:]
  -[SSRRemoteControlClient _handleServerError:]
  -[SSRRemoteControlClient initWithRemoteDeviceUUID:]
  -[SSRRemoteControlClient addImplicitTrainingUtteranceToRemoteFilePath:forVoiceProfileId:withVoiceTriggerCtxt:locale:withOtherCtxt:completion:]
  -[SSRRemoteControlClient _isImplicitTrainingRequiredForVoiceProfileId:locale:error:]


SSRTrialAssetProvider : NSObject <SSRAssetProviding>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRTrialAssetProvider init]
  -[SSRTrialAssetProvider getAssetProviderType]
  -[SSRTrialAssetProvider installedAssetOfType:forLanguageCode:]
  -[SSRTrialAssetProvider reloadForLocale:]


CSVTUIKeywordDetector : NSObject
  // instance methods
  -[CSVTUIKeywordDetector initWithAsset:]
  -[CSVTUIKeywordDetector analyze:]
  -[CSVTUIKeywordDetector reset]
  -[CSVTUIKeywordDetector _sampleLengthFrom:To:]
  -[CSVTUIKeywordDetector .cxx_destruct]
  -[CSVTUIKeywordDetector triggeredUtterance:]


SSRVoiceProfileComposer : NSObject
  // class methods
  +[SSRVoiceProfileComposer sharedTrainer]

  // instance methods
  -[SSRVoiceProfileComposer addUtterance:toProfile:]
  -[SSRVoiceProfileComposer addUtterance:toProfile:withAsset:]


SSRVoiceProfileRetrainerPSR : NSObject <EARSyncPSRAudioProcessorDelegate, SSRVoiceProfileRetrainer>
 @property  SSRSpeakerRecognitionScorer *psrScorer
 @property  SSRVoiceProfile *voiceProfile
 @property  unsigned long spIdType
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  NSString *configVersion
 @property  NSURL *psrModelFilePath
 @property  NSDictionary *comparativeModels
 @property  unsigned long currUttLengthInMs
 @property  NSData *speakerVector
 @property  unsigned long speakerVectorSize
 @property  unsigned long processedAudioDurationMs
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  NSURL *modelFilePath
 @property  BOOL implicitTrainingRequired
 @property  unsigned long retrainerType

  // instance methods
  -[SSRVoiceProfileRetrainerPSR setConfigVersion:]
  -[SSRVoiceProfileRetrainerPSR modelFilePath]
  -[SSRVoiceProfileRetrainerPSR dealloc]
  -[SSRVoiceProfileRetrainerPSR configVersion]
  -[SSRVoiceProfileRetrainerPSR .cxx_destruct]
  -[SSRVoiceProfileRetrainerPSR setQueue:]
  -[SSRVoiceProfileRetrainerPSR queue]
  -[SSRVoiceProfileRetrainerPSR processedAudioDurationMs]
  -[SSRVoiceProfileRetrainerPSR setProcessedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerPSR configFilePath]
  -[SSRVoiceProfileRetrainerPSR setConfigFilePath:]
  -[SSRVoiceProfileRetrainerPSR speakerVector]
  -[SSRVoiceProfileRetrainerPSR setSpeakerVector:]
  -[SSRVoiceProfileRetrainerPSR resourceFilePath]
  -[SSRVoiceProfileRetrainerPSR setResourceFilePath:]
  -[SSRVoiceProfileRetrainerPSR initWithVoiceRetrainingContext:]
  -[SSRVoiceProfileRetrainerPSR resetModelForRetraining]
  -[SSRVoiceProfileRetrainerPSR addUtterances:withPolicy:withCompletion:]
  -[SSRVoiceProfileRetrainerPSR needsRetrainingWithAudioFiles:]
  -[SSRVoiceProfileRetrainerPSR purgeLastSpeakerEmbedding]
  -[SSRVoiceProfileRetrainerPSR purgeConfusionInformationWithPolicy:]
  -[SSRVoiceProfileRetrainerPSR implicitTrainingRequired]
  -[SSRVoiceProfileRetrainerPSR retrainerType]
  -[SSRVoiceProfileRetrainerPSR voiceProfile]
  -[SSRVoiceProfileRetrainerPSR setVoiceProfile:]
  -[SSRVoiceProfileRetrainerPSR spIdType]
  -[SSRVoiceProfileRetrainerPSR setSpIdType:]
  -[SSRVoiceProfileRetrainerPSR comparativeModels]
  -[SSRVoiceProfileRetrainerPSR setComparativeModels:]
  -[SSRVoiceProfileRetrainerPSR _logSpeakerConfusionWithExplicitScores:withImplicitScores:withPurgeUtterances:forProfile:forConfigVersion:]
  -[SSRVoiceProfileRetrainerPSR _composeSpeakerConfusionWithScores:forProfiles:]
  -[SSRVoiceProfileRetrainerPSR _logSpeakerConfusion:forProfileArray:withPrependString:]
  -[SSRVoiceProfileRetrainerPSR _processAudioFile:withPSRProcessor:]
  -[SSRVoiceProfileRetrainerPSR _processSpeakerVector:withSize:withScorers:processedAudioDurationMs:]
  -[SSRVoiceProfileRetrainerPSR psrScorer]
  -[SSRVoiceProfileRetrainerPSR setPsrScorer:]
  -[SSRVoiceProfileRetrainerPSR psrModelFilePath]
  -[SSRVoiceProfileRetrainerPSR setPsrModelFilePath:]
  -[SSRVoiceProfileRetrainerPSR currUttLengthInMs]
  -[SSRVoiceProfileRetrainerPSR setCurrUttLengthInMs:]
  -[SSRVoiceProfileRetrainerPSR speakerVectorSize]
  -[SSRVoiceProfileRetrainerPSR setSpeakerVectorSize:]


SSRLoggingAggregator : NSObject
 @property  unsigned long voiceProfilePruningFailureReasonCode
 @property  float voiceProfileUpdateScoreMSE
 @property  unsigned long voiceProfileDiscardedUtteranceCount
 @property  unsigned long voiceProfilePrunedUtteranceCount
 @property  unsigned long voiceProfileRetainedUtteranceCount
 @property  unsigned long voiceProfileRetrainingFailureReasonCode
 @property  double retrainingWaitTime
 @property  unsigned long speakerRecognitionProcessingStatus
 @property  double speakerRecognitionWaitTime
 @property  unsigned long speakerRecognitionPSRProcessingStatus
 @property  unsigned long speakerRecognitionSATProcessingStatus

  // instance methods
  -[SSRLoggingAggregator .cxx_destruct]
  -[SSRLoggingAggregator initWithEvent:locale:configVersion:]
  -[SSRLoggingAggregator pushAnalyticsWithLazyBlock:]
  -[SSRLoggingAggregator setVoiceProfilePruningFailureReasonCode:]
  -[SSRLoggingAggregator setVoiceProfileUpdateScoreMSE:]
  -[SSRLoggingAggregator setVoiceProfileDiscardedUtteranceCount:]
  -[SSRLoggingAggregator setvoiceProfilePrunedUtteranceCount:]
  -[SSRLoggingAggregator setVoiceProfileRetainedUtteranceCount:]
  -[SSRLoggingAggregator appendVoiceProfileExplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator appendVoiceProfileImplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator appendVoiceProfileDiscardedImplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator appendVoiceProfileFailedExplicitUtteranceScoreWith:]
  -[SSRLoggingAggregator setVoiceProfileRetrainingFailureReasonCode:]
  -[SSRLoggingAggregator setRetrainingWaitTime:]
  -[SSRLoggingAggregator setSpeakerRecognitionProcessingStatus:]
  -[SSRLoggingAggregator setSpeakerRecognitionWaitTime:]
  -[SSRLoggingAggregator pushAnalytics]
  -[SSRLoggingAggregator voiceProfilePruningFailureReasonCode]
  -[SSRLoggingAggregator voiceProfileUpdateScoreMSE]
  -[SSRLoggingAggregator voiceProfileDiscardedUtteranceCount]
  -[SSRLoggingAggregator voiceProfilePrunedUtteranceCount]
  -[SSRLoggingAggregator setVoiceProfilePrunedUtteranceCount:]
  -[SSRLoggingAggregator voiceProfileRetainedUtteranceCount]
  -[SSRLoggingAggregator voiceProfileRetrainingFailureReasonCode]
  -[SSRLoggingAggregator retrainingWaitTime]
  -[SSRLoggingAggregator speakerRecognitionProcessingStatus]
  -[SSRLoggingAggregator speakerRecognitionWaitTime]
  -[SSRLoggingAggregator speakerRecognitionPSRProcessingStatus]
  -[SSRLoggingAggregator setSpeakerRecognitionPSRProcessingStatus:]
  -[SSRLoggingAggregator speakerRecognitionSATProcessingStatus]
  -[SSRLoggingAggregator setSpeakerRecognitionSATProcessingStatus:]


SSRSpeakerRecognizerSAT : NSObject <SSRSpeakerAnalyzerSATDelegate, SSRSpeakerRecognizer>
 @property  SSRSpeakerRecognitionContext *spIdCtx
 @property  NSString *sessionId
 @property  NSDictionary *lastSpeakerInfo
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <SSRSpeakerRecognizerDelegate> *delegate
 @property  NSString *invocationStyleStr
 @property  unsigned long extraSamplesAtStart
 @property  unsigned long tdEndInSampleCount
 @property  unsigned long totalNumSamplesReceived
 @property  unsigned long numTdTiSamplesProcessed
 @property  BOOL processingEnded
 @property  SSRSpeakerAnalyzerSAT *satAnalyzer
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription
 @property  NSDictionary *lastScoreCard

  // instance methods
  -[SSRSpeakerRecognizerSAT endAudio]
  -[SSRSpeakerRecognizerSAT setSessionId:]
  -[SSRSpeakerRecognizerSAT sessionId]
  -[SSRSpeakerRecognizerSAT setDelegate:]
  -[SSRSpeakerRecognizerSAT delegate]
  -[SSRSpeakerRecognizerSAT dealloc]
  -[SSRSpeakerRecognizerSAT .cxx_destruct]
  -[SSRSpeakerRecognizerSAT setQueue:]
  -[SSRSpeakerRecognizerSAT queue]
  -[SSRSpeakerRecognizerSAT initWithContext:delegate:]
  -[SSRSpeakerRecognizerSAT setExtraSamplesAtStart:]
  -[SSRSpeakerRecognizerSAT extraSamplesAtStart]
  -[SSRSpeakerRecognizerSAT resetWithContext:]
  -[SSRSpeakerRecognizerSAT processAudioData:numSamples:]
  -[SSRSpeakerRecognizerSAT lastScoreCard]
  -[SSRSpeakerRecognizerSAT _initializeWithContext:]
  -[SSRSpeakerRecognizerSAT spIdCtx]
  -[SSRSpeakerRecognizerSAT setSpIdCtx:]
  -[SSRSpeakerRecognizerSAT lastSpeakerInfo]
  -[SSRSpeakerRecognizerSAT setLastSpeakerInfo:]
  -[SSRSpeakerRecognizerSAT invocationStyleStr]
  -[SSRSpeakerRecognizerSAT setInvocationStyleStr:]
  -[SSRSpeakerRecognizerSAT processingEnded]
  -[SSRSpeakerRecognizerSAT setProcessingEnded:]
  -[SSRSpeakerRecognizerSAT totalNumSamplesReceived]
  -[SSRSpeakerRecognizerSAT setTotalNumSamplesReceived:]
  -[SSRSpeakerRecognizerSAT voiceRecognitionSATAnalyzer:hasVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerSAT voiceRecognitionSATAnalyzerFinishedProcessing:withVoiceRecognitionInfo:]
  -[SSRSpeakerRecognizerSAT tdEndInSampleCount]
  -[SSRSpeakerRecognizerSAT setTdEndInSampleCount:]
  -[SSRSpeakerRecognizerSAT numTdTiSamplesProcessed]
  -[SSRSpeakerRecognizerSAT setNumTdTiSamplesProcessed:]
  -[SSRSpeakerRecognizerSAT satAnalyzer]
  -[SSRSpeakerRecognizerSAT setSatAnalyzer:]


SSRVoiceProfileStoreCleaner : NSObject
  // instance methods
  -[SSRVoiceProfileStoreCleaner filterDuplicatedSiriProfilesFrom:]
  -[SSRVoiceProfileStoreCleaner filterInvalidSiriProfilesFrom:]
  -[SSRVoiceProfileStoreCleaner cleanupProfileStore]
  -[SSRVoiceProfileStoreCleaner _cleanupAppDomain:]
  -[SSRVoiceProfileStoreCleaner _cleanuplanguageCodePath:forAppDomain:]
  -[SSRVoiceProfileStoreCleaner _cleanupImplicitUtteranceCacheForProfile:]
  -[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesForProfile:payloadUtteranceLifeTimeInDays:]
  -[SSRVoiceProfileStoreCleaner _cleanupContentsOfSatFolder:]
  -[SSRVoiceProfileStoreCleaner _cleanupInvalidAudioFiles:]
  -[SSRVoiceProfileStoreCleaner _cleanupOrphanedMetafilesAtURL:]
  -[SSRVoiceProfileStoreCleaner _cleanupPayloadUtterancesFromProfile:forModelType:exceedingLifeTimeInDays:]
  -[SSRVoiceProfileStoreCleaner cleanupInvalidModelsForProfile:withAssetArray:]
  -[SSRVoiceProfileStoreCleaner _cleanupModelFilesAtDir:forAssetArray:]


CSVTUIRemoteRecordClient : NSObject
 @property  OS_remote_device *device
 @property  <CSVTUIRemoteRecordClientDelegate> *delegate
 @property  unsigned long audioStreamHandleId
 @property  NSString *deviceId

  // instance methods
  -[CSVTUIRemoteRecordClient deviceId]
  -[CSVTUIRemoteRecordClient isConnected]
  -[CSVTUIRemoteRecordClient setDelegate:]
  -[CSVTUIRemoteRecordClient isRecording]
  -[CSVTUIRemoteRecordClient delegate]
  -[CSVTUIRemoteRecordClient dealloc]
  -[CSVTUIRemoteRecordClient .cxx_destruct]
  -[CSVTUIRemoteRecordClient setDevice:]
  -[CSVTUIRemoteRecordClient device]
  -[CSVTUIRemoteRecordClient init]
  -[CSVTUIRemoteRecordClient stopRecording:]
  -[CSVTUIRemoteRecordClient voiceTriggerEventInfo]
  -[CSVTUIRemoteRecordClient audioStreamHandleId]
  -[CSVTUIRemoteRecordClient initWithDeviceId:audioStreamHandleId:]
  -[CSVTUIRemoteRecordClient didDeviceConnect:]
  -[CSVTUIRemoteRecordClient didDeviceDisconnect:]
  -[CSVTUIRemoteRecordClient waitingForConnection:error:]
  -[CSVTUIRemoteRecordClient _handleServerEvent:]
  -[CSVTUIRemoteRecordClient _handleServerError:]
  -[CSVTUIRemoteRecordClient _handleServerMessage:]
  -[CSVTUIRemoteRecordClient _handleDidStartRecordingMessage:]
  -[CSVTUIRemoteRecordClient _handleTwoShotDetectedMessage:]
  -[CSVTUIRemoteRecordClient startRecordingWithOptions:error:]
  -[CSVTUIRemoteRecordClient didPlayEndpointBeep]
  -[CSVTUIRemoteRecordClient hasPendingTwoShotBeep]


CSVTUISelfLoggingDigitalZeroReporter : NSObject <CSDigitalZeroReporting>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUISelfLoggingDigitalZeroReporter .cxx_destruct]
  -[CSVTUISelfLoggingDigitalZeroReporter reportDigitalZerosWithAudioZeroRun:]
  -[CSVTUISelfLoggingDigitalZeroReporter initWithSiriSetupID:PageNumber:withPhId:]
  -[CSVTUISelfLoggingDigitalZeroReporter digitalZeroDetected]
  -[CSVTUISelfLoggingDigitalZeroReporter logDigitalZeroDetectionComplete]


SSRVoiceProfile : NSObject <NSSecureCoding>
 @property  NSString *profileBasePath
 @property  NSString *voiceProfileBasePath
 @property  NSString *voiceProfileImplicitCacheDirPath
 @property  NSString *voiceProfileIdentity
 @property  unsigned long voiceProfileVersion
 @property  unsigned long productCategory
 @property  NSString *pruningCookie
 @property  BOOL profileLocallyAvailable
 @property  NSNumber *profilePitch
 @property  NSString *userName
 @property  NSString *locale
 @property  NSString *appDomain
 @property  NSDate *dateAdded
 @property  NSString *profileID
 @property  NSString *siriProfileId

  // class methods
  +[SSRVoiceProfile supportsSecureCoding]

  // instance methods
  -[SSRVoiceProfile userName]
  -[SSRVoiceProfile dateAdded]
  -[SSRVoiceProfile encodeWithCoder:]
  -[SSRVoiceProfile initWithDictionary:]
  -[SSRVoiceProfile .cxx_destruct]
  -[SSRVoiceProfile locale]
  -[SSRVoiceProfile dictionaryRepresentation]
  -[SSRVoiceProfile profileID]
  -[SSRVoiceProfile setUserName:]
  -[SSRVoiceProfile initWithCoder:]
  -[SSRVoiceProfile siriProfileId]
  -[SSRVoiceProfile appDomain]
  -[SSRVoiceProfile productCategory]
  -[SSRVoiceProfile initNewVoiceProfileWithLocale:withAppDomain:]
  -[SSRVoiceProfile setSharedSiriProfileId:]
  -[SSRVoiceProfile voiceProfileModelFilePathForRecognizerType:spIdType:]
  -[SSRVoiceProfile _copyExplicitAudio:withSpIdType:]
  -[SSRVoiceProfile importVoiceProfileAtPath:]
  -[SSRVoiceProfile addUtterances:spIdType:]
  -[SSRVoiceProfile getExplicitEnrollmentUtterancesForType:]
  -[SSRVoiceProfile getExplicitMarkedEnrollmentUtterancesForType:]
  -[SSRVoiceProfile getEnrollmentUtterancesForModelType:]
  -[SSRVoiceProfile getImplicitEnrollmentUtterancesPriorTo:forType:]
  -[SSRVoiceProfile getImplicitEnrollmentUtterancesForType:]
  -[SSRVoiceProfile profileLocallyAvailable]
  -[SSRVoiceProfile voiceProfileBasePath]
  -[SSRVoiceProfile voiceProfileImplicitCacheDirPath]
  -[SSRVoiceProfile voiceProfileAudioDirPathForSpidType:]
  -[SSRVoiceProfile voiceProfileModelDirForSpidType:recognizerType:]
  -[SSRVoiceProfile _voiceProfilePathForSpidType:]
  -[SSRVoiceProfile deleteModelForSpidType:recognizerType:]
  -[SSRVoiceProfile voiceProfileVersion]
  -[SSRVoiceProfile voiceProfileIdentity]
  -[SSRVoiceProfile markSATEnrollmentSuccess]
  -[SSRVoiceProfile markSATEnrollmentMigrated]
  -[SSRVoiceProfile isMarkedSATMigrated]
  -[SSRVoiceProfile isMarkedSATEnrolled]
  -[SSRVoiceProfile _isSATMarkedWithMarker:]
  -[SSRVoiceProfile _markSATEnrollmentWithMarker:]
  -[SSRVoiceProfile _getProfileVersionFilePath]
  -[SSRVoiceProfile _updateVoiceProfileVersionFile]
  -[SSRVoiceProfile pruningCookie]
  -[SSRVoiceProfile updatePruningCookie:]
  -[SSRVoiceProfile profileBasePath]
  -[SSRVoiceProfile setProfileBasePath:]
  -[SSRVoiceProfile profilePitch]
  -[SSRVoiceProfile setProfilePitch:]


SSRTriggerPhraseDetectorQuasar : NSObject
  // instance methods
  -[SSRTriggerPhraseDetectorQuasar endAudio]
  -[SSRTriggerPhraseDetectorQuasar reset]
  -[SSRTriggerPhraseDetectorQuasar .cxx_destruct]
  -[SSRTriggerPhraseDetectorQuasar analyzeWavData:numSamples:]
  -[SSRTriggerPhraseDetectorQuasar initWithLocale:configPath:resourcePath:]


SSRUtils : NSObject
  // class methods
  +[SSRUtils deviceCategoryForDeviceProductType:]
  +[SSRUtils deviceCategoryStringRepresentationForCategoryType:]
  +[SSRUtils streamAudioFromFileUrl:audioStreamBasicDescriptor:samplesPerStreamChunk:audioDataAvailableHandler:]
  +[SSRUtils stringForInvocationStyle:]
  +[SSRUtils stringForCSSpIdType:]
  +[SSRUtils explicitSpIdTypeForSpId:]
  +[SSRUtils spIdTypeForString:]
  +[SSRUtils stringForSpeakerRecognizerType:]
  +[SSRUtils stringForVoiceProfileRetrainerType:]
  +[SSRUtils satConfigFileNameForCSSpIdType:]
  +[SSRUtils psrConfigFileNameForCSSpIdType:]
  +[SSRUtils satConfigFileNameForCSSpIdType:forModelType:forAssetType:]
  +[SSRUtils spIdVoiceProfileImportRootDir]
  +[SSRUtils createDirectoryIfDoesNotExist:]
  +[SSRUtils ssrAudioLogsDir]
  +[SSRUtils ssrAudioLogsCountWithinPrivacyLimit]
  +[SSRUtils cleanupOrphanedVoiceIdGradingFiles]
  +[SSRUtils spidAudioTrainUtterancesDir]
  +[SSRUtils isSpeakerRecognitionSupportedInLocale:]
  +[SSRUtils readJsonFileAtPath:]
  +[SSRUtils getVoiceProfileProductCategoryFromVersionFilePath:]
  +[SSRUtils getVoiceProfileIdentityFromVersionFilePath:]
  +[SSRUtils isCurrentDeviceCompatibleWithNewerVoiceProfileAt:]
  +[SSRUtils isCurrentDeviceCompatibleWithVoiceProfileAt:]
  +[SSRUtils getImplicitUtteranceCacheDirectory]
  +[SSRUtils getNumberOfAudioFilesInDirectory:]
  +[SSRUtils dumpFilesInDirectory:]
  +[SSRUtils getContentsOfDirectory:]
  +[SSRUtils getHomeUserIdForVoiceProfile:withCompletion:]
  +[SSRUtils getVoiceProfilesForSiriProfileId:]
  +[SSRUtils getVoiceProfileForSiriProfileId:forLanguageCode:]
  +[SSRUtils logSpeakerRecognitionGradingMetadataAtFilepath:withScoreInfo:]
  +[SSRUtils segmentVoiceTriggerFromAudioFile:withVTEventInfo:withStorePayloadPortion:withCompletion:]
  +[SSRUtils getEnrollmentUtterancesFromDirectory:]
  +[SSRUtils getExplicitEnrollmentUtterancesFromDirectory:]
  +[SSRUtils getExplicitMarkedEnrollmentUtterancesFromDirectory:]
  +[SSRUtils getEnrollmentUtterancesCountFromDirectory:withCountBlock:]
  +[SSRUtils getImplicitEnrollmentUtterancesFromDirectory:]
  +[SSRUtils _getUtterancesFromDirectory:]
  +[SSRUtils removeItemAtPath:]
  +[SSRUtils moveContentsOfSrcDirectory:toDestDirectory:]
  +[SSRUtils encryptFileAt:andSaveTo:error:]
  +[SSRUtils combineScoreFromPSR:fromSAT:withCombinedWt:]
  +[SSRUtils markFileInTVasSUPurgeable:]
  +[SSRUtils markAllFilesInTVOfDirectoryAsSUPurgeable:]


SSRVoiceProfilePruner : NSObject <SSRSpeakerRecognitionControllerDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRVoiceProfilePruner _deleteUtterances:]
  -[SSRVoiceProfilePruner pruneVoiceProfile:forSpIdType:withAsset:]
  -[SSRVoiceProfilePruner _getScoresForAudio:withController:withDetector:forProfile:withCompletion:]
  -[SSRVoiceProfilePruner _retrainVoiceProfile:withAsset:]


SSRVoiceProfileRetrainingContext : NSObject
 @property  NSArray *compareVoiceProfileArray
 @property  SSRVoiceProfile *voiceProfile
 @property  unsigned long spIdType
 @property  NSURL *resourceFilePath
 @property  NSString *configVersion
 @property  BOOL filterToVoiceTriggerUtterances
 @property  BOOL forceRetrain
 @property  unsigned long maxAllowedSpeakerVectors
 @property  NSDictionary *modelsContext
 @property  float combinationWeight
 @property  CSAsset *asset
 @property  SSRLoggingAggregator *logAggregator
 @property  NSString *sessionId

  // instance methods
  -[SSRVoiceProfileRetrainingContext sessionId]
  -[SSRVoiceProfileRetrainingContext configVersion]
  -[SSRVoiceProfileRetrainingContext setAsset:]
  -[SSRVoiceProfileRetrainingContext .cxx_destruct]
  -[SSRVoiceProfileRetrainingContext asset]
  -[SSRVoiceProfileRetrainingContext initWithVoiceRetrainingContext:error:]
  -[SSRVoiceProfileRetrainingContext resourceFilePath]
  -[SSRVoiceProfileRetrainingContext voiceProfile]
  -[SSRVoiceProfileRetrainingContext setVoiceProfile:]
  -[SSRVoiceProfileRetrainingContext spIdType]
  -[SSRVoiceProfileRetrainingContext compareVoiceProfileArray]
  -[SSRVoiceProfileRetrainingContext setCompareVoiceProfileArray:]
  -[SSRVoiceProfileRetrainingContext filterToVoiceTriggerUtterances]
  -[SSRVoiceProfileRetrainingContext forceRetrain]
  -[SSRVoiceProfileRetrainingContext maxAllowedSpeakerVectors]
  -[SSRVoiceProfileRetrainingContext modelsContext]
  -[SSRVoiceProfileRetrainingContext combinationWeight]
  -[SSRVoiceProfileRetrainingContext logAggregator]
  -[SSRVoiceProfileRetrainingContext setLogAggregator:]


SSRVoiceProfileModelContext : NSObject
 @property  NSURL *configFilePath
 @property  NSURL *voiceProfileModelFilePath
 @property  NSDictionary *compareModelFilePaths

  // instance methods
  -[SSRVoiceProfileModelContext .cxx_destruct]
  -[SSRVoiceProfileModelContext configFilePath]
  -[SSRVoiceProfileModelContext initWithConfigFilePath:withModelPath:withCompareModelFilePaths:]
  -[SSRVoiceProfileModelContext voiceProfileModelFilePath]
  -[SSRVoiceProfileModelContext compareModelFilePaths]


SSRVoiceProfileMetadataManager : NSObject
  // class methods
  +[SSRVoiceProfileMetadataManager _getBaseMetaDictionaryForUtterancePath:]
  +[SSRVoiceProfileMetadataManager _writeMetaDict:forUtterancePath:]
  +[SSRVoiceProfileMetadataManager isUtteranceImplicitlyTrained:]
  +[SSRVoiceProfileMetadataManager recordedTimeStampOfFile:]
  +[SSRVoiceProfileMetadataManager saveUtteranceMetadataForUtterance:enrollmentType:isHandheldEnrollment:triggerSource:audioInput:otherBiometricResult:containsPayload:]
  +[SSRVoiceProfileMetadataManager getUtteranceEnrollmentType:]
  +[SSRVoiceProfileMetadataManager recordedTimeStampFromFileName:]


CSVTUIRegularExpressionMatcher : NSObject
  // class methods
  +[CSVTUIRegularExpressionMatcher matchWithString:TrailingStr:LeadingStr:Pattern:]


CSVTUITrainingSessionWithPayload : CSVTUITrainingSession <SFSpeechRecognitionTaskDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndPointDelegate>
 @property  NSDictionary *voiceTriggerEventInfo
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUITrainingSessionWithPayload .cxx_destruct]
  -[CSVTUITrainingSessionWithPayload speechRecognitionTask:didHypothesizeTranscription:]
  -[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishRecognition:]
  -[CSVTUITrainingSessionWithPayload speechRecognitionTask:didFinishSuccessfully:]
  -[CSVTUITrainingSessionWithPayload voiceTriggerEventInfo]
  -[CSVTUITrainingSessionWithPayload setVoiceTriggerEventInfo:]
  -[CSVTUITrainingSessionWithPayload audioSessionDidStartRecording:error:]
  -[CSVTUITrainingSessionWithPayload audioSessionDidStopRecording:]
  -[CSVTUITrainingSessionWithPayload audioSessionRecordBufferAvailable:]
  -[CSVTUITrainingSessionWithPayload audioSessionErrorDidOccur:]
  -[CSVTUITrainingSessionWithPayload audioSessionUnsupportedAudioRoute]
  -[CSVTUITrainingSessionWithPayload didDetectBeginOfSpeech]
  -[CSVTUITrainingSessionWithPayload didDetectEndOfSpeech:]
  -[CSVTUITrainingSessionWithPayload startTraining]
  -[CSVTUITrainingSessionWithPayload shouldHandleSession]
  -[CSVTUITrainingSessionWithPayload shouldMatchPayload]
  -[CSVTUITrainingSessionWithPayload _registerVoiceTriggerTimeout]
  -[CSVTUITrainingSessionWithPayload _firedVoiceTriggerTimeout]
  -[CSVTUITrainingSessionWithPayload _registerForceEndPointTimeout]
  -[CSVTUITrainingSessionWithPayload _registerEndPointTimeout]
  -[CSVTUITrainingSessionWithPayload _firedEndPointTimeout]
  -[CSVTUITrainingSessionWithPayload _reportStopListening]
  -[CSVTUITrainingSessionWithPayload handleAudioInput:]
  -[CSVTUITrainingSessionWithPayload closeSessionWithStatus:successfully:]
  -[CSVTUITrainingSessionWithPayload matchRecognitionResult:withMatchedBlock:withNonMatchedBlock:]


CSVTUITrainingSession : NSObject <SFSpeechRecognitionTaskDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndPointDelegate>
 @property  NSDictionary *voiceTriggerEventInfo
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[CSVTUITrainingSession .cxx_destruct]
  -[CSVTUITrainingSession speechRecognitionTask:didHypothesizeTranscription:]
  -[CSVTUITrainingSession voiceTriggerEventInfo]
  -[CSVTUITrainingSession setVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession audioSessionDidStartRecording:error:]
  -[CSVTUITrainingSession audioSessionDidStopRecording:]
  -[CSVTUITrainingSession audioSessionRecordBufferAvailable:]
  -[CSVTUITrainingSession audioSessionErrorDidOccur:]
  -[CSVTUITrainingSession audioSessionUnsupportedAudioRoute]
  -[CSVTUITrainingSession didDetectBeginOfSpeech]
  -[CSVTUITrainingSession didDetectEndOfSpeech:]
  -[CSVTUITrainingSession startTraining]
  -[CSVTUITrainingSession _registerEndPointTimeout]
  -[CSVTUITrainingSession handleAudioInput:]
  -[CSVTUITrainingSession closeSessionWithStatus:successfully:]
  -[CSVTUITrainingSession handleMasterTimeout:]
  -[CSVTUITrainingSession initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:zeroCounter:completion:]
  -[CSVTUITrainingSession initWithUtteranceId:sessionNumber:Locale:audioSession:keywordDetector:speechRecognizer:speechRecognitionRequest:sessionDelegate:sessionDispatchQueue:mhUUID:zeroCounter:completionWithResult:]
  -[CSVTUITrainingSession resultAlreadyReported]
  -[CSVTUITrainingSession closeSessionWithCompletion:]
  -[CSVTUITrainingSession closeSessionWithStatus:successfully:complete:]
  -[CSVTUITrainingSession closeSessionWithStatus:successfully:voiceTriggerEventInfo:completeWithResult:]
  -[CSVTUITrainingSession suspendTraining]
  -[CSVTUITrainingSession resumeTraining]
  -[CSVTUITrainingSession setupPhraseSpotter]
  -[CSVTUITrainingSession requestTriggeredUtterance:]
  -[CSVTUITrainingSession updateMeterAndForward]
  -[CSVTUITrainingSession handleAudioBufferForVTWithAudioInput:withDetectedBlock:]
  -[CSVTUITrainingSession feedSpeechRecognitionTrailingSamplesWithCompletedBlock:]
  -[CSVTUITrainingSession feedSpeechRecognitionWithPCMBuffer]
  -[CSVTUITrainingSession trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession computeRequiredTrailingSamples]
  -[CSVTUITrainingSession pushAudioInputIntoPCMBuffer:]
  -[CSVTUITrainingSession createAVAudioPCMBufferWithNSData:]
  -[CSVTUITrainingSession numSamplesInPCMBuffer]
  -[CSVTUITrainingSession logTrainingSessionCompleteWithVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession createDigitalZeroReporterWithVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession getTrainingAudioStatusWithVTEI:digitalZeroReporter:]
  -[CSVTUITrainingSession setupSpeechRecognitionTaskWithVoiceTriggerEventInfo:]
  -[CSVTUITrainingSession finishSpeechRecognitionTask]
  -[CSVTUITrainingSession startMasterTimerWithTimeout:]
  -[CSVTUITrainingSession stopMasterTimer]


SSRVoiceProfileManager : NSObject
 @property  unsigned long currentDeviceCategory
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSUUID *endpointUUID
 @property  SSRRemoteControlClient *remoteControlClient

  // class methods
  +[SSRVoiceProfileManager sharedInstance]
  +[SSRVoiceProfileManager sharedInstanceWithEndpointId:]

  // instance methods
  -[SSRVoiceProfileManager getUserVoiceProfileUploadPathWithEnrolledLanguageList:]
  -[SSRVoiceProfileManager _CSSATCachePath]
  -[SSRVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryForProfileId:forDeviceCategory:forVoiceProfileVersion:]
  -[SSRVoiceProfileManager discardSiriEnrollmentForProfileId:forLanguageCode:]
  -[SSRVoiceProfileManager notifyUserVoiceProfileUploadComplete]
  -[SSRVoiceProfileManager baseDir]
  -[SSRVoiceProfileManager voiceProfileForId:]
  -[SSRVoiceProfileManager notifyUserVoiceProfileDownloadReadyForUser:getData:completion:]
  -[SSRVoiceProfileManager getCacheDirectoryForAppDomain:]
  -[SSRVoiceProfileManager _CSSATUploadPathForSiriProfileId:]
  -[SSRVoiceProfileManager _isLegacyEnrollmentMarkedWith:forLanguageCode:]
  -[SSRVoiceProfileManager markSATEnrollmentSuccessForVoiceProfile:]
  -[SSRVoiceProfileManager triggerRetrainingVoiceProfile:withContext:withCompletion:]
  -[SSRVoiceProfileManager notifyImplicitTrainingUtteranceAvailable:forVoiceProfileId:withRecordDeviceInfo:withRecordCtxt:withVoiceTriggerCtxt:withOtherCtxt:assetToUse:withCompletion:]
  -[SSRVoiceProfileManager SSRBasePathForAppDomain:]
  -[SSRVoiceProfileManager isVoiceProfileUploadedToiCloudForLanguageCode:withCompletionBlock:]
  -[SSRVoiceProfileManager cleanupVoiceProfileModelFilesForLocale:]
  -[SSRVoiceProfileManager _checkIfDownloadRequiredForProfileId:]
  -[SSRVoiceProfileManager uploadUserVoiceProfileForSiriProfileId:withUploadTrigger:completion:]
  -[SSRVoiceProfileManager _isRemoteVoiceTriggerAvailable]
  -[SSRVoiceProfileManager enableVoiceTriggerUponVoiceProfileSyncForLanguage:]
  -[SSRVoiceProfileManager setRemoteControlClient:]
  -[SSRVoiceProfileManager provisionedVoiceProfilesForAppDomain:withLocale:]
  -[SSRVoiceProfileManager importVoiceProfile:appDomain:withSharedUserId:withLocale:withAsset:withCompletion:]
  -[SSRVoiceProfileManager pruneImplicitUtterancesOfProfile:withAsset:]
  -[SSRVoiceProfileManager initWithEndpointId:]
  -[SSRVoiceProfileManager getVoiceProfileAnalyticsForAppDomain:withLocale:]
  -[SSRVoiceProfileManager triggerVoiceProfileMigrationWithCompletion:]
  -[SSRVoiceProfileManager _copyExplicitEnrollmentFilesFromPath:toPath:withCompletion:]
  -[SSRVoiceProfileManager _getVoiceProfilePathsToBeUploadedForSiriProfileId:]
  -[SSRVoiceProfileManager .cxx_destruct]
  -[SSRVoiceProfileManager modelDirectoryPathForProfile:]
  -[SSRVoiceProfileManager getCachedVoiceProfileAvailabilityMetaBlob]
  -[SSRVoiceProfileManager triggerVoiceProfileCleanupWithCompletion:]
  -[SSRVoiceProfileManager _downloadAndEnrollVoiceProfileForProfileId:withDownloadTriggerBlock:]
  -[SSRVoiceProfileManager _markVoiceProfileTrainingSyncForLanguage:]
  -[SSRVoiceProfileManager triggerVoiceProfileDownload]
  -[SSRVoiceProfileManager newVoiceProfileWithLocale:withAppDomain:]
  -[SSRVoiceProfileManager deleteUserVoiceProfile:]
  -[SSRVoiceProfileManager isImplicitTrainingRequiredForVoiceProfileId:locale:completion:]
  -[SSRVoiceProfileManager _enableVoiceTriggerIfLanguageMatches:]
  -[SSRVoiceProfileManager _getVoiceProfilesForSiriProfileId:withLanguageCode:]
  -[SSRVoiceProfileManager deleteAllVoiceProfilesForAppDomain:]
  -[SSRVoiceProfileManager isSATEnrollmentMigratedForSiriProfileId:forLanguageCode:]
  -[SSRVoiceProfileManager isSpeakerRecognitionAvailable]
  -[SSRVoiceProfileManager setEndpointUUID:]
  -[SSRVoiceProfileManager _isDirectory:]
  -[SSRVoiceProfileManager setQueue:]
  -[SSRVoiceProfileManager provisionedVoiceProfilesForLocale:]
  -[SSRVoiceProfileManager isSATEnrolledForSiriProfileId:forLanguageCode:]
  -[SSRVoiceProfileManager SSRSpeakerProfilesBasePath]
  -[SSRVoiceProfileManager remoteControlClient]
  -[SSRVoiceProfileManager notifyUserVoiceProfileUpdateReady]
  -[SSRVoiceProfileManager updateVoiceProfile:withUserName:]
  -[SSRVoiceProfileManager getSATEnrollmentPath]
  -[SSRVoiceProfileManager queue]
  -[SSRVoiceProfileManager getUserVoiceProfileUpdateDirectory]
  -[SSRVoiceProfileManager _copyVoiceProfileAtPath:toPath:]
  -[SSRVoiceProfileManager setCurrentDeviceCategory:]
  -[SSRVoiceProfileManager notifyUserVoiceProfileUploadCompleteForSiriProfileId:withError:]
  -[SSRVoiceProfileManager _CSSATCachePathForAppDomain:]
  -[SSRVoiceProfileManager devicesWithVoiceProfileIniCloudForLanguage:]
  -[SSRVoiceProfileManager endpointUUID]
  -[SSRVoiceProfileManager discardSiriEnrollmentForLanguageCode:]
  -[SSRVoiceProfileManager currentDeviceCategory]
  -[SSRVoiceProfileManager _prepareVoiceProfileWithSiriProfileId:withUploadBlock:]
  -[SSRVoiceProfileManager addUtterances:toProfile:withContext:withCompletion:]
  -[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:withBackupMetaBlob:]
  -[SSRVoiceProfileManager _enrollVoiceProfileForSiriProfileId:fromCacheDirectoryPath:withCategoryType:]
  -[SSRVoiceProfileManager init]
  -[SSRVoiceProfileManager _isMarkedForVoiceProfileTrainingSyncForLanguage:]
  -[SSRVoiceProfileManager _downloadVoiceProfileForProfileId:forDeviceCategory:withDownloadTriggerBlock:withCompletion:]
  -[SSRVoiceProfileManager triggerVoiceProfileDuplicatesCleanup]
  -[SSRVoiceProfileManager hasVoiceProfileIniCloudForLanguageCode:]
  -[SSRVoiceProfileManager _CSSATLegacyUploadPath]
  -[SSRVoiceProfileManager _CSSATDownloadPath]
  -[SSRVoiceProfileManager _getUserVoiceProfileDownloadCacheDirectoryWithUpdatePath:]


CSVTUIAudioRecorderRemoteDeviceContext : NSObject
 @property  unsigned long remoteTrainingDeviceType
 @property  NSArray *remoteTrainingDeviceUUIDList

  // instance methods
  -[CSVTUIAudioRecorderRemoteDeviceContext .cxx_destruct]
  -[CSVTUIAudioRecorderRemoteDeviceContext initWithRemoteTrainingDeviceType:remoteTrainingDeviceUUIDList:]
  -[CSVTUIAudioRecorderRemoteDeviceContext remoteTrainingDeviceType]
  -[CSVTUIAudioRecorderRemoteDeviceContext remoteTrainingDeviceUUIDList]


CSVTUIAudioRecorder : NSObject <AVVoiceControllerRecordDelegate, CSAudioServerCrashEventProviding, CSAudioSessionEventProviding>
 @property  NSObject<OS_dispatch_queue> *queue
 @property  NSObject<OS_dispatch_queue> *voiceControllerCreationQueue
 @property  NSHashTable *observers
 @property  CSVTUIAudioRecorderRemoteDeviceContext *remoteDeviceContext
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[CSVTUIAudioRecorder _convertDeactivateOption:]

  // instance methods
  -[CSVTUIAudioRecorder unregisterObserver:]
  -[CSVTUIAudioRecorder playbackRoute]
  -[CSVTUIAudioRecorder dealloc]
  -[CSVTUIAudioRecorder .cxx_destruct]
  -[CSVTUIAudioRecorder registerObserver:]
  -[CSVTUIAudioRecorder setObservers:]
  -[CSVTUIAudioRecorder setQueue:]
  -[CSVTUIAudioRecorder queue]
  -[CSVTUIAudioRecorder deactivateAudioSession:error:]
  -[CSVTUIAudioRecorder observers]
  -[CSVTUIAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
  -[CSVTUIAudioRecorder voiceControllerBeginRecordInterruption:]
  -[CSVTUIAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
  -[CSVTUIAudioRecorder voiceControllerEndRecordInterruption:]
  -[CSVTUIAudioRecorder voiceControllerMediaServicesWereLost:]
  -[CSVTUIAudioRecorder voiceControllerMediaServicesWereReset:]
  -[CSVTUIAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
  -[CSVTUIAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
  -[CSVTUIAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
  -[CSVTUIAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
  -[CSVTUIAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
  -[CSVTUIAudioRecorder setContext:error:]
  -[CSVTUIAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
  -[CSVTUIAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
  -[CSVTUIAudioRecorder initWithQueue:error:]
  -[CSVTUIAudioRecorder _destroyVoiceController]
  -[CSVTUIAudioRecorder _voiceControllerWithError:]
  -[CSVTUIAudioRecorder _shouldUseRemoteBuiltInMic:]
  -[CSVTUIAudioRecorder _processAudioChain:audioStreamHandleId:remoteVAD:atTime:arrivalTimestampToAudioRecorder:numberOfChannels:]
  -[CSVTUIAudioRecorder _processAudioBuffer:audioStreamHandleId:arrivalTimestampToAudioRecorder:]
  -[CSVTUIAudioRecorder _audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:]
  -[CSVTUIAudioRecorder _audioRecorderDidStopRecordingForReason:streamHandleID:]
  -[CSVTUIAudioRecorder voiceControllerCreationQueue]
  -[CSVTUIAudioRecorder setVoiceControllerCreationQueue:]
  -[CSVTUIAudioRecorder updateAudioRecorderForTrainingDevice:deviceUUIDs:]
  -[CSVTUIAudioRecorder prepareAudioStreamRecordWithStreamHandleId:error:]
  -[CSVTUIAudioRecorder startAudioStreamWithStreamHandleId:error:]
  -[CSVTUIAudioRecorder stopAudioStreamWithStreamHandleId:error:]
  -[CSVTUIAudioRecorder isRecordingWithStreamHandleId:]
  -[CSVTUIAudioRecorder recordRouteWithStreamHandleId:]
  -[CSVTUIAudioRecorder _getRecordSettingsWithRequest]
  -[CSVTUIAudioRecorder remoteDeviceContext]
  -[CSVTUIAudioRecorder setRemoteDeviceContext:]


SSRAssetManager : NSObject
 @property  NSArray *assetProviders
 @property  NSString *currentLanguageCode
 @property  NSObject<OS_dispatch_queue> *queue
 @property  <SSRAssetManagerDelegate> *delegate

  // class methods
  +[SSRAssetManager sharedManager]

  // instance methods
  -[SSRAssetManager setDelegate:]
  -[SSRAssetManager delegate]
  -[SSRAssetManager .cxx_destruct]
  -[SSRAssetManager setQueue:]
  -[SSRAssetManager currentLanguageCode]
  -[SSRAssetManager queue]
  -[SSRAssetManager init]
  -[SSRAssetManager setCurrentLanguageCode:]
  -[SSRAssetManager allInstalledAssetsOfType:forLanguage:]
  -[SSRAssetManager installedAssetOfType:forLanguage:]
  -[SSRAssetManager _convertVersionStringToFloat:]
  -[SSRAssetManager _latestVersionedAssetOfType:fromProviders:forLocale:]
  -[SSRAssetManager assetProviders]
  -[SSRAssetManager setAssetProviders:]


SSRSpeakerRecognitionController : NSObject <SSRSpeakerRecognitionOrchestratorDelegate>
 @property  SSRSpeakerRecognitionContext *context
 @property  <SSRSpeakerRecognitionControllerDelegate> *delegate
 @property  SSRSpeakerRecognitionOrchestrator *orchestrator
 @property  NSDictionary *lastScoreCard
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRSpeakerRecognitionController endAudio]
  -[SSRSpeakerRecognitionController setDelegate:]
  -[SSRSpeakerRecognitionController delegate]
  -[SSRSpeakerRecognitionController .cxx_destruct]
  -[SSRSpeakerRecognitionController setContext:]
  -[SSRSpeakerRecognitionController context]
  -[SSRSpeakerRecognitionController processAudio:withNumberOfSamples:]
  -[SSRSpeakerRecognitionController initWithContext:withDelegate:error:]
  -[SSRSpeakerRecognitionController getLatestSpeakerInfo]
  -[SSRSpeakerRecognitionController resetWithContext:]
  -[SSRSpeakerRecognitionController lastScoreCard]
  -[SSRSpeakerRecognitionController voiceRecognitionOrchestrator:hasVoiceRecognitionInfo:]
  -[SSRSpeakerRecognitionController voiceRecognitionOrchestratorFinishedProcessing:withFinalVoiceRecognitionInfo:]
  -[SSRSpeakerRecognitionController orchestrator]
  -[SSRSpeakerRecognitionController setOrchestrator:]
  -[SSRSpeakerRecognitionController setLastScoreCard:]


SSRMobileAssetProvider : NSObject <SSRAssetProviding>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRMobileAssetProvider _findLatestInstalledAsset:]
  -[SSRMobileAssetProvider getAssetProviderType]
  -[SSRMobileAssetProvider installedAssetOfType:forLanguageCode:]
  -[SSRMobileAssetProvider allInstalledAssetsOfType:forLanguage:]
  -[SSRMobileAssetProvider _getVoiceTriggerAssetTypeString]
  -[SSRMobileAssetProvider _getVoiceTriggerAssetCurrentCompatibilityVersion]
  -[SSRMobileAssetProvider _getSSRAssetCurrentCompatibilityVersion]
  -[SSRMobileAssetProvider _getSSRAssetTypeString]
  -[SSRMobileAssetProvider _getEndpointAssetTypeString]
  -[SSRMobileAssetProvider _getEndpointAssetCurrentCompatibilityVersion]
  -[SSRMobileAssetProvider _buildAssetQueryForAssetType:]
  -[SSRMobileAssetProvider _installedMobileAssetOfType:forLanguage:]
  -[SSRMobileAssetProvider _filteredAssets:forLanguage:]


SSRVoiceProfileStore : NSObject
 @property  NSMutableArray *voiceProfileArray
 @property  NSObject<OS_dispatch_queue> *queue
 @property  SSRVoiceProfileStorePrefs *storePrefs

  // class methods
  +[SSRVoiceProfileStore sharedInstance]

  // instance methods
  -[SSRVoiceProfileStore cleanupVoiceProfileModelFilesForLocale:]
  -[SSRVoiceProfileStore .cxx_destruct]
  -[SSRVoiceProfileStore deleteUserVoiceProfile:]
  -[SSRVoiceProfileStore setQueue:]
  -[SSRVoiceProfileStore updateVoiceProfile:withUserName:]
  -[SSRVoiceProfileStore queue]
  -[SSRVoiceProfileStore initStore]
  -[SSRVoiceProfileStore userVoiceProfilesForAppDomain:]
  -[SSRVoiceProfileStore userVoiceProfilesForAppDomain:forLocale:]
  -[SSRVoiceProfileStore userVoiceProfilesForLocale:]
  -[SSRVoiceProfileStore userVoiceProfileForVoiceProfileID:]
  -[SSRVoiceProfileStore migrateVoiceProfilesIfNeededWithCompletionBlock:]
  -[SSRVoiceProfileStore cleanupDuplicatedProfiles]
  -[SSRVoiceProfileStore cleanupVoiceProfileStore:]
  -[SSRVoiceProfileStore _synchronizeSiriVoiceProfilesWithAssistant]
  -[SSRVoiceProfileStore isImplicitTrainingRequiredToVoiceProfile:withAsset:completion:]
  -[SSRVoiceProfileStore addImplicitUtterance:toVoiceProfile:withAsset:withTriggerSource:withAudioInput:withCompletion:]
  -[SSRVoiceProfileStore logVoiceProfileConfusionWithCleanup:]
  -[SSRVoiceProfileStore _logVoiceProfileConfusionWithCleanup:]
  -[SSRVoiceProfileStore evaluateImplicitAdditionPolicyWithScores:forProfile:withImplicitThreshold:withDeltaThreshold:]
  -[SSRVoiceProfileStore _getTopScoringProfileIdFromScores:]
  -[SSRVoiceProfileStore addUserVoiceProfile:withContext:withCompletion:]
  -[SSRVoiceProfileStore _deleteUserVoiceProfile:]
  -[SSRVoiceProfileStore checkIfVoiceProfile:needsUpdatedWith:withCategory:]
  -[SSRVoiceProfileStore _checkIfRetrainingRequiredForProfile:]
  -[SSRVoiceProfileStore retrainVoiceProfile:withContext:withCompletion:]
  -[SSRVoiceProfileStore _loadVoiceProfiles]
  -[SSRVoiceProfileStore _enrolledVoiceProfiles]
  -[SSRVoiceProfileStore _updateTrainedUsersWithAction:UserVoiceProfile:]
  -[SSRVoiceProfileStore _saveTrainedUsers:]
  -[SSRVoiceProfileStore _retrainLiveOnOnboardedProfilesForLanguage:withForceRetrain:withCompletion:]
  -[SSRVoiceProfileStore _retrainVoiceProfile:withContext:]
  -[SSRVoiceProfileStore _retrainVoiceProfile:withContext:withUtterances:]
  -[SSRVoiceProfileStore copyAudioFiles:toProfile:forModelType:]
  -[SSRVoiceProfileStore voiceProfileArray]
  -[SSRVoiceProfileStore setVoiceProfileArray:]
  -[SSRVoiceProfileStore storePrefs]
  -[SSRVoiceProfileStore setStorePrefs:]


SSRBiometricMatch : NSObject <BKDeviceDelegate>
 @property  BKDevice *biometricDevice
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[SSRBiometricMatch sharedInstance]

  // instance methods
  -[SSRBiometricMatch .cxx_destruct]
  -[SSRBiometricMatch init]
  -[SSRBiometricMatch biometricDevice]
  -[SSRBiometricMatch setBiometricDevice:]
  -[SSRBiometricMatch getLastBiometricMatchForVoiceTriggerTimeStamp:]
  -[SSRBiometricMatch _getLastBiometricMatchEvent:atTime:]


SSRSpeakerAnalyzerSAT : NSObject
 @property  <SSRSpeakerAnalyzerSATDelegate> *delegate
 @property  NSURL *configFilePath
 @property  NSURL *resourceFilePath
 @property  SSRSpeakerRecognitionContext *context
 @property  NSDictionary *voiceProfilesModelFilePaths
 @property  NSDictionary *voiceProfilesExpModelFilePaths
 @property  NSArray *satScorers
 @property  NSDictionary *scoreCard
 @property  NSObject<OS_dispatch_queue> *queue

  // instance methods
  -[SSRSpeakerAnalyzerSAT endAudio]
  -[SSRSpeakerAnalyzerSAT setDelegate:]
  -[SSRSpeakerAnalyzerSAT delegate]
  -[SSRSpeakerAnalyzerSAT dealloc]
  -[SSRSpeakerAnalyzerSAT .cxx_destruct]
  -[SSRSpeakerAnalyzerSAT setQueue:]
  -[SSRSpeakerAnalyzerSAT setContext:]
  -[SSRSpeakerAnalyzerSAT queue]
  -[SSRSpeakerAnalyzerSAT context]
  -[SSRSpeakerAnalyzerSAT resetForNewRequest]
  -[SSRSpeakerAnalyzerSAT configFilePath]
  -[SSRSpeakerAnalyzerSAT setConfigFilePath:]
  -[SSRSpeakerAnalyzerSAT processAudioData:numSamples:]
  -[SSRSpeakerAnalyzerSAT initWithVoiceRecognitionContext:delegate:queue:]
  -[SSRSpeakerAnalyzerSAT getVoiceRecognizerResults]
  -[SSRSpeakerAnalyzerSAT resourceFilePath]
  -[SSRSpeakerAnalyzerSAT setResourceFilePath:]
  -[SSRSpeakerAnalyzerSAT voiceProfilesModelFilePaths]
  -[SSRSpeakerAnalyzerSAT setVoiceProfilesModelFilePaths:]
  -[SSRSpeakerAnalyzerSAT voiceProfilesExpModelFilePaths]
  -[SSRSpeakerAnalyzerSAT setVoiceProfilesExpModelFilePaths:]
  -[SSRSpeakerAnalyzerSAT _updateScoreCardForFinalResult:]
  -[SSRSpeakerAnalyzerSAT _getAnalyzedResult]
  -[SSRSpeakerAnalyzerSAT _getSuperVectorWithEndPoint:]
  -[SSRSpeakerAnalyzerSAT _processSuperVector:withSize:processedAudioDurationMs:isFinal:]
  -[SSRSpeakerAnalyzerSAT satScorers]
  -[SSRSpeakerAnalyzerSAT setSatScorers:]
  -[SSRSpeakerAnalyzerSAT scoreCard]
  -[SSRSpeakerAnalyzerSAT setScoreCard:]


SSREnrollmentDataManager : NSObject
  // class methods
  +[SSREnrollmentDataManager _getBaseMetaDictionaryForUtterancePath:]
  +[SSREnrollmentDataManager saveRawUtteranceAndMetadata:to:isExplicitEnrollment:]
  +[SSREnrollmentDataManager saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:]
  +[SSREnrollmentDataManager saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:]
  +[SSREnrollmentDataManager saveMetadata:isExplicitEnrollment:]
  +[SSREnrollmentDataManager writeMetaDict:atMetaPath:]


SSRVoiceProfileStorePrefs : NSObject
  // class methods
  +[SSRVoiceProfileStorePrefs sharedStorePrefs]

  // instance methods
  -[SSRVoiceProfileStorePrefs saveKnownUserVoiceProfiles:]
  -[SSRVoiceProfileStorePrefs setVoiceProfileStoreVersion:]
  -[SSRVoiceProfileStorePrefs loadKnownUserVoiceProfiles]
  -[SSRVoiceProfileStorePrefs getVoiceProfileStoreVersion]


SSRSpeakerRecognitionContext : NSObject
 @property  NSArray *voiceProfileArray
 @property  unsigned long spIdType
 @property  CSAsset *asset
 @property  NSString *locale
 @property  NSUUID *endpointUUID
 @property  unsigned long activeChannel
 @property  unsigned long scoreType
 @property  unsigned long recognitionStyle
 @property  float combinationWeight
 @property  NSDictionary *vtEventInfo
 @property  NSString *configVersion
 @property  NSURL *resourceFilePath
 @property  NSURL *vadResourcePath
 @property  NSDictionary *modelsContext
 @property  NSDictionary *expModelsContext
 @property  NSDictionary *numEnrollmentUtterances
 @property  unsigned long maxAllowedAudioSamples
 @property  BOOL osTransactionReqd
 @property  NSString *debugUtteranceAudioFile
 @property  NSString *debugUtteranceMetaFile
 @property  SSRLoggingAggregator *logAggregator
 @property  NSString *sessionId

  // instance methods
  -[SSRSpeakerRecognitionContext activeChannel]
  -[SSRSpeakerRecognitionContext sessionId]
  -[SSRSpeakerRecognitionContext dealloc]
  -[SSRSpeakerRecognitionContext configVersion]
  -[SSRSpeakerRecognitionContext setAsset:]
  -[SSRSpeakerRecognitionContext .cxx_destruct]
  -[SSRSpeakerRecognitionContext asset]
  -[SSRSpeakerRecognitionContext locale]
  -[SSRSpeakerRecognitionContext setEndpointUUID:]
  -[SSRSpeakerRecognitionContext setLocale:]
  -[SSRSpeakerRecognitionContext endpointUUID]
  -[SSRSpeakerRecognitionContext initWithVoiceRecognitionContext:error:]
  -[SSRSpeakerRecognitionContext scoreType]
  -[SSRSpeakerRecognitionContext resourceFilePath]
  -[SSRSpeakerRecognitionContext spIdType]
  -[SSRSpeakerRecognitionContext setSpIdType:]
  -[SSRSpeakerRecognitionContext modelsContext]
  -[SSRSpeakerRecognitionContext combinationWeight]
  -[SSRSpeakerRecognitionContext logAggregator]
  -[SSRSpeakerRecognitionContext setLogAggregator:]
  -[SSRSpeakerRecognitionContext voiceProfileArray]
  -[SSRSpeakerRecognitionContext setVoiceProfileArray:]
  -[SSRSpeakerRecognitionContext composeModelContextsForProfiles:forSpIdType:forAsset:completion:]
  -[SSRSpeakerRecognitionContext _checkIfModelsPresentForProfiles:forSpIdType:forAsset:]
  -[SSRSpeakerRecognitionContext pickAssetForProfiles:forSpIdType:]
  -[SSRSpeakerRecognitionContext pickAssetForProfiles:forSpIdType:withAssetArray:]
  -[SSRSpeakerRecognitionContext numEnrollmentUtterances]
  -[SSRSpeakerRecognitionContext recognitionStyle]
  -[SSRSpeakerRecognitionContext vtEventInfo]
  -[SSRSpeakerRecognitionContext vadResourcePath]
  -[SSRSpeakerRecognitionContext expModelsContext]
  -[SSRSpeakerRecognitionContext maxAllowedAudioSamples]
  -[SSRSpeakerRecognitionContext osTransactionReqd]
  -[SSRSpeakerRecognitionContext debugUtteranceAudioFile]
  -[SSRSpeakerRecognitionContext debugUtteranceMetaFile]


SSRSpeakerRecognitionModelContext : NSObject
 @property  NSURL *configFilePath
 @property  NSDictionary *voiceProfilesModelFilePaths

  // instance methods
  -[SSRSpeakerRecognitionModelContext .cxx_destruct]
  -[SSRSpeakerRecognitionModelContext configFilePath]
  -[SSRSpeakerRecognitionModelContext voiceProfilesModelFilePaths]
  -[SSRSpeakerRecognitionModelContext initWithConfigFilePath:withModelFilePaths:]


CSVTUIASRGrammars : NSObject <NSURLSessionDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[CSVTUIASRGrammars sharedGrammars]

  // instance methods
  -[CSVTUIASRGrammars .cxx_destruct]
  -[CSVTUIASRGrammars init]
  -[CSVTUIASRGrammars createGrammars]
  -[CSVTUIASRGrammars getTrailingPatternsForUtt:Locale:]
  -[CSVTUIASRGrammars _getTrailingPatternsWithGrammars:withLocale:]
  -[CSVTUIASRGrammars getLeadingPatternsForUtt:Locale:]
  -[CSVTUIASRGrammars _getLeadingPatternsWithGrammars:withLocale:]
  -[CSVTUIASRGrammars getRegexPatternsForUtt:Locale:]
  -[CSVTUIASRGrammars _getRegexPatternsWithGrammars:withUtt:withLocale:]
  -[CSVTUIASRGrammars getLMEforLocale:]
  -[CSVTUIASRGrammars _getLMEWithGrammar:withLocale:]


SSRPitchExtractor : NSObject <EARAudioResultsGeneratorDelegate>
 @property  EARAudioResultsGenerator *resultsGenerator
 @property  NSObject<OS_dispatch_queue> *queue
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[SSRPitchExtractor initWithAsset:]
  -[SSRPitchExtractor .cxx_destruct]
  -[SSRPitchExtractor setQueue:]
  -[SSRPitchExtractor queue]
  -[SSRPitchExtractor _processAudioFileURL:]
  -[SSRPitchExtractor getPitchForUtteranceAudioFiles:]
  -[SSRPitchExtractor _getVoicingWeightedPitchForResultMatrix:]
  -[SSRPitchExtractor _getVoicingProbFromRawData:]
  -[SSRPitchExtractor _getPitchHzFromRawData:]
  -[SSRPitchExtractor resultsGenerator]
  -[SSRPitchExtractor setResultsGenerator:]


SSRAESKeyManager : NSObject
  // class methods
  +[SSRAESKeyManager getVoiceTriggerProfilesAESKey]
  +[SSRAESKeyManager generateIfNecessaryVoiceTriggerProfilesAESKey]
  +[SSRAESKeyManager generateIfNecessaryAESKeyWithKeySizeInBits:applicationTag:keyLabel:shouldGenerateIfNecessary:]
  +[SSRAESKeyManager generateAESKeyWithKeySizeInBits:]
  +[SSRAESKeyManager storeAESKeyInKeychain:applicationTag:keyLabel:]
  +[SSRAESKeyManager getAESKeyFromKeychainWithApplicationTag:keyLabel:]
  +[SSRAESKeyManager deleteAESKeyWithApplicationTag:keyLabel:]
  +[SSRAESKeyManager getKeychainAttributesForAESKeyWithApplicationTag:keyLabel:]


CSVTUITrainingResult : NSObject
 @property  long long sessionId
 @property  int sessionStatus
 @property  int audioStatus

  // instance methods
  -[CSVTUITrainingResult sessionId]
  -[CSVTUITrainingResult sessionStatus]
  -[CSVTUITrainingResult audioStatus]
  -[CSVTUITrainingResult initWithSessionId:sessionStatus:audioStatus:]


CSAudioRecordContext(AVVC)
	// instance methods
	-[CSAudioRecordContext(AVVC) avvcContextSettings]

MAAsset(CSAsset)
	// instance methods
	-[MAAsset(CSAsset) path]
	-[MAAsset(CSAsset) isDownloading]
	-[MAAsset(CSAsset) _version]
	-[MAAsset(CSAsset) _compatibilityVersion]
	-[MAAsset(CSAsset) _footprint]
	-[MAAsset(CSAsset) isPremium]
	-[MAAsset(CSAsset) getCSAssetOfType:]
	-[MAAsset(CSAsset) isCSAssetInstalled]
	-[MAAsset(CSAsset) canBePurged]
	-[MAAsset(CSAsset) isLatestCompareTo:]

CSUtils(LanguageCode)
	// class methods
	+[CSUtils(LanguageCode) hasRemoteBuiltInMic]
	+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
	+[CSUtils(LanguageCode) getSiriLanguageWithEndpointId:fallbackLanguage:]
	+[CSUtils(LanguageCode) isRemoteDarwinWithDeviceId:]
	+[CSUtils(LanguageCode) isRecordContextVoiceTrigger:]
	+[CSUtils(LanguageCode) isRecordContextBuiltInVoiceTrigger:]
	+[CSUtils(LanguageCode) isRecordContextDarwinVoiceTrigger:]
	+[CSUtils(LanguageCode) isRecordContextRemoraVoiceTrigger:]
	+[CSUtils(LanguageCode) isRecordContextHomeButtonPress:]
	+[CSUtils(LanguageCode) isRecordContextAutoPrompt:]
	+[CSUtils(LanguageCode) isRecordContextSpeakerIdTrainingTrigger:]
	+[CSUtils(LanguageCode) isRecordContextHearstVoiceTrigger:]
	+[CSUtils(LanguageCode) isRecordContextHearstDoubleTap:]
	+[CSUtils(LanguageCode) isRecordContextRaiseToSpeak:]
	+[CSUtils(LanguageCode) isRecordContextJarvisVoiceTrigger:]
	+[CSUtils(LanguageCode) isRecordContextJarvisButtonPress:]
	+[CSUtils(LanguageCode) isValidRecordContext:]
	+[CSUtils(LanguageCode) recordContextString:]

(CSVTUIEditDistance)
	// instance methods
	-[(CSVTUIEditDistance) _stringByFixingNamePattern:]
	-[(CSVTUIEditDistance) _stringByStrippingLeadingNoise:]
	-[(CSVTUIEditDistance) _stringByStrippingTrailingNoise:]
	-[(CSVTUIEditDistance) _stringByStrippingNoiseLeadingNoise:TrailingNoise:]
	-[(CSVTUIEditDistance) _hasSubstring:]
	-[(CSVTUIEditDistance) _matchesRegularExpression:]
	-[(CSVTUIEditDistance) _caseInsensitiveHasMatchInEnumeration:]
	-[(CSVTUIEditDistance) _firstMatchesForRegularExpressions:]
	-[(CSVTUIEditDistance) _firstMatchesForRegularExpression:]

AVVCContextSettings(debugDescription)
	// instance methods
	-[AVVCContextSettings(debugDescription) debugDescription]

AVVCStartRecordSettings(debugDescription)
	// instance methods
	-[AVVCStartRecordSettings(debugDescription) debugDescription]

CSAsset(SpeakerRecognition)
	// instance methods
	-[CSAsset(SpeakerRecognition) containsSpeakerRecognitionCategory]
	-[CSAsset(SpeakerRecognition) satScoreThresholdForPhId:]
	-[CSAsset(SpeakerRecognition) satScoreThreshold]
	-[CSAsset(SpeakerRecognition) multiUserLowScoreThreshold]
	-[CSAsset(SpeakerRecognition) multiUserHighScoreThreshold]
	-[CSAsset(SpeakerRecognition) multiUserConfidentScoreThreshold]
	-[CSAsset(SpeakerRecognition) multiUserDeltaScoreThreshold]
	-[CSAsset(SpeakerRecognition) psrCombinationWeight]
	-[CSAsset(SpeakerRecognition) satImplicitProfileThreshold]
	-[CSAsset(SpeakerRecognition) satImplicitProfileDeltaThreshold]
	-[CSAsset(SpeakerRecognition) satVTImplicitThreshold]
	-[CSAsset(SpeakerRecognition) pruningExplicitUttThresholdSAT]
	-[CSAsset(SpeakerRecognition) pruningExplicitUttThresholdPSR]
	-[CSAsset(SpeakerRecognition) pruningThresholdSAT]
	-[CSAsset(SpeakerRecognition) pruningThresholdPSR]
	-[CSAsset(SpeakerRecognition) pruningNumRetentionUtterance]
	-[CSAsset(SpeakerRecognition) maxAllowedEnrollmentUtterances]
	-[CSAsset(SpeakerRecognition) voiceProfilePruningCookie]
	-[CSAsset(SpeakerRecognition) keywordDetectorQuasarConfigFilePath]
	-[CSAsset(SpeakerRecognition) keywordDetectorNDAPIConfigFilePath]
	-[CSAsset(SpeakerRecognition) satImplicitTrainingEnabled]
	-[CSAsset(SpeakerRecognition) containsMultiUserThresholds]
	-[CSAsset(SpeakerRecognition) useSpeakerRecognitionAsset]

01 00 0a00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFAnalytics 
01 00 0a00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFMultiUserConnection 
01 00 0a00 /System/Library/PrivateFrameworks/AssistantServices.framework/AssistantServices: AFSettingsConnection 
01 00 0800 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVAudioFormat 
01 00 0800 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVAudioPCMBuffer 
01 00 1200 /System/Library/PrivateFrameworks/Celestial.framework/Celestial: AVSystemController 
01 00 0800 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVVCContextSettings 
01 00 0800 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVVCPrepareRecordSettings 
01 00 0800 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVVCStartRecordSettings 
01 00 0800 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVVoiceController 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAsset 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAudioChunk 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAudioCircularBuffer 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAudioFileManager 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAudioPowerMeter 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAudioRecordContext 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSAudioZeroCounter 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSConfig 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSContinuousVoiceTriggerConfigDecoder 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSDiagnosticReporter 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSDispatchGroup 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSFAudioStreamBasicDescriptionFactory 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSFPreferences 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSFTimeUtils 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSMobileAssetVersions 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSOSTransaction 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSPlainAudioFileWriter 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSRemoteAssetManager 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSUtils 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSVTUITrainingSelfLogger 
01 00 0400 /System/Library/PrivateFrameworks/CoreSpeechFoundation.framework/CoreSpeechFoundation: CSVoiceTriggerSecondPassConfigDecoder 
01 00 0700 /System/Library/PrivateFrameworks/DistributedEvaluation.framework/DistributedEvaluation: DESRecordStore 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: EARAudioResultsGenerator 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: EARCaesuraSilencePosteriorGenerator 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: EARSyncPSRAudioProcessor 
01 00 0600 /System/Library/Frameworks/HealthKit.framework/HealthKit: HKHealthStore 
01 00 0600 /System/Library/Frameworks/HealthKit.framework/HealthKit: HKMedicalIDStore 
01 00 0b00 /System/Library/PrivateFrameworks/MobileAsset.framework/MobileAsset: MAAsset 
01 00 0b00 /System/Library/PrivateFrameworks/MobileAsset.framework/MobileAsset: MAAssetQuery 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSArray 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSAssertionHandler 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSBundle 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSCalendar 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSCharacterSet 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSConstantDictionary 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantDoubleNumber 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantFloatNumber 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantIntegerNumber 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSData 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDate 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSDateFormatter 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDictionary 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSDistributedNotificationCenter 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSError 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileManager 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSHashTable 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSJSONSerialization 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSLocale 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableArray 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableData 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableDictionary 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableSet 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSMutableString 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumber 
01 00 1800 /usr/lib/libobjc.A.dylib: NSObject 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSPredicate 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSRegularExpression 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSScanner 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSSet 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSString 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSTimer 
01 00 1b00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSURL 
01 00 0100 /System/Library/Frameworks/Foundation.framework/Foundation: NSUUID 
01 00 0940 /System/Library/Frameworks/Speech.framework/Speech: SFSpeechAudioBufferRecognitionRequest 
01 00 0940 /System/Library/Frameworks/Speech.framework/Speech: SFSpeechRecognizer 
01 00 0f00 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNAudioStreamAnalyzer 
01 00 0f00 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectSpeechUtteranceRequest 
01 00 0e00 /System/Library/PrivateFrameworks/VoiceTrigger.framework/VoiceTrigger: VTPreferences 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: _EAREndpointFeatures 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: _EAREndpointer 
01 00 0340 /System/Library/PrivateFrameworks/EmbeddedAcousticRecognition.framework/EmbeddedAcousticRecognition: _EARSyncSpeechRecognizer 
