|| __DATA.__data _VCPPhotosProcessing_ForceFullScanKey
|| __DATA.__data _VCPProcessingTask_MaxNumberOfAssetToProcess
|| __DATA.__data _VCPTurboProcessing_DutyCyclingKey
|| __DATA.__data _VCPTurboProcessing_QualityOfServiceKey
|| __DATA.__data _VCPTurboProcessing_VCPTaskIDsKey
|| __DATA.__data _VCPVideoStabilizationProcessing_GyroKey
|| __DATA.__data _VCPVideoStabilizationProcessing_PixelKey
|| __DATA.__objc_data _OBJC_CLASS_$_MADActivitySchedulingRecord
|| __DATA.__objc_data _OBJC_CLASS_$_VCPCaptureAnalysisSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPContentAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceAnchor
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceGeometry
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFaceProcessingServiceWorker
|| __DATA.__objc_data _OBJC_CLASS_$_VCPFullAnalysisURLProcessingTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHandObservation
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHandPoseImageRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHandPoseVideoRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeFaceIdentificationTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeKitAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeKitAnalysisSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHomeResidentMaintenanceTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHumanPoseEspressoSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHumanPoseImageRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPHumanPoseVideoRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageConverter
|| __DATA.__objc_data _OBJC_CLASS_$_VCPImageHandsAnalyzer
|| __DATA.__objc_data _OBJC_CLASS_$_VCPInMemoryAVAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPKeypoint
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMADServiceImagePixelBufferAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMADServiceImageProcessingTaskBatch
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMADServiceImageURLAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMotionFlowObservation
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMotionFlowRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieCurationResults
|| __DATA.__objc_data _OBJC_CLASS_$_VCPMovieHighlightResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPersonObservation
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPhotosAutoCounterWorker
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPhotosSceneprintAssetProcessingTask
|| __DATA.__objc_data _OBJC_CLASS_$_VCPPriorityAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPProtoAssetAnalysis
|| __DATA.__objc_data _OBJC_CLASS_$_VCPRealTimeAnalysisService
|| __DATA.__objc_data _OBJC_CLASS_$_VCPRequest
|| __DATA.__objc_data _OBJC_CLASS_$_VCPURLAsset
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoKeyFrameResult
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoProcessor
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoProcessorSession
|| __DATA.__objc_data _OBJC_CLASS_$_VCPVideoStabilizationAssetProcessingTask
|| __DATA_CONST.__const _HomeKitAnalysisServiceName
|| __DATA_CONST.__const _HomeKitSessionAnalysisServiceName
|| __DATA_CONST.__const _MADFaceLibraryProcessing_ModifyPersonRequest
|| __DATA_CONST.__const _MADFaceLibraryProcessing_SubTasks
|| __DATA_CONST.__const _MediaAnalysisActivityLevelResultsKey
|| __DATA_CONST.__const _MediaAnalysisAdjustedFingerprintKey
|| __DATA_CONST.__const _MediaAnalysisAnalysisTypesKey
|| __DATA_CONST.__const _MediaAnalysisApplauseResultsKey
|| __DATA_CONST.__const _MediaAnalysisBabbleResultsKey
|| __DATA_CONST.__const _MediaAnalysisBlurResultsKey
|| __DATA_CONST.__const _MediaAnalysisCameraMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisCheeringResultsKey
|| __DATA_CONST.__const _MediaAnalysisClassificationResultsKey
|| __DATA_CONST.__const _MediaAnalysisColorNormalizationResultsKey
|| __DATA_CONST.__const _MediaAnalysisCompositionResultsKey
|| __DATA_CONST.__const _MediaAnalysisDateAnalyzedKey
|| __DATA_CONST.__const _MediaAnalysisDateModifiedKey
|| __DATA_CONST.__const _MediaAnalysisDistanceResultsKey
|| __DATA_CONST.__const _MediaAnalysisDomain
|| __DATA_CONST.__const _MediaAnalysisExposureResultsKey
|| __DATA_CONST.__const _MediaAnalysisFacePrintResultsKey
|| __DATA_CONST.__const _MediaAnalysisFaceResultsKey
|| __DATA_CONST.__const _MediaAnalysisFeatureVectorResultsKey
|| __DATA_CONST.__const _MediaAnalysisFineSubjectMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisFlagsKey
|| __DATA_CONST.__const _MediaAnalysisHandsResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanActionClassificationResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanActionResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanPoseInternalResultsKey
|| __DATA_CONST.__const _MediaAnalysisHumanPoseResultsKey
|| __DATA_CONST.__const _MediaAnalysisInterestingnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisInterpolationResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisObjectsResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisRecommendResultsKey
|| __DATA_CONST.__const _MediaAnalysisIrisSharpnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisJunkResultsKey
|| __DATA_CONST.__const _MediaAnalysisKeyFrameBlurResultsKey
|| __DATA_CONST.__const _MediaAnalysisKeyFrameResourceResultsKey
|| __DATA_CONST.__const _MediaAnalysisKeyFrameResultsKey
|| __DATA_CONST.__const _MediaAnalysisKeyFrameStillResultsKey
|| __DATA_CONST.__const _MediaAnalysisLaughterResultsKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoBounceActivityDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoEffectsResultsKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoFinalDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoGatingResultErrorKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoGatingResultFailKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoGatingResultPassKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoGatingResultUnsetKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoLongexpActivityDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoLoopActivityDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoPostGateDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoPreGateFacesDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoPreGateStillMetadataDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoPreGateVideoMLDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoPreGateVideoTrimDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoShortInputDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoStabilizeGateDecisionKey
|| __DATA_CONST.__const _MediaAnalysisLivePhotoStabilizeResultKey
|| __DATA_CONST.__const _MediaAnalysisLoudnessResultsKey
|| __DATA_CONST.__const _MediaAnalysisMasterFingerprintKey
|| __DATA_CONST.__const _MediaAnalysisMetaAdjusterDisplacementResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaAdjusterRecipeResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaAdjusterResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaFocusResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaHomographyDimensionResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaHomographyResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaInterpolatedFrameResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaItemPTSResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaLensSwitchResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaMotionBlurResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaMotionProcessedResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaOriginalPTSInNanosResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaPTSInNanosResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaPresentationTimeResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaStabilizationFrameResultsKey
|| __DATA_CONST.__const _MediaAnalysisMetaStabilizationResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovieHighlightResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovieHighlightScoreResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovieSummaryResultsKey
|| __DATA_CONST.__const _MediaAnalysisMovingObjectResultsKey
|| __DATA_CONST.__const _MediaAnalysisMusicResultsKey
|| __DATA_CONST.__const _MediaAnalysisObstructionResultsKey
|| __DATA_CONST.__const _MediaAnalysisOrientationResultsKey
|| __DATA_CONST.__const _MediaAnalysisPetsFaceResultsKey
|| __DATA_CONST.__const _MediaAnalysisPetsResultsKey
|| __DATA_CONST.__const _MediaAnalysisPhotosServiceName
|| __DATA_CONST.__const _MediaAnalysisPreEncodeResultsKey
|| __DATA_CONST.__const _MediaAnalysisQualityKey
|| __DATA_CONST.__const _MediaAnalysisQualityResultsKey
|| __DATA_CONST.__const _MediaAnalysisRealTimeServiceName
|| __DATA_CONST.__const _MediaAnalysisResultAestheticAllScoresKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticFailureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticHarmoniousColorScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticImmersivenessScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticInterestingSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticIntrusiveObjectPresenceScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticLivelyColorScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticLowKeyLightingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticNoiseScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticOverallScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantCameraTiltScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantCompositionScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantLightingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantPatternScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantPerspectiveScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantPostProcessingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantReflectionsScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticPleasantSymmetryScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticSharplyFocusedSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticTastefullyBlurredScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticWellChosenBackgroundScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticWellFramedSubjectScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAestheticWellTimedShotScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultAttributesKey
|| __DATA_CONST.__const _MediaAnalysisResultBestPlaybackCropAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultClassificationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultColorNormalizationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDistanceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDominantLineAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDuplicateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultDurationKey
|| __DATA_CONST.__const _MediaAnalysisResultEnergyAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceIdentifierAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePoseYawAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePositionAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFacePrintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceQualityAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFaceQualityFlagKey
|| __DATA_CONST.__const _MediaAnalysisResultFeatureVectorAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultFlagsKey
|| __DATA_CONST.__const _MediaAnalysisResultFlashAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultGyroStabilizationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsKeypointsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHandsKeypointsConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionScoreAbsoluteAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionScoreRelativeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanActionsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanIDAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanKeypointsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultHumanScoreAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultIndexAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultInterpolationURLAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultJunkAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultJunkConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameContentScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameExposureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameExpressionChangeScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameFaceQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameGlobalQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFramePenaltyScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameQualityScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameScoreAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameSharpnessScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTextureScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTimeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameTimestampKey
|| __DATA_CONST.__const _MediaAnalysisResultKeyFrameVisualPleasingScoreKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsGatingDescriptionsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsMatchingScenesAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLivePhotoEffectsRecipeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLongExposureSuggestionStateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultLoopSuggestionStateAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultMaxHighlightDurationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultMaxHighlightStartAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultMovingObjectsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultNeighborAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultNeighborDateModifiedAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultOrientationAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPeakAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPetsBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPetsConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultPreEncodeDataAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultProbableRotationDirectionAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultProbableRotationDirectionConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultQualityKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyAcceptableCropKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyBoundsAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyObjectnessAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSaliencyPreferredCropKey
|| __DATA_CONST.__const _MediaAnalysisResultSceneprintAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSceneprintDistanceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSharpnessAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSharpnessFacesAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultShotTypeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSlowMoFlickerAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSongSignatureAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultStabilizationAnalysisConfidence
|| __DATA_CONST.__const _MediaAnalysisResultStabilizationRecipeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultStartKey
|| __DATA_CONST.__const _MediaAnalysisResultStillTimeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultSummaryTimerangeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultTextureAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultUnderExposeAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultVanishingPointAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultVanishingPointConfidenceAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultWPAttributeKey
|| __DATA_CONST.__const _MediaAnalysisResultsKey
|| __DATA_CONST.__const _MediaAnalysisRotationAnalysisResultsKey
|| __DATA_CONST.__const _MediaAnalysisSaliencyResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneChangeResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneResultsKey
|| __DATA_CONST.__const _MediaAnalysisSceneprintResultsKey
|| __DATA_CONST.__const _MediaAnalysisServiceName
|| __DATA_CONST.__const _MediaAnalysisShotTypeResultsKey
|| __DATA_CONST.__const _MediaAnalysisSongResultsKey
|| __DATA_CONST.__const _MediaAnalysisStatsFlagsKey
|| __DATA_CONST.__const _MediaAnalysisSubjectMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisSubtleMotionResultsKey
|| __DATA_CONST.__const _MediaAnalysisSyncPointKey
|| __DATA_CONST.__const _MediaAnalysisTrackingResultsKey
|| __DATA_CONST.__const _MediaAnalysisUtteranceResultsKey
|| __DATA_CONST.__const _MediaAnalysisVersionKey
|| __DATA_CONST.__const _MediaAnalysisVideoStabilizationResultsKey
|| __DATA_CONST.__const _MediaAnalysisVoiceResultsKey
|| __DATA_CONST.__const _MediaAnalysisWPResultsKey
|| __DATA_CONST.__const _VCPAnalysisCountFailedKey
|| __DATA_CONST.__const _VCPAnalysisCountPrioritizedProcessedKey
|| __DATA_CONST.__const _VCPAnalysisCountPrioritizedTotalAllowedKey
|| __DATA_CONST.__const _VCPAnalysisCountProcessedKey
|| __DATA_CONST.__const _VCPAnalysisCountTotalAllowedKey
|| __DATA_CONST.__const _VCPAnalysisPersonVIPStatusKey
|| __DATA_CONST.__const _VCPAnalysisPetVIPStatusKey
|| __DATA_CONST.__const _VCPAnalysisResultUsingBestResourceKey
|| __DATA_CONST.__const _VCPAnalysisResultWarningImageTooSmallKey
|| __DATA_CONST.__const _VCPAnalyticsEventDasDutyCycleKey
|| __DATA_CONST.__const _VCPAnalyticsEventDasDutyCycleTaskKey
|| __DATA_CONST.__const _VCPAnalyticsEventLivePhotoEffectAnalysisResultsKey
|| __DATA_CONST.__const _VCPAnalyticsEventLivePhotoFillingGaps
|| __DATA_CONST.__const _VCPAnalyticsEventLivePhotoKeyFrameResultsKey
|| __DATA_CONST.__const _VCPAnalyticsEventMovieCurationResultsKey
|| __DATA_CONST.__const _VCPAnalyticsEventPetsAnalysisKey
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsBounceActivityDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsFinalGateDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsLongexpActivityDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsLoopActivityDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsPostGateDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsPreGateFacesDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsPreGateStillMetadataDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsPreGateVideoMLDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsPreGateVideoTrimDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsShortInputDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsStabilizeGateDecision
|| __DATA_CONST.__const _VCPAnalyticsFieldEffectsStabilizeResult
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyAggregatedBoundingBoxSizeRatio
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyAssetType
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyAvgSpeed
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyDownloadAssetCount
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyDownloadBytes
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyDuration
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsFaceQualityDominant
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsFaceQualityDominantEdit
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsSemanticDominant
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsSemanticDominantEdit
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsSharpnessDominant
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsSharpnessDominantEdit
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsSuggested
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameIsSuggestedEdit
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameScoreDifference
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameScoreDifferenceEdit
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameTimestampOffset
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyFrameTimestampOffsetEdit
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyLargestBoundingBoxSizeRatio
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyNumberOfPetFacesDetected
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyNumberOfPetsDetected
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyPreviousQoS
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyPreviousQoSDuration
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyQoS
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyQoSDelay
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyRequestedQoS
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyResourceType
|| __DATA_CONST.__const _VCPAnalyticsFieldKeySceneType
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyTaskName
|| __DATA_CONST.__const _VCPAnalyticsFieldKeyTaskStatus
|| __DATA_CONST.__const _VCPAnalyticsFieldMovieCurationAutoPlayableScore
|| __DATA_CONST.__const _VCPAnalyticsFieldMovieCurationIsTrimmed
|| __DATA_CONST.__const _VCPAnalyticsFieldMovieCurationMediaType
|| __DATA_CONST.__const _VCPAnalyticsFieldMovieCurationSummaryDuration
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowInnerUp
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowOuterUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationBrowOuterUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekPuff
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekSquintLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationCheekSquintRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeBlinkLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeBlinkRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookInLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookInRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookOutLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookOutRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeLookUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeSquintLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeSquintRight
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeWideLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationEyeWideRight
|| __DATA_CONST.__const _VCPBlendShapeLocationJawForward
|| __DATA_CONST.__const _VCPBlendShapeLocationJawLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationJawOpen
|| __DATA_CONST.__const _VCPBlendShapeLocationJawRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthClose
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthDimpleLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthDimpleRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFrownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFrownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthFunnel
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLowerDownLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthLowerDownRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPressLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPressRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthPucker
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRollLower
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthRollUpper
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthShrugLower
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthShrugUpper
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthSmileLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthSmileRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthStretchLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthStretchRight
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthUpperUpLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationMouthUpperUpRight
|| __DATA_CONST.__const _VCPBlendShapeLocationNoseSneerLeft
|| __DATA_CONST.__const _VCPBlendShapeLocationNoseSneerRight
|| __DATA_CONST.__const _VCPBlendShapeLocationTongueOut
|| __DATA_CONST.__const _VCPBoundingBoxKey
|| __DATA_CONST.__const _VCPCaptureAnalysisAggregatedSubjectMotionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisDispatchQueuePropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisDurationKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceAnchorResultKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceBoundsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceResultsKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFaceRollAnglesPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFlagsKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFocalLengthInPixelsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFrameHeightPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisFrameWidthPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisGlobalMotionKey
|| __DATA_CONST.__const _VCPCaptureAnalysisInterestingnessScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObjectsMotionKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObjectsPropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisObstructionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisQualityKey
|| __DATA_CONST.__const _VCPCaptureAnalysisRegionsOfInterestResultKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSceneChangeScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSharpnessScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisStartKey
|| __DATA_CONST.__const _VCPCaptureAnalysisSubjectMotionScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisTrackingScoreKey
|| __DATA_CONST.__const _VCPCaptureAnalysisTurboModePropertyKey
|| __DATA_CONST.__const _VCPCaptureAnalysisVoiceResultsKey
|| __DATA_CONST.__const _VCPConfidenceKey
|| __DATA_CONST.__const _VCPContentTypeKey
|| __DATA_CONST.__const _VCPEspressoSessionConfigPropertyKey
|| __DATA_CONST.__const _VCPEspressoSessionLoadModelKey
|| __DATA_CONST.__const _VCPEspressoSessionRevisionPropertyKey
|| __DATA_CONST.__const _VCPFaceMetadataArrayKey
|| __DATA_CONST.__const _VCPFaceRectangleKey
|| __DATA_CONST.__const _VCPFaceRollKey
|| __DATA_CONST.__const _VCPFaceYawKey
|| __DATA_CONST.__const _VCPFacesToDelete
|| __DATA_CONST.__const _VCPFacesToPersist
|| __DATA_CONST.__const _VCPKeyValueNumberOfAssetsAllowedForPhotosFaceProcessing
|| __DATA_CONST.__const _VCPKeyValueNumberOfAssetsAnalyzedForPhotosFaceProcessing
|| __DATA_CONST.__const _VCPKeyValuePrioritizedProcessedForPhotosFaceProcessing
|| __DATA_CONST.__const _VCPKeyValuePrioritizedTotalAllowedForPhotosFaceProcessing
|| __DATA_CONST.__const _VCPLibraryClustersMinusVisionClusters
|| __DATA_CONST.__const _VCPMAAutoCounterOptInStatusKey
|| __DATA_CONST.__const _VCPMAEmbeddingChecksumkey
|| __DATA_CONST.__const _VCPMAEmbeddingDataKey
|| __DATA_CONST.__const _VCPMAFileURL
|| __DATA_CONST.__const _VCPMAGroundTruthURL
|| __DATA_CONST.__const _VCPMAPersonIdentifier
|| __DATA_CONST.__const _VCPMAPersonInformation
|| __DATA_CONST.__const _VCPMAPersonInformationAge
|| __DATA_CONST.__const _VCPMAPersonInformationEthnicity
|| __DATA_CONST.__const _VCPMAPersonInformationSex
|| __DATA_CONST.__const _VCPMAVIPPetModelLastGenerationKey
|| __DATA_CONST.__const _VCPMediaAnalysisServiceFaceReclusteringDeletePersonsKey
|| __DATA_CONST.__const _VCPMediaAnalysisServiceFaceReclusteringShouldReclusterKey
|| __DATA_CONST.__const _VCPMediaAnalysisServiceFaceReclusteringThresholdKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingBuildPersonsKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingClassifyContactPicturesKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingClusterFacesKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingDeletePersonsKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingIncrementalFaceClusteringKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingIncrementalPersonBuildingKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingPromotePersonsKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonProcessingRebuildFaceIDModelKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonPromoterAdvancedStatusKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonPromoterRequestAdvancedStatusKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonPromoterStatusKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonSuggestionConfirmedKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonSuggestionKeyFaceClusterSequenceNumberKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonSuggestionKeyFaceIdentifierKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonSuggestionPersonFaceCountKey
|| __DATA_CONST.__const _VCPMediaAnalysisServicePersonSuggestionPersonIdentifierKey
|| __DATA_CONST.__const _VCPMediaAnalysisServiceRebuildPersonWithLocalIdentifierKey
|| __DATA_CONST.__const _VCPMediaAnalysisService_InProcessOption
|| __DATA_CONST.__const _VCPMediaAnalysisService_SceneprintRevisionOption
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowOnDemand
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowOnDemandGyro
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowOnDemandPixel
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_AllowStreaming
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_HighlightBestTrim
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_HighlightIndex
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_HighlightStartRange
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_HighlightTargetDuration
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_HighlightTolerance
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_KeepPrivateResults
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_MaxHighlightDuration
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_ScaledSlomoTime
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_Standalone
|| __DATA_CONST.__const _VCPMediaAnalyzerOption_StoreAnalysis
|| __DATA_CONST.__const _VCPPhotoLibrariesDefaultsKey
|| __DATA_CONST.__const _VCPPriorityScoreKey
|| __DATA_CONST.__const _VCPQuickFaceIDModelLastGenerationKey
|| __DATA_CONST.__const _VCPQuickFaceIdentification
|| __DATA_CONST.__const _VCPRequestForceCPUPropertyKey
|| __DATA_CONST.__const _VCPRequestFrameHeightPropertyKey
|| __DATA_CONST.__const _VCPRequestFrameWidthPropertyKey
|| __DATA_CONST.__const _VCPRequestHumanActionWinSizePropertyKey
|| __DATA_CONST.__const _VCPRequestMaxNumOfHandsPropertyKey
|| __DATA_CONST.__const _VCPRequestRevisionPropertyKey
|| __DATA_CONST.__const _VCPVideoProcessor_FramesPerSecondKey
|| __DATA_CONST.__const _VCPVisionClustersMinusLibraryClusters
|| __DATA_CONST.__const _kMAComputeOperationType_ImageAnalysis
|| __DATA_CONST.__const _kMAComputeOperationType_MovieAnalysis
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPAnalysisProgressQuery
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPDefaultPhotoLibraryManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPDeviceInformation
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPDownloadManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPEffectsAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceClusterer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceCropManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceIDModel
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceMerger
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceProcessingVersionManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFaceUtils
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPFingerprint
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPImageDescriptor
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPImageManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPInterAssetAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPInternetReachability
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPLoaned
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPLogManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMABaseTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADCoreAnalyticsManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADResource
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADResourceLock
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADResourceManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADServiceImageAsset
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADServiceImagePhotosAsset
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMADServiceImageProcessingTask
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMAEmbeddingAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMediaAnalysisService
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMediaAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMetaTrackDecoder
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPMovieAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPObjectPool
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPersonBuilder
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotoAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosAsset
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosFaceProcessingContext
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosPersistenceDelegate
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPhotosQuickFaceIdentificationManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPPreAnalyzer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPProtoLivePhotoEffectsRecipe
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPSceneTaxonomy
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPSharedInstanceManager
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPTimeMeasurement
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPTimer
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPVNImageprintWrapper
|| __DATA_DIRTY.__objc_data _OBJC_CLASS_$_VCPVideoStabilizer
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VCPMABaseTask
|| __DATA_DIRTY.__objc_data _OBJC_METACLASS_$_VCPMADResource
|| __TEXT.__const _MediaAnalysisBlacklistAgeOutInterval
|| __TEXT.__const _MediaAnalysisBlacklistThreshold
|| __TEXT.__const _MediaAnalysisChangedVersion17
|| __TEXT.__const _MediaAnalysisChangedVersion3
|| __TEXT.__const _MediaAnalysisChangedVersion35
|| __TEXT.__const _MediaAnalysisChangedVersion39
|| __TEXT.__const _MediaAnalysisChangedVersion6
|| __TEXT.__const _MediaAnalysisChangedVersion7
|| __TEXT.__const _MediaAnalysisCloseupShotThreshold
|| __TEXT.__const _MediaAnalysisDeleteRetainInterval
|| __TEXT.__const _MediaAnalysisDistanceUnknown
|| __TEXT.__const _MediaAnalysisFlagsCameraAll
|| __TEXT.__const _MediaAnalysisFlagsExpression
|| __TEXT.__const _MediaAnalysisMaxHighlightDuration
|| __TEXT.__const _MediaAnalysisMidShotThreshold
|| __TEXT.__const _MediaAnalysisMinValidVersion
|| __TEXT.__const _MediaAnalysisPreferredDimension
|| __TEXT.__const _MediaAnalysisQualityUnknown
|| __TEXT.__const _MediaAnalysisTypeAllInternal
|| __TEXT.__const _MediaAnalysisTypeGyroAnalytics
|| __TEXT.__const _MediaAnalysisVersion
|| __TEXT.__const _MediaAnalysisVeryWideShotThreshold
|| __TEXT.__const _MediaAnalysisWideShotThreshold
|| __TEXT.__const _MediaAnalysisZeroQualityScore
|| __TEXT.__const _VCPFaceClustererMinimumFaceGroupSizeForCreatingMergeCandidates
|| __TEXT.__const _VCPLogToOSLogType
|| __TEXT.__const _VCPMAEmbeddingProcessingVersion
|| __TEXT.__const _VCPMAEmbeddingVoucherThumbnailFileSize
|| __TEXT.__const _VCPMAFullAnalysisTypesImage
|| __TEXT.__const _VCPMAFullAnalysisTypesLivePhoto
|| __TEXT.__const _VCPMAFullAnalysisTypesMovie
|| __TEXT.__const _VCPMAFullAnalysisTypesThumbnail
|| __TEXT.__const _VCPPhotosFaceAnalysisTaskID
|| __TEXT.__const _VCPPhotosFaceProcessingVersion
|| __TEXT.__const _VCPPhotosFaceProcessingVersion5
|| __TEXT.__const _VCPPhotosFaceProcessingVersion7
|| __TEXT.__const _VCPPhotosFaceProcessingVersion8
|| __TEXT.__const _VCPPhotosMediaAnalysisTaskID
|| __TEXT.__const _VCPPhotosMultiWorkerAnalysisTaskID
|| __TEXT.__const _VCPPhotosOCRProcessingFromGatingVersion
|| __TEXT.__const _VCPPhotosOCRProcessingVersion
|| __TEXT.__const _VCPPhotosSceneAnalysisTaskID
|| __TEXT.__const _VCPPhotosSceneProcessingVersion
|| __TEXT.__const _VCPQuickFaceIdentificationModelClassificationThreshold
|| __TEXT.__const _VCPQuickFaceIdentificationModelRebuildPeriod
|| __TEXT.__text _DeviceGeqD5x
|| __TEXT.__text _DeviceHasANE
|| __TEXT.__text _MAComputeRequest_Create
|| __TEXT.__text _MAComputeRequest_ParseOutput
|| __TEXT.__text _MAComputeRequest_Start
|| __TEXT.__text _MADPersonPromoterHasProcessedForLibrary
|| __TEXT.__text _MADStatusDescription
|| __TEXT.__text _MediaAnalysisConvertAnalysisToOriginalTime
|| __TEXT.__text _MediaAnalysisConvertAnalysisToScaledTime
|| __TEXT.__text _MediaAnalysisFacePosition
|| __TEXT.__text _MediaAnalysisFlagsForTypes
|| __TEXT.__text _MediaAnalysisLivePhotoGatingResultKeyToType
|| __TEXT.__text _MediaAnalysisLogLevel
|| __TEXT.__text _MediaAnalysisMergeAnalysis
|| __TEXT.__text _MediaAnalysisPoseYawFromRadian
|| __TEXT.__text _MediaAnalysisPostProcessAnalysis
|| __TEXT.__text _MediaAnalysisPostProcessCurationScore
|| __TEXT.__text _MediaAnalysisPostProcessMovieHighlights
|| __TEXT.__text _MediaAnalysisPostProcessSlowmoResults
|| __TEXT.__text _MediaAnalysisPurgeResources
|| __TEXT.__text _MediaAnalysisResultsKeyToAnalysisType
|| __TEXT.__text _MediaAnalysisResultsKeyToType
|| __TEXT.__text _MediaAnalysisResultsKeysForAnalysisTypes
|| __TEXT.__text _MediaAnalysisResultsTypeToKey
|| __TEXT.__text _MediaAnalysisResultsTypesForAnalysisTypes
|| __TEXT.__text _MediaAnalysisResultsUpdatedSince
|| __TEXT.__text _MediaAnalysisShotType
|| __TEXT.__text _MediaAnalysisStripInternalResultsFromAnalysis
|| __TEXT.__text _MediaAnalysisStripKeyframeResourceResultsFromAnalysis
|| __TEXT.__text _MediaAnalysisStripOutdatedAnalysis
|| __TEXT.__text _MediaAnalysisTypeDescription
|| __TEXT.__text _MediaAnalysisTypeShortDescription
|| __TEXT.__text _MediaAnalysisTypesUpdatedSince
|| __TEXT.__text _SocType
|| __TEXT.__text _VCPBaseRetryIntervalSeconds
|| __TEXT.__text _VCPBuildPersons
|| __TEXT.__text _VCPFaceAnalysisFaceModelOverwrite
|| __TEXT.__text _VCPFetchPersonPromoterClusterForEvaluation
|| __TEXT.__text _VCPMAEmbeddingTypeDescription
|| __TEXT.__text _VCPMAGetModelLineupFromVCPPhotosFaceProcessingVersion
|| __TEXT.__text _VCPMAGetRevisionForVisionModel
|| __TEXT.__text _VCPMAIsAppleInternal
|| __TEXT.__text _VCPMAQoSDescription
|| __TEXT.__text _VCPMAVIPTypeDescription
|| __TEXT.__text _VCPNextRetryDateFromLastRetryDate
|| __TEXT.__text _VCPPerformance_LogMeasurement
|| __TEXT.__text _VCPPerformance_QueryMeasurements
|| __TEXT.__text _VCPPerformance_RecordMeasurement
|| __TEXT.__text _VCPPerformance_ReportSummary
|| __TEXT.__text _VCPPerformance_Reset
|| __TEXT.__text _VCPPhotosMRCCachingEnabled
|| __TEXT.__text _VCPPhotosMRCCachingSupported
|| __TEXT.__text _VCPPhotosParseCachingEnabled
|| __TEXT.__text _VCPPhotosParseCachingSupported
|| __TEXT.__text _VCPPhotosVisualSearchProcessingVersion
|| __TEXT.__text _VCPProcessingStatusDescription
|| __TEXT.__text _VCPProcessingStatusShortDescription
|| __TEXT.__text _VCPPromotePersons
|| __TEXT.__text _VCPProtoAssetAnalysisReadFrom
|| __TEXT.__text _VCPProtoLivePhotoEffectsRecipeReadFrom
|| __TEXT.__text _VCPSignPostLog
|| __TEXT.__text _VCPSpecialLabelFromSceneClassificationID
|| __TEXT.__text _VCPSpecialLabelToSceneClassificationID
|| __TEXT.__text _VCPTaskIDDescription
|| __TEXT.__text _VCPVersionForTask
|| __TEXT.__text _angleForTransform
|| __TEXT.__text _orientationForTransform
__ AVFAudio: _AVFormatIDKey
__ AVFAudio: _AVLinearPCMBitDepthKey
__ AVFAudio: _AVLinearPCMIsBigEndianKey
__ AVFAudio: _AVLinearPCMIsFloatKey
__ AVFAudio: _AVLinearPCMIsNonInterleaved
__ AVFAudio: _AVNumberOfChannelsKey
__ AVFAudio: _AVSampleRateKey
__ AVFAudio: _OBJC_CLASS_$_AVAudioFormat
__ AVFAudio: _OBJC_CLASS_$_AVAudioPCMBuffer
__ AVFoundation: _AVFileTypeMPEG4
__ AVFoundation: _AVFileTypeQuickTimeMovie
__ AVFoundation: _AVMediaTypeAudio
__ AVFoundation: _AVMediaTypeMetadata
__ AVFoundation: _AVMediaTypeVideo
__ AVFoundation: _AVMetadataFormatQuickTimeMetadata
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataDetectedFace
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataIsMontage
__ AVFoundation: _AVMetadataIdentifierQuickTimeMetadataVideoOrientation
__ AVFoundation: _AVMetadataKeySpaceQuickTimeMetadata
__ AVFoundation: _AVMetadataQuickTimeMetadataKeyIsMontage
__ AVFoundation: _AVVideoCodecKey
__ AVFoundation: _AVVideoCodecTypeH264
__ AVFoundation: _AVVideoCodecTypeHEVC
__ AVFoundation: _AVVideoCompressionPropertiesKey
__ AVFoundation: _OBJC_CLASS_$_AVAsset
__ AVFoundation: _OBJC_CLASS_$_AVAssetImageGenerator
__ AVFoundation: _OBJC_CLASS_$_AVAssetReader
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderOutputMetadataAdaptor
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderSampleReferenceOutput
__ AVFoundation: _OBJC_CLASS_$_AVAssetReaderTrackOutput
__ AVFoundation: _OBJC_CLASS_$_AVAssetTrack
__ AVFoundation: _OBJC_CLASS_$_AVAssetWriter
__ AVFoundation: _OBJC_CLASS_$_AVAssetWriterInput
__ AVFoundation: _OBJC_CLASS_$_AVMediaDataStorage
__ AVFoundation: _OBJC_CLASS_$_AVMetadataItem
__ AVFoundation: _OBJC_CLASS_$_AVMutableComposition
__ AVFoundation: _OBJC_CLASS_$_AVMutableMovie
__ AVFoundation: _OBJC_CLASS_$_AVTimedMetadataGroup
__ AVFoundation: _OBJC_CLASS_$_AVURLAsset
__ AVFoundation: _OBJC_METACLASS_$_AVURLAsset
__ Accelerate: _sgetrf_
__ Accelerate: _sgetri_
__ Accelerate: _vDSP_create_fftsetup
__ Accelerate: _vDSP_ctoz
__ Accelerate: _vDSP_deq22
__ Accelerate: _vDSP_destroy_fftsetup
__ Accelerate: _vDSP_dotpr
__ Accelerate: _vDSP_f3x3
__ Accelerate: _vDSP_f5x5
__ Accelerate: _vDSP_fft2d_zrip
__ Accelerate: _vDSP_imgfir
__ Accelerate: _vDSP_maxmgv
__ Accelerate: _vDSP_meanv
__ Accelerate: _vDSP_mmul
__ Accelerate: _vDSP_mtrans
__ Accelerate: _vDSP_normalize
__ Accelerate: _vDSP_sve
__ Accelerate: _vDSP_svesq
__ Accelerate: _vDSP_vabs
__ Accelerate: _vDSP_vadd
__ Accelerate: _vDSP_vclr
__ Accelerate: _vDSP_vfill
__ Accelerate: _vDSP_vfltu8
__ Accelerate: _vDSP_vsadd
__ Accelerate: _vDSP_vsdiv
__ Accelerate: _vDSP_vsmul
__ Accelerate: _vDSP_vsorti
__ Accelerate: _vDSP_vsub
__ Accelerate: _vDSP_ztoc
__ Accelerate: _vDSP_zvcmul
__ Accelerate: _vDSP_zvmags
__ Accelerate: _vImageScale_ARGB8888
__ AudioToolbox: _AudioComponentFindNext
__ AudioToolbox: _AudioComponentInstanceDispose
__ AudioToolbox: _AudioComponentInstanceNew
__ AudioToolbox: _AudioUnitAddPropertyListener
__ AudioToolbox: _AudioUnitGetProperty
__ AudioToolbox: _AudioUnitInitialize
__ AudioToolbox: _AudioUnitProcessMultiple
__ AudioToolbox: _AudioUnitReset
__ AudioToolbox: _AudioUnitSetProperty
__ AutoLoop: _alInterpolateMetadataForGap
__ AutoLoop: _autoloopSettingsDestroy
__ AutoLoop: _autoloopSettingsSetDisableStabilizationGPU
__ AutoLoop: _autoloopSettingsSetGating
__ AutoLoop: _autoloopSettingsSetOptimizeForMemoryUse
__ AutoLoop: _createAutoLoopSettingsForAsset
__ AutoLoop: _createBundleDefaultGatingClassifierURL
__ AutoLoop: _getGatingResult
__ AutoLoop: _liveAnalysisResultDestroy
__ AutoLoop: _liveAnalysisResultToDictionary
__ AutoLoop: _runLiveAnalysisPipeline
__ CMCapture: _FigLivePhotoMetadataComputeDeserializationSize
__ CMCapture: _FigLivePhotoMetadataComputeSerializationSizeV3
__ CMCapture: _FigLivePhotoMetadataDeserializeIntoBuffer
__ CMCapture: _kFigMetadataDataType_QuickTimeMetadataLivePhotoInfo
__ CMCapture: _kFigMetadataIdentifier_QuickTimeMetadataLivePhotoInfo
__ CMPhoto: _CMPhotoCompressionSessionAddImage
__ CMPhoto: _CMPhotoCompressionSessionCloseContainerAndCopyBacking
__ CMPhoto: _CMPhotoCompressionSessionCreate
__ CMPhoto: _CMPhotoCompressionSessionFlushCachedBuffers
__ CMPhoto: _CMPhotoCompressionSessionOpenEmptyContainer
__ CMPhoto: _CMPhotoDecompressionContainerCreateDictionaryDescription
__ CMPhoto: _CMPhotoDecompressionContainerCreateImageForIndex
__ CMPhoto: _CMPhotoDecompressionContainerGetImageGeometryForIndex
__ CMPhoto: _CMPhotoDecompressionSessionCreate
__ CMPhoto: _CMPhotoDecompressionSessionCreateContainer
__ CMPhoto: _CMPhotoDecompressionSessionDiscardCachedBuffers
__ CMPhoto: _kCMPhotoCompressionContainerOption_BackingType
__ CMPhoto: _kCMPhotoCompressionContainerOption_Format
__ CMPhoto: _kCMPhotoCompressionContainerOption_ImageCountHint
__ CMPhoto: _kCMPhotoCompressionOption_CodecType
__ CMPhoto: _kCMPhotoCompressionOption_ForceHighSpeed
__ CMPhoto: _kCMPhotoCompressionOption_PreferSoftwareCodec
__ CMPhoto: _kCMPhotoCompressionOption_QualityControllerParameters
__ CMPhoto: _kCMPhotoCompressionOption_QualityControllerType
__ CMPhoto: _kCMPhotoDecompressionContainerDescription_PrimaryImageIndex
__ CMPhoto: _kCMPhotoDecompressionOption_ApplyTransform
__ CMPhoto: _kCMPhotoDecompressionOption_MaxPixelSize
__ CMPhoto: _kCMPhotoDecompressionOption_OutputPixelFormat
__ CMPhoto: _kCMPhotoQualityControllerParameter_ByteBudget
__ CVNLP: _CVNLPCommSafetyHandlerImageClassificationScores
__ CVNLP: _CVNLPCommSafetyImageSensitivity
__ CVNLP: _CVNLPCommSafetyUseAnyAvailableDevice
__ CVNLP: _OBJC_CLASS_$_CVNLPCommSafetyHandler
__ CoreAnalytics: _AnalyticsSendEvent
__ CoreAppleCVA: __ZN3cva12VecLibLapackIfE5ormqrENS_4math8MULTSIDEENS2_5TRANSEiiiPfiS5_S5_iS5_i
__ CoreAppleCVA: __ZN3cva6VecLibIfE4gemmEbbiiifPKfiS3_ifPfi
__ CoreAppleCVA: __ZN3cva6VecLibIfE4gemvEbiifPKfiS3_ifPfi
__ CoreAppleCVA: __ZN3cva6vecLib5geqrfIfEEviiPT_iS3_S3_iPi
__ CoreAppleCVA: __ZN3cva6vecLib5gesvdIfEEvcciiPKT_iPS2_S5_iS5_iS5_iPi
__ CoreAppleCVA: __ZN3cva6vecLib5trtrsIfEEvccciiPKT_iPS2_iPi
__ CoreFoundation: _CFAbsoluteTimeGetCurrent
__ CoreFoundation: _CFArrayAppendValue
__ CoreFoundation: _CFArrayCreateCopy
__ CoreFoundation: _CFArrayCreateMutable
__ CoreFoundation: _CFArrayGetCount
__ CoreFoundation: _CFArrayGetValueAtIndex
__ CoreFoundation: _CFArrayInsertValueAtIndex
__ CoreFoundation: _CFArrayRemoveAllValues
__ CoreFoundation: _CFArrayRemoveValueAtIndex
__ CoreFoundation: _CFBooleanGetTypeID
__ CoreFoundation: _CFBundleCopyResourcesDirectoryURL
__ CoreFoundation: _CFBundleGetBundleWithIdentifier
__ CoreFoundation: _CFDataAppendBytes
__ CoreFoundation: _CFDataCreate
__ CoreFoundation: _CFDataCreateMutable
__ CoreFoundation: _CFDataCreateWithBytesNoCopy
__ CoreFoundation: _CFDataGetBytePtr
__ CoreFoundation: _CFDataGetBytes
__ CoreFoundation: _CFDataGetLength
__ CoreFoundation: _CFDataGetMutableBytePtr
__ CoreFoundation: _CFDataGetTypeID
__ CoreFoundation: _CFDataSetLength
__ CoreFoundation: _CFDictionaryAddValue
__ CoreFoundation: _CFDictionaryContainsKey
__ CoreFoundation: _CFDictionaryCreateMutable
__ CoreFoundation: _CFDictionaryGetValue
__ CoreFoundation: _CFDictionarySetValue
__ CoreFoundation: _CFEqual
__ CoreFoundation: _CFGetTypeID
__ CoreFoundation: _CFNumberCreate
__ CoreFoundation: _CFNumberGetValue
__ CoreFoundation: _CFPropertyListCreateWithData
__ CoreFoundation: _CFRelease
__ CoreFoundation: _CFRetain
__ CoreFoundation: _CFShow
__ CoreFoundation: _CFStringCompare
__ CoreFoundation: _CFStringCreateArrayBySeparatingStrings
__ CoreFoundation: _CFStringCreateMutableCopy
__ CoreFoundation: _CFStringCreateWithCString
__ CoreFoundation: _CFStringCreateWithFormat
__ CoreFoundation: _CFStringFindAndReplace
__ CoreFoundation: _CFStringGetCString
__ CoreFoundation: _CFStringGetDoubleValue
__ CoreFoundation: _CFStringGetLength
__ CoreFoundation: _CFStringGetMaximumSizeForEncoding
__ CoreFoundation: _CFURLCopyPath
__ CoreFoundation: _CFURLCreateAbsoluteURLWithBytes
__ CoreFoundation: _CFURLCreateWithString
__ CoreFoundation: _NSGenericException
__ CoreFoundation: _NSRangeException
__ CoreFoundation: _NSURLContentModificationDateKey
__ CoreFoundation: _NSURLContentTypeKey
__ CoreFoundation: _OBJC_CLASS_$_NSArray
__ CoreFoundation: _OBJC_CLASS_$_NSConstantArray
__ CoreFoundation: _OBJC_CLASS_$_NSData
__ CoreFoundation: _OBJC_CLASS_$_NSDate
__ CoreFoundation: _OBJC_CLASS_$_NSDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSException
__ CoreFoundation: _OBJC_CLASS_$_NSLocale
__ CoreFoundation: _OBJC_CLASS_$_NSMutableArray
__ CoreFoundation: _OBJC_CLASS_$_NSMutableData
__ CoreFoundation: _OBJC_CLASS_$_NSMutableDictionary
__ CoreFoundation: _OBJC_CLASS_$_NSMutableSet
__ CoreFoundation: _OBJC_CLASS_$_NSNull
__ CoreFoundation: _OBJC_CLASS_$_NSSet
__ CoreFoundation: _OBJC_CLASS_$_NSURL
__ CoreFoundation: _OBJC_CLASS_$_NSUserDefaults
__ CoreFoundation: _OBJC_EHTYPE_$_NSException
__ CoreFoundation: __CFRuntimeCreateInstance
__ CoreFoundation: __CFRuntimeRegisterClass
__ CoreFoundation: ___CFConstantStringClassReference
__ CoreFoundation: ___NSArray0__struct
__ CoreFoundation: ___NSDictionary0__struct
__ CoreFoundation: ___kCFBooleanFalse
__ CoreFoundation: ___kCFBooleanTrue
__ CoreFoundation: _kCFAllocatorDefault
__ CoreFoundation: _kCFAllocatorNull
__ CoreFoundation: _kCFBooleanFalse
__ CoreFoundation: _kCFBooleanTrue
__ CoreFoundation: _kCFTypeArrayCallBacks
__ CoreFoundation: _kCFTypeDictionaryKeyCallBacks
__ CoreFoundation: _kCFTypeDictionaryValueCallBacks
__ CoreGraphics: _CGAffineTransformConcat
__ CoreGraphics: _CGAffineTransformIdentity
__ CoreGraphics: _CGAffineTransformInvert
__ CoreGraphics: _CGAffineTransformMakeScale
__ CoreGraphics: _CGBitmapContextCreate
__ CoreGraphics: _CGBitmapContextCreateImage
__ CoreGraphics: _CGColorSpaceCreateDeviceRGB
__ CoreGraphics: _CGColorSpaceCreateWithName
__ CoreGraphics: _CGColorSpaceGetModel
__ CoreGraphics: _CGColorSpaceGetNumberOfComponents
__ CoreGraphics: _CGColorSpaceRelease
__ CoreGraphics: _CGColorSpaceSupportsOutput
__ CoreGraphics: _CGContextConcatCTM
__ CoreGraphics: _CGContextDrawImage
__ CoreGraphics: _CGContextRelease
__ CoreGraphics: _CGContextSetBlendMode
__ CoreGraphics: _CGContextSetInterpolationQuality
__ CoreGraphics: _CGContextSetShouldAntialias
__ CoreGraphics: _CGImageCreateWithImageInRect
__ CoreGraphics: _CGImageGetBitmapInfo
__ CoreGraphics: _CGImageGetColorSpace
__ CoreGraphics: _CGImageGetHeight
__ CoreGraphics: _CGImageGetProperty
__ CoreGraphics: _CGImageGetWidth
__ CoreGraphics: _CGImageRelease
__ CoreGraphics: _CGPointZero
__ CoreGraphics: _CGRectApplyAffineTransform
__ CoreGraphics: _CGRectContainsRect
__ CoreGraphics: _CGRectCreateDictionaryRepresentation
__ CoreGraphics: _CGRectGetMaxX
__ CoreGraphics: _CGRectGetMaxY
__ CoreGraphics: _CGRectGetMidX
__ CoreGraphics: _CGRectGetMidY
__ CoreGraphics: _CGRectGetMinX
__ CoreGraphics: _CGRectGetMinY
__ CoreGraphics: _CGRectInset
__ CoreGraphics: _CGRectIntersection
__ CoreGraphics: _CGRectIntersectsRect
__ CoreGraphics: _CGRectIsEmpty
__ CoreGraphics: _CGRectIsInfinite
__ CoreGraphics: _CGRectIsNull
__ CoreGraphics: _CGRectMakeWithDictionaryRepresentation
__ CoreGraphics: _CGRectNull
__ CoreGraphics: _CGRectUnion
__ CoreGraphics: _CGRectZero
__ CoreGraphics: _CGSizeCreateDictionaryRepresentation
__ CoreGraphics: _CGSizeZero
__ CoreGraphics: _kCGColorSpaceSRGB
__ CoreGraphics: _kCGImagePropertyIOSurface
__ CoreML: _OBJC_CLASS_$_MLArrayBatchProvider
__ CoreML: _OBJC_CLASS_$_MLFeatureValue
__ CoreML: _OBJC_CLASS_$_MLModel
__ CoreML: _OBJC_CLASS_$_MLPredictionOptions
__ CoreMedia: _CMAudioFormatDescriptionGetStreamBasicDescription
__ CoreMedia: _CMBaseObjectGetDerivedStorage
__ CoreMedia: _CMBaseObjectGetVTable
__ CoreMedia: _CMBlockBufferAssureBlockMemory
__ CoreMedia: _CMBlockBufferCreateWithMemoryBlock
__ CoreMedia: _CMBlockBufferGetDataLength
__ CoreMedia: _CMBlockBufferGetDataPointer
__ CoreMedia: _CMByteStreamGetClassID
__ CoreMedia: _CMDerivedObjectCreate
__ CoreMedia: _CMFormatDescriptionEqual
__ CoreMedia: _CMFormatDescriptionGetMediaSubType
__ CoreMedia: _CMMetadataFormatDescriptionGetIdentifiers
__ CoreMedia: _CMSampleBufferCreate
__ CoreMedia: _CMSampleBufferCreateCopyWithNewTiming
__ CoreMedia: _CMSampleBufferCreateForImageBuffer
__ CoreMedia: _CMSampleBufferGetDataBuffer
__ CoreMedia: _CMSampleBufferGetDecodeTimeStamp
__ CoreMedia: _CMSampleBufferGetDuration
__ CoreMedia: _CMSampleBufferGetFormatDescription
__ CoreMedia: _CMSampleBufferGetImageBuffer
__ CoreMedia: _CMSampleBufferGetNumSamples
__ CoreMedia: _CMSampleBufferGetOutputDuration
__ CoreMedia: _CMSampleBufferGetOutputPresentationTimeStamp
__ CoreMedia: _CMSampleBufferGetPresentationTimeStamp
__ CoreMedia: _CMSampleBufferGetSampleAttachmentsArray
__ CoreMedia: _CMSampleBufferGetSampleSize
__ CoreMedia: _CMSampleBufferSetOutputPresentationTimeStamp
__ CoreMedia: _CMSetAttachment
__ CoreMedia: _CMTimeAdd
__ CoreMedia: _CMTimeCompare
__ CoreMedia: _CMTimeCopyAsDictionary
__ CoreMedia: _CMTimeGetSeconds
__ CoreMedia: _CMTimeMake
__ CoreMedia: _CMTimeMakeFromDictionary
__ CoreMedia: _CMTimeMakeWithEpoch
__ CoreMedia: _CMTimeMakeWithSeconds
__ CoreMedia: _CMTimeMultiply
__ CoreMedia: _CMTimeMultiplyByFloat64
__ CoreMedia: _CMTimeMultiplyByRatio
__ CoreMedia: _CMTimeRangeContainsTime
__ CoreMedia: _CMTimeRangeContainsTimeRange
__ CoreMedia: _CMTimeRangeCopyAsDictionary
__ CoreMedia: _CMTimeRangeEqual
__ CoreMedia: _CMTimeRangeFromTimeToTime
__ CoreMedia: _CMTimeRangeGetEnd
__ CoreMedia: _CMTimeRangeGetIntersection
__ CoreMedia: _CMTimeRangeGetUnion
__ CoreMedia: _CMTimeRangeMake
__ CoreMedia: _CMTimeRangeMakeFromDictionary
__ CoreMedia: _CMTimeSubtract
__ CoreMedia: _CMVideoFormatDescriptionCreateForImageBuffer
__ CoreMedia: _CMVideoFormatDescriptionGetCleanAperture
__ CoreMedia: _CMVideoFormatDescriptionGetPresentationDimensions
__ CoreMedia: _FigMetadataFormatDescriptionGetIdentifierForLocalID
__ CoreMedia: _FigMetadataFormatDescriptionGetLocalIDForMetadataIdentifyingFactors
__ CoreMedia: _FigMetadataFormatDescriptionGetSetupDataForLocalID
__ CoreMedia: _kCMByteStreamProperty_AvailableLength
__ CoreMedia: _kCMByteStreamProperty_EntireLength
__ CoreMedia: _kCMByteStreamProperty_EntireLengthAvailableOnDemand
__ CoreMedia: _kCMByteStreamProperty_ReadSupported
__ CoreMedia: _kCMByteStreamProperty_URL
__ CoreMedia: _kCMByteStreamProperty_WriteSupported
__ CoreMedia: _kCMMetadataIdentifier_QuickTimeMetadataVideoOrientation
__ CoreMedia: _kCMSampleAttachmentKey_DependsOnOthers
__ CoreMedia: _kCMSampleAttachmentKey_HEVCSyncSampleNALUnitType
__ CoreMedia: _kCMSampleAttachmentKey_NotSync
__ CoreMedia: _kCMSampleBufferAttachmentKey_FinalFrame
__ CoreMedia: _kCMSampleBufferAttachmentKey_ForceKeyFrame
__ CoreMedia: _kCMSampleBufferAttachmentKey_RequestNonReferenceFrame
__ CoreMedia: _kCMTimeIndefinite
__ CoreMedia: _kCMTimeInvalid
__ CoreMedia: _kCMTimeNegativeInfinity
__ CoreMedia: _kCMTimePositiveInfinity
__ CoreMedia: _kCMTimeRangeInvalid
__ CoreMedia: _kCMTimeRangeZero
__ CoreMedia: _kCMTimeZero
__ CoreMedia: _kCMTimingInfoInvalid
__ CoreMedia: _kFigByteStreamProperty_UTI
__ CoreMedia: _kFigMetadataIdentifier_QuickTimeMetadataStillImageTime
__ CoreVideo: _CVBufferGetAttachment
__ CoreVideo: _CVBufferPropagateAttachments
__ CoreVideo: _CVBufferSetAttachment
__ CoreVideo: _CVImageBufferGetColorSpace
__ CoreVideo: _CVPixelBufferCreate
__ CoreVideo: _CVPixelBufferCreateWithIOSurface
__ CoreVideo: _CVPixelBufferGetBaseAddress
__ CoreVideo: _CVPixelBufferGetBaseAddressOfPlane
__ CoreVideo: _CVPixelBufferGetBytesPerRow
__ CoreVideo: _CVPixelBufferGetBytesPerRowOfPlane
__ CoreVideo: _CVPixelBufferGetExtendedPixels
__ CoreVideo: _CVPixelBufferGetHeight
__ CoreVideo: _CVPixelBufferGetHeightOfPlane
__ CoreVideo: _CVPixelBufferGetIOSurface
__ CoreVideo: _CVPixelBufferGetPixelFormatType
__ CoreVideo: _CVPixelBufferGetWidth
__ CoreVideo: _CVPixelBufferGetWidthOfPlane
__ CoreVideo: _CVPixelBufferLockBaseAddress
__ CoreVideo: _CVPixelBufferPoolCreate
__ CoreVideo: _CVPixelBufferPoolCreatePixelBuffer
__ CoreVideo: _CVPixelBufferRelease
__ CoreVideo: _CVPixelBufferRetain
__ CoreVideo: _CVPixelBufferUnlockBaseAddress
__ CoreVideo: _kCVImageBufferCGColorSpaceKey
__ CoreVideo: _kCVImageBufferCleanApertureHeightKey
__ CoreVideo: _kCVImageBufferCleanApertureHorizontalOffsetKey
__ CoreVideo: _kCVImageBufferCleanApertureKey
__ CoreVideo: _kCVImageBufferCleanApertureVerticalOffsetKey
__ CoreVideo: _kCVImageBufferCleanApertureWidthKey
__ CoreVideo: _kCVPixelBufferBytesPerRowAlignmentKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsBottomKey
__ CoreVideo: _kCVPixelBufferExtendedPixelsRightKey
__ CoreVideo: _kCVPixelBufferHeightKey
__ CoreVideo: _kCVPixelBufferIOSurfacePropertiesKey
__ CoreVideo: _kCVPixelBufferPixelFormatTypeKey
__ CoreVideo: _kCVPixelBufferWidthKey
__ Espresso: _espresso_context_destroy
__ Espresso: _espresso_create_context
__ Espresso: _espresso_create_plan
__ Espresso: _espresso_get_default_storage_type
__ Espresso: _espresso_network_bind_buffer
__ Espresso: _espresso_network_bind_direct_cvpixelbuffer
__ Espresso: _espresso_network_select_configuration
__ Espresso: _espresso_plan_add_network
__ Espresso: _espresso_plan_build
__ Espresso: _espresso_plan_build_clean
__ Espresso: _espresso_plan_destroy
__ Espresso: _espresso_plan_execute_sync
__ Espresso: _espresso_plan_get_phase
__ Espresso: _espresso_plan_submit
__ Foundation: _NSAllMapTableKeys
__ Foundation: _NSCocoaErrorDomain
__ Foundation: _NSLocalizedDescriptionKey
__ Foundation: _NSLog
__ Foundation: _NSOSStatusErrorDomain
__ Foundation: _NSPointFromString
__ Foundation: _NSRectFromString
__ Foundation: _NSSizeFromString
__ Foundation: _NSStringFromClass
__ Foundation: _NSStringFromPoint
__ Foundation: _NSStringFromRect
__ Foundation: _NSStringFromSize
__ Foundation: _NSTemporaryDirectory
__ Foundation: _NSUnderlyingErrorKey
__ Foundation: _OBJC_CLASS_$_NSBundle
__ Foundation: _OBJC_CLASS_$_NSCharacterSet
__ Foundation: _OBJC_CLASS_$_NSCompoundPredicate
__ Foundation: _OBJC_CLASS_$_NSConstantDoubleNumber
__ Foundation: _OBJC_CLASS_$_NSConstantFloatNumber
__ Foundation: _OBJC_CLASS_$_NSConstantIntegerNumber
__ Foundation: _OBJC_CLASS_$_NSCountedSet
__ Foundation: _OBJC_CLASS_$_NSDateFormatter
__ Foundation: _OBJC_CLASS_$_NSError
__ Foundation: _OBJC_CLASS_$_NSFileManager
__ Foundation: _OBJC_CLASS_$_NSIndexSet
__ Foundation: _OBJC_CLASS_$_NSJSONSerialization
__ Foundation: _OBJC_CLASS_$_NSKeyedArchiver
__ Foundation: _OBJC_CLASS_$_NSKeyedUnarchiver
__ Foundation: _OBJC_CLASS_$_NSLock
__ Foundation: _OBJC_CLASS_$_NSMapTable
__ Foundation: _OBJC_CLASS_$_NSMutableString
__ Foundation: _OBJC_CLASS_$_NSNumber
__ Foundation: _OBJC_CLASS_$_NSNumberFormatter
__ Foundation: _OBJC_CLASS_$_NSPredicate
__ Foundation: _OBJC_CLASS_$_NSProcessInfo
__ Foundation: _OBJC_CLASS_$_NSProgress
__ Foundation: _OBJC_CLASS_$_NSPropertyListSerialization
__ Foundation: _OBJC_CLASS_$_NSSortDescriptor
__ Foundation: _OBJC_CLASS_$_NSString
__ Foundation: _OBJC_CLASS_$_NSUUID
__ Foundation: _OBJC_CLASS_$_NSValue
__ Foundation: _OBJC_CLASS_$_NSXPCConnection
__ Foundation: _OBJC_CLASS_$_NSXPCInterface
__ IOKit: _IOObjectRelease
__ IOKit: _IORegistryEntryCreateCFProperty
__ IOKit: _IORegistryEntryFromPath
__ IOKit: _kIOMasterPortDefault
__ IOSurfaceAccelerator: _IOSurfaceAcceleratorCreate
__ IOSurfaceAccelerator: _IOSurfaceAcceleratorTransformSurface
__ ImageIO: _CGImageDestinationAddImageAndMetadata
__ ImageIO: _CGImageDestinationCreateWithData
__ ImageIO: _CGImageDestinationFinalize
__ ImageIO: _CGImageMetadataCopyStringValueWithPath
__ ImageIO: _CGImageMetadataCreateMutable
__ ImageIO: _CGImageMetadataRegisterNamespaceForPrefix
__ ImageIO: _CGImageMetadataSetValueWithPath
__ ImageIO: _CGImageSourceCopyMetadataAtIndex
__ ImageIO: _CGImageSourceCopyPropertiesAtIndex
__ ImageIO: _CGImageSourceCreateIOSurfaceAtIndex
__ ImageIO: _CGImageSourceCreateImageAtIndex
__ ImageIO: _CGImageSourceCreateWithData
__ ImageIO: _CGImageSourceCreateWithURL
__ ImageIO: _kCGImageDestinationLossyCompressionQuality
__ ImageIO: _kCGImagePropertyExifAuxDictionary
__ ImageIO: _kCGImagePropertyExifAuxROIRegionFaceType
__ ImageIO: _kCGImagePropertyExifAuxROIRegionHeight
__ ImageIO: _kCGImagePropertyExifAuxROIRegionList
__ ImageIO: _kCGImagePropertyExifAuxROIRegionType
__ ImageIO: _kCGImagePropertyExifAuxROIRegionWidth
__ ImageIO: _kCGImagePropertyExifAuxROIRegionX
__ ImageIO: _kCGImagePropertyExifAuxROIRegionY
__ ImageIO: _kCGImagePropertyExifDictionary
__ ImageIO: _kCGImagePropertyExifExposureTime
__ ImageIO: _kCGImagePropertyExifFlash
__ ImageIO: _kCGImagePropertyMakerAppleDictionary
__ ImageIO: _kCGImagePropertyOrientation
__ ImageIO: _kCGImagePropertyPixelHeight
__ ImageIO: _kCGImagePropertyPixelWidth
__ ImageIO: _kCGImagePropertyTIFFDictionary
__ ImageIO: _kCGImagePropertyTIFFMake
__ ImageIO: _kCGImagePropertyTIFFModel
__ ImageIO: _kCGImageSourceShouldCache
__ ImageIO: _kCGImageSourceSkipMetadata
__ ImageIO: _kCGImageSourceSubsampleFactor
__ ImageIO: _kCGImageSourceUseCoreImage
__ ImageIO: _kCGImageSourceUseHardwareAcceleration
__ InertiaCam: _ICAnalysisAddFrame
__ InertiaCam: _ICAnalysisInit
__ InertiaCam: _ICAnalysisStopAndGetResult
__ InertiaCam: _ICCalcCinematicL1Corrections
__ InertiaCam: _ICDestroyResult
__ InertiaCam: _ICFillHomographyGaps
__ InertiaCam: _ICGetAnalysisConfidence
__ InertiaCam: _ICGetResultConfidence
__ InertiaCam: _ICGetResultHomographies
__ InertiaCam: _ICGetResultStats
__ InertiaCam: _ICStoreAnalyticsViaDodML
__ InertiaCam: _ICSynthesizeAnalysis
__ InertiaCam: _IC_ANALYTICS_SOURCETYPE_LIVEPHOTO
__ InertiaCam: _IC_ANALYTICS_SOURCETYPE_OTHERVIDEO
__ InertiaCam: _IC_A_FRAMEINSTRUCTIONS
__ InertiaCam: _IC_A_FRAMETRANSFORM_HOMOGRAPHY
__ InertiaCam: _IC_A_FRAMETRANSFORM_RAWTIME
__ InertiaCam: _IC_A_HOMOGRAPHIES_INVERTED
__ InertiaCam: _IC_A_HOMOGRAPHIES_MAP_TO_REFERENCE
__ InertiaCam: _IC_A_REQUESTED_CROP_RECT
__ InertiaCam: _IC_A_SOURCE_SIZE
__ InertiaCam: _IC_A_STAT_FRAME_COUNT
__ InertiaCam: _IC_A_TRIM_DURATION
__ InertiaCam: _IC_A_TRIM_START_TIME
__ InertiaCam: _IC_C_CROP_FRACTION
__ InertiaCam: _IC_C_FIRST_INDEX
__ InertiaCam: _IC_C_LAST_INDEX
__ InertiaCam: _IC_C_MOTION_BLUR_VECTOR
__ MediaAnalysisServices: _OBJC_CLASS_$_MADEmbeddingGenerationRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADImageSafetyClassificationRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADImageSafetyClassificationResult
__ MediaAnalysisServices: _OBJC_CLASS_$_MADRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIDocumentRecognitionRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIDocumentRecognitionResult
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIMachineReadableCodeDetectionRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIMachineReadableCodeDetectionResult
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchGatingDomainInfo
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchGatingRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchGatingResult
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchGatingResultItem
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchRegionAttributes
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchRequest
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchResult
__ MediaAnalysisServices: _OBJC_CLASS_$_MADVIVisualSearchResultItem
__ MediaToolbox: _FigAssetCreateWithByteStream
__ MediaToolbox: _FigAssetReaderCreateWithAsset
__ MediaToolbox: _kFigFileType_QuickTimeMovie
__ Metal: _MTLCreateSystemDefaultDevice
__ Metal: _OBJC_CLASS_$_MTLTextureDescriptor
__ MetalPerformanceShaders: _MPSSetHeapCacheDuration
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNBinaryConvolution
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNConvolution
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNConvolutionDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNDepthWiseConvolutionDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNFullyConnected
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSCNNPoolingMax
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImage
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImageBilinearScale
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSImageDescriptor
__ MetalPerformanceShaders: _OBJC_CLASS_$_MPSTemporaryImage
__ PhotoLibraryServices: _kPLLocationUtilsCoarseLocationHorizontalAccuracy
__ Photos: _OBJC_CLASS_$_PHAsset
__ Photos: _OBJC_CLASS_$_PHAssetChangeRequest
__ Photos: _OBJC_CLASS_$_PHAssetCollection
__ Photos: _OBJC_CLASS_$_PHAssetResource
__ Photos: _OBJC_CLASS_$_PHAssetResourceManager
__ Photos: _OBJC_CLASS_$_PHAssetResourceRequestOptions
__ Photos: _OBJC_CLASS_$_PHCollection
__ Photos: _OBJC_CLASS_$_PHFace
__ Photos: _OBJC_CLASS_$_PHFaceChangeRequest
__ Photos: _OBJC_CLASS_$_PHFaceCrop
__ Photos: _OBJC_CLASS_$_PHFaceCropChangeRequest
__ Photos: _OBJC_CLASS_$_PHFaceGroup
__ Photos: _OBJC_CLASS_$_PHFaceGroupChangeRequest
__ Photos: _OBJC_CLASS_$_PHFaceprint
__ Photos: _OBJC_CLASS_$_PHFetchOptions
__ Photos: _OBJC_CLASS_$_PHFetchResult
__ Photos: _OBJC_CLASS_$_PHMoment
__ Photos: _OBJC_CLASS_$_PHObject
__ Photos: _OBJC_CLASS_$_PHPerson
__ Photos: _OBJC_CLASS_$_PHPersonChangeRequest
__ Photos: _OBJC_CLASS_$_PHPhotoLibrary
__ Photos: _OBJC_CLASS_$_PHSceneClassification
__ Photos: _PHAssetMediaAnalysisDataWithColorNormalizationDictionaryAndRevision
__ Photos: _PHAssetPropertySetCharacterRecognition
__ Photos: _PHAssetPropertySetCloudLocalState
__ Photos: _PHAssetPropertySetCore
__ Photos: _PHAssetPropertySetCuration
__ Photos: _PHAssetPropertySetFaceWorker
__ Photos: _PHAssetPropertySetIdentifier
__ Photos: _PHAssetPropertySetMediaAnalysis
__ Photos: _PHAssetPropertySetOriginalMetadata
__ Photos: _PHAssetPropertySetPhotoIris
__ Photos: _PHAssetPropertySetPlacesCore
__ Photos: _PHAssetPropertySetSceneAnalysis
__ Photos: _PHAssetPropertySetSceneprint
__ Photos: _PHAssetPropertySetVisualSearch
__ Photos: _PHFacePropertySetClustering
__ Photos: _PHFacePropertySetCore
__ Photos: _PHFacePropertySetIdentifier
__ Photos: _PHFacePropertySetPersonBuilder
__ Photos: _PHPhotosErrorDomain
__ PhotosFormats: _OBJC_CLASS_$_PFPhotosFaceUtilities
__ PhotosFormats: _OBJC_CLASS_$_PFSlowMotionConfiguration
__ PhotosFormats: _OBJC_CLASS_$_PFSlowMotionUtilities
__ PhotosFormats: _OBJC_CLASS_$_PFVideoAVObjectBuilder
__ PhotosFormats: _OBJC_CLASS_$_PFVideoAdjustments
__ PhotosFormats: _PFPhotosSceneProcessingFromCameraVersion
__ ProtocolBuffer: _OBJC_CLASS_$_PBCodable
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._bytes
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._error
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._length
__ ProtocolBuffer: _OBJC_IVAR_$_PBDataReader._pos
__ ProtocolBuffer: _OBJC_METACLASS_$_PBCodable
__ ProtocolBuffer: _PBDataWriterPlaceMark
__ ProtocolBuffer: _PBDataWriterRecallMark
__ ProtocolBuffer: _PBDataWriterWriteBOOLField
__ ProtocolBuffer: _PBDataWriterWriteDataField
__ ProtocolBuffer: _PBDataWriterWriteDoubleField
__ ProtocolBuffer: _PBDataWriterWriteFloatField
__ ProtocolBuffer: _PBDataWriterWriteInt32Field
__ ProtocolBuffer: _PBDataWriterWriteInt64Field
__ ProtocolBuffer: _PBDataWriterWriteStringField
__ ProtocolBuffer: _PBDataWriterWriteSubmessage
__ ProtocolBuffer: _PBDataWriterWriteUint32Field
__ ProtocolBuffer: _PBDataWriterWriteUint64Field
__ ProtocolBuffer: _PBReaderPlaceMark
__ ProtocolBuffer: _PBReaderReadData
__ ProtocolBuffer: _PBReaderReadString
__ ProtocolBuffer: _PBReaderRecallMark
__ ProtocolBuffer: _PBReaderSkipValueWithTag
__ ProtocolBuffer: _PBRepeatedFloatAdd
__ ProtocolBuffer: _PBRepeatedFloatClear
__ ProtocolBuffer: _PBRepeatedFloatCopy
__ ProtocolBuffer: _PBRepeatedFloatHash
__ ProtocolBuffer: _PBRepeatedFloatIsEqual
__ ProtocolBuffer: _PBRepeatedFloatNSArray
__ ProtocolBuffer: _PBRepeatedFloatSet
__ ProtocolBuffer: _PBRepeatedInt64Add
__ ProtocolBuffer: _PBRepeatedInt64Clear
__ ProtocolBuffer: _PBRepeatedInt64Copy
__ ProtocolBuffer: _PBRepeatedInt64Hash
__ ProtocolBuffer: _PBRepeatedInt64IsEqual
__ ProtocolBuffer: _PBRepeatedInt64NSArray
__ ProtocolBuffer: _PBRepeatedInt64Set
__ ProtocolBuffer: __ZN2PB13TextFormatter11beginObjectEPKc
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKcd
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKcf
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKci
__ ProtocolBuffer: __ZN2PB13TextFormatter6formatEPKcj
__ ProtocolBuffer: __ZN2PB13TextFormatter9endObjectEv
__ ProtocolBuffer: __ZN2PB4BaseD2Ev
__ ProtocolBuffer: __ZN2PB6Reader10recallMarkERKNS_10ReaderMarkE
__ ProtocolBuffer: __ZN2PB6Reader4skipEjhi
__ ProtocolBuffer: __ZN2PB6Reader9placeMarkERNS_10ReaderMarkE
__ ProtocolBuffer: __ZN2PB6ReaderC1EPKhm
__ ProtocolBuffer: __ZN2PB6Writer11writeVarIntEij
__ ProtocolBuffer: __ZN2PB6Writer11writeVarIntEjj
__ ProtocolBuffer: __ZN2PB6Writer15writeSubmessageERKNS_4BaseEj
__ ProtocolBuffer: __ZN2PB6Writer5writeEdj
__ ProtocolBuffer: __ZN2PB6Writer5writeEfj
__ ProtocolBuffer: __ZN2PB6WriterC1Ev
__ ProtocolBuffer: __ZN2PB6WriterD1Ev
__ ProtocolBuffer: __ZTIN2PB4BaseE
__ SoftLinking: __sl_dlopen
__ SoundAnalysis: _OBJC_CLASS_$_SNAudioStreamAnalyzer
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectSoundRequest
__ SoundAnalysis: _OBJC_CLASS_$_SNDetectionResult
__ SoundAnalysis: _SNSoundIdentifierApplause
__ SoundAnalysis: _SNSoundIdentifierBabble
__ SoundAnalysis: _SNSoundIdentifierCheering
__ SoundAnalysis: _SNSoundIdentifierLaughter
__ SoundAnalysis: _SNSoundIdentifierMusic
__ SoundAnalysis: _SNSoundIdentifierSpeech
__ SystemConfiguration: _SCNetworkReachabilityCreateWithAddress
__ SystemConfiguration: _SCNetworkReachabilityGetFlags
__ SystemConfiguration: _SCNetworkReachabilitySetCallback
__ SystemConfiguration: _SCNetworkReachabilitySetDispatchQueue
__ UniformTypeIdentifiers: _OBJC_CLASS_$_UTType
__ UniformTypeIdentifiers: _UTTypeHEIC
__ UniformTypeIdentifiers: _UTTypeHEIF
__ UniformTypeIdentifiers: _UTTypeImage
__ UniformTypeIdentifiers: _UTTypeJPEG
__ UniformTypeIdentifiers: _UTTypeMovie
__ UniformTypeIdentifiers: _UTTypePNG
__ UniformTypeIdentifiers: _UTTypeVideo
__ VideoToolbox: _VTCompressionSessionCompleteFrames
__ VideoToolbox: _VTCompressionSessionCreate
__ VideoToolbox: _VTCompressionSessionEncodeFrame
__ VideoToolbox: _VTCompressionSessionPrepareToEncodeFrames
__ VideoToolbox: _VTCreateCGImageFromCVPixelBuffer
__ VideoToolbox: _VTImageRotationSessionCreate
__ VideoToolbox: _VTImageRotationSessionTransferImage
__ VideoToolbox: _VTPixelTransferSessionCreate
__ VideoToolbox: _VTPixelTransferSessionTransferImage
__ VideoToolbox: _VTSessionSetProperty
__ VideoToolbox: _kVTCompressionPropertyKey_AllowFrameReordering
__ VideoToolbox: _kVTCompressionPropertyKey_AllowOpenGOP
__ VideoToolbox: _kVTCompressionPropertyKey_AllowTemporalCompression
__ VideoToolbox: _kVTCompressionPropertyKey_AverageBitRate
__ VideoToolbox: _kVTCompressionPropertyKey_BaseLayerFrameRate
__ VideoToolbox: _kVTCompressionPropertyKey_FigThreadPriority
__ VideoToolbox: _kVTCompressionPropertyKey_MaximizePowerEfficiency
__ VideoToolbox: _kVTCompressionPropertyKey_Priority
__ VideoToolbox: _kVTCompressionPropertyKey_QuantizationScalingMatrixPreset
__ VideoToolbox: _kVTCompressionPropertyKey_RealTime
__ VideoToolbox: _kVTCompressionPropertyKey_Usage
__ VideoToolbox: _kVTCompressionProperty_MaxQuantizationParameter
__ VideoToolbox: _kVTCompressionProperty_SoftMinQuantizationParameter
__ VideoToolbox: _kVTPixelTransferPropertyKey_ScalingMode
__ VideoToolbox: _kVTScalingMode_CropSourceToCleanAperture
__ VideoToolbox: _kVTVideoEncoderSpecification_RequireHardwareAcceleratedVideoEncoder
__ Vision: _OBJC_CLASS_$_VN1JC7R3k4455fKQz0dY1VhQ
__ Vision: _OBJC_CLASS_$_VN5kJNH3eYuyaLxNpZr5Z7zi
__ Vision: _OBJC_CLASS_$_VN6Mb1ME89lyW3HpahkEygIG
__ Vision: _OBJC_CLASS_$_VN6kBnCOr2mZlSV6yV1dLwB
__ Vision: _OBJC_CLASS_$_VNAlignFaceRectangleRequest
__ Vision: _OBJC_CLASS_$_VNAnimalObservation
__ Vision: _OBJC_CLASS_$_VNAnimalprint
__ Vision: _OBJC_CLASS_$_VNBarcodeObservation
__ Vision: _OBJC_CLASS_$_VNCanceller
__ Vision: _OBJC_CLASS_$_VNClassifyFaceAttributesRequest
__ Vision: _OBJC_CLASS_$_VNClassifyImageAestheticsRequest
__ Vision: _OBJC_CLASS_$_VNClassifyJunkImageRequest
__ Vision: _OBJC_CLASS_$_VNClassifyMemeImageRequest
__ Vision: _OBJC_CLASS_$_VNClassifyPotentialLandmarkRequest
__ Vision: _OBJC_CLASS_$_VNClustererBuilder
__ Vision: _OBJC_CLASS_$_VNClustererBuilderOptions
__ Vision: _OBJC_CLASS_$_VNClustererQuery
__ Vision: _OBJC_CLASS_$_VNCreateAnimalprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateFaceTorsoprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateFaceprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateImageprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateNeuralHashprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateSceneprintRequest
__ Vision: _OBJC_CLASS_$_VNCreateTorsoprintRequest
__ Vision: _OBJC_CLASS_$_VNDetectBarcodesRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceCaptureQualityRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceExpressionsRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceGazeRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceLandmarksRequest
__ Vision: _OBJC_CLASS_$_VNDetectFacePoseRequest
__ Vision: _OBJC_CLASS_$_VNDetectFaceRectanglesRequest
__ Vision: _OBJC_CLASS_$_VNDetectHumanRectanglesRequest
__ Vision: _OBJC_CLASS_$_VNDocumentObservation
__ Vision: _OBJC_CLASS_$_VNEntityIdentificationModel
__ Vision: _OBJC_CLASS_$_VNEntityIdentificationModelConfiguration
__ Vision: _OBJC_CLASS_$_VNEntityIdentificationModelReadOptions
__ Vision: _OBJC_CLASS_$_VNEntityIdentificationModelWriteOptions
__ Vision: _OBJC_CLASS_$_VNFaceObservation
__ Vision: _OBJC_CLASS_$_VNFaceTorsoprint
__ Vision: _OBJC_CLASS_$_VNFaceprint
__ Vision: _OBJC_CLASS_$_VNGenerateAttentionBasedSaliencyImageRequest
__ Vision: _OBJC_CLASS_$_VNGenerateObjectnessBasedSaliencyImageRequest
__ Vision: _OBJC_CLASS_$_VNIdentifyJunkRequest
__ Vision: _OBJC_CLASS_$_VNImageBlurScoreRequest
__ Vision: _OBJC_CLASS_$_VNImageExposureScoreRequest
__ Vision: _OBJC_CLASS_$_VNImageRequestHandler
__ Vision: _OBJC_CLASS_$_VNImageprint
__ Vision: _OBJC_CLASS_$_VNMutableEntityIdentificationModel
__ Vision: _OBJC_CLASS_$_VNMutablePersonsModel
__ Vision: _OBJC_CLASS_$_VNPersonsModel
__ Vision: _OBJC_CLASS_$_VNPersonsModelConfiguration
__ Vision: _OBJC_CLASS_$_VNPersonsModelReadOptions
__ Vision: _OBJC_CLASS_$_VNPersonsModelWriteOptions
__ Vision: _OBJC_CLASS_$_VNProcessingDevice
__ Vision: _OBJC_CLASS_$_VNRecognizeAnimalsRequest
__ Vision: _OBJC_CLASS_$_VNRecognizeDocumentElementsRequest
__ Vision: _OBJC_CLASS_$_VNRecognizeDocumentsRequest
__ Vision: _OBJC_CLASS_$_VNRecognizeObjectsRequest
__ Vision: _OBJC_CLASS_$_VNRequest
__ Vision: _OBJC_CLASS_$_VNSceneClassificationRequest
__ Vision: _OBJC_CLASS_$_VNSceneObservation
__ Vision: _OBJC_CLASS_$_VNSceneprint
__ Vision: _OBJC_CLASS_$_VNSession
__ Vision: _OBJC_CLASS_$_VNVYvzEtX1JlUdu8xx5qhDI
__ Vision: _VN0af6454e97767772ce64a19ddaf61f0c
__ Vision: _VN1HsiXmKrxTsH8TYOuN5s7G3uHSP75iYS
__ Vision: _VN1I7oR8JHxER2i7d6nQxNtHhGXxkJuH7c
__ Vision: _VN1PwKd46IDZj2ErCN9d1fTn3FuN3h4d9p
__ Vision: _VN1VQUXOcXrfZPXtaGgfZBhujM6uH6hvmI
__ Vision: _VN1kD4zwSpSn6esc2wHjyAeZ2IRmwqjgtt
__ Vision: _VN1yPD9G185LIMKFd9RgandG6vUu4B3DZk
__ Vision: _VN21VM8NbCJMJjpepNo1kZkxteFybpDwlB
__ Vision: _VN220a6626eb3cb51295a4e250ad9da319
__ Vision: _VN2AhEqI0IOCJAaCX6zovlg85aFZ80JfES
__ Vision: _VN2DSYD77FUMKqtcogofprEd
__ Vision: _VN2TVJG6FfNTt72vwVKOv1Jf5dWtEHvQIS
__ Vision: _VN2X5h7waRTqk71pInqK4dnT6sZ6dRElxe
__ Vision: _VN2eECeAuLQ8wnXvvNNkc5XEtpjqyiYvIp
__ Vision: _VN2nEhtfck4KB7KsvJeCeSEPcGLfKzeUKi
__ Vision: _VN2vIWnsZbk4Su55oeWfKDq1
__ Vision: _VN31UxDngUK44hDexm8CSuZnlLxECLb0yU
__ Vision: _VN34LMYSFC7onytwsvH0y6uz2QaYvqY9qi
__ Vision: _VN35FOB1QhtSfYGRIJvTgtTq
__ Vision: _VN3FNQUJVIs2puI1uPc9mxh7
__ Vision: _VN3WbFaDRN3PTBiMaMEq5ttCx7hmmfySmR
__ Vision: _VN3rKrpi4DELvo8AgM5Y3C68ryFlgB1grk
__ Vision: _VN42tJSMaSWdsAnZKXv8XcZg2j2AIS7gjm
__ Vision: _VN465E5iEqlR2tknJ0qZkyAn3yIDrmUpJw
__ Vision: _VN4MFjUmPIIWefw2ZktBTwVB
__ Vision: _VN4QuphG8kE4qDaDycivBkX5
__ Vision: _VN4bzonkXHYlzBnJNXcyyPd8WLw1wAI1Pv
__ Vision: _VN4lC1NTVMt6oWugtej0fqgS3z5p60aMup
__ Vision: _VN4lCLwxDV30rFLSeoihd8yM1zdbka3cVu
__ Vision: _VN4oD9MSPBdmmSq6KG3k7nYqdSMT5aNp6p
__ Vision: _VN4qKg9nfl3p0M4juXFIsbUb7tpfCv9epx
__ Vision: _VN5JBEfctS0JUWeTVUxBAKOSXCUuMqPxTg
__ Vision: _VN5SpoOVxahuTheCrHGepAYKTVB1baFLhQ
__ Vision: _VN5iEOkR2NrIkLsZRvJTn61k1ovk3hvuxY
__ Vision: _VN5ijZTfHVHp6ubCHBh4oIZR1SW4xbvQ00
__ Vision: _VN607hNga4JKRc1ljftiy9QfPCqbXQmLP4
__ Vision: _VN62b042cc67e0a7d589ecdb58232fe23d
__ Vision: _VN6LhAjooMZpZkrkhS48XbQt7602EpEAxv
__ Vision: _VN6XNMvaRunPpzWjGa9uUHD6
__ Vision: _VN6YAJH4UBXYDBoH6cemKhJR7fPi2dt5Qd
__ Vision: _VN6ZsEIQ9ri2eF1vhsxw5COm
__ Vision: _VN6a4sQBuQ5pSiUEd6p9iQflpz8xkWOnD2
__ Vision: _VN6cM1E1jfvMnUZoEeDjinPOtJKpacqIpr
__ Vision: _VN6i04vrZluouTItkCUMtS916cLgTyvODX
__ Vision: _VN6lDi9hTBjr2vdjAJ5rwdun4YEH09u5F5
__ Vision: _VN6pbJdmseepvIGYzcDyryle1xGdZEWhHN
__ Vision: _VN79a8f83d9d55eb4eb2c9695902c47b53
__ Vision: _VN7CY11MLEimaE8WoiQ4opgi5HOi84j0UH
__ Vision: _VN7ICFqxCpgr8BTWkFrFGYTQ3INUhxhYXR
__ Vision: _VN7ar6bR0PqRvM9BZ0nqEdwh61tXzue1Ut
__ Vision: _VN7gQUejje8mmnE9GSTsVBVV
__ Vision: _VN7ja3fTi9TZDyKN8NdYJaWqla1NRFdcRX
__ Vision: _VN7vELTVTtPH26ptfCYi9dUHH8NxJ7O3cF
__ Vision: _VN7yMsLB9ggBYLDbJYIMGMSW6YBgi5uH2p
__ Vision: _VN81aedeb999c79d74e79af7f1c922cf97
__ Vision: _VN9bdc36cda32be948a5089e37392596ec
__ Vision: _VN9f5b8e9dc1b3c824d79372f87b072ee3
__ Vision: _VNBarcodeSymbologyAppClipCode
__ Vision: _VNBarcodeSymbologyQR
__ Vision: _VNClusteringAlgorithm_Greedy
__ Vision: _VNClusteringAlgorithm_GreedyWithTorso
__ Vision: _VNDGCsUiwnQwGz0qSSQPGGd177EyoSaoGN
__ Vision: _VNErrorDomain
__ Vision: _VNExpressionFaceSmiling
__ Vision: _VNFaceAttributeAgeAdult
__ Vision: _VNFaceAttributeAgeBaby
__ Vision: _VNFaceAttributeAgeChild
__ Vision: _VNFaceAttributeAgeSenior
__ Vision: _VNFaceAttributeAgeYoungAdult
__ Vision: _VNFaceAttributeEyesClosed
__ Vision: _VNFaceAttributeEyesOpen
__ Vision: _VNFaceAttributeFaceHairBeard
__ Vision: _VNFaceAttributeFaceHairGoatee
__ Vision: _VNFaceAttributeFaceHairMoustache
__ Vision: _VNFaceAttributeFaceHairStubble
__ Vision: _VNFaceAttributeFaceHairUnsure
__ Vision: _VNFaceAttributeGlassesNone
__ Vision: _VNFaceAttributeGlassesPrescription
__ Vision: _VNFaceAttributeGlassesSunglasses
__ Vision: _VNFaceAttributeHairColorBlack
__ Vision: _VNFaceAttributeHairColorBlonde
__ Vision: _VNFaceAttributeHairColorBrown
__ Vision: _VNFaceAttributeHairColorGray
__ Vision: _VNFaceAttributeHairColorRed
__ Vision: _VNFaceAttributeHairColorWhite
__ Vision: _VNFaceAttributeNotSmiling
__ Vision: _VNFaceAttributeSmiling
__ Vision: _VNPdH78Lr962vQvRIq2JApX2QJZtbR3fvi
__ Vision: _VNPotentialLandmarkIdentifier
__ Vision: _VNRecognizeDocumentElementIdentifierAppCode
__ Vision: _VNRecognizeDocumentElementIdentifierDocument
__ Vision: _VNRecognizeDocumentElementIdentifierQRCode
__ Vision: _VNRecognizeDocumentElementIdentifierText
__ Vision: _VNRequestWarningImageTooSmall
__ Vision: _VNRequestWarningImageTooSmallForFaceObservations
__ Vision: _VNSY8t4EoTztuqIL02g8uVA0
__ Vision: _VNVideoProcessingOptionFrameCadence
__ Vision: _VNVideoProcessingOptionTimeInterval
__ Vision: _VNa0c07362d05e1dafb35b96d20d5ce42d
__ Vision: _VNa9xpOJNvRoaW9plFGZ9Eo0
__ Vision: _VNacdca02f0900c2cb198193f3eec7b6c9
__ Vision: _VNbe5c67b06e95370f5a7b67b13e73637c
__ Vision: _VNeeab04670e53ebeb25150a31963a1aa6
__ Vision: _VNmNJnu0xlW8CZXt6hJ7Rpb0
__ VisualIntelligence: _OBJC_CLASS_$_VIAnnotation
__ VisualIntelligence: _OBJC_CLASS_$_VIImageRegion
__ VisualIntelligence: _OBJC_CLASS_$_VIParsedVisualQuery
__ VisualIntelligence: _OBJC_CLASS_$_VIQueryContext
__ VisualIntelligence: _OBJC_CLASS_$_VIRegionalAnnotation
__ VisualIntelligence: _OBJC_CLASS_$_VIService
__ VisualIntelligence: _OBJC_CLASS_$_VITextBlockAnnotation
__ VisualIntelligence: _OBJC_CLASS_$_VIVisualQuery
__ VisualIntelligence: _VIQueryContextApplicationIdentifierKey
__ VisualIntelligence: _VIQueryContextFeatureIdentifierKey
__ VisualIntelligence: _VIQueryContextImageTypeKey
__ VisualIntelligence: _VIQueryContextImageURLKey
__ VisualIntelligence: _VIQueryContextLocationKey
__ VisualIntelligence: _VIQueryContextPreferredMetalDeviceKey
__ VisualIntelligence: _VIQueryContextQueryIDKey
__ VisualIntelligence: _VIQueryContextReferralURLKey
__ VisualIntelligence: _VIQueryContextUIScaleKey
__ libMobileGestalt.dylib: _MGGetBoolAnswer
__ libMobileGestalt.dylib: _MGGetStringAnswer
__ libSystem.B.dylib: _APP_SANDBOX_READ
__ libSystem.B.dylib: _APP_SANDBOX_READ_WRITE
__ libSystem.B.dylib: _CC_MD5_Final
__ libSystem.B.dylib: _CC_MD5_Init
__ libSystem.B.dylib: _CC_MD5_Update
__ libSystem.B.dylib: _CC_SHA1
__ libSystem.B.dylib: _CC_SHA256
__ libSystem.B.dylib: __Block_copy
__ libSystem.B.dylib: __Block_object_assign
__ libSystem.B.dylib: __Block_object_dispose
__ libSystem.B.dylib: __Block_release
__ libSystem.B.dylib: __NSConcreteGlobalBlock
__ libSystem.B.dylib: __NSConcreteStackBlock
__ libSystem.B.dylib: __Unwind_Resume
__ libSystem.B.dylib: ___chkstk_darwin
__ libSystem.B.dylib: ___cxa_atexit
__ libSystem.B.dylib: ___error
__ libSystem.B.dylib: ___sincos_stret
__ libSystem.B.dylib: ___sincosf_stret
__ libSystem.B.dylib: ___stack_chk_fail
__ libSystem.B.dylib: ___stack_chk_guard
__ libSystem.B.dylib: __dispatch_source_type_timer
__ libSystem.B.dylib: __os_feature_enabled_impl
__ libSystem.B.dylib: __os_log_default
__ libSystem.B.dylib: __os_log_error_impl
__ libSystem.B.dylib: __os_log_impl
__ libSystem.B.dylib: __os_signpost_emit_with_name_impl
__ libSystem.B.dylib: _abort
__ libSystem.B.dylib: _abort_report_np
__ libSystem.B.dylib: _acosf
__ libSystem.B.dylib: _asinf
__ libSystem.B.dylib: _atan2f
__ libSystem.B.dylib: _atanf
__ libSystem.B.dylib: _bzero
__ libSystem.B.dylib: _calloc
__ libSystem.B.dylib: _close
__ libSystem.B.dylib: _cosf
__ libSystem.B.dylib: _dispatch_apply
__ libSystem.B.dylib: _dispatch_async
__ libSystem.B.dylib: _dispatch_get_global_queue
__ libSystem.B.dylib: _dispatch_group_async
__ libSystem.B.dylib: _dispatch_group_create
__ libSystem.B.dylib: _dispatch_group_enter
__ libSystem.B.dylib: _dispatch_group_leave
__ libSystem.B.dylib: _dispatch_group_wait
__ libSystem.B.dylib: _dispatch_once
__ libSystem.B.dylib: _dispatch_once_f
__ libSystem.B.dylib: _dispatch_queue_attr_make_with_autorelease_frequency
__ libSystem.B.dylib: _dispatch_queue_create
__ libSystem.B.dylib: _dispatch_resume
__ libSystem.B.dylib: _dispatch_semaphore_create
__ libSystem.B.dylib: _dispatch_semaphore_signal
__ libSystem.B.dylib: _dispatch_semaphore_wait
__ libSystem.B.dylib: _dispatch_source_cancel
__ libSystem.B.dylib: _dispatch_source_create
__ libSystem.B.dylib: _dispatch_source_set_event_handler
__ libSystem.B.dylib: _dispatch_source_set_timer
__ libSystem.B.dylib: _dispatch_sync
__ libSystem.B.dylib: _dispatch_time
__ libSystem.B.dylib: _dlerror
__ libSystem.B.dylib: _dlsym
__ libSystem.B.dylib: _erff
__ libSystem.B.dylib: _exp
__ libSystem.B.dylib: _exp2f
__ libSystem.B.dylib: _expf
__ libSystem.B.dylib: _fclose
__ libSystem.B.dylib: _fmod
__ libSystem.B.dylib: _fmodf
__ libSystem.B.dylib: _fopen
__ libSystem.B.dylib: _fprintf
__ libSystem.B.dylib: _fread
__ libSystem.B.dylib: _free
__ libSystem.B.dylib: _hypotf
__ libSystem.B.dylib: _log10f
__ libSystem.B.dylib: _log2
__ libSystem.B.dylib: _log2f
__ libSystem.B.dylib: _logf
__ libSystem.B.dylib: _lseek
__ libSystem.B.dylib: _mach_absolute_time
__ libSystem.B.dylib: _mach_timebase_info
__ libSystem.B.dylib: _malloc
__ libSystem.B.dylib: _matrix_identity_float4x4
__ libSystem.B.dylib: _memcmp
__ libSystem.B.dylib: _memcpy
__ libSystem.B.dylib: _memmove
__ libSystem.B.dylib: _memset
__ libSystem.B.dylib: _memset_pattern16
__ libSystem.B.dylib: _open
__ libSystem.B.dylib: _os_log_create
__ libSystem.B.dylib: _os_log_type_enabled
__ libSystem.B.dylib: _os_signpost_enabled
__ libSystem.B.dylib: _os_signpost_id_generate
__ libSystem.B.dylib: _os_transaction_create
__ libSystem.B.dylib: _os_variant_has_internal_diagnostics
__ libSystem.B.dylib: _posix_memalign
__ libSystem.B.dylib: _powf
__ libSystem.B.dylib: _pread
__ libSystem.B.dylib: _printf
__ libSystem.B.dylib: _puts
__ libSystem.B.dylib: _qos_class_self
__ libSystem.B.dylib: _qsort
__ libSystem.B.dylib: _read
__ libSystem.B.dylib: _rename
__ libSystem.B.dylib: _sandbox_extension_consume
__ libSystem.B.dylib: _sandbox_extension_issue_file
__ libSystem.B.dylib: _sandbox_extension_release
__ libSystem.B.dylib: _sinf
__ libSystem.B.dylib: _strcmp
__ libSystem.B.dylib: _strlen
__ libSystem.B.dylib: _strspn
__ libSystem.B.dylib: _tan
__ libSystem.B.dylib: _write
__ libc++.1.dylib: __ZNKSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEE3strEv
__ libc++.1.dylib: __ZNKSt3__119__shared_weak_count13__get_deleterERKSt9type_info
__ libc++.1.dylib: __ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNKSt3__121__basic_string_commonILb1EE20__throw_length_errorEv
__ libc++.1.dylib: __ZNKSt3__16locale9use_facetERNS0_2idE
__ libc++.1.dylib: __ZNKSt3__18ios_base6getlocEv
__ libc++.1.dylib: __ZNKSt9exception4whatEv
__ libc++.1.dylib: __ZNSt11logic_errorC2EPKc
__ libc++.1.dylib: __ZNSt12length_errorD1Ev
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6resizeEmc
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC1ERKS5_
__ libc++.1.dylib: __ZNSt3__112basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEED1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE3putEc
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE5flushEv
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE6sentryC1ERS3_
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEE6sentryD1Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEb
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEd
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEi
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEl
__ libc++.1.dylib: __ZNSt3__113basic_ostreamIcNS_11char_traitsIcEEElsEm
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEEC2Ev
__ libc++.1.dylib: __ZNSt3__115basic_streambufIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt3__119__shared_weak_count14__release_weakEv
__ libc++.1.dylib: __ZNSt3__119__shared_weak_countD2Ev
__ libc++.1.dylib: __ZNSt3__14cerrE
__ libc++.1.dylib: __ZNSt3__14coutE
__ libc++.1.dylib: __ZNSt3__15ctypeIcE2idE
__ libc++.1.dylib: __ZNSt3__15mutex4lockEv
__ libc++.1.dylib: __ZNSt3__15mutex6unlockEv
__ libc++.1.dylib: __ZNSt3__15mutexD1Ev
__ libc++.1.dylib: __ZNSt3__16localeD1Ev
__ libc++.1.dylib: __ZNSt3__18ios_base33__set_badbit_and_consider_rethrowEv
__ libc++.1.dylib: __ZNSt3__18ios_base4initEPv
__ libc++.1.dylib: __ZNSt3__18ios_base5clearEj
__ libc++.1.dylib: __ZNSt3__19basic_iosIcNS_11char_traitsIcEEED2Ev
__ libc++.1.dylib: __ZNSt9exceptionD2Ev
__ libc++.1.dylib: __ZSt13set_terminatePFvvE
__ libc++.1.dylib: __ZSt7nothrow
__ libc++.1.dylib: __ZSt9terminatev
__ libc++.1.dylib: __ZTINSt3__119__shared_weak_countE
__ libc++.1.dylib: __ZTISt12length_error
__ libc++.1.dylib: __ZTISt9bad_alloc
__ libc++.1.dylib: __ZTISt9exception
__ libc++.1.dylib: __ZTIi
__ libc++.1.dylib: __ZTTNSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
__ libc++.1.dylib: __ZTVN10__cxxabiv117__class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv120__si_class_type_infoE
__ libc++.1.dylib: __ZTVN10__cxxabiv121__vmi_class_type_infoE
__ libc++.1.dylib: __ZTVNSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
__ libc++.1.dylib: __ZTVNSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
__ libc++.1.dylib: __ZTVSt12length_error
__ libc++.1.dylib: __ZdaPv
__ libc++.1.dylib: __ZdaPvRKSt9nothrow_t
__ libc++.1.dylib: __ZdlPv
__ libc++.1.dylib: __ZdlPvRKSt9nothrow_t
__ libc++.1.dylib: __Znam
__ libc++.1.dylib: __ZnamRKSt9nothrow_t
__ libc++.1.dylib: __Znwm
__ libc++.1.dylib: __ZnwmRKSt9nothrow_t
__ libc++.1.dylib: ___cxa_allocate_exception
__ libc++.1.dylib: ___cxa_begin_catch
__ libc++.1.dylib: ___cxa_end_catch
__ libc++.1.dylib: ___cxa_free_exception
__ libc++.1.dylib: ___cxa_guard_abort
__ libc++.1.dylib: ___cxa_guard_acquire
__ libc++.1.dylib: ___cxa_guard_release
__ libc++.1.dylib: ___cxa_pure_virtual
__ libc++.1.dylib: ___cxa_rethrow
__ libc++.1.dylib: ___cxa_throw
__ libc++.1.dylib: ___gxx_personality_v0
__ libobjc.A.dylib: _OBJC_CLASS_$_NSObject
__ libobjc.A.dylib: _OBJC_METACLASS_$_NSObject
__ libobjc.A.dylib: ___objc_personality_v0
__ libobjc.A.dylib: __objc_empty_cache
__ libobjc.A.dylib: _objc_alloc
__ libobjc.A.dylib: _objc_alloc_init
__ libobjc.A.dylib: _objc_autorelease
__ libobjc.A.dylib: _objc_autoreleasePoolPop
__ libobjc.A.dylib: _objc_autoreleasePoolPush
__ libobjc.A.dylib: _objc_autoreleaseReturnValue
__ libobjc.A.dylib: _objc_begin_catch
__ libobjc.A.dylib: _objc_copyStruct
__ libobjc.A.dylib: _objc_copyWeak
__ libobjc.A.dylib: _objc_destroyWeak
__ libobjc.A.dylib: _objc_end_catch
__ libobjc.A.dylib: _objc_enumerationMutation
__ libobjc.A.dylib: _objc_exception_rethrow
__ libobjc.A.dylib: _objc_exception_throw
__ libobjc.A.dylib: _objc_getAssociatedObject
__ libobjc.A.dylib: _objc_getClass
__ libobjc.A.dylib: _objc_getProperty
__ libobjc.A.dylib: _objc_initWeak
__ libobjc.A.dylib: _objc_loadWeakRetained
__ libobjc.A.dylib: _objc_msgSend
__ libobjc.A.dylib: _objc_msgSendSuper2
__ libobjc.A.dylib: _objc_opt_class
__ libobjc.A.dylib: _objc_opt_isKindOfClass
__ libobjc.A.dylib: _objc_opt_new
__ libobjc.A.dylib: _objc_opt_respondsToSelector
__ libobjc.A.dylib: _objc_release
__ libobjc.A.dylib: _objc_retain
__ libobjc.A.dylib: _objc_retainAutorelease
__ libobjc.A.dylib: _objc_retainAutoreleaseReturnValue
__ libobjc.A.dylib: _objc_retainAutoreleasedReturnValue
__ libobjc.A.dylib: _objc_retainBlock
__ libobjc.A.dylib: _objc_setAssociatedObject
__ libobjc.A.dylib: _objc_setProperty_atomic
__ libobjc.A.dylib: _objc_setProperty_atomic_copy
__ libobjc.A.dylib: _objc_setProperty_nonatomic_copy
__ libobjc.A.dylib: _objc_storeStrong
__ libobjc.A.dylib: _objc_storeWeak
__ libobjc.A.dylib: _objc_sync_enter
__ libobjc.A.dylib: _objc_sync_exit
__ libobjc.A.dylib: _objc_terminate
__ libobjc.A.dylib: _objc_unsafeClaimAutoreleasedReturnValue
__ libsqlite3.dylib: _sqlite3_bind_double
__ libsqlite3.dylib: _sqlite3_bind_int
__ libsqlite3.dylib: _sqlite3_bind_int64
__ libsqlite3.dylib: _sqlite3_bind_null
__ libsqlite3.dylib: _sqlite3_bind_text
__ libsqlite3.dylib: _sqlite3_close
__ libsqlite3.dylib: _sqlite3_column_blob
__ libsqlite3.dylib: _sqlite3_column_bytes
__ libsqlite3.dylib: _sqlite3_column_double
__ libsqlite3.dylib: _sqlite3_column_int
__ libsqlite3.dylib: _sqlite3_column_int64
__ libsqlite3.dylib: _sqlite3_column_text
__ libsqlite3.dylib: _sqlite3_column_type
__ libsqlite3.dylib: _sqlite3_finalize
__ libsqlite3.dylib: _sqlite3_open
__ libsqlite3.dylib: _sqlite3_prepare_v2
__ libsqlite3.dylib: _sqlite3_step
MonzaV4_1Input : NSObject <MLFeatureProvider>
 @property  ^{__CVBuffer=} inputImage
 @property  NSSet *featureNames

  // instance methods
  -[MonzaV4_1Input setInputImage:]
  -[MonzaV4_1Input featureNames]
  -[MonzaV4_1Input featureValueForName:]
  -[MonzaV4_1Input inputImage]
  -[MonzaV4_1Input dealloc]
  -[MonzaV4_1Input initWithInputImage:]
  -[MonzaV4_1Input initWithInputImageFromCGImage:error:]
  -[MonzaV4_1Input initWithInputImageAtURL:error:]
  -[MonzaV4_1Input setInputImageWithCGImage:error:]
  -[MonzaV4_1Input setInputImageWithURL:error:]


MonzaV4_1Output : NSObject <MLFeatureProvider>
 @property  MLMultiArray *angle
 @property  NSSet *featureNames

  // instance methods
  -[MonzaV4_1Output angle]
  -[MonzaV4_1Output .cxx_destruct]
  -[MonzaV4_1Output featureNames]
  -[MonzaV4_1Output setAngle:]
  -[MonzaV4_1Output featureValueForName:]
  -[MonzaV4_1Output initWithAngle:]


MonzaV4_1 : NSObject
 @property  MLModel *model

  // class methods
  +[MonzaV4_1 URLOfModelInThisBundle]
  +[MonzaV4_1 loadContentsOfURL:configuration:completionHandler:]
  +[MonzaV4_1 loadWithConfiguration:completionHandler:]

  // instance methods
  -[MonzaV4_1 initWithContentsOfURL:error:]
  -[MonzaV4_1 predictionsFromInputs:options:error:]
  -[MonzaV4_1 .cxx_destruct]
  -[MonzaV4_1 predictionFromFeatures:error:]
  -[MonzaV4_1 init]
  -[MonzaV4_1 initWithContentsOfURL:configuration:error:]
  -[MonzaV4_1 predictionFromFeatures:options:error:]
  -[MonzaV4_1 model]
  -[MonzaV4_1 initWithMLModel:]
  -[MonzaV4_1 initWithConfiguration:error:]
  -[MonzaV4_1 predictionFromInputImage:error:]


VCPAudioAnalyzer : NSObject
  // instance methods
  -[VCPAudioAnalyzer .cxx_destruct]
  -[VCPAudioAnalyzer processSampleBuffer:]
  -[VCPAudioAnalyzer dealloc]
  -[VCPAudioAnalyzer processAudioSamples:timestamp:]
  -[VCPAudioAnalyzer finalizeAnalysisAtTime:]
  -[VCPAudioAnalyzer audioFormatRequirements]
  -[VCPAudioAnalyzer setupWithSample:]
  -[VCPAudioAnalyzer voiceDetections]
  -[VCPAudioAnalyzer initWithAnalysisTypes:forStreaming:]
  -[VCPAudioAnalyzer analyzeAsset:cancel:results:]
  -[VCPAudioAnalyzer analyzeSampleBuffer:]


VCPSoundDetector : NSObject <SNResultsObserving>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPSoundDetector results]
  -[VCPSoundDetector .cxx_destruct]
  -[VCPSoundDetector request:didProduceResult:]
  -[VCPSoundDetector finalizeAnalysisAtTime:]
  -[VCPSoundDetector addDetectionFromTime:toTime:confidence:]
  -[VCPSoundDetector initWithTrackStart:threshold:resultsKey:]


VCPAudioClassifier : NSObject
  // instance methods
  -[VCPAudioClassifier initWithTypes:]
  -[VCPAudioClassifier results]
  -[VCPAudioClassifier .cxx_destruct]
  -[VCPAudioClassifier setupWithSample:andSampleBatchSize:]
  -[VCPAudioClassifier processAudioSamples:timestamp:]
  -[VCPAudioClassifier finalizeAnalysisAtTime:]


VCPVideoStabilizer : VCPVideoAnalyzer
 @property  ^v analysisResultRef
 @property  ^v correctionResultRef
 @property  NSDictionary *results
 @property  float cropFraction
 @property  NSMutableArray *motionBlurVector
 @property  BOOL gyroStabilization
 @property  float analysisConfidence
 @property  BOOL validStabilization

  // class methods
  +[VCPVideoStabilizer saveStabilizationRecipe]
  +[VCPVideoStabilizer videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:]

  // instance methods
  -[VCPVideoStabilizer setResults:]
  -[VCPVideoStabilizer results]
  -[VCPVideoStabilizer .cxx_destruct]
  -[VCPVideoStabilizer init]
  -[VCPVideoStabilizer dealloc]
  -[VCPVideoStabilizer setCropFraction:]
  -[VCPVideoStabilizer cropFraction]
  -[VCPVideoStabilizer correctionResultRef]
  -[VCPVideoStabilizer setCorrectionResultRef:]
  -[VCPVideoStabilizer motionBlurVector]
  -[VCPVideoStabilizer setMotionBlurVector:]
  -[VCPVideoStabilizer gyroStabilization]
  -[VCPVideoStabilizer validStabilization]
  -[VCPVideoStabilizer finishAnalysisPass:]
  -[VCPVideoStabilizer setGyroStabilization:]
  -[VCPVideoStabilizer setAnalysisResultRef:]
  -[VCPVideoStabilizer analysisResultRef]
  -[VCPVideoStabilizer setAnalysisConfidence:]
  -[VCPVideoStabilizer analysisConfidence]
  -[VCPVideoStabilizer setValidStabilization:]
  -[VCPVideoStabilizer convertAnalysisResult]


VCPImageHumanPoseAnalyzer : VCPImageAnalyzer
 @property  BOOL trackingMode

  // class methods
  +[VCPImageHumanPoseAnalyzer sharedModel:]
  +[VCPImageHumanPoseAnalyzer saveKeypoints]

  // instance methods
  -[VCPImageHumanPoseAnalyzer .cxx_destruct]
  -[VCPImageHumanPoseAnalyzer trackingMode]
  -[VCPImageHumanPoseAnalyzer init]
  -[VCPImageHumanPoseAnalyzer setTrackingMode:]
  -[VCPImageHumanPoseAnalyzer dealloc]
  -[VCPImageHumanPoseAnalyzer configForAspectRatio:]
  -[VCPImageHumanPoseAnalyzer createModelWithHeight:srcWidth:]
  -[VCPImageHumanPoseAnalyzer parsePersons:width:height:]
  -[VCPImageHumanPoseAnalyzer processPersons:width:height:]
  -[VCPImageHumanPoseAnalyzer copyImage:toData:withChannels:]
  -[VCPImageHumanPoseAnalyzer reInitModel]
  -[VCPImageHumanPoseAnalyzer createInput:withBuffer:modelInputHeight:modelInputWidth:]
  -[VCPImageHumanPoseAnalyzer generateHumanPose:]
  -[VCPImageHumanPoseAnalyzer initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:]
  -[VCPImageHumanPoseAnalyzer updateModelForAspectRatio:]
  -[VCPImageHumanPoseAnalyzer preferredInputFormat:height:format:]
  -[VCPImageHumanPoseAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPProtoLivePhotoKeyFrameResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  double timestamp
 @property  float qualityScoreForLivePhoto
 @property  float visualPleasingScore
 @property  float overallFaceQualityScore
 @property  float exposureScore
 @property  float penaltyScore
 @property  float textureScore
 @property  float sharpness
 @property  NSMutableArray *faceResults
 @property  BOOL hasGlobalQualityScore
 @property  float globalQualityScore
 @property  BOOL hasContentScore
 @property  float contentScore
 @property  float expressionChangeScore

  // class methods
  +[VCPProtoLivePhotoKeyFrameResult resultFromLegacyDictionary:]
  +[VCPProtoLivePhotoKeyFrameResult faceResultsType]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameResult setExposureScore:]
  -[VCPProtoLivePhotoKeyFrameResult .cxx_destruct]
  -[VCPProtoLivePhotoKeyFrameResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameResult sharpness]
  -[VCPProtoLivePhotoKeyFrameResult exposureScore]
  -[VCPProtoLivePhotoKeyFrameResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameResult timestamp]
  -[VCPProtoLivePhotoKeyFrameResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameResult setSharpness:]
  -[VCPProtoLivePhotoKeyFrameResult setTimestamp:]
  -[VCPProtoLivePhotoKeyFrameResult faceResults]
  -[VCPProtoLivePhotoKeyFrameResult setContentScore:]
  -[VCPProtoLivePhotoKeyFrameResult contentScore]
  -[VCPProtoLivePhotoKeyFrameResult addFaceResults:]
  -[VCPProtoLivePhotoKeyFrameResult faceResultsCount]
  -[VCPProtoLivePhotoKeyFrameResult clearFaceResults]
  -[VCPProtoLivePhotoKeyFrameResult faceResultsAtIndex:]
  -[VCPProtoLivePhotoKeyFrameResult setGlobalQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult setHasGlobalQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult hasGlobalQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult setHasContentScore:]
  -[VCPProtoLivePhotoKeyFrameResult hasContentScore]
  -[VCPProtoLivePhotoKeyFrameResult qualityScoreForLivePhoto]
  -[VCPProtoLivePhotoKeyFrameResult setQualityScoreForLivePhoto:]
  -[VCPProtoLivePhotoKeyFrameResult visualPleasingScore]
  -[VCPProtoLivePhotoKeyFrameResult setVisualPleasingScore:]
  -[VCPProtoLivePhotoKeyFrameResult overallFaceQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult setOverallFaceQualityScore:]
  -[VCPProtoLivePhotoKeyFrameResult penaltyScore]
  -[VCPProtoLivePhotoKeyFrameResult setPenaltyScore:]
  -[VCPProtoLivePhotoKeyFrameResult textureScore]
  -[VCPProtoLivePhotoKeyFrameResult setTextureScore:]
  -[VCPProtoLivePhotoKeyFrameResult setFaceResults:]
  -[VCPProtoLivePhotoKeyFrameResult globalQualityScore]
  -[VCPProtoLivePhotoKeyFrameResult expressionChangeScore]
  -[VCPProtoLivePhotoKeyFrameResult setExpressionChangeScore:]
  -[VCPProtoLivePhotoKeyFrameResult exportToLegacyDictionary]


VCPBlurAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPBlurAnalyzer computeSharpnessScore:forObjects:inImage:]
  -[VCPBlurAnalyzer computeRegionSharpness:width:height:stride:]


VCPVideoCNNAnalyzer : VCPVideoAnalyzer
  // class methods
  +[VCPVideoCNNAnalyzer forcePersonDetection]

  // instance methods
  -[VCPVideoCNNAnalyzer results]
  -[VCPVideoCNNAnalyzer .cxx_destruct]
  -[VCPVideoCNNAnalyzer dealloc]
  -[VCPVideoCNNAnalyzer configForAspectRatio:]
  -[VCPVideoCNNAnalyzer cropAndScale:regionCrop:]
  -[VCPVideoCNNAnalyzer copyImage:withChannels:]
  -[VCPVideoCNNAnalyzer runTasks:duration:persons:regionCrop:]
  -[VCPVideoCNNAnalyzer initWithTimeOfInteret:frameRate:phFaces:timeRange:]
  -[VCPVideoCNNAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoCNNAnalyzer finishAnalysisPass:]
  -[VCPVideoCNNAnalyzer loadAnalysisResults:audioResults:]


VCPBoundingBox : NSObject
 @property  float minX
 @property  float maxX
 @property  float minY
 @property  float maxY
 @property  float confidence
 @property  float flag
 @property  int classIndex

  // instance methods
  -[VCPBoundingBox maxX]
  -[VCPBoundingBox minX]
  -[VCPBoundingBox minY]
  -[VCPBoundingBox maxY]
  -[VCPBoundingBox area]
  -[VCPBoundingBox flag]
  -[VCPBoundingBox setConfidence:]
  -[VCPBoundingBox confidence]
  -[VCPBoundingBox setMaxX:]
  -[VCPBoundingBox union:]
  -[VCPBoundingBox setMinX:]
  -[VCPBoundingBox setMinY:]
  -[VCPBoundingBox setMaxY:]
  -[VCPBoundingBox intersect:]
  -[VCPBoundingBox setFlag:]
  -[VCPBoundingBox initWithXYAndSize:y:width:height:confidence:]
  -[VCPBoundingBox initWithCenterAndSize:y:width:height:confidence:]
  -[VCPBoundingBox computeIntersectionOverUnion:]
  -[VCPBoundingBox getCGRectWithClipWidth:height:]
  -[VCPBoundingBox setClassIndex:]
  -[VCPBoundingBox classIndex]


VCPProtoMovieBabbleResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieBabbleResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieBabbleResult setTimeRange:]
  -[VCPProtoMovieBabbleResult timeRange]
  -[VCPProtoMovieBabbleResult setConfidence:]
  -[VCPProtoMovieBabbleResult mergeFrom:]
  -[VCPProtoMovieBabbleResult .cxx_destruct]
  -[VCPProtoMovieBabbleResult confidence]
  -[VCPProtoMovieBabbleResult dictionaryRepresentation]
  -[VCPProtoMovieBabbleResult writeTo:]
  -[VCPProtoMovieBabbleResult isEqual:]
  -[VCPProtoMovieBabbleResult copyTo:]
  -[VCPProtoMovieBabbleResult readFrom:]
  -[VCPProtoMovieBabbleResult copyWithZone:]
  -[VCPProtoMovieBabbleResult exportToLegacyDictionary]


VCPCNNBlock : NSObject
 @property  NSMutableArray *inputSize
 @property  NSMutableArray *outputSize
 @property  VCPCNNData *input
 @property  VCPCNNData *output
 @property  VCPCNNMetalContext *context
 @property  BOOL generateOutput

  // instance methods
  -[VCPCNNBlock setInput:]
  -[VCPCNNBlock output]
  -[VCPCNNBlock input]
  -[VCPCNNBlock .cxx_destruct]
  -[VCPCNNBlock setOutput:]
  -[VCPCNNBlock inputSize]
  -[VCPCNNBlock outputSize]
  -[VCPCNNBlock useGPU]
  -[VCPCNNBlock forward]
  -[VCPCNNBlock setInputSize:]
  -[VCPCNNBlock context]
  -[VCPCNNBlock setOutputSize:]
  -[VCPCNNBlock generateOutput]
  -[VCPCNNBlock setGenerateOutput:]
  -[VCPCNNBlock supportGPU]
  -[VCPCNNBlock constructBlock:context:]
  -[VCPCNNBlock readFromDisk:quantFactor:]


VCPCNNBlurAnalyzer : VCPImageAnalyzer
 @property  BOOL sdof

  // class methods
  +[VCPCNNBlurAnalyzer analyzer]
  +[VCPCNNBlurAnalyzer analyzerWithRevision:]

  // instance methods
  -[VCPCNNBlurAnalyzer sdof]
  -[VCPCNNBlurAnalyzer init]
  -[VCPCNNBlurAnalyzer initWithRevision:]
  -[VCPCNNBlurAnalyzer getRevision]
  -[VCPCNNBlurAnalyzer calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:]
  -[VCPCNNBlurAnalyzer copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:]
  -[VCPCNNBlurAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzer getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzer computeSharpnessScore:textureness:contrast:imgWidth:cancel:]
  -[VCPCNNBlurAnalyzer setSdof:]
  -[VCPCNNBlurAnalyzer scaleRegion:ofImage:toData:withWidth:andHeight:]
  -[VCPCNNBlurAnalyzer computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:]


VCPCNNBlurAnalyzerEspresso : VCPCNNBlurAnalyzer
  // class methods
  +[VCPCNNBlurAnalyzerEspresso sharedModel:]
  +[VCPCNNBlurAnalyzerEspresso sharedModelPoolWithRevision:]

  // instance methods
  -[VCPCNNBlurAnalyzerEspresso .cxx_destruct]
  -[VCPCNNBlurAnalyzerEspresso init]
  -[VCPCNNBlurAnalyzerEspresso dealloc]
  -[VCPCNNBlurAnalyzerEspresso initWithRevision:]
  -[VCPCNNBlurAnalyzerEspresso calculateScoreFromNetworkOutputV2:]
  -[VCPCNNBlurAnalyzerEspresso copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:]
  -[VCPCNNBlurAnalyzerEspresso prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzerEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzerEspresso computeSharpnessScore:textureness:contrast:imgWidth:cancel:]


VCPCNNBlurAnalyzerMPS : VCPCNNBlurAnalyzer
  // instance methods
  -[VCPCNNBlurAnalyzerMPS .cxx_destruct]
  -[VCPCNNBlurAnalyzerMPS init]
  -[VCPCNNBlurAnalyzerMPS prepareModelForSourceWidth:andSourceHeight:]
  -[VCPCNNBlurAnalyzerMPS getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNBlurAnalyzerMPS computeSharpnessScore:textureness:contrast:imgWidth:cancel:]


VCPCNNConvBlock : VCPCNNBlock
  // class methods
  +[VCPCNNConvBlock convBlockClass:]
  +[VCPCNNConvBlock convBlockWithFilterSize:filterNum:chunk:reLU:padding:]
  +[VCPCNNConvBlock convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]

  // instance methods
  -[VCPCNNConvBlock .cxx_destruct]
  -[VCPCNNConvBlock useGPU]
  -[VCPCNNConvBlock supportGPU]
  -[VCPCNNConvBlock initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]
  -[VCPCNNConvBlock constructBlock:context:]


VCPCNNConvBlockBinary : VCPCNNBlock
  // instance methods
  -[VCPCNNConvBlockBinary .cxx_destruct]
  -[VCPCNNConvBlockBinary useGPU]
  -[VCPCNNConvBlockBinary forward]
  -[VCPCNNConvBlockBinary dealloc]
  -[VCPCNNConvBlockBinary supportGPU]
  -[VCPCNNConvBlockBinary constructBlock:context:]
  -[VCPCNNConvBlockBinary readFromDisk:quantFactor:]
  -[VCPCNNConvBlockBinary fillConvWeightsGPU]
  -[VCPCNNConvBlockBinary gpuForward]
  -[VCPCNNConvBlockBinary initWithParameters:filterNum:convType:reLU:padding:]


VCPCNNConvBlockGPU : VCPCNNConvBlock
  // instance methods
  -[VCPCNNConvBlockGPU .cxx_destruct]
  -[VCPCNNConvBlockGPU forward]
  -[VCPCNNConvBlockGPU dealloc]
  -[VCPCNNConvBlockGPU releaseBatchNormMemory]
  -[VCPCNNConvBlockGPU readFromDisk:quantFactor:]
  -[VCPCNNConvBlockGPU readBatchNormParam:quantFactor:]
  -[VCPCNNConvBlockGPU fillConvWeightsGPU]
  -[VCPCNNConvBlockGPU gpuForward]


VCPCNNConvBlockScalar : VCPCNNConvBlock
  // instance methods
  -[VCPCNNConvBlockScalar forward]
  -[VCPCNNConvBlockScalar readFromDisk:quantFactor:]


VCPCNNConvBlockVector : VCPCNNConvBlock
  // class methods
  +[VCPCNNConvBlockVector isFilterSizeSupported:]

  // instance methods
  -[VCPCNNConvBlockVector forward]
  -[VCPCNNConvBlockVector initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:]
  -[VCPCNNConvBlockVector readFromDisk:quantFactor:]
  -[VCPCNNConvBlockVector straightForwardForChunkFour]
  -[VCPCNNConvBlockVector chunkFourForward]


VCPCNNData : NSObject
 @property  NSMutableArray *size
 @property  ^f data
 @property  BOOL isInputOutput
 @property  MPSImage *mpsImg
 @property  VCPCNNMetalContext *context

  // class methods
  +[VCPCNNData cnnDataWithGPUContext:]
  +[VCPCNNData cnnData]
  +[VCPCNNData cnnDataClass]
  +[VCPCNNData cnnDataWithPlane:height:width:context:]

  // instance methods
  -[VCPCNNData .cxx_destruct]
  -[VCPCNNData data]
  -[VCPCNNData normalization]
  -[VCPCNNData init]
  -[VCPCNNData softmax]
  -[VCPCNNData setSize:]
  -[VCPCNNData setData:]
  -[VCPCNNData setContext:]
  -[VCPCNNData size]
  -[VCPCNNData dealloc]
  -[VCPCNNData context]
  -[VCPCNNData allocBuffers:]
  -[VCPCNNData reallocGPUTemporalBuffers]
  -[VCPCNNData mpsImg]
  -[VCPCNNData readFromDisk:quantFactor:]
  -[VCPCNNData initWithGPUContext:]
  -[VCPCNNData initWithParameters:height:width:context:]
  -[VCPCNNData bufferAllocCPU]
  -[VCPCNNData randInit]
  -[VCPCNNData convertCPUData2GPU]
  -[VCPCNNData convertGPUData2CPU]
  -[VCPCNNData copyImage:withChunk:]
  -[VCPCNNData isInputOutput]
  -[VCPCNNData setIsInputOutput:]
  -[VCPCNNData setMpsImg:]


VCPCNNDataGPU : VCPCNNData
  // instance methods
  -[VCPCNNDataGPU allocBuffers:]
  -[VCPCNNDataGPU reallocGPUTemporalBuffers]
  -[VCPCNNDataGPU convertCPUData2GPU]
  -[VCPCNNDataGPU convertGPUData2CPU]
  -[VCPCNNDataGPU bufferAllocGPU]


VCPFaceCrop : NSObject
 @property  NSString *localIdentifier
 @property  short state

  // instance methods
  -[VCPFaceCrop imageDimensions]
  -[VCPFaceCrop .cxx_destruct]
  -[VCPFaceCrop setState:]
  -[VCPFaceCrop state]
  -[VCPFaceCrop localIdentifier]
  -[VCPFaceCrop copyWithZone:]
  -[VCPFaceCrop faceCropData]
  -[VCPFaceCrop originatingFace]
  -[VCPFaceCrop initWithLocalIdentifier:faceCropData:]
  -[VCPFaceCrop initWithFaceCropData:originatingFace:]


VCPCNNEspressoContext : NSObject
 @property  ^v espressoContext

  // class methods
  +[VCPCNNEspressoContext supportGPU]
  +[VCPCNNEspressoContext createContextWithForceCPU]
  +[VCPCNNEspressoContext createContextWithMPSGraph]
  +[VCPCNNEspressoContext createContextPreferred]
  +[VCPCNNEspressoContext sharedContextWithForceCPU:]
  +[VCPCNNEspressoContext sharedContextWithMPSGraph:]
  +[VCPCNNEspressoContext sharedContextPreferred:]

  // instance methods
  -[VCPCNNEspressoContext dealloc]
  -[VCPCNNEspressoContext espressoContext]
  -[VCPCNNEspressoContext initWithForceCPU:forceNNGraph:shared:]


VCPCNNFaceLandmarkDetector : NSObject
  // class methods
  +[VCPCNNFaceLandmarkDetector detector]

  // instance methods
  -[VCPCNNFaceLandmarkDetector .cxx_destruct]
  -[VCPCNNFaceLandmarkDetector landmarks]
  -[VCPCNNFaceLandmarkDetector getInputBuffer]
  -[VCPCNNFaceLandmarkDetector computeLandmarks:]
  -[VCPCNNFaceLandmarkDetector analyzeFrame:withFaceBounds:]


VCPCNNFaceLandmarkDetectorEspresso : VCPCNNFaceLandmarkDetector
  // class methods
  +[VCPCNNFaceLandmarkDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNFaceLandmarkDetectorEspresso .cxx_destruct]
  -[VCPCNNFaceLandmarkDetectorEspresso init]
  -[VCPCNNFaceLandmarkDetectorEspresso dealloc]
  -[VCPCNNFaceLandmarkDetectorEspresso getInputBuffer]
  -[VCPCNNFaceLandmarkDetectorEspresso computeLandmarks:]


VCPCNNFaceLandmarkDetectorMPS : VCPCNNFaceLandmarkDetector
  // instance methods
  -[VCPCNNFaceLandmarkDetectorMPS .cxx_destruct]
  -[VCPCNNFaceLandmarkDetectorMPS init]
  -[VCPCNNFaceLandmarkDetectorMPS getInputBuffer]
  -[VCPCNNFaceLandmarkDetectorMPS computeLandmarks:]


VCPCNNFlattenBlock : VCPCNNBlock
  // instance methods
  -[VCPCNNFlattenBlock initWithParameters:]
  -[VCPCNNFlattenBlock forward]
  -[VCPCNNFlattenBlock constructBlock:context:]


VCPCNNFullConnectionBlock : VCPCNNBlock
  // class methods
  +[VCPCNNFullConnectionBlock fcBlockWithNumNeurons:NeuronType:]

  // instance methods
  -[VCPCNNFullConnectionBlock useGPU]
  -[VCPCNNFullConnectionBlock dealloc]
  -[VCPCNNFullConnectionBlock supportGPU]
  -[VCPCNNFullConnectionBlock constructBlock:context:]
  -[VCPCNNFullConnectionBlock readFromDisk:quantFactor:]
  -[VCPCNNFullConnectionBlock initWithParameters:NeuronType:]
  -[VCPCNNFullConnectionBlock readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:]
  -[VCPCNNFullConnectionBlock loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNFullConnectionBlockGPU : VCPCNNFullConnectionBlock
  // instance methods
  -[VCPCNNFullConnectionBlockGPU .cxx_destruct]
  -[VCPCNNFullConnectionBlockGPU forward]
  -[VCPCNNFullConnectionBlockGPU convVCPNeuronTypeToMPS:]
  -[VCPCNNFullConnectionBlockGPU shuffleWeights:fromSrc:inputChannels:inputHeight:inputWidth:outputChannels:]
  -[VCPCNNFullConnectionBlockGPU setupMPS]
  -[VCPCNNFullConnectionBlockGPU loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNFullConnectionBlockScalar : VCPCNNFullConnectionBlock
  // instance methods
  -[VCPCNNFullConnectionBlockScalar forward]
  -[VCPCNNFullConnectionBlockScalar loadWeights:inputDim:outputDim:quantFactor:]


VCPCNNGazeAnalysis : NSObject
  // class methods
  +[VCPCNNGazeAnalysis sharedModel:]

  // instance methods
  -[VCPCNNGazeAnalysis .cxx_destruct]
  -[VCPCNNGazeAnalysis init]
  -[VCPCNNGazeAnalysis dealloc]
  -[VCPCNNGazeAnalysis copyImage:toData:]
  -[VCPCNNGazeAnalysis createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:]
  -[VCPCNNGazeAnalysis detectEyeOpennessForFace:inBuffer:eyeOpenness:]


VCPVideoGyroStabilizer : VCPVideoStabilizer
  // instance methods
  -[VCPVideoGyroStabilizer .cxx_destruct]
  -[VCPVideoGyroStabilizer initWithMetadata:sourceSize:cropRect:]
  -[VCPVideoGyroStabilizer storeAnalytics:isLivePhoto:]
  -[VCPVideoGyroStabilizer convertAnalysisResult]


VCPCNNHandKeypointsDetector : NSObject
  // class methods
  +[VCPCNNHandKeypointsDetector detector:sharedModel:modelName:]

  // instance methods
  -[VCPCNNHandKeypointsDetector copyImage:toData:]
  -[VCPCNNHandKeypointsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:]
  -[VCPCNNHandKeypointsDetector generateHandKeypoints:keypointConfidence:offset:]
  -[VCPCNNHandKeypointsDetector cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:]
  -[VCPCNNHandKeypointsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:]
  -[VCPCNNHandKeypointsDetector handKeypointsDetection:box:keypoints:keypointConfidence:forGFT:]


VCPCNNMetalContext : NSObject
 @property  <MTLDevice> *device
 @property  <MTLCommandQueue> *commandQueue
 @property  <MTLCommandBuffer> *commandBuffer

  // class methods
  +[VCPCNNMetalContext sharedCommandQueue]
  +[VCPCNNMetalContext supportGPU]
  +[VCPCNNMetalContext supportVectorForward]

  // instance methods
  -[VCPCNNMetalContext setDevice:]
  -[VCPCNNMetalContext setCommandBuffer:]
  -[VCPCNNMetalContext commandQueue]
  -[VCPCNNMetalContext .cxx_destruct]
  -[VCPCNNMetalContext execute]
  -[VCPCNNMetalContext setCommandQueue:]
  -[VCPCNNMetalContext device]
  -[VCPCNNMetalContext commandBuffer]
  -[VCPCNNMetalContext initNewContext:]


VCPMADVIVisualSearchTask : NSObject <VCPMADServiceImageProcessingSubtaskProtocol, VCPMADTaskProtocol>
  // class methods
  +[VCPMADVIVisualSearchTask dependencies]
  +[VCPMADVIVisualSearchTask taskWithRequest:imageAsset:andSignpostPayload:]

  // instance methods
  -[VCPMADVIVisualSearchTask setPreferredMetalDevice:]
  -[VCPMADVIVisualSearchTask resourceRequirement]
  -[VCPMADVIVisualSearchTask .cxx_destruct]
  -[VCPMADVIVisualSearchTask createQueryContextWithError:]
  -[VCPMADVIVisualSearchTask cancel]
  -[VCPMADVIVisualSearchTask initWithRequest:imageAsset:andSignpostPayload:]
  -[VCPMADVIVisualSearchTask storeResults:]
  -[VCPMADVIVisualSearchTask autoCancellable]
  -[VCPMADVIVisualSearchTask run]


VCPHumanPoseVideoRequest : VCPRequest
  // instance methods
  -[VCPHumanPoseVideoRequest .cxx_destruct]
  -[VCPHumanPoseVideoRequest initWithOptions:]
  -[VCPHumanPoseVideoRequest init]
  -[VCPHumanPoseVideoRequest preferredInputSizeWithOptions:error:]
  -[VCPHumanPoseVideoRequest preferredPixelFormat]
  -[VCPHumanPoseVideoRequest associatePersons:withExisingPersons:]
  -[VCPHumanPoseVideoRequest computeActionScoreForPerson:]
  -[VCPHumanPoseVideoRequest normDistance:point2:]
  -[VCPHumanPoseVideoRequest computeVarWithID:index1:index2:interVar:intraVar:]
  -[VCPHumanPoseVideoRequest bodyDistance:withBodyB:]
  -[VCPHumanPoseVideoRequest processSampleBuffer:withOptions:error:]
  -[VCPHumanPoseVideoRequest cleanupWithOptions:error:]


VCPCNNModel : NSObject
 @property  VCPCNNData *output

  // instance methods
  -[VCPCNNModel output]
  -[VCPCNNModel add:]
  -[VCPCNNModel .cxx_destruct]
  -[VCPCNNModel init]
  -[VCPCNNModel size]
  -[VCPCNNModel initWithParameters:useGPU:]
  -[VCPCNNModel getGPUContext]
  -[VCPCNNModel prepareNetworkFromURL:withInputSize:]
  -[VCPCNNModel forward:]
  -[VCPCNNModel dynamicForward:paramFileUrl:cancel:]


VCPCNNModelEspresso : NSObject
 @property  {vector<espresso_buffer_t inputBlobs
 @property  {vector<espresso_buffer_t outputBlobs
 @property  {?=^v^v[4Q][4Q]QQQQQQQQQQi} inputBlob
 @property  {?=^v^v[4Q][4Q]QQQQQQQQQQi} outputBlob
 @property  NSString *resConfig

  // instance methods
  -[VCPCNNModelEspresso .cxx_construct]
  -[VCPCNNModelEspresso .cxx_destruct]
  -[VCPCNNModelEspresso softmax]
  -[VCPCNNModelEspresso dealloc]
  -[VCPCNNModelEspresso initWithParameters:inputNames:outputNames:properties:]
  -[VCPCNNModelEspresso outputBlob]
  -[VCPCNNModelEspresso espressoForward:]
  -[VCPCNNModelEspresso prepareModelWithConfig:]
  -[VCPCNNModelEspresso inputBlob]
  -[VCPCNNModelEspresso normalization:]
  -[VCPCNNModelEspresso getPlanPhase]
  -[VCPCNNModelEspresso prepareModelInput:]
  -[VCPCNNModelEspresso prepareModelInputs:]
  -[VCPCNNModelEspresso espressoForwardInputs:]
  -[VCPCNNModelEspresso getEspressoContext]
  -[VCPCNNModelEspresso inputBlobs]
  -[VCPCNNModelEspresso setInputBlobs:]
  -[VCPCNNModelEspresso outputBlobs]
  -[VCPCNNModelEspresso setOutputBlobs:]
  -[VCPCNNModelEspresso setInputBlob:]
  -[VCPCNNModelEspresso setOutputBlob:]
  -[VCPCNNModelEspresso resConfig]


VCPCNNMPSDataSource : NSObject <MPSCNNConvolutionDataSource>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // instance methods
  -[VCPCNNMPSDataSource weights]
  -[VCPCNNMPSDataSource load]
  -[VCPCNNMPSDataSource label]
  -[VCPCNNMPSDataSource purge]
  -[VCPCNNMPSDataSource .cxx_destruct]
  -[VCPCNNMPSDataSource descriptor]
  -[VCPCNNMPSDataSource dataType]
  -[VCPCNNMPSDataSource copyWithZone:device:]
  -[VCPCNNMPSDataSource copyWithZone:]
  -[VCPCNNMPSDataSource biasTerms]
  -[VCPCNNMPSDataSource initWith:convolutionDescriptor:kernelWeights:biasTerm:]


VCPBackwarp : NSObject
  // instance methods
  -[VCPBackwarp initWithDevice:]
  -[VCPBackwarp .cxx_destruct]
  -[VCPBackwarp configureGPU]
  -[VCPBackwarp encodeToCommandBuffer:input:output:flow:upscaledFlow:]


VCPCorrelation : NSObject
  // instance methods
  -[VCPCorrelation initWithDevice:]
  -[VCPCorrelation .cxx_destruct]
  -[VCPCorrelation configureGPU]
  -[VCPCorrelation encodeToCommandBuffer:firstInput:secondInput:correlation:]


VCPEspressoModel : NSObject
  // instance methods
  -[VCPEspressoModel loadModel:]
  -[VCPEspressoModel .cxx_destruct]
  -[VCPEspressoModel dealloc]
  -[VCPEspressoModel prepareModelWithFile:engine:config:error:]
  -[VCPEspressoModel freeModel]
  -[VCPEspressoModel buildModelWithConfig:error:]
  -[VCPEspressoModel initModelWithName:andConfig:]
  -[VCPEspressoModel updateModelWithConfig:error:]


VCPFlowDecoder : VCPEspressoModel
  // instance methods
  -[VCPFlowDecoder .cxx_destruct]
  -[VCPFlowDecoder bindWithBuffers:correlation:flow:outputFlow:]
  -[VCPFlowDecoder initModule:config:]
  -[VCPFlowDecoder estimateFlow:correlation:flow:outputFlow:callback:]


VCPFlowFeatureExtractor : VCPEspressoModel
  // instance methods
  -[VCPFlowFeatureExtractor .cxx_destruct]
  -[VCPFlowFeatureExtractor initModule:config:]
  -[VCPFlowFeatureExtractor bindWithBuffers:imgFeature:]
  -[VCPFlowFeatureExtractor extractFeatureFromImage:toFeature:callback:]
  -[VCPFlowFeatureExtractor setFeatureShape:height:width:level:]


VCPModelR2D2 : NSObject
 @property  int inputHeight
 @property  int inputWidth

  // instance methods
  -[VCPModelR2D2 inputHeight]
  -[VCPModelR2D2 .cxx_destruct]
  -[VCPModelR2D2 inputWidth]
  -[VCPModelR2D2 createModules]
  -[VCPModelR2D2 allocateFeatures]
  -[VCPModelR2D2 configForAspectRatio:]
  -[VCPModelR2D2 updateModelForAspectRatio:]
  -[VCPModelR2D2 preferredInputFormat:height:format:]
  -[VCPModelR2D2 allocateStorages]
  -[VCPModelR2D2 extractFeatureFromImage:toFeature:]
  -[VCPModelR2D2 allocateCorreleationBuffer:forLevel:]
  -[VCPModelR2D2 estimateFlowForLevel:upperFlow:outputFlow:]
  -[VCPModelR2D2 updateModulesWithConfig:]
  -[VCPModelR2D2 releaseFeatureBuffers]
  -[VCPModelR2D2 releaseStorages]
  -[VCPModelR2D2 initUsingLightweight:aspectRatio:numLevels:startLevel:]
  -[VCPModelR2D2 extractFeaturesFromFirst:andSecond:]
  -[VCPModelR2D2 estimateMotionFlow:]
  -[VCPModelR2D2 scaleFlowTo:inFlow:]
  -[VCPModelR2D2 releaseMemory]


VCPProtoKeypoint : PBCodable <NSCopying>
 @property  float x
 @property  float y
 @property  float confidence

  // instance methods
  -[VCPProtoKeypoint y]
  -[VCPProtoKeypoint setX:]
  -[VCPProtoKeypoint setY:]
  -[VCPProtoKeypoint x]
  -[VCPProtoKeypoint setConfidence:]
  -[VCPProtoKeypoint mergeFrom:]
  -[VCPProtoKeypoint confidence]
  -[VCPProtoKeypoint dictionaryRepresentation]
  -[VCPProtoKeypoint writeTo:]
  -[VCPProtoKeypoint isEqual:]
  -[VCPProtoKeypoint copyTo:]
  -[VCPProtoKeypoint readFrom:]
  -[VCPProtoKeypoint copyWithZone:]


VCPCNNPetsDetector : NSObject
  // class methods
  +[VCPCNNPetsDetector detector:]

  // instance methods
  -[VCPCNNPetsDetector copyImage:toData:withChannels:]
  -[VCPCNNPetsDetector getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetector postProcBoxes:maxNumRegions:]
  -[VCPCNNPetsDetector petsDetection:petsRegions:petsFaceRegions:cancel:]
  -[VCPCNNPetsDetector generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:]
  -[VCPCNNPetsDetector createModel:srcWidth:]
  -[VCPCNNPetsDetector generatePetsBoxes:faceBoxes:cancel:]
  -[VCPCNNPetsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetector nonMaxSuppression:]


VCPProtoMovieApplauseResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieApplauseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieApplauseResult setTimeRange:]
  -[VCPProtoMovieApplauseResult timeRange]
  -[VCPProtoMovieApplauseResult setConfidence:]
  -[VCPProtoMovieApplauseResult mergeFrom:]
  -[VCPProtoMovieApplauseResult .cxx_destruct]
  -[VCPProtoMovieApplauseResult confidence]
  -[VCPProtoMovieApplauseResult dictionaryRepresentation]
  -[VCPProtoMovieApplauseResult writeTo:]
  -[VCPProtoMovieApplauseResult isEqual:]
  -[VCPProtoMovieApplauseResult copyTo:]
  -[VCPProtoMovieApplauseResult readFrom:]
  -[VCPProtoMovieApplauseResult copyWithZone:]
  -[VCPProtoMovieApplauseResult exportToLegacyDictionary]


VCPCNNPetsDetectorEspresso : VCPCNNPetsDetector
  // class methods
  +[VCPCNNPetsDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNPetsDetectorEspresso .cxx_destruct]
  -[VCPCNNPetsDetectorEspresso dealloc]
  -[VCPCNNPetsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNPetsDetectorEspresso initWithMaxNumRegions:]
  -[VCPCNNPetsDetectorEspresso createModel:srcWidth:]
  -[VCPCNNPetsDetectorEspresso generatePetsBoxes:faceBoxes:cancel:]


VCPCNNPoolingBlock : VCPCNNBlock
  // class methods
  +[VCPCNNPoolingBlock poolingBlockWithPoolX:poolY:chunk:]

  // instance methods
  -[VCPCNNPoolingBlock useGPU]
  -[VCPCNNPoolingBlock forward]
  -[VCPCNNPoolingBlock supportGPU]
  -[VCPCNNPoolingBlock constructBlock:context:]
  -[VCPCNNPoolingBlock initWithParameters:poolY:chunk:]


VCPCNNPoolingBlockGPU : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockGPU .cxx_destruct]
  -[VCPCNNPoolingBlockGPU forward]


VCPCNNPoolingBlockScalar : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockScalar forward]


VCPMADVIDocumentRecognitionResource : VCPMADVisionResource
  // class methods
  +[VCPMADVIDocumentRecognitionResource sharedResource]

  // instance methods
  -[VCPMADVIDocumentRecognitionResource inactiveCost]
  -[VCPMADVIDocumentRecognitionResource activeCost]


VCPMADVIDocumentRecognitionTask : NSObject <VCPMADServiceImageProcessingSubtaskProtocol, VCPMADTaskProtocol>
  // class methods
  +[VCPMADVIDocumentRecognitionTask dependencies]
  +[VCPMADVIDocumentRecognitionTask taskWithRequest:imageAsset:andSignpostPayload:]

  // instance methods
  -[VCPMADVIDocumentRecognitionTask setPreferredMetalDevice:]
  -[VCPMADVIDocumentRecognitionTask resourceRequirement]
  -[VCPMADVIDocumentRecognitionTask .cxx_destruct]
  -[VCPMADVIDocumentRecognitionTask cancel]
  -[VCPMADVIDocumentRecognitionTask initWithRequest:imageAsset:andSignpostPayload:]
  -[VCPMADVIDocumentRecognitionTask autoCancellable]
  -[VCPMADVIDocumentRecognitionTask canReuseResultsForRequest]
  -[VCPMADVIDocumentRecognitionTask run]


VCPVideoProcessor : NSObject
 @property  @? progressHandler

  // instance methods
  -[VCPVideoProcessor .cxx_destruct]
  -[VCPVideoProcessor setProgressHandler:]
  -[VCPVideoProcessor progressHandler]
  -[VCPVideoProcessor cancel]
  -[VCPVideoProcessor initWithURL:]
  -[VCPVideoProcessor addRequest:withConfiguration:error:]
  -[VCPVideoProcessor removeRequest:error:]
  -[VCPVideoProcessor analyzeWithStart:andDuration:error:]
  -[VCPVideoProcessor _analyzeWithStart:andDuration:error:]


VCPCNNPoolingBlockVector : VCPCNNPoolingBlock
  // instance methods
  -[VCPCNNPoolingBlockVector forward]


VCPCNNPoseEstimator : NSObject
  // class methods
  +[VCPCNNPoseEstimator estimator]

  // instance methods
  -[VCPCNNPoseEstimator getInputBuffer]
  -[VCPCNNPoseEstimator computePoseScore:]
  -[VCPCNNPoseEstimator detectPoseForFace:inBuffer:yaw:]


MADActivitySchedulingRecord : NSObject
 @property  unsigned long activityID
 @property  NSDate *startTime
 @property  double duration
 @property  int exitStatus

  // instance methods
  -[MADActivitySchedulingRecord setStartTime:]
  -[MADActivitySchedulingRecord exitStatus]
  -[MADActivitySchedulingRecord setDuration:]
  -[MADActivitySchedulingRecord startTime]
  -[MADActivitySchedulingRecord duration]
  -[MADActivitySchedulingRecord activityID]
  -[MADActivitySchedulingRecord setActivityID:]
  -[MADActivitySchedulingRecord setExitStatus:]


VCPVideoProcessorSession : NSObject
 @property  unsigned int orientation

  // instance methods
  -[VCPVideoProcessorSession setOrientation:]
  -[VCPVideoProcessorSession .cxx_construct]
  -[VCPVideoProcessorSession .cxx_destruct]
  -[VCPVideoProcessorSession init]
  -[VCPVideoProcessorSession orientation]
  -[VCPVideoProcessorSession addRequest:withConfiguration:error:]
  -[VCPVideoProcessorSession removeRequest:error:]
  -[VCPVideoProcessorSession shouldProcessSampleWithTimeRange:atSamplingInterval:]
  -[VCPVideoProcessorSession processSampleBuffer:withEndTime:error:]
  -[VCPVideoProcessorSession processSampleBuffer:error:]
  -[VCPVideoProcessorSession flushWithEndTime:error:]


VCPCNNPoseEstimatorEspresso : VCPCNNPoseEstimator
  // class methods
  +[VCPCNNPoseEstimatorEspresso sharedModel:]

  // instance methods
  -[VCPCNNPoseEstimatorEspresso .cxx_destruct]
  -[VCPCNNPoseEstimatorEspresso init]
  -[VCPCNNPoseEstimatorEspresso dealloc]
  -[VCPCNNPoseEstimatorEspresso getInputBuffer]
  -[VCPCNNPoseEstimatorEspresso computePoseScore:]


VCPProtoLivePhotoKeyFrameFaceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoBounds *faceBounds
 @property  float faceQuality

  // class methods
  +[VCPProtoLivePhotoKeyFrameFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameFaceResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameFaceResult .cxx_destruct]
  -[VCPProtoLivePhotoKeyFrameFaceResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameFaceResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameFaceResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameFaceResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameFaceResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameFaceResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameFaceResult faceQuality]
  -[VCPProtoLivePhotoKeyFrameFaceResult setFaceBounds:]
  -[VCPProtoLivePhotoKeyFrameFaceResult faceBounds]
  -[VCPProtoLivePhotoKeyFrameFaceResult setFaceQuality:]
  -[VCPProtoLivePhotoKeyFrameFaceResult exportToLegacyDictionary]


VCPCNNPoseEstimatorMPS : VCPCNNPoseEstimator
  // instance methods
  -[VCPCNNPoseEstimatorMPS .cxx_destruct]
  -[VCPCNNPoseEstimatorMPS init]
  -[VCPCNNPoseEstimatorMPS getInputBuffer]
  -[VCPCNNPoseEstimatorMPS computePoseScore:]


VCPPhotosQuickFaceDetectionManager : NSObject
  // instance methods
  -[VCPPhotosQuickFaceDetectionManager initWithPhotoLibrary:]
  -[VCPPhotosQuickFaceDetectionManager .cxx_destruct]
  -[VCPPhotosQuickFaceDetectionManager init]
  -[VCPPhotosQuickFaceDetectionManager processAsset:]
  -[VCPPhotosQuickFaceDetectionManager _persistFaces:forAsset:]


VCPCNNSmileDetector : NSObject
  // class methods
  +[VCPCNNSmileDetector detector]

  // instance methods
  -[VCPCNNSmileDetector getInputBuffer]
  -[VCPCNNSmileDetector computeSmileScore:]
  -[VCPCNNSmileDetector detectSmileForFace:inBuffer:smile:]


VCPCNNSmileDetectorEspresso : VCPCNNSmileDetector
  // class methods
  +[VCPCNNSmileDetectorEspresso sharedModel:]

  // instance methods
  -[VCPCNNSmileDetectorEspresso .cxx_destruct]
  -[VCPCNNSmileDetectorEspresso init]
  -[VCPCNNSmileDetectorEspresso dealloc]
  -[VCPCNNSmileDetectorEspresso getInputBuffer]
  -[VCPCNNSmileDetectorEspresso computeSmileScore:]


VCPCNNSmileDetectorMPS : VCPCNNSmileDetector
  // instance methods
  -[VCPCNNSmileDetectorMPS .cxx_destruct]
  -[VCPCNNSmileDetectorMPS init]
  -[VCPCNNSmileDetectorMPS getInputBuffer]
  -[VCPCNNSmileDetectorMPS computeSmileScore:]


VCPDatabaseBatchIterator : NSObject
 @property  PHAsset *asset
 @property  NSDictionary *analysis

  // class methods
  +[VCPDatabaseBatchIterator iteratorForAssets:withDatabaseReader:resultTypes:batchSize:]

  // instance methods
  -[VCPDatabaseBatchIterator next]
  -[VCPDatabaseBatchIterator .cxx_destruct]
  -[VCPDatabaseBatchIterator nextBatch]
  -[VCPDatabaseBatchIterator asset]
  -[VCPDatabaseBatchIterator analysis]
  -[VCPDatabaseBatchIterator initWithDatabaseReader:forAssets:resultsTypes:batchSize:]


VCPDatabaseReader : NSObject
  // class methods
  +[VCPDatabaseReader shouldQueryInternalFields]
  +[VCPDatabaseReader databaseForPhotoLibrary:]

  // instance methods
  -[VCPDatabaseReader closeDatabase]
  -[VCPDatabaseReader initWithPhotoLibrary:]
  -[VCPDatabaseReader .cxx_destruct]
  -[VCPDatabaseReader valueForKey:]
  -[VCPDatabaseReader dealloc]
  -[VCPDatabaseReader openDatabase]
  -[VCPDatabaseReader queryAnalysesForAssets:withTypes:]
  -[VCPDatabaseReader parseHeader:startColumn:analysis:]
  -[VCPDatabaseReader parseResults:typeColumn:dataColumn:results:]
  -[VCPDatabaseReader executeDatabaseBlock:]
  -[VCPDatabaseReader queryHeaderForAsset:analysis:assetId:]
  -[VCPDatabaseReader queryResultsForAssetId:analysis:]
  -[VCPDatabaseReader queryResultsForAssetId:withTypes:analysis:]
  -[VCPDatabaseReader queryHeadersForAssets:analyses:idMap:]
  -[VCPDatabaseReader queryResultsForAssets:withTypes:batchResults:]
  -[VCPDatabaseReader _queryValue:forKey:]
  -[VCPDatabaseReader queryBlacklistedLocalIdentifiers]
  -[VCPDatabaseReader queryAnalysisPropertiesForAsset:]
  -[VCPDatabaseReader queryLocalIdentifiersForTaskID:withStatus:]
  -[VCPDatabaseReader querySchedulingHistoryRecords:forActivityID:sinceDate:]
  -[VCPDatabaseReader queryAnalysisPropertiesForAssets:]
  -[VCPDatabaseReader blacklistedLocalIdentifiersFromAssets:]
  -[VCPDatabaseReader queryFailedProcessingStatusFromAssets:forTaskID:]
  -[VCPDatabaseReader countForTaskID:withProcessingStatus:]
  -[VCPDatabaseReader queryAnalysisForAsset:]
  -[VCPDatabaseReader isAssetBlacklisted:blacklistDate:]
  -[VCPDatabaseReader queryAssetsAnalyzedSince:]
  -[VCPDatabaseReader queryAnalysisForAsset:withTypes:]


VCPMADResourceLock : NSObject
  // instance methods
  -[VCPMADResourceLock .cxx_destruct]
  -[VCPMADResourceLock reset]
  -[VCPMADResourceLock initWithResourceManager:andResource:]
  -[VCPMADResourceLock dealloc]


VCPMADResourceEntry : NSObject
 @property  VCPMADResource *resource
 @property  long long activeCount

  // instance methods
  -[VCPMADResourceEntry activeCount]
  -[VCPMADResourceEntry setResource:]
  -[VCPMADResourceEntry initWithResource:]
  -[VCPMADResourceEntry setActiveCount:]
  -[VCPMADResourceEntry .cxx_destruct]
  -[VCPMADResourceEntry resource]


VCPMADResourceManager : NSObject
  // class methods
  +[VCPMADResourceManager sharedManager]

  // instance methods
  -[VCPMADResourceManager reserveBudget:]
  -[VCPMADResourceManager currentBudget]
  -[VCPMADResourceManager _reserveBudget:]
  -[VCPMADResourceManager .cxx_destruct]
  -[VCPMADResourceManager init]
  -[VCPMADResourceManager _setBudget:]
  -[VCPMADResourceManager activateResource:]
  -[VCPMADResourceManager purgeAllResources]
  -[VCPMADResourceManager dealloc]
  -[VCPMADResourceManager checkTimeout]
  -[VCPMADResourceManager deactivateResource:]
  -[VCPMADResourceManager entryForResource:]
  -[VCPMADResourceManager _purgeAllResources]


VCPVideoCNNBackbone : NSObject
 @property  ^f outputLastLayer400
 @property  ^f outputBeforeFc
 @property  ^f outputBeforePooling

  // class methods
  +[VCPVideoCNNBackbone sharedModel:outputNames:properties:]

  // instance methods
  -[VCPVideoCNNBackbone .cxx_destruct]
  -[VCPVideoCNNBackbone initWithConfig:]
  -[VCPVideoCNNBackbone inference:]
  -[VCPVideoCNNBackbone outputLastLayer400]
  -[VCPVideoCNNBackbone outputBeforePooling]
  -[VCPVideoCNNBackbone outputBeforeFc]


VCPHuman : NSObject
 @property  unsigned long flags
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  float confidence

  // class methods
  +[VCPHuman flagsFromKeypoints:withMinConfidence:]

  // instance methods
  -[VCPHuman setFlags:]
  -[VCPHuman setConfidence:]
  -[VCPHuman confidence]
  -[VCPHuman init]
  -[VCPHuman flags]
  -[VCPHuman setBounds:]
  -[VCPHuman bounds]


VCPDeviceInformation : NSObject
  // class methods
  +[VCPDeviceInformation marketingName]
  +[VCPDeviceInformation isHomePod]
  +[VCPDeviceInformation canRenderVariation]


VCPProtoMovieStabilizationResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float analysisConfidence
 @property  BOOL gyroStabilization
 @property  BOOL hasRecipeBlob
 @property  NSData *recipeBlob

  // class methods
  +[VCPProtoMovieStabilizationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieStabilizationResult mergeFrom:]
  -[VCPProtoMovieStabilizationResult .cxx_destruct]
  -[VCPProtoMovieStabilizationResult dictionaryRepresentation]
  -[VCPProtoMovieStabilizationResult writeTo:]
  -[VCPProtoMovieStabilizationResult isEqual:]
  -[VCPProtoMovieStabilizationResult copyTo:]
  -[VCPProtoMovieStabilizationResult readFrom:]
  -[VCPProtoMovieStabilizationResult copyWithZone:]
  -[VCPProtoMovieStabilizationResult gyroStabilization]
  -[VCPProtoMovieStabilizationResult exportToLegacyDictionary]
  -[VCPProtoMovieStabilizationResult setGyroStabilization:]
  -[VCPProtoMovieStabilizationResult setAnalysisConfidence:]
  -[VCPProtoMovieStabilizationResult analysisConfidence]
  -[VCPProtoMovieStabilizationResult setRecipeBlob:]
  -[VCPProtoMovieStabilizationResult hasRecipeBlob]
  -[VCPProtoMovieStabilizationResult recipeBlob]


VCPMADVIVisualSearchResource : VCPMADVIResource
  // class methods
  +[VCPMADVIVisualSearchResource sharedResource]


VCPProtoMovieHumanActionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float absoluteScore
 @property  float relativeScore
 @property  float humanScore
 @property  BOOL hasFaceId
 @property  NSString *faceId
 @property  BOOL hasBounds
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoMovieHumanActionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHumanActionResult setTimeRange:]
  -[VCPProtoMovieHumanActionResult timeRange]
  -[VCPProtoMovieHumanActionResult mergeFrom:]
  -[VCPProtoMovieHumanActionResult faceId]
  -[VCPProtoMovieHumanActionResult .cxx_destruct]
  -[VCPProtoMovieHumanActionResult hasBounds]
  -[VCPProtoMovieHumanActionResult dictionaryRepresentation]
  -[VCPProtoMovieHumanActionResult writeTo:]
  -[VCPProtoMovieHumanActionResult isEqual:]
  -[VCPProtoMovieHumanActionResult copyTo:]
  -[VCPProtoMovieHumanActionResult readFrom:]
  -[VCPProtoMovieHumanActionResult copyWithZone:]
  -[VCPProtoMovieHumanActionResult setBounds:]
  -[VCPProtoMovieHumanActionResult setFaceId:]
  -[VCPProtoMovieHumanActionResult bounds]
  -[VCPProtoMovieHumanActionResult hasFaceId]
  -[VCPProtoMovieHumanActionResult absoluteScore]
  -[VCPProtoMovieHumanActionResult setAbsoluteScore:]
  -[VCPProtoMovieHumanActionResult relativeScore]
  -[VCPProtoMovieHumanActionResult setRelativeScore:]
  -[VCPProtoMovieHumanActionResult humanScore]
  -[VCPProtoMovieHumanActionResult setHumanScore:]
  -[VCPProtoMovieHumanActionResult exportToLegacyDictionary]


VCPEdgeDetector : NSObject
  // instance methods
  -[VCPEdgeDetector dealloc]
  -[VCPEdgeDetector noiseReduction:sigma:imageFiltered:]
  -[VCPEdgeDetector gradientEstimation:width:height:gradient:gradientMag:]
  -[VCPEdgeDetector isInImage:width:height:]
  -[VCPEdgeDetector initWithImage:edgeMap:width:height:widthExtension:heightExtension:]
  -[VCPEdgeDetector detectWithSigma:lowThreshold:highThreshold:]


VCPEffectsAnalyzer : NSObject
  // class methods
  +[VCPEffectsAnalyzer isAutoLoopFramworkAvailable]
  +[VCPEffectsAnalyzer usePHAssetScene]
  +[VCPEffectsAnalyzer gatingResultKeyToIndex]
  +[VCPEffectsAnalyzer getResultIndex:]
  +[VCPEffectsAnalyzer gatingTypeKeys]

  // instance methods
  -[VCPEffectsAnalyzer enumerateMatchingScenesOfAsset:forLongExposureUsingBlock:]
  -[VCPEffectsAnalyzer generateStatsToBeCollectedFrom:]
  -[VCPEffectsAnalyzer reportLivePhotoEffectAnalysisResults:]
  -[VCPEffectsAnalyzer performanSceneClassificationOfImageFileAtURL:]
  -[VCPEffectsAnalyzer matchingNodeForSceneClassification:inSceneNames:]
  -[VCPEffectsAnalyzer initWithAnalysisResults:]
  -[VCPEffectsAnalyzer initWithFlagHasFaceOrPet:]
  -[VCPEffectsAnalyzer analyzeAsset:onDemand:cancel:statsFlags:results:]


VCPImageExposurePreAnalyzer : VCPImageAnalyzer
 @property  float exposureScore

  // instance methods
  -[VCPImageExposurePreAnalyzer exposureScore]
  -[VCPImageExposurePreAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageExposurePreAnalyzer computeRegionNoise:blockTextureness:average:width:height:stride:]
  -[VCPImageExposurePreAnalyzer computeNoiseLevel:width:height:stride:textureness:]


VCPGeometryUtils : NSObject
  // class methods
  +[VCPGeometryUtils rectFromMappingNormalizedRect:toBounds:]
  +[VCPGeometryUtils normalizedRectForRect:inBounds:]
  +[VCPGeometryUtils normalizedRectForRect:inBoundsOfSize:]
  +[VCPGeometryUtils rectFromMappingNormalizedRect:toBoundsOfSize:]
  +[VCPGeometryUtils pointFromNormalizedPoint:inBounds:]


VCPTimer : NSObject
  // class methods
  +[VCPTimer timerWithIntervalSeconds:isOneShot:andBlock:]
  +[VCPTimer timerWithInterval:unit:oneShot:andBlock:]

  // instance methods
  -[VCPTimer handleTimerEvent]
  -[VCPTimer .cxx_destruct]
  -[VCPTimer initWithIntervalNanoseconds:isOneShot:andBlock:]
  -[VCPTimer destroy]
  -[VCPTimer dealloc]


VCPExifAnalyzer : NSObject
  // instance methods
  -[VCPExifAnalyzer .cxx_destruct]
  -[VCPExifAnalyzer transformUprightAboutTopLeft:]
  -[VCPExifAnalyzer addFaceResults:flags:]
  -[VCPExifAnalyzer initWithProperties:forAnalysisTypes:]
  -[VCPExifAnalyzer analyzeAsset:results:]


VCPFace : NSObject
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  BOOL leftEyeClosed
 @property  BOOL rightEyeClosed
 @property  BOOL smile
 @property  long long yaw
 @property  int trackID
 @property  float confidence
 @property  float faceQuality
 @property  VNFaceObservation *observation

  // instance methods
  -[VCPFace setConfidence:]
  -[VCPFace setYaw:]
  -[VCPFace .cxx_destruct]
  -[VCPFace leftEyeClosed]
  -[VCPFace rightEyeClosed]
  -[VCPFace setObservation:]
  -[VCPFace confidence]
  -[VCPFace trackID]
  -[VCPFace setLeftEyeClosed:]
  -[VCPFace setRightEyeClosed:]
  -[VCPFace smile]
  -[VCPFace init]
  -[VCPFace yaw]
  -[VCPFace setTrackID:]
  -[VCPFace setBounds:]
  -[VCPFace observation]
  -[VCPFace bounds]
  -[VCPFace faceQuality]
  -[VCPFace faceBounds:height:]
  -[VCPFace flagsForOrientation:width:height:]
  -[VCPFace faceBoundsWithTransform:height:transform:]
  -[VCPFace setSmile:]
  -[VCPFace setFaceQuality:]


VCPFaceDetectionRange : NSObject
 @property  {?=qiIq} start
 @property  {?=qiIq} last
 @property  unsigned long flags
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bounds
 @property  unsigned long position
 @property  unsigned long faceID

  // instance methods
  -[VCPFaceDetectionRange setFlags:]
  -[VCPFaceDetectionRange setLast:]
  -[VCPFaceDetectionRange setStart:]
  -[VCPFaceDetectionRange faceID]
  -[VCPFaceDetectionRange last]
  -[VCPFaceDetectionRange flags]
  -[VCPFaceDetectionRange start]
  -[VCPFaceDetectionRange setBounds:]
  -[VCPFaceDetectionRange setPosition:]
  -[VCPFaceDetectionRange bounds]
  -[VCPFaceDetectionRange position]
  -[VCPFaceDetectionRange setFaceID:]


VCPTimeMeasurement : NSObject
 @property  double elapsedTimeSeconds
 @property  BOOL started

  // instance methods
  -[VCPTimeMeasurement started]
  -[VCPTimeMeasurement elapsedTimeSeconds]
  -[VCPTimeMeasurement stop]
  -[VCPTimeMeasurement init]
  -[VCPTimeMeasurement reset]
  -[VCPTimeMeasurement start]


VCPHomeFaceIdentificationTask : NSObject <VCPMADTaskProtocol>
  // class methods
  +[VCPHomeFaceIdentificationTask taskWithFaceCrop:andCompletionHandler:]

  // instance methods
  -[VCPHomeFaceIdentificationTask resourceRequirement]
  -[VCPHomeFaceIdentificationTask .cxx_destruct]
  -[VCPHomeFaceIdentificationTask run:]
  -[VCPHomeFaceIdentificationTask cancel]
  -[VCPHomeFaceIdentificationTask autoCancellable]
  -[VCPHomeFaceIdentificationTask dealloc]
  -[VCPHomeFaceIdentificationTask run]
  -[VCPHomeFaceIdentificationTask initWithFaceCrop:andCompletionHandler:]
  -[VCPHomeFaceIdentificationTask configureRequest:withRevision:]


VCPFingerprint : NSObject
 @property  NSString *master
 @property  NSString *adjusted

  // class methods
  +[VCPFingerprint fingerprintWithMaster:adjusted:]

  // instance methods
  -[VCPFingerprint master]
  -[VCPFingerprint .cxx_destruct]
  -[VCPFingerprint adjusted]
  -[VCPFingerprint init]
  -[VCPFingerprint isEqualToFingerprint:]
  -[VCPFingerprint initWithMaster:adjusted:]


VCPFaceAnalyzer : NSObject
  // class methods
  +[VCPFaceAnalyzer _faceprintFastMode]
  +[VCPFaceAnalyzer _allowANE]

  // instance methods
  -[VCPFaceAnalyzer .cxx_destruct]
  -[VCPFaceAnalyzer initWithContext:]
  -[VCPFaceAnalyzer dealloc]
  -[VCPFaceAnalyzer _calculateIoUBetweenObservation:andObservation:]
  -[VCPFaceAnalyzer _calculateOverlappingBetweenFaceObservation:andHumanObservation:]
  -[VCPFaceAnalyzer getVCPPhotosFaceFromFaceObservation:humanObservation:sourceWidth:sourceHeight:visionRequests:algorithmVersion:force:andError:]
  -[VCPFaceAnalyzer _qualityMeasureForFace:countOfFacesOnAsset:]
  -[VCPFaceAnalyzer _isColocatingAnimalObservation:withFaceObservations:orTorsoObservations:]
  -[VCPFaceAnalyzer _checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:]
  -[VCPFaceAnalyzer _createBlurRequests:andExposureRequests:forFaceObservations:]
  -[VCPFaceAnalyzer getVCPPhotosFacesFromFaceObservations:humanObservations:animalObservations:sourceWidth:sourceHeight:visionRequests:blurScorePerFace:exposureScorePerFace:tooSmallFaceObservations:algorithmVersion:]
  -[VCPFaceAnalyzer _vcpPhotosFaceArrayFromAsset:]
  -[VCPFaceAnalyzer _verifiedPersonsFetchResultWithLocalIdentifiers:andPhotoLibrary:andError:]
  -[VCPFaceAnalyzer analyzeWithImage:andAsset:andOptions:andResults:]
  -[VCPFaceAnalyzer _performAnalysis:withRequestHandler:options:sourceWidth:sourceHeight:]
  -[VCPFaceAnalyzer _refineAnalysis:forAsset:andImage:]
  -[VCPFaceAnalyzer _loadPVImage:forAsset:]
  -[VCPFaceAnalyzer _detectFacesWithPVImage:forAsset:withAnalysis:]
  -[VCPFaceAnalyzer processAsset:withAnalysis:]


VCPFrameScoreFilter : NSObject
  // instance methods
  -[VCPFrameScoreFilter dealloc]
  -[VCPFrameScoreFilter initWithFilterTabs:distanceVariance:diffVariance:]
  -[VCPFrameScoreFilter processFrameScore:validScore:]


VCPProtoLivePhotoKeyFrameStillResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness
 @property  float textureness
 @property  BOOL hasFlash
 @property  float stillTime

  // class methods
  +[VCPProtoLivePhotoKeyFrameStillResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoKeyFrameStillResult hasFlash]
  -[VCPProtoLivePhotoKeyFrameStillResult mergeFrom:]
  -[VCPProtoLivePhotoKeyFrameStillResult dictionaryRepresentation]
  -[VCPProtoLivePhotoKeyFrameStillResult writeTo:]
  -[VCPProtoLivePhotoKeyFrameStillResult isEqual:]
  -[VCPProtoLivePhotoKeyFrameStillResult sharpness]
  -[VCPProtoLivePhotoKeyFrameStillResult copyTo:]
  -[VCPProtoLivePhotoKeyFrameStillResult readFrom:]
  -[VCPProtoLivePhotoKeyFrameStillResult copyWithZone:]
  -[VCPProtoLivePhotoKeyFrameStillResult setSharpness:]
  -[VCPProtoLivePhotoKeyFrameStillResult textureness]
  -[VCPProtoLivePhotoKeyFrameStillResult setTextureness:]
  -[VCPProtoLivePhotoKeyFrameStillResult setHasFlash:]
  -[VCPProtoLivePhotoKeyFrameStillResult stillTime]
  -[VCPProtoLivePhotoKeyFrameStillResult setStillTime:]
  -[VCPProtoLivePhotoKeyFrameStillResult exportToLegacyDictionary]


VCPProtoImageSceneprintResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *sceneprintBlob

  // class methods
  +[VCPProtoImageSceneprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageSceneprintResult mergeFrom:]
  -[VCPProtoImageSceneprintResult .cxx_destruct]
  -[VCPProtoImageSceneprintResult dictionaryRepresentation]
  -[VCPProtoImageSceneprintResult writeTo:]
  -[VCPProtoImageSceneprintResult isEqual:]
  -[VCPProtoImageSceneprintResult copyTo:]
  -[VCPProtoImageSceneprintResult readFrom:]
  -[VCPProtoImageSceneprintResult copyWithZone:]
  -[VCPProtoImageSceneprintResult setSceneprintBlob:]
  -[VCPProtoImageSceneprintResult sceneprintBlob]
  -[VCPProtoImageSceneprintResult exportToLegacyDictionary]


VCPFullVideoAnalyzer : VCPVideoAnalyzer
 @property  float qualityScore
 @property  float actionScore
 @property  float interestingnessScore
 @property  float obstructionScore
 @property  float trackingScore
 @property  NSDictionary *objectsMotion
 @property  NSArray *globalMotion

  // class methods
  +[VCPFullVideoAnalyzer enableMoflow]
  +[VCPFullVideoAnalyzer useSceneprintInSceneAnalysis]

  // instance methods
  -[VCPFullVideoAnalyzer process:]
  -[VCPFullVideoAnalyzer .cxx_construct]
  -[VCPFullVideoAnalyzer results]
  -[VCPFullVideoAnalyzer .cxx_destruct]
  -[VCPFullVideoAnalyzer initWithTransform:]
  -[VCPFullVideoAnalyzer setActionScore:]
  -[VCPFullVideoAnalyzer actionScore]
  -[VCPFullVideoAnalyzer dealloc]
  -[VCPFullVideoAnalyzer qualityScore]
  -[VCPFullVideoAnalyzer setQualityScore:]
  -[VCPFullVideoAnalyzer analyzeFrame:withTimestamp:andDuration:properties:flags:]
  -[VCPFullVideoAnalyzer seedAnalyzersWithPixelBuffer:startTime:]
  -[VCPFullVideoAnalyzer estimateExpressionScore:encodeStats:frameWidth:frameHeight:]
  -[VCPFullVideoAnalyzer isStableMetaMotion:]
  -[VCPFullVideoAnalyzer reviseFrameTrackScore:saliencyRegions:]
  -[VCPFullVideoAnalyzer processAndEstimateQualityScore:]
  -[VCPFullVideoAnalyzer setInterestingnessScore:]
  -[VCPFullVideoAnalyzer computeExposureScoreOfFrame:]
  -[VCPFullVideoAnalyzer interestingnessScore]
  -[VCPFullVideoAnalyzer addSceneAnalysisResult:to:optional:]
  -[VCPFullVideoAnalyzer estimateQualityScore:]
  -[VCPFullVideoAnalyzer addResult:to:forKey:optional:]
  -[VCPFullVideoAnalyzer initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:]
  -[VCPFullVideoAnalyzer prepareVideoAnalysisByScenes:]
  -[VCPFullVideoAnalyzer prepareLivePhotoAnalysisByScenes:]
  -[VCPFullVideoAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPFullVideoAnalyzer finishAnalysisPass:]
  -[VCPFullVideoAnalyzer privateResults]
  -[VCPFullVideoAnalyzer getSceneSwichFrequency]
  -[VCPFullVideoAnalyzer setNextCaptureFrame:]
  -[VCPFullVideoAnalyzer obstructionScore]
  -[VCPFullVideoAnalyzer setObstructionScore:]
  -[VCPFullVideoAnalyzer trackingScore]
  -[VCPFullVideoAnalyzer setTrackingScore:]
  -[VCPFullVideoAnalyzer objectsMotion]
  -[VCPFullVideoAnalyzer globalMotion]


VCPGaborFilter : NSObject
  // instance methods
  -[VCPGaborFilter dealloc]
  -[VCPGaborFilter createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:]
  -[VCPGaborFilter initWithNumberOfScales:numOfOrientations:width:height:]
  -[VCPGaborFilter processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:]


VCPHoughTransform : NSObject
  // instance methods
  -[VCPHoughTransform dealloc]
  -[VCPHoughTransform Transform]
  -[VCPHoughTransform initWithEdgeMap:mapWidth:mapHeight:angleStep:]
  -[VCPHoughTransform DetectLinesWithThreshold:output:]


VCPCNNPersonKeypointsDetector : NSObject
  // instance methods
  -[VCPCNNPersonKeypointsDetector .cxx_destruct]
  -[VCPCNNPersonKeypointsDetector dealloc]
  -[VCPCNNPersonKeypointsDetector copyImage:toData:]
  -[VCPCNNPersonKeypointsDetector createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:]
  -[VCPCNNPersonKeypointsDetector parseKeypoints:]
  -[VCPCNNPersonKeypointsDetector initWithForceCPU:sharedModel:]
  -[VCPCNNPersonKeypointsDetector analyzeFrame:withBox:keypoints:]


VCPImageAnalyzer : NSObject
  // instance methods
  -[VCPImageAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageAnalyzer calculateTextureness:height:width:sdof:result:]
  -[VCPImageAnalyzer analyzePixelBufferInTiles:results:cancel:]
  -[VCPImageAnalyzer processTile:results:cancel:]
  -[VCPImageAnalyzer aggregateTileResults:tileRect:imageSize:landscape:results:]


VCPVNImageprintWrapper : NSObject
 @property  unsigned long type
 @property  int version
 @property  NSData *data

  // class methods
  +[VCPVNImageprintWrapper wrapperWithImageprintType:version:andData:]
  +[VCPVNImageprintWrapper generateVNImageprintWithType:archiveData:andError:]

  // instance methods
  -[VCPVNImageprintWrapper .cxx_destruct]
  -[VCPVNImageprintWrapper data]
  -[VCPVNImageprintWrapper type]
  -[VCPVNImageprintWrapper version]
  -[VCPVNImageprintWrapper initWithImageprintType:version:andData:]
  -[VCPVNImageprintWrapper calculateDistance:toWrapper:andError:]


VCPVideoCNNActionClassifier : VCPVideoCNNTask
  // class methods
  +[VCPVideoCNNActionClassifier sharedModel:inputNames:properties:]

  // instance methods
  -[VCPVideoCNNActionClassifier .cxx_construct]
  -[VCPVideoCNNActionClassifier results]
  -[VCPVideoCNNActionClassifier .cxx_destruct]
  -[VCPVideoCNNActionClassifier finishAnalysisPass:]
  -[VCPVideoCNNActionClassifier initWithPHFaces:]
  -[VCPVideoCNNActionClassifier run:withPersons:andRegionCrop:atTime:andDuration:]


VCPImageBlurAnalyzer : VCPBlurAnalyzer
 @property  float sharpness
 @property  float textureScore

  // instance methods
  -[VCPImageBlurAnalyzer .cxx_destruct]
  -[VCPImageBlurAnalyzer sharpness]
  -[VCPImageBlurAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageBlurAnalyzer textureScore]
  -[VCPImageBlurAnalyzer setFaceResults:]
  -[VCPImageBlurAnalyzer initWithFaceResults:sdof:revision:]
  -[VCPImageBlurAnalyzer prepareFaceBlurModel:]
  -[VCPImageBlurAnalyzer scaleRegion:ofImage:toData:withWidth:andHeight:]
  -[VCPImageBlurAnalyzer getFaceScoreFromOutput:ratio:]
  -[VCPImageBlurAnalyzer estimateDistance:prevHomography:]
  -[VCPImageBlurAnalyzer analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:]
  -[VCPImageBlurAnalyzer computeLocalSharpness:]
  -[VCPImageBlurAnalyzer spatialPooling]
  -[VCPImageBlurAnalyzer computeCNNFaceSharpness:result:cancel:]
  -[VCPImageBlurAnalyzer computeSharpnessScore:forFacesInImage:]
  -[VCPImageBlurAnalyzer computeGyroSharpness:]
  -[VCPImageBlurAnalyzer initWithFaceResults:sdof:]
  -[VCPImageBlurAnalyzer setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:]


VCPMABaseTask : NSObject <VCPMADTaskProtocol>
 @property  @? completionHandler
 @property  @? cancelBlock

  // instance methods
  -[VCPMABaseTask isCanceled]
  -[VCPMABaseTask resourceRequirement]
  -[VCPMABaseTask .cxx_destruct]
  -[VCPMABaseTask initWithCompletionHandler:]
  -[VCPMABaseTask init]
  -[VCPMABaseTask run:]
  -[VCPMABaseTask cancelBlock]
  -[VCPMABaseTask setCancelBlock:]
  -[VCPMABaseTask cancel]
  -[VCPMABaseTask autoCancellable]
  -[VCPMABaseTask dealloc]
  -[VCPMABaseTask completionHandler]
  -[VCPMABaseTask run]


VCPImageCompositionAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageCompositionAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPImageConverter : NSObject
  // instance methods
  -[VCPImageConverter init]
  -[VCPImageConverter dealloc]
  -[VCPImageConverter initWithPixelFormat:]
  -[VCPImageConverter resize:height:]
  -[VCPImageConverter convertImage:yuvFrame:]


VCPMADEmbeddingGenerationTask : NSObject <VCPMADServiceImageProcessingSubtaskProtocol, VCPMADTaskProtocol>
  // class methods
  +[VCPMADEmbeddingGenerationTask dependencies]
  +[VCPMADEmbeddingGenerationTask taskWithRequest:imageAsset:andSignpostPayload:]

  // instance methods
  -[VCPMADEmbeddingGenerationTask resourceRequirement]
  -[VCPMADEmbeddingGenerationTask .cxx_destruct]
  -[VCPMADEmbeddingGenerationTask cancel]
  -[VCPMADEmbeddingGenerationTask initWithRequest:imageAsset:andSignpostPayload:]
  -[VCPMADEmbeddingGenerationTask autoCancellable]
  -[VCPMADEmbeddingGenerationTask run]


VCPImageDescriptor : NSObject <VCPDistanceDescriptorProtocol>
  // class methods
  +[VCPImageDescriptor preferredPixelFormat]
  +[VCPImageDescriptor usePHAssetData]
  +[VCPImageDescriptor descriptorWithImage:]
  +[VCPImageDescriptor descriptorWithData:]

  // instance methods
  -[VCPImageDescriptor initWithImage:]
  -[VCPImageDescriptor .cxx_destruct]
  -[VCPImageDescriptor serialize]
  -[VCPImageDescriptor initWithData:]
  -[VCPImageDescriptor computeDistance:toDescriptor:]


VCPImageExposureAnalyzer : VCPImageAnalyzer
 @property  float exposureScore

  // instance methods
  -[VCPImageExposureAnalyzer exposureScore]
  -[VCPImageExposureAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageExposureAnalyzer computeRegionNoise:blockTextureness:average:width:height:stride:]
  -[VCPImageExposureAnalyzer computeNoiseLevel:width:height:stride:textureness:]


VCPVideoCNNTask : NSObject
  // instance methods
  -[VCPVideoCNNTask results]
  -[VCPVideoCNNTask run:]
  -[VCPVideoCNNTask finishAnalysisPass:]
  -[VCPVideoCNNTask run:withPersons:andRegionCrop:atTime:andDuration:]


VCPAnalysisProgressQuery : NSObject
  // class methods
  +[VCPAnalysisProgressQuery queryProgressDetail:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:]
  +[VCPAnalysisProgressQuery queryProgress:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:]
  +[VCPAnalysisProgressQuery queryCachedFaceAnalysisProgress:forPhotoLibrary:withExtendTimeoutBlock:]
  +[VCPAnalysisProgressQuery _countMediaAnalysisWithAssetBatch:andDatabase:]
  +[VCPAnalysisProgressQuery _countFaceAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countSceneAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countOCRAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countVisualSearchAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countEmbeddingAnalysisWithAssetBatch:]
  +[VCPAnalysisProgressQuery _countAnalysisWithAssetBatch:andDatabase:andTaskID:]
  +[VCPAnalysisProgressQuery _countFailuresWithAssetBatch:andDatabase:andTaskID:]
  +[VCPAnalysisProgressQuery _vipStatusForPhotoLibrary:andType:]
  +[VCPAnalysisProgressQuery _queryProgressDetailExpressEmbeddingAnalysis:forPhotoLibrary:]
  +[VCPAnalysisProgressQuery _processedPredicateForTaskID:]
  +[VCPAnalysisProgressQuery _screenProgress]
  +[VCPAnalysisProgressQuery _queryProgressDetailExpress:forPhotoLibrary:andTaskID:]
  +[VCPAnalysisProgressQuery _scanPhotoLibrary:withTaskID:statistics:andExtendTimeoutBlock:]
  +[VCPAnalysisProgressQuery reportProgressForPhotoLibrary:andTaskID:withExtendTimeoutBlock:]


VCPImageFaceDetector : VCPImageAnalyzer
  // class methods
  +[VCPImageFaceDetector faceDetector]

  // instance methods
  -[VCPImageFaceDetector analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageFaceDetector faceDetection:faces:cancel:]
  -[VCPImageFaceDetector isDuplicate:withRect:]
  -[VCPImageFaceDetector processTile:results:cancel:]
  -[VCPImageFaceDetector aggregateTileResults:tileRect:imageSize:landscape:results:]


VCPImageFaceExpressionAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageFaceExpressionAnalyzer .cxx_destruct]
  -[VCPImageFaceExpressionAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageFaceExpressionAnalyzer initWithFaceResults:]


VCPVideoStabilizationAssetProcessingTask : NSObject <VCPMADTaskProtocol>
  // class methods
  +[VCPVideoStabilizationAssetProcessingTask deserializeStabilizationRecipeInAttributes:]
  +[VCPVideoStabilizationAssetProcessingTask taskWithAssets:andOptions:andCompletionHandler:]

  // instance methods
  -[VCPVideoStabilizationAssetProcessingTask main]
  -[VCPVideoStabilizationAssetProcessingTask resourceRequirement]
  -[VCPVideoStabilizationAssetProcessingTask .cxx_destruct]
  -[VCPVideoStabilizationAssetProcessingTask cancel]
  -[VCPVideoStabilizationAssetProcessingTask autoCancellable]
  -[VCPVideoStabilizationAssetProcessingTask dealloc]
  -[VCPVideoStabilizationAssetProcessingTask run]
  -[VCPVideoStabilizationAssetProcessingTask initWithAssets:andOptions:andCompletionHandler:]


VCPImageFaceQualityAnalyzer : VCPImageAnalyzer
 @property  NSMutableArray *faceQualityScores

  // instance methods
  -[VCPImageFaceQualityAnalyzer .cxx_destruct]
  -[VCPImageFaceQualityAnalyzer dealloc]
  -[VCPImageFaceQualityAnalyzer analyzeDetectedFaces:faceResults:cancel:]
  -[VCPImageFaceQualityAnalyzer faceQualityScores]
  -[VCPImageFaceQualityAnalyzer setFaceQualityScores:]


VCPMADCoreAnalyticsManager : NSObject
  // class methods
  +[VCPMADCoreAnalyticsManager sharedManager]

  // instance methods
  -[VCPMADCoreAnalyticsManager .cxx_destruct]
  -[VCPMADCoreAnalyticsManager init]
  -[VCPMADCoreAnalyticsManager flush]
  -[VCPMADCoreAnalyticsManager dealloc]
  -[VCPMADCoreAnalyticsManager sendEvent:withAnalytics:]
  -[VCPMADCoreAnalyticsManager setValue:forField:andEvent:]
  -[VCPMADCoreAnalyticsManager accumulateInt64Value:forField:andEvent:]
  -[VCPMADCoreAnalyticsManager accumulateDoubleValue:forField:andEvent:]
  -[VCPMADCoreAnalyticsManager sendSessionEvent:]


VCPImageLivePhotoBlurAnalyzer : VCPBlurAnalyzer
  // instance methods
  -[VCPImageLivePhotoBlurAnalyzer .cxx_destruct]
  -[VCPImageLivePhotoBlurAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageLivePhotoBlurAnalyzer initWithMovingObjectsResults:]


VCPFaceIDModel : NSObject
  // class methods
  +[VCPFaceIDModel persistPetsModel:toPath:error:]
  +[VCPFaceIDModel _loadModelAtPath:error:]
  +[VCPFaceIDModel addFaceObservations:forPersonIdentifier:toModel:error:]
  +[VCPFaceIDModel loadVIPModelAtPath:withVIPType:error:]
  +[VCPFaceIDModel _loadPetsModelAtPath:error:]
  +[VCPFaceIDModel petClassificationThreshold]
  +[VCPFaceIDModel classifyAnimalObservation:withModel:error:]
  +[VCPFaceIDModel animalObservationFromAnimalprintData:]
  +[VCPFaceIDModel personVIPModelFileName]
  +[VCPFaceIDModel newMutablePersonsModel]
  +[VCPFaceIDModel faceObservationFromFaceprintData:]
  +[VCPFaceIDModel classifyFaceObservation:withModel:error:]
  +[VCPFaceIDModel petVIPModelFileName]
  +[VCPFaceIDModel persistModel:toPath:error:]


VCPFaceProcessingVersionManager : NSObject
  // class methods
  +[VCPFaceProcessingVersionManager sharedManagerForPhotoLibrary:]
  +[VCPFaceProcessingVersionManager resetLevelDescription:]

  // instance methods
  -[VCPFaceProcessingVersionManager initWithPhotoLibrary:]
  -[VCPFaceProcessingVersionManager currentProcessingVersion]
  -[VCPFaceProcessingVersionManager _updateVersionStateFileWithError:]
  -[VCPFaceProcessingVersionManager .cxx_destruct]
  -[VCPFaceProcessingVersionManager resetAnalysisDataWithResetLevel:error:]
  -[VCPFaceProcessingVersionManager _updateCurrentProcessingVersion:]
  -[VCPFaceProcessingVersionManager defaultProcessingVersion]
  -[VCPFaceProcessingVersionManager migrateFaceProcessingToVersion:]
  -[VCPFaceProcessingVersionManager _versionStateURL]


VCPKeypoint : NSObject
 @property  {CGPoint=dd} location
 @property  float confidence

  // instance methods
  -[VCPKeypoint setConfidence:]
  -[VCPKeypoint confidence]
  -[VCPKeypoint setLocation:]
  -[VCPKeypoint location]


VCPPersonObservation : NSObject
 @property  NSArray *keypoints
 @property  float relativeActionScore
 @property  float absoluteActionScore
 @property  int personID
 @property  int revision

  // instance methods
  -[VCPPersonObservation setPersonID:]
  -[VCPPersonObservation personID]
  -[VCPPersonObservation setRevision:]
  -[VCPPersonObservation .cxx_destruct]
  -[VCPPersonObservation revision]
  -[VCPPersonObservation keypoints]
  -[VCPPersonObservation setRelativeActionScore:]
  -[VCPPersonObservation setAbsoluteActionScore:]
  -[VCPPersonObservation setKeypoints:]
  -[VCPPersonObservation relativeActionScore]
  -[VCPPersonObservation absoluteActionScore]


VCPHandObservation : NSObject
 @property  NSArray *keypoints
 @property  int chirality
 @property  int handID
 @property  int revision

  // instance methods
  -[VCPHandObservation setRevision:]
  -[VCPHandObservation .cxx_destruct]
  -[VCPHandObservation revision]
  -[VCPHandObservation keypoints]
  -[VCPHandObservation chirality]
  -[VCPHandObservation setKeypoints:]
  -[VCPHandObservation setChirality:]
  -[VCPHandObservation handID]
  -[VCPHandObservation setHandID:]


VCPMotionFlowObservation : NSObject
 @property  ^{__CVBuffer=} pixelBuffer
 @property  int revision

  // instance methods
  -[VCPMotionFlowObservation pixelBuffer]
  -[VCPMotionFlowObservation setRevision:]
  -[VCPMotionFlowObservation revision]
  -[VCPMotionFlowObservation dealloc]
  -[VCPMotionFlowObservation setPixelBuffer:]


VCPMAMLFeatureProvider : NSObject <MLFeatureProvider>
 @property  NSSet *featureNames

  // class methods
  +[VCPMAMLFeatureProvider featureProviderWithCVPixelBuffer:andFeatureName:]

  // instance methods
  -[VCPMAMLFeatureProvider .cxx_destruct]
  -[VCPMAMLFeatureProvider featureNames]
  -[VCPMAMLFeatureProvider init]
  -[VCPMAMLFeatureProvider featureValueForName:]
  -[VCPMAMLFeatureProvider dealloc]
  -[VCPMAMLFeatureProvider initWithCVPixelBuffer:andFeatureName:]


VCPImageManager : NSObject
  // class methods
  +[VCPImageManager allowFastPathDecodeWithUniformType:pixelWidth:andPixelHeight:]
  +[VCPImageManager loggingEnabled]
  +[VCPImageManager sharedImageManager]
  +[VCPImageManager _exportReencodedJPEG]
  +[VCPImageManager canDecodeAcceleratedUniformTypeIdentifier:]

  // instance methods
  -[VCPImageManager convertPixelBuffer:toPixelFormat:]
  -[VCPImageManager imageForResource:pixelFormat:]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromImageURL:]
  -[VCPImageManager decodeImageSource:withUniformTypeIdentifier:pixelFormat:maxDimension:orientation:pixelBuffer:]
  -[VCPImageManager createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPImageManager pixelBufferWithFormat:fromImageURL:flushCache:]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:orientation:]
  -[VCPImageManager compressCVPixelBuffer:toJPEGData:targetBitStreamLength:padding:]
  -[VCPImageManager .cxx_destruct]
  -[VCPImageManager imageForResource:pixelFormat:maxDimension:]
  -[VCPImageManager acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:orientation:flushCache:]
  -[VCPImageManager flushCache]
  -[VCPImageManager pixelBufferWithFormat:andMaxDimension:fromImageURL:orientation:]
  -[VCPImageManager init]
  -[VCPImageManager dataForResource:]
  -[VCPImageManager dealloc]
  -[VCPImageManager drawImage:pixelFormat:withOrientation:maxDimension:pixelBuffer:]
  -[VCPImageManager pixelBufferWithFormat:fromImageURL:flushCache:orientation:]


VCPProtoMovieHumanPoseResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence
 @property  VCPProtoBounds *bounds
 @property  int flags

  // class methods
  +[VCPProtoMovieHumanPoseResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHumanPoseResult setTimeRange:]
  -[VCPProtoMovieHumanPoseResult timeRange]
  -[VCPProtoMovieHumanPoseResult setFlags:]
  -[VCPProtoMovieHumanPoseResult setConfidence:]
  -[VCPProtoMovieHumanPoseResult mergeFrom:]
  -[VCPProtoMovieHumanPoseResult .cxx_destruct]
  -[VCPProtoMovieHumanPoseResult confidence]
  -[VCPProtoMovieHumanPoseResult dictionaryRepresentation]
  -[VCPProtoMovieHumanPoseResult writeTo:]
  -[VCPProtoMovieHumanPoseResult isEqual:]
  -[VCPProtoMovieHumanPoseResult copyTo:]
  -[VCPProtoMovieHumanPoseResult readFrom:]
  -[VCPProtoMovieHumanPoseResult flags]
  -[VCPProtoMovieHumanPoseResult copyWithZone:]
  -[VCPProtoMovieHumanPoseResult setBounds:]
  -[VCPProtoMovieHumanPoseResult bounds]
  -[VCPProtoMovieHumanPoseResult exportToLegacyDictionary]


VCPMergeCandidatePair : NSObject
 @property  NSString *person1LocalIdentifier
 @property  NSString *person2LocalIdentifier
 @property  NSString *reason

  // class methods
  +[VCPMergeCandidatePair mergeCandidatePairWithPerson:andPerson:reason:]

  // instance methods
  -[VCPMergeCandidatePair .cxx_destruct]
  -[VCPMergeCandidatePair isEqual:]
  -[VCPMergeCandidatePair reason]
  -[VCPMergeCandidatePair person1LocalIdentifier]
  -[VCPMergeCandidatePair person2LocalIdentifier]
  -[VCPMergeCandidatePair initWithPerson:andPerson:reason:]


VCPPhotosPersistenceDelegate : NSObject <PVPersonPromoterDelegate>
 @property  BOOL personBuilderMergeCandidatesDisabled
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPPhotosPersistenceDelegate newAssetFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newAllFacesFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newFacesDeterministicSortDescriptors]
  +[VCPPhotosPersistenceDelegate enumerateFetchResult:withBatchSize:handler:]
  +[VCPPhotosPersistenceDelegate newAllPersonsFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newVerifiedPersonsFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate newVisibleFacesFetchOptionsWithPhotoLibrary:]
  +[VCPPhotosPersistenceDelegate _includeTorsoOnlyFaces]

  // instance methods
  -[VCPPhotosPersistenceDelegate initWithPhotoLibrary:]
  -[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
  -[VCPPhotosPersistenceDelegate _fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:]
  -[VCPPhotosPersistenceDelegate countOfClusteringEligibleFaces]
  -[VCPPhotosPersistenceDelegate _duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:]
  -[VCPPhotosPersistenceDelegate _getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:]
  -[VCPPhotosPersistenceDelegate keyFaceForPerson:qualityMeasureByFace:updateBlock:]
  -[VCPPhotosPersistenceDelegate unclusteredClusteringEligibleFaceLocalIdentifiers:]
  -[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:]
  -[VCPPhotosPersistenceDelegate fetchFaceWithLocalIdentifier:error:]
  -[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:]
  -[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
  -[VCPPhotosPersistenceDelegate logPVErrorMessage:]
  -[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:]
  -[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate countOfClusteredFaces]
  -[VCPPhotosPersistenceDelegate .cxx_destruct]
  -[VCPPhotosPersistenceDelegate _level0ClusterIdForFaceCSN:level0Clusters:]
  -[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
  -[VCPPhotosPersistenceDelegate resetLibraryClustersWithCanceler:error:]
  -[VCPPhotosPersistenceDelegate fetchFaceWithClusterSequenceNumber:error:]
  -[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:]
  -[VCPPhotosPersistenceDelegate personBuilderMergeCandidatesDisabled]
  -[VCPPhotosPersistenceDelegate _getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:]
  -[VCPPhotosPersistenceDelegate _faceToFaceCountMapForFaces:]
  -[VCPPhotosPersistenceDelegate facesFromAsset:]
  -[VCPPhotosPersistenceDelegate _updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:]
  -[VCPPhotosPersistenceDelegate groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:]
  -[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
  -[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
  -[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
  -[VCPPhotosPersistenceDelegate fetchPersonWithLocalIdentifier:options:error:]
  -[VCPPhotosPersistenceDelegate deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:]
  -[VCPPhotosPersistenceDelegate logPVInfoMessage:]
  -[VCPPhotosPersistenceDelegate dedupeGraphVerifiedPersonsInFaceGroup:personCache:]
  -[VCPPhotosPersistenceDelegate logPVDebugMessage:]
  -[VCPPhotosPersistenceDelegate deleteEmptyGroupsAndReturnError:]
  -[VCPPhotosPersistenceDelegate countOfFaces]
  -[VCPPhotosPersistenceDelegate setPersonBuilderMergeCandidatesDisabled:]
  -[VCPPhotosPersistenceDelegate otherFacesOnAssetWithFace:options:]
  -[VCPPhotosPersistenceDelegate suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:]
  -[VCPPhotosPersistenceDelegate _enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:]
  -[VCPPhotosPersistenceDelegate facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:]
  -[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:]
  -[VCPPhotosPersistenceDelegate densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:]
  -[VCPPhotosPersistenceDelegate _fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:]
  -[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:]
  -[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
  -[VCPPhotosPersistenceDelegate performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:]
  -[VCPPhotosPersistenceDelegate countOfUnclusteredClusteringEligibleFaces]
  -[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
  -[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
  -[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:]
  -[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
  -[VCPPhotosPersistenceDelegate needsPersonBuilding]
  -[VCPPhotosPersistenceDelegate logPVWarningMessage:]
  -[VCPPhotosPersistenceDelegate _ungroupFaceClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate _categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:cancelOrExtendTimeoutBlock:photoLibrary:]
  -[VCPPhotosPersistenceDelegate _resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate _localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:cancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate cleanupUngroupedFacesWithNonZeroClusterSequenceNumbers:error:]
  -[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:cancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:cancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate _facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:]
  -[VCPPhotosPersistenceDelegate _representativenessByFaceCSNFromFaces:cancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate _cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate _dedupeFaceCropsForFaceGroups:withCancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate _checkRejectedFaceCropsForFaceGroups:withCancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate _getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:cancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate _completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:error:]
  -[VCPPhotosPersistenceDelegate _updatedFaceGroupByFGLocalIdentifierFromClusterCSNsWithCancelOrExtendTimeoutBlock:fetchLimit:]
  -[VCPPhotosPersistenceDelegate _buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:cancelOrExtendTimeoutBlock:context:]
  -[VCPPhotosPersistenceDelegate invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate cleanupGroupedFacesWithClusterSequenceNumberSetToZero:error:]
  -[VCPPhotosPersistenceDelegate persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate resetLibraryClustersWithCancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate cleanupMergeCandidatesWithMinimumFaceGroupSize:cancelOrExtendTimeoutBlock:error:]
  -[VCPPhotosPersistenceDelegate buildPersonWithFaceClusterer:keyFaceUpdateBlock:context:cancelOrExtendTimeoutBlock:]
  -[VCPPhotosPersistenceDelegate removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:cancelOrExtendTimeoutBlock:error:]


VCPCNNPersonDetector : NSObject
  // instance methods
  -[VCPCNNPersonDetector .cxx_construct]
  -[VCPCNNPersonDetector .cxx_destruct]
  -[VCPCNNPersonDetector copyImage:toData:]
  -[VCPCNNPersonDetector generatePersonRegions:boxes:maxNumRegions:]
  -[VCPCNNPersonDetector createInput:withBuffer:inputHeight:inputWidth:]
  -[VCPCNNPersonDetector generatePersonBoxes:]
  -[VCPCNNPersonDetector initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:]
  -[VCPCNNPersonDetector personDetection:personRegions:cancel:]
  -[VCPCNNPersonDetector retrieveBoxes:outHeight:outWidth:boxes:anchorBox:]
  -[VCPCNNPersonDetector nonMaxSuppression:]


VCPImagePetsAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImagePetsAnalyzer .cxx_destruct]
  -[VCPImagePetsAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImagePetsAnalyzer initWithMaxNumRegions:]
  -[VCPImagePetsAnalyzer convertResultsToDict:results:]


VCPImageQualityAnalyzer : NSObject
 @property  float qualityScore

  // instance methods
  -[VCPImageQualityAnalyzer qualityScore]
  -[VCPImageQualityAnalyzer analyzeImageQuality:irisPhotoOffsetSec:cancel:]


VCPImageSaliencyAnalyzer : VCPImageAnalyzer
  // class methods
  +[VCPImageSaliencyAnalyzer analyzerWith:prune:]

  // instance methods
  -[VCPImageSaliencyAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageSaliencyAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzer getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzer processTile:results:cancel:]
  -[VCPImageSaliencyAnalyzer aggregateTileResults:tileRect:imageSize:landscape:results:]
  -[VCPImageSaliencyAnalyzer initWithMaxNumRegions:prune:]
  -[VCPImageSaliencyAnalyzer copyImage:toData:withChunk:]
  -[VCPImageSaliencyAnalyzer computeScore:width:height:posX:posY:]
  -[VCPImageSaliencyAnalyzer scaleImage:toData:withWidth:andHeight:]
  -[VCPImageSaliencyAnalyzer saliencyDetection:salientRegions:cancel:]
  -[VCPImageSaliencyAnalyzer pruneRegions:]
  -[VCPImageSaliencyAnalyzer generateSalientRegion:outHeight:outWidth:]
  -[VCPImageSaliencyAnalyzer outputScaling]
  -[VCPImageSaliencyAnalyzer getSalientRegions:]


VCPImageSaliencyAnalyzerBinary : VCPImageSaliencyAnalyzer
  // instance methods
  -[VCPImageSaliencyAnalyzerBinary .cxx_destruct]
  -[VCPImageSaliencyAnalyzerBinary prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerBinary getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzerBinary outputScaling]
  -[VCPImageSaliencyAnalyzerBinary getSalientRegions:]


VCPImageSaliencyAnalyzerFull : VCPImageSaliencyAnalyzer
  // instance methods
  -[VCPImageSaliencyAnalyzerFull .cxx_destruct]
  -[VCPImageSaliencyAnalyzerFull prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerFull getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzerFull getSalientRegions:]


VCPImageSaliencyAnalyzerFullEspresso : VCPImageSaliencyAnalyzer
  // class methods
  +[VCPImageSaliencyAnalyzerFullEspresso sharedModel:]

  // instance methods
  -[VCPImageSaliencyAnalyzerFullEspresso .cxx_destruct]
  -[VCPImageSaliencyAnalyzerFullEspresso dealloc]
  -[VCPImageSaliencyAnalyzerFullEspresso prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageSaliencyAnalyzerFullEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPImageSaliencyAnalyzerFullEspresso getSalientRegions:]


VCPSceneProcessingImageManager : NSObject
  // class methods
  +[VCPSceneProcessingImageManager imageManager]

  // instance methods
  -[VCPSceneProcessingImageManager _pooledPixelBuffer:withDimension:]
  -[VCPSceneProcessingImageManager .cxx_destruct]
  -[VCPSceneProcessingImageManager _createPixelBuffer:withWidth:andHeight:]
  -[VCPSceneProcessingImageManager init]
  -[VCPSceneProcessingImageManager _createPixelBuffer:withMinorDimension:fromFullPixelBuffer:]
  -[VCPSceneProcessingImageManager dealloc]
  -[VCPSceneProcessingImageManager fullPixelBuffer:toScaledBuffer:]
  -[VCPSceneProcessingImageManager scalePixelBuffer:toPixelBuffer:width:height:]
  -[VCPSceneProcessingImageManager _createPixelBuffer:withColorSpace:fromPixelBuffer:]
  -[VCPSceneProcessingImageManager loadFullPixelBuffer:scaledPixelBuffer299:scaledPixelBuffer360:fromImageURL:abnormalDimension:]


VCPPreAnalysisImageEntry : NSObject
 @property  ^{__CVBuffer=} pixelBuffer
 @property  unsigned long count

  // instance methods
  -[VCPPreAnalysisImageEntry pixelBuffer]
  -[VCPPreAnalysisImageEntry initWithPixelBuffer:]
  -[VCPPreAnalysisImageEntry .cxx_construct]
  -[VCPPreAnalysisImageEntry .cxx_destruct]
  -[VCPPreAnalysisImageEntry count]
  -[VCPPreAnalysisImageEntry dealloc]
  -[VCPPreAnalysisImageEntry setCount:]


VCPPreAnalysisImage : NSObject
 @property  ^{__CVBuffer=} sourcePixelBuffer

  // instance methods
  -[VCPPreAnalysisImage initWithPixelBuffer:]
  -[VCPPreAnalysisImage .cxx_construct]
  -[VCPPreAnalysisImage .cxx_destruct]
  -[VCPPreAnalysisImage sourcePixelBuffer]
  -[VCPPreAnalysisImage preWarmWidth:andHeight:]
  -[VCPPreAnalysisImage pixelBuffer:width:height:]


VCPPreAnalysisRequests : NSObject
 @property  VNClassifyImageAestheticsRequest *aestheticsRequest
 @property  VNSceneClassificationRequest *classificationRequest
 @property  VNCreateSceneprintRequest *sceneprintRequest
 @property  VNGenerateAttentionBasedSaliencyImageRequest *saliencyRequest
 @property  VNClassifyJunkImageRequest *junkImageRequest
 @property  VNRecognizeObjectsRequest *objectRequest
 @property  VNGenerateObjectnessBasedSaliencyImageRequest *saliencyObjectnessRequest
 @property  VNClassifyPotentialLandmarkRequest *landmarkRequest
 @property  VNVYvzEtX1JlUdu8xx5qhDI *nsfwRequest
 @property  VN6Mb1ME89lyW3HpahkEygIG *tabooRequest
 @property  VN5kJNH3eYuyaLxNpZr5Z7zi *semanticRequest
 @property  VNCreateSceneprintRequest *sceneprintRawRequest
 @property  VNClassifyMemeImageRequest *memeRequest
 @property  VN1JC7R3k4455fKQz0dY1VhQ *adjustmentsRequest
 @property  VNRecognizeDocumentElementsRequest *documentRequest

  // instance methods
  -[VCPPreAnalysisRequests .cxx_destruct]
  -[VCPPreAnalysisRequests classificationRequest]
  -[VCPPreAnalysisRequests aestheticsRequest]
  -[VCPPreAnalysisRequests setAestheticsRequest:]
  -[VCPPreAnalysisRequests setClassificationRequest:]
  -[VCPPreAnalysisRequests sceneprintRequest]
  -[VCPPreAnalysisRequests setSceneprintRequest:]
  -[VCPPreAnalysisRequests saliencyRequest]
  -[VCPPreAnalysisRequests setSaliencyRequest:]
  -[VCPPreAnalysisRequests junkImageRequest]
  -[VCPPreAnalysisRequests setJunkImageRequest:]
  -[VCPPreAnalysisRequests objectRequest]
  -[VCPPreAnalysisRequests setObjectRequest:]
  -[VCPPreAnalysisRequests saliencyObjectnessRequest]
  -[VCPPreAnalysisRequests setSaliencyObjectnessRequest:]
  -[VCPPreAnalysisRequests landmarkRequest]
  -[VCPPreAnalysisRequests setLandmarkRequest:]
  -[VCPPreAnalysisRequests nsfwRequest]
  -[VCPPreAnalysisRequests setNsfwRequest:]
  -[VCPPreAnalysisRequests tabooRequest]
  -[VCPPreAnalysisRequests setTabooRequest:]
  -[VCPPreAnalysisRequests semanticRequest]
  -[VCPPreAnalysisRequests setSemanticRequest:]
  -[VCPPreAnalysisRequests sceneprintRawRequest]
  -[VCPPreAnalysisRequests setSceneprintRawRequest:]
  -[VCPPreAnalysisRequests memeRequest]
  -[VCPPreAnalysisRequests setMemeRequest:]
  -[VCPPreAnalysisRequests adjustmentsRequest]
  -[VCPPreAnalysisRequests setAdjustmentsRequest:]
  -[VCPPreAnalysisRequests documentRequest]
  -[VCPPreAnalysisRequests setDocumentRequest:]


VCPPreAnalyzer : NSObject
  // class methods
  +[VCPPreAnalyzer _allowANE]
  +[VCPPreAnalyzer _includeRotation]
  +[VCPPreAnalyzer _includeMeme]
  +[VCPPreAnalyzer _includeDocument]
  +[VCPPreAnalyzer _useR14J9]
  +[VCPPreAnalyzer _includeDO]
  +[VCPPreAnalyzer _includeSO]
  +[VCPPreAnalyzer _includeLM]
  +[VCPPreAnalyzer _includeNSFW]
  +[VCPPreAnalyzer _includeSE]
  +[VCPPreAnalyzer _includeSDG]
  +[VCPPreAnalyzer _includeWP]
  +[VCPPreAnalyzer _includeIVS]
  +[VCPPreAnalyzer _getSHRevision]
  +[VCPPreAnalyzer _enableSceneAssetConcurrency]

  // instance methods
  -[VCPPreAnalyzer .cxx_construct]
  -[VCPPreAnalyzer .cxx_destruct]
  -[VCPPreAnalyzer init]
  -[VCPPreAnalyzer dealloc]
  -[VCPPreAnalyzer _createPixelBufferPool:withBufferSize:andPixelFormat:]
  -[VCPPreAnalyzer _convertFromBuffer:toLumaPixelBuffer:]
  -[VCPPreAnalyzer _configureRequest:withRevision:]
  -[VCPPreAnalyzer _processBoundingBoxFromDetectedObjects:forSceneClassID:]
  -[VCPPreAnalyzer _insertBoundingBox:toSortedBoundingBoxes:]
  -[VCPPreAnalyzer _extractAndSortBoundingBoxFromDetectedObjects:]
  -[VCPPreAnalyzer _parseClassificationObservations:toClassificationResults:]
  -[VCPPreAnalyzer _parseClassificationObservations:withPrefix:toClassificationResults:]
  -[VCPPreAnalyzer _generateSceneClassifications:fromRequests:]
  -[VCPPreAnalyzer _obfuscateLabelName:]
  -[VCPPreAnalyzer _createRequests:]
  -[VCPPreAnalyzer _collectSceneAnalysisResults:fromRequests:wpResults:ivsResults:ignoreSceneClassification:]
  -[VCPPreAnalyzer _performSceneAnalysis:image:abnormalDimension:]
  -[VCPPreAnalyzer _performBlurAnalysis:withLumaPixelBuffer:isSDOF:]
  -[VCPPreAnalyzer _performExposureAnalysis:withLumaPixelBuffer:]
  -[VCPPreAnalyzer _performRotationAnalysis:withColorPixelBuffer:]
  -[VCPPreAnalyzer _loadImageURL:abnormalDimension:colorPixelBuffer:andLumaPixelBuffer:image:]
  -[VCPPreAnalyzer _performAnalysis:abnormalDimension:isSDOF:colorPixelBuffer:andLumaPixelBuffer:image:]
  -[VCPPreAnalyzer _createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPPreAnalyzer analyzeWithImageURL:abnormalDimension:isSDOF:completionHandler:]


VCPInterAssetAnalyzer : NSObject
  // class methods
  +[VCPInterAssetAnalyzer thumbnailSizeForAsset:withResources:]
  +[VCPInterAssetAnalyzer canUseLastFrameOfAsset:withResources:]

  // instance methods
  -[VCPInterAssetAnalyzer init]
  -[VCPInterAssetAnalyzer _generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:]
  -[VCPInterAssetAnalyzer _getThumbnailForAsset:withResouces:andPixelFormat:]
  -[VCPInterAssetAnalyzer computeDistance:fromArray:toArray:]
  -[VCPInterAssetAnalyzer computeDistance:withDescriptorClass:fromAsset:toAsset:]
  -[VCPInterAssetAnalyzer generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:]


VCPJunkAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPJunkAnalyzer analyzePixelBuffer:flags:results:cancel:]


VCPMADVIResource : VCPMADResource
 @property  VIService *service

  // instance methods
  -[VCPMADVIResource purge]
  -[VCPMADVIResource .cxx_destruct]
  -[VCPMADVIResource inactiveCost]
  -[VCPMADVIResource init]
  -[VCPMADVIResource activeCost]
  -[VCPMADVIResource service]


VCPLandmarkValidator : NSObject
 @property  ^f orientation

  // instance methods
  -[VCPLandmarkValidator setOrientation:]
  -[VCPLandmarkValidator .cxx_destruct]
  -[VCPLandmarkValidator orientation]
  -[VCPLandmarkValidator dealloc]
  -[VCPLandmarkValidator initWithModelFile:paramFile:numTri:triList:angle:]
  -[VCPLandmarkValidator validateOneImage:landmarks:numofLandmarks:score:]


VCPLightMotionAnalyzer : VCPVideoAnalyzer
 @property  float actionScore

  // class methods
  +[VCPLightMotionAnalyzer autoLiveMotionScore:]

  // instance methods
  -[VCPLightMotionAnalyzer .cxx_construct]
  -[VCPLightMotionAnalyzer .cxx_destruct]
  -[VCPLightMotionAnalyzer init]
  -[VCPLightMotionAnalyzer actionScore]
  -[VCPLightMotionAnalyzer dealloc]
  -[VCPLightMotionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPLightMotionAnalyzer cameraMotionDetection:]
  -[VCPLightMotionAnalyzer generateThresholds:withConfidences:]
  -[VCPLightMotionAnalyzer initWithQueue:turbo:]
  -[VCPLightMotionAnalyzer prewarmWithWidth:height:]
  -[VCPLightMotionAnalyzer analyzeFrame:withTimestamp:andDuration:completion:]


VCPLightVideoAnalyzer : NSObject
 @property  NSDictionary *publicResults
 @property  NSDictionary *privateResults

  // instance methods
  -[VCPLightVideoAnalyzer .cxx_destruct]
  -[VCPLightVideoAnalyzer privateResults]
  -[VCPLightVideoAnalyzer findMetaTrackforType:]
  -[VCPLightVideoAnalyzer publicResults]
  -[VCPLightVideoAnalyzer processMetaTrackForType:cancel:flags:]
  -[VCPLightVideoAnalyzer checkTimeRangeConsistency]
  -[VCPLightVideoAnalyzer postProcessOrientationResults]
  -[VCPLightVideoAnalyzer initWithAVAsset:forAnalysisTypes:]
  -[VCPLightVideoAnalyzer analyzeAsset:flags:]


VCPMAMLModel : NSObject
 @property  MLModel *model
 @property  long long inputSize
 @property  unsigned int inputPixelFormat
 @property  NSString *inputFeatureName
 @property  NSString *outputFeatureName

  // class methods
  +[VCPMAMLModel vcp_sharedModelWithModelName:]

  // instance methods
  -[VCPMAMLModel .cxx_destruct]
  -[VCPMAMLModel init]
  -[VCPMAMLModel inputSize]
  -[VCPMAMLModel inputFeatureName]
  -[VCPMAMLModel outputFeatureName]
  -[VCPMAMLModel model]
  -[VCPMAMLModel initWithModelName:]
  -[VCPMAMLModel inputPixelFormat]


VCPClusteringAccuracyMeasures : NSObject
 @property  float weightedAveragePrecision
 @property  float weightedAverageRecall
 @property  float numSingletons
 @property  float numValidSingletons
 @property  NSMutableArray *precisionPerCluster
 @property  NSMutableArray *recallPerPersonToGroundTruth
 @property  NSMutableArray *recallPerPersonExcludeMissDetection

  // instance methods
  -[VCPClusteringAccuracyMeasures .cxx_destruct]
  -[VCPClusteringAccuracyMeasures init]
  -[VCPClusteringAccuracyMeasures addClusterPrecision:forPersonID:personFaceCount:validFaceCount:identitySize:]
  -[VCPClusteringAccuracyMeasures addIdentityRecallToGroundTruth:forPersonID:personFaceCount:identitySize:]
  -[VCPClusteringAccuracyMeasures addIdentityRecallExcludeMissDetection:forPersonID:personFaceCount:identitySize:]
  -[VCPClusteringAccuracyMeasures weightedAveragePrecision]
  -[VCPClusteringAccuracyMeasures setWeightedAveragePrecision:]
  -[VCPClusteringAccuracyMeasures weightedAverageRecall]
  -[VCPClusteringAccuracyMeasures setWeightedAverageRecall:]
  -[VCPClusteringAccuracyMeasures numSingletons]
  -[VCPClusteringAccuracyMeasures setNumSingletons:]
  -[VCPClusteringAccuracyMeasures numValidSingletons]
  -[VCPClusteringAccuracyMeasures setNumValidSingletons:]
  -[VCPClusteringAccuracyMeasures precisionPerCluster]
  -[VCPClusteringAccuracyMeasures setPrecisionPerCluster:]
  -[VCPClusteringAccuracyMeasures recallPerPersonToGroundTruth]
  -[VCPClusteringAccuracyMeasures setRecallPerPersonToGroundTruth:]
  -[VCPClusteringAccuracyMeasures recallPerPersonExcludeMissDetection]
  -[VCPClusteringAccuracyMeasures setRecallPerPersonExcludeMissDetection:]


VCPPhotosAutoCounterWorker : NSObject
  // class methods
  +[VCPPhotosAutoCounterWorker _dumpFaceprint]
  +[VCPPhotosAutoCounterWorker _dumpAssetsToFaces]
  +[VCPPhotosAutoCounterWorker workerWithPhotoLibrary:]

  // instance methods
  -[VCPPhotosAutoCounterWorker initWithPhotoLibrary:]
  -[VCPPhotosAutoCounterWorker .cxx_destruct]
  -[VCPPhotosAutoCounterWorker _groundTruthURL]
  -[VCPPhotosAutoCounterWorker _loadGroundTruthURL:toGroundTruth:error:]
  -[VCPPhotosAutoCounterWorker _loadGroundTruth:error:]
  -[VCPPhotosAutoCounterWorker _processFetchedFaceGroup:forPersonID:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker _fetchPersonWithIdentifier:facesPerAsset:assetInformation:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker _fetchPeopleHomePersons]
  -[VCPPhotosAutoCounterWorker _overlapRatioOf:with:]
  -[VCPPhotosAutoCounterWorker _exportAssetsToFacesDetails:]
  -[VCPPhotosAutoCounterWorker _parseGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker _measureClusterWithClusterStateURL:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker _measurePVPersonClusters:groundTruthFaceCountPerPerson:groundTruthPersonInformation:groundTruthFaceToPerson:groundTruthAssetToFaces:measures:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker _reportCoreAnalyticsWithVisionClusterMeasure:personClusterMeasure:personClusters:andGroundTruthInformation:]
  -[VCPPhotosAutoCounterWorker calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:withGroundtruth:results:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker _parseSIMLGroundTruthWithURL:faceCountPerPerson:personInformation:faceToPerson:assetToFaces:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker exportClustersStates:error:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker optInPersonCount]
  -[VCPPhotosAutoCounterWorker _anonymizedName:]
  -[VCPPhotosAutoCounterWorker optInStatus:error:]
  -[VCPPhotosAutoCounterWorker optInPerson:error:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker calculateAndReportClusterAccuracyWithVisionClusterURL:andPersonClusters:results:extendTimeoutBlock:cancelBlock:]
  -[VCPPhotosAutoCounterWorker validateClusterAccuracyWithSIMLGroundtruth:results:extendTimeoutBlock:cancelBlock:]


VCPLogManager : NSObject
 @property  int logLevel

  // class methods
  +[VCPLogManager dateFormatter]
  +[VCPLogManager sharedLogManager]

  // instance methods
  -[VCPLogManager logLevel]
  -[VCPLogManager init]


VCPVideoPersonDetector : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoPersonDetector .cxx_destruct]
  -[VCPVideoPersonDetector persons]
  -[VCPVideoPersonDetector init]
  -[VCPVideoPersonDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoPersonDetector detectPersons:persons:]


VCPMovieCurationAnalyzer : NSObject
  // instance methods
  -[VCPMovieCurationAnalyzer results]
  -[VCPMovieCurationAnalyzer .cxx_destruct]
  -[VCPMovieCurationAnalyzer setMaxHighlightDuration:]
  -[VCPMovieCurationAnalyzer postProcessKeyFrames]
  -[VCPMovieCurationAnalyzer reportMovieCurationAnalysisResults:withSummaryAnalytics:]
  -[VCPMovieCurationAnalyzer addHighlight:to:]
  -[VCPMovieCurationAnalyzer addSummary:to:]
  -[VCPMovieCurationAnalyzer initWithAnalysisTypes:transform:timeRange:isLivePhoto:frameStats:hadFlash:hadZoom:keyFrameResults:isTimelapse:preferredTimeRange:asset:]
  -[VCPMovieCurationAnalyzer analyzeKeyFrame:withTimestamp:andDuration:flags:]
  -[VCPMovieCurationAnalyzer loadVideoAnalysisResults:audioAnalysisResults:andFaceRanges:frameSize:]
  -[VCPMovieCurationAnalyzer generateMovieCurations]


VCPVideoKeyFrameResult : NSObject
 @property  {?=qiIq} timeStamp
 @property  float score

  // instance methods
  -[VCPVideoKeyFrameResult timeStamp]
  -[VCPVideoKeyFrameResult score]
  -[VCPVideoKeyFrameResult initWithTime:andScore:]


VCPMovieHighlightResult : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score
 @property  VCPVideoKeyFrameResult *keyFrame

  // instance methods
  -[VCPMovieHighlightResult .cxx_destruct]
  -[VCPMovieHighlightResult score]
  -[VCPMovieHighlightResult timerange]
  -[VCPMovieHighlightResult keyFrame]
  -[VCPMovieHighlightResult initWithTimeRange:score:andKeyFrame:]


VCPMovieCurationResults : NSObject
 @property  PHAsset *phAsset
 @property  NSMutableArray *highlights
 @property  NSMutableDictionary *results

  // instance methods
  -[VCPMovieCurationResults setResults:]
  -[VCPMovieCurationResults phAsset]
  -[VCPMovieCurationResults results]
  -[VCPMovieCurationResults .cxx_destruct]
  -[VCPMovieCurationResults highlights]
  -[VCPMovieCurationResults initWithPHAsset:]


VCPMovieHighlight : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score
 @property  float averageScore
 @property  float junkScore
 @property  float qualityScore
 @property  float expressionScore
 @property  float actionScore
 @property  float voiceScore
 @property  float humanActionScore
 @property  float humanPoseScore
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bestPlaybackCrop
 @property  BOOL isAutoPlayable
 @property  BOOL isTrimmed
 @property  VCPImageDescriptor *descriptor
 @property  VCPVideoKeyFrame *keyFrame
 @property  NSData *colorNormalization

  // instance methods
  -[VCPMovieHighlight setScore:]
  -[VCPMovieHighlight setDescriptor:]
  -[VCPMovieHighlight .cxx_destruct]
  -[VCPMovieHighlight descriptor]
  -[VCPMovieHighlight initWithTimeRange:]
  -[VCPMovieHighlight score]
  -[VCPMovieHighlight setActionScore:]
  -[VCPMovieHighlight actionScore]
  -[VCPMovieHighlight colorNormalization]
  -[VCPMovieHighlight qualityScore]
  -[VCPMovieHighlight setQualityScore:]
  -[VCPMovieHighlight averageScore]
  -[VCPMovieHighlight setAverageScore:]
  -[VCPMovieHighlight junkScore]
  -[VCPMovieHighlight setJunkScore:]
  -[VCPMovieHighlight isAutoPlayable]
  -[VCPMovieHighlight timerange]
  -[VCPMovieHighlight bestPlaybackCrop]
  -[VCPMovieHighlight keyFrame]
  -[VCPMovieHighlight isTrimmed]
  -[VCPMovieHighlight isShort]
  -[VCPMovieHighlight checkAutoPlayable]
  -[VCPMovieHighlight setTimerange:]
  -[VCPMovieHighlight setKeyFrame:]
  -[VCPMovieHighlight setBestPlaybackCrop:]
  -[VCPMovieHighlight setColorNormalization:]
  -[VCPMovieHighlight setIsTrimmed:]
  -[VCPMovieHighlight setIsAutoPlayable:]
  -[VCPMovieHighlight mergeSegment:]
  -[VCPMovieHighlight copyScoresFrom:]
  -[VCPMovieHighlight setExpressionScore:]
  -[VCPMovieHighlight setVoiceScore:]
  -[VCPMovieHighlight setHumanActionScore:]
  -[VCPMovieHighlight setHumanPoseScore:]
  -[VCPMovieHighlight expressionScore]
  -[VCPMovieHighlight humanPoseScore]
  -[VCPMovieHighlight humanActionScore]
  -[VCPMovieHighlight voiceScore]


VCPExpressionSegment : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  float score

  // instance methods
  -[VCPExpressionSegment setTimeRange:]
  -[VCPExpressionSegment setScore:]
  -[VCPExpressionSegment timeRange]
  -[VCPExpressionSegment score]


VCPMovieHighlightAnalyzer : NSObject
  // class methods
  +[VCPMovieHighlightAnalyzer getMinimumHighlightInSec]

  // instance methods
  -[VCPMovieHighlightAnalyzer addSegment:]
  -[VCPMovieHighlightAnalyzer results]
  -[VCPMovieHighlightAnalyzer .cxx_destruct]
  -[VCPMovieHighlightAnalyzer movieSummary]
  -[VCPMovieHighlightAnalyzer setMaxHighlightDuration:]
  -[VCPMovieHighlightAnalyzer initWithAnalysisType:isLivePhoto:hadFlash:hadZoom:isTimelapse:preferredTimeRange:asset:]
  -[VCPMovieHighlightAnalyzer prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:frameSize:]
  -[VCPMovieHighlightAnalyzer generateHighlights]
  -[VCPMovieHighlightAnalyzer highlightScoreResults]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreResults]
  -[VCPMovieHighlightAnalyzer selectHighlightsForTimelapse]
  -[VCPMovieHighlightAnalyzer selectHighlights]
  -[VCPMovieHighlightAnalyzer evaluateSegment:]
  -[VCPMovieHighlightAnalyzer computeColorNormalization]
  -[VCPMovieHighlightAnalyzer loadHighlightScoreResults:]
  -[VCPMovieHighlightAnalyzer maxTrimMovieHighlight:]
  -[VCPMovieHighlightAnalyzer targetProcessRange:maxRange:]
  -[VCPMovieHighlightAnalyzer targetMovieHighlight:mergedRange:maxRange:]
  -[VCPMovieHighlightAnalyzer isGoodQuality:]
  -[VCPMovieHighlightAnalyzer targetTrimRange:searchRange:]
  -[VCPMovieHighlightAnalyzer targetExtendRange:maxRange:]
  -[VCPMovieHighlightAnalyzer findBestHighlightSegment:targetTrim:]
  -[VCPMovieHighlightAnalyzer findBestTrim:]
  -[VCPMovieHighlightAnalyzer highlightScoreForTimeRange:average:]
  -[VCPMovieHighlightAnalyzer computeQualityTrimFor:withKeyFrame:]
  -[VCPMovieHighlightAnalyzer computeTrimWithHighlightScoreFor:]
  -[VCPMovieHighlightAnalyzer pickKeyFramesInRange:]
  -[VCPMovieHighlightAnalyzer searchFeatureVectorOfSegment:]
  -[VCPMovieHighlightAnalyzer computeBestPlaybackCrop:]
  -[VCPMovieHighlightAnalyzer computeActionFaceTrimFor:]
  -[VCPMovieHighlightAnalyzer computeSteadyTranslationTrimFor:]
  -[VCPMovieHighlightAnalyzer checkCameraZoom:]
  -[VCPMovieHighlightAnalyzer generateExpressionSegments:]
  -[VCPMovieHighlightAnalyzer analyzeOverallQuality:]
  -[VCPMovieHighlightAnalyzer computeExpressionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeActionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeVoiceScoreInTimeRange:]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreOfSegment:]
  -[VCPMovieHighlightAnalyzer qualityScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer junkScoreForTimerange:lengthScale:]
  -[VCPMovieHighlightAnalyzer computeSubtleMotionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer cameraMotionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer computeHumanActionScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer computeHumanPoseScoreInTimerange:]
  -[VCPMovieHighlightAnalyzer actionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer subtleMotionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer expressionScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer voiceScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer visualPleasingScoreForTimerange:]
  -[VCPMovieHighlightAnalyzer initWithPostProcessOptions:]
  -[VCPMovieHighlightAnalyzer postProcessMovieHighlight:]
  -[VCPMovieHighlightAnalyzer computeHighlightScoreOfRange:]
  -[VCPMovieHighlightAnalyzer SetKeyFramesForSegments:]
  -[VCPMovieHighlightAnalyzer pickHighlightsFrom:]


VCPMediaAnalysisService : NSObject <VCPMediaAnalysisClientProtocol>
  // class methods
  +[VCPMediaAnalysisService queryCachedFaceAnalysisProgress:forPhotoLibrary:]
  +[VCPMediaAnalysisService queryProgressDetail:forPhotoLibrary:andTaskID:]
  +[VCPMediaAnalysisService queryProgressDetail:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:]
  +[VCPMediaAnalysisService queryProgressDetail:forPhotoLibraryURL:andTaskID:withExtendTimeoutBlock:]
  +[VCPMediaAnalysisService analysisService]
  +[VCPMediaAnalysisService queryProgress:forPhotoLibrary:andTaskID:]
  +[VCPMediaAnalysisService errorWithDescription:]
  +[VCPMediaAnalysisService queryProgress:forPhotoLibrary:andTaskID:withExtendTimeoutBlock:]
  +[VCPMediaAnalysisService queryProgressDetail:forPhotoLibraryURL:andTaskID:]
  +[VCPMediaAnalysisService sharedAnalysisService]
  +[VCPMediaAnalysisService queryCachedFaceAnalysisProgress:forPhotoLibrary:withExtendTimeoutBlock:]

  // instance methods
  -[VCPMediaAnalysisService requestDumpAutoCounterForPhotoLibraryURL:completionHandler:]
  -[VCPMediaAnalysisService requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService .cxx_destruct]
  -[VCPMediaAnalysisService requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService cancelBackgroundActivity]
  -[VCPMediaAnalysisService requestAutoCounterAccuracyCalculationForPhotoLibraryURL:completionHandler:]
  -[VCPMediaAnalysisService notifyLibraryAvailableAtURL:]
  -[VCPMediaAnalysisService requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestMediaAnalysisDatabaseBackupForPhotoLibraryURL:withCompletionHandler:]
  -[VCPMediaAnalysisService requestAutoCounterAccuracyCalculationForPhotoLibraryURL:clusterStateURL:groundTruthURL:completionHandler:]
  -[VCPMediaAnalysisService requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService init]
  -[VCPMediaAnalysisService requestAutoCounterSIMLValidationForPhotoLibraryURL:simlGroundTruthURL:completionHandler:]
  -[VCPMediaAnalysisService connection]
  -[VCPMediaAnalysisService requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService cancelAllRequests]
  -[VCPMediaAnalysisService requestIdentificationOfFaces:withCompletionHandler:]
  -[VCPMediaAnalysisService requestBackgroundAnalysisForAssets:fromPhotoLibraryWithURL:realTime:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService queryAutoCounterOptInStatusForPhotoLibraryURL:withPersonLocalIdentifiers:completionHandler:]
  -[VCPMediaAnalysisService requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:]
  -[VCPMediaAnalysisService requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestPersonPreferenceForPhotoLibraryURL:completionHandler:]
  -[VCPMediaAnalysisService requestPersonProcessingForPhotoLibraryURL:options:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService invalidate]
  -[VCPMediaAnalysisService requestFRCForAssetURL:withOptions:progressHandler:andCompletionHandler:]
  -[VCPMediaAnalysisService requestOptInAutoCounterForPhotoLibraryURL:withPersons:completionHandler:]
  -[VCPMediaAnalysisService requestResetPetClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService cancelRequest:]
  -[VCPMediaAnalysisService requestProcessingTypes:forAssetsWithLocalIdentifiers:fromPhotoLibraryWithURL:progressHandler:completionHandler:]
  -[VCPMediaAnalysisService requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:]
  -[VCPMediaAnalysisService requestVIPModelFilepathForPhotoLibraryURL:forModelType:completionHandler:]
  -[VCPMediaAnalysisService reportProgress:forRequest:]


VCPMediaAnalyzer : NSObject
  // class methods
  +[VCPMediaAnalyzer sharedMediaAnalyzer]
  +[VCPMediaAnalyzer _getDistanceDescriptorClass]

  // instance methods
  -[VCPMediaAnalyzer .cxx_destruct]
  -[VCPMediaAnalyzer init]
  -[VCPMediaAnalyzer connection]
  -[VCPMediaAnalyzer dealloc]
  -[VCPMediaAnalyzer requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:]
  -[VCPMediaAnalyzer cancelAnalysisWithRequestID:]
  -[VCPMediaAnalyzer postProcessMovieHighlightDuration:withOptions:]
  -[VCPMediaAnalyzer curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:]
  -[VCPMediaAnalyzer requestAnalysis:forAssets:withOptions:andProgressHandler:andError:]
  -[VCPMediaAnalyzer requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:]
  -[VCPMediaAnalyzer distanceFromAsset:toAsset:duplicate:distance:]
  -[VCPMediaAnalyzer distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:]
  -[VCPMediaAnalyzer _setupMediaAnalysisServiceConnection]
  -[VCPMediaAnalyzer _getSandboxExtensionForMediaAnalysisDatabaseWithPhotoLibraryURL:]
  -[VCPMediaAnalyzer _postProcessMovieHighlights:analysis:withOptions:]
  -[VCPMediaAnalyzer _addClassificationResults:analysis:]
  -[VCPMediaAnalyzer _metaAnalysisTypesForAsset:]
  -[VCPMediaAnalyzer _analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:]
  -[VCPMediaAnalyzer _databaseForPhotoLibrary:]
  -[VCPMediaAnalyzer requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:]
  -[VCPMediaAnalyzer assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:]
  -[VCPMediaAnalyzer _getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:]
  -[VCPMediaAnalyzer _checkDuplicate:withAsset:duplicate:]
  -[VCPMediaAnalyzer _queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:]
  -[VCPMediaAnalyzer _typesToRemove:requested:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssets:withOptions:andProgressHandler:analyses:]
  -[VCPMediaAnalyzer _getDatabaseSandboxExtensionForPhotoLibraryURL:]
  -[VCPMediaAnalyzer requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:]
  -[VCPMediaAnalyzer analyzeOndemand:pairedURL:forAnalysisTypes:error:]
  -[VCPMediaAnalyzer requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:]
  -[VCPMediaAnalyzer assetsAnalyzedSinceDate:completionHandler:]
  -[VCPMediaAnalyzer requestMovieHighlightsForAssets:withOptions:]
  -[VCPMediaAnalyzer requestLivePhotoEffectsForAssets:allowOnDemand:flags:]
  -[VCPMediaAnalyzer completeStorage]


VCPMADVIVisualSearchGatingTask : NSObject <VCPMADServiceImageProcessingSubtaskProtocol, VCPMADTaskProtocol>
  // class methods
  +[VCPMADVIVisualSearchGatingTask dependencies]
  +[VCPMADVIVisualSearchGatingTask taskWithRequest:imageAsset:andSignpostPayload:]

  // instance methods
  -[VCPMADVIVisualSearchGatingTask setPreferredMetalDevice:]
  -[VCPMADVIVisualSearchGatingTask resourceRequirement]
  -[VCPMADVIVisualSearchGatingTask .cxx_destruct]
  -[VCPMADVIVisualSearchGatingTask createQueryContextWithError:]
  -[VCPMADVIVisualSearchGatingTask cancel]
  -[VCPMADVIVisualSearchGatingTask initWithRequest:imageAsset:andSignpostPayload:]
  -[VCPMADVIVisualSearchGatingTask storeResults:]
  -[VCPMADVIVisualSearchGatingTask autoCancellable]
  -[VCPMADVIVisualSearchGatingTask run]


VCPMetaSegment : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames

  // instance methods
  -[VCPMetaSegment timeRange]
  -[VCPMetaSegment init]
  -[VCPMetaSegment mergeSegment:]
  -[VCPMetaSegment numOfFrames]
  -[VCPMetaSegment updateSegment:]
  -[VCPMetaSegment resetSegment:]
  -[VCPMetaSegment finalizeAtTime:]


VCPMetaTrackDecoder : NSObject
  // instance methods
  -[VCPMetaTrackDecoder .cxx_destruct]
  -[VCPMetaTrackDecoder initWithTrack:]
  -[VCPMetaTrackDecoder status]
  -[VCPMetaTrackDecoder dealloc]
  -[VCPMetaTrackDecoder copyNextMetadataGroup]


VCPMovieAnalyzer : NSObject
 @property  BOOL allowStreaming
 @property  float maxHighlightDuration
 @property  BOOL faceDominated
 @property  long long status

  // class methods
  +[VCPMovieAnalyzer canAnalyzeUndegraded:withResources:]
  +[VCPMovieAnalyzer analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  +[VCPMovieAnalyzer getMaximumHighlightInSec]
  +[VCPMovieAnalyzer getHumanActionClassiferType]

  // instance methods
  -[VCPMovieAnalyzer .cxx_destruct]
  -[VCPMovieAnalyzer status]
  -[VCPMovieAnalyzer maxHighlightDuration]
  -[VCPMovieAnalyzer setMaxHighlightDuration:]
  -[VCPMovieAnalyzer privateResults]
  -[VCPMovieAnalyzer initWithPHAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer analyzeAsset:streamed:]
  -[VCPMovieAnalyzer setAllowStreaming:]
  -[VCPMovieAnalyzer initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer processExistingAnalysisForTimeRange:analysisTypes:]
  -[VCPMovieAnalyzer createDecoderForTrack:timerange:forAnalysisTypes:]
  -[VCPMovieAnalyzer createVideoAnalyzer:withFrameStats:]
  -[VCPMovieAnalyzer postProcessAutoPlayable:]
  -[VCPMovieAnalyzer analyzeVideoSegment:timerange:forAnalysisTypes:cancel:]
  -[VCPMovieAnalyzer allowStreaming]
  -[VCPMovieAnalyzer loadPropertiesForAsset:]
  -[VCPMovieAnalyzer performMetadataAnalysisOnAsset:withCancelBlock:]
  -[VCPMovieAnalyzer analyzeVideoTrack:start:forAnalysisTypes:cancel:]
  -[VCPMovieAnalyzer generateKeyFrameResource:]
  -[VCPMovieAnalyzer initWithPHAsset:withPausedAnalysis:forAnalysisTypes:]
  -[VCPMovieAnalyzer faceDominated]
  -[VCPMovieAnalyzer setFaceDominated:]


VCPProtoImageHumanPoseResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds
 @property  int flags
 @property  NSMutableArray *keypoints

  // class methods
  +[VCPProtoImageHumanPoseResult resultFromLegacyDictionary:]
  +[VCPProtoImageHumanPoseResult keypointsType]

  // instance methods
  -[VCPProtoImageHumanPoseResult setFlags:]
  -[VCPProtoImageHumanPoseResult setConfidence:]
  -[VCPProtoImageHumanPoseResult mergeFrom:]
  -[VCPProtoImageHumanPoseResult .cxx_destruct]
  -[VCPProtoImageHumanPoseResult confidence]
  -[VCPProtoImageHumanPoseResult dictionaryRepresentation]
  -[VCPProtoImageHumanPoseResult writeTo:]
  -[VCPProtoImageHumanPoseResult isEqual:]
  -[VCPProtoImageHumanPoseResult copyTo:]
  -[VCPProtoImageHumanPoseResult readFrom:]
  -[VCPProtoImageHumanPoseResult flags]
  -[VCPProtoImageHumanPoseResult copyWithZone:]
  -[VCPProtoImageHumanPoseResult setBounds:]
  -[VCPProtoImageHumanPoseResult bounds]
  -[VCPProtoImageHumanPoseResult keypoints]
  -[VCPProtoImageHumanPoseResult exportToLegacyDictionary]
  -[VCPProtoImageHumanPoseResult setKeypoints:]
  -[VCPProtoImageHumanPoseResult addKeypoints:]
  -[VCPProtoImageHumanPoseResult keypointsCount]
  -[VCPProtoImageHumanPoseResult clearKeypoints]
  -[VCPProtoImageHumanPoseResult keypointsAtIndex:]


VCPMotionFlowAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPMotionFlowAnalyzer createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPMotionFlowAnalyzer .cxx_construct]
  -[VCPMotionFlowAnalyzer .cxx_destruct]
  -[VCPMotionFlowAnalyzer init]
  -[VCPMotionFlowAnalyzer dealloc]
  -[VCPMotionFlowAnalyzer analyzePixelBuffer:withFrame:withTimestamp:andDuration:]
  -[VCPMotionFlowAnalyzer convertPixelBuffer:toPixelBuffer:withPixelFormat:]
  -[VCPMotionFlowAnalyzer convertFlow:]
  -[VCPMotionFlowAnalyzer prepareAnalyzerWithCVPixelBuffer:]
  -[VCPMotionFlowAnalyzer preProcessing:]
  -[VCPMotionFlowAnalyzer generateMotionFlow]


VCPLivePhotoKeyFrameAnalyzer : NSObject
  // instance methods
  -[VCPLivePhotoKeyFrameAnalyzer initWithWidth:height:]
  -[VCPLivePhotoKeyFrameAnalyzer dealloc]
  -[VCPLivePhotoKeyFrameAnalyzer createFaceHeatMap:imageFaces:]
  -[VCPLivePhotoKeyFrameAnalyzer computeOverallFaceQualityScore:]
  -[VCPLivePhotoKeyFrameAnalyzer selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:]
  -[VCPLivePhotoKeyFrameAnalyzer fetchAndComputeScoreForKeyFrame:withResult:]
  -[VCPLivePhotoKeyFrameAnalyzer computeScoreForPhoto:withRefKeyFrame:]
  -[VCPLivePhotoKeyFrameAnalyzer reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:]
  -[VCPLivePhotoKeyFrameAnalyzer getFaceHeat:]
  -[VCPLivePhotoKeyFrameAnalyzer updateFaceHeatMap:]
  -[VCPLivePhotoKeyFrameAnalyzer analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:]


VCPMADVisionResource : VCPMADResource
 @property  VNSession *session

  // instance methods
  -[VCPMADVisionResource purge]
  -[VCPMADVisionResource .cxx_destruct]
  -[VCPMADVisionResource init]
  -[VCPMADVisionResource session]


VCPPhotosQuickFaceIdentificationManager : NSObject
  // class methods
  +[VCPPhotosQuickFaceIdentificationManager _fastFaceMigrationEnabled]

  // instance methods
  -[VCPPhotosQuickFaceIdentificationManager initWithPhotoLibrary:]
  -[VCPPhotosQuickFaceIdentificationManager _loadPersonsModelAndInitializeFaceAnalyzer]
  -[VCPPhotosQuickFaceIdentificationManager _persistResults:withFaces:forAsset:]
  -[VCPPhotosQuickFaceIdentificationManager .cxx_destruct]
  -[VCPPhotosQuickFaceIdentificationManager fetchEntityForModelType:]
  -[VCPPhotosQuickFaceIdentificationManager _loadPetsModel]
  -[VCPPhotosQuickFaceIdentificationManager init]
  -[VCPPhotosQuickFaceIdentificationManager _persistPetsModel:error:]
  -[VCPPhotosQuickFaceIdentificationManager _keepCurrentPersonsModelWithExtendTimeout:]
  -[VCPPhotosQuickFaceIdentificationManager _faceProcessingPassGoalWithExtendTimeout:]
  -[VCPPhotosQuickFaceIdentificationManager _modelLastGenerationDidExceedTimeIntervalForType:]
  -[VCPPhotosQuickFaceIdentificationManager classifyVIPPets]
  -[VCPPhotosQuickFaceIdentificationManager _needToGenerateModelWithType:ignoreLastGenerationTime:withExtendTimeout:]
  -[VCPPhotosQuickFaceIdentificationManager _classifyFaces:forAsset:withResults:]
  -[VCPPhotosQuickFaceIdentificationManager _fetchPersonsToFeedVIPModel]
  -[VCPPhotosQuickFaceIdentificationManager _fetchPetsToFeedVIPModel]
  -[VCPPhotosQuickFaceIdentificationManager _generatePersonsModelWithExtendTimeoutBlock:cancel:]
  -[VCPPhotosQuickFaceIdentificationManager generateVIPModelWithType:ignoreLastGenerationTime:modelGenerated:extendTimeout:andCancel:]
  -[VCPPhotosQuickFaceIdentificationManager _persistPersonsModel:error:]
  -[VCPPhotosQuickFaceIdentificationManager _generatePetsModelWithExtendTimeoutBlock:cancel:]
  -[VCPPhotosQuickFaceIdentificationManager processAsset:]


VCPPhotoAnalyzer : NSObject
 @property  BOOL allowStreaming
 @property  long long status

  // class methods
  +[VCPPhotoAnalyzer canAnalyzeUndegraded:withResources:]
  +[VCPPhotoAnalyzer analyzerWithVCPAsset:forAnalysisTypes:]
  +[VCPPhotoAnalyzer resourceForAsset:withResources:]

  // instance methods
  -[VCPPhotoAnalyzer .cxx_destruct]
  -[VCPPhotoAnalyzer status]
  -[VCPPhotoAnalyzer initWithPHAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPPhotoAnalyzer setAllowStreaming:]
  -[VCPPhotoAnalyzer analyzeAsset:]
  -[VCPPhotoAnalyzer initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:]
  -[VCPPhotoAnalyzer allowStreaming]
  -[VCPPhotoAnalyzer processExistingAnalyses:]
  -[VCPPhotoAnalyzer updateDegradedFlagForMajorDimension:]
  -[VCPPhotoAnalyzer downscaleImage:scaledImage:majorDimension:]
  -[VCPPhotoAnalyzer _reportPetsAnalysisWithResults:]
  -[VCPPhotoAnalyzer existingAnalysisForMovieAnalyzer]
  -[VCPPhotoAnalyzer checkFaceDominant]
  -[VCPPhotoAnalyzer analyzeImage:performedAnalyses:cancel:]


VCPPnPSolver : NSObject
 @property  {?=[4]} pose

  // instance methods
  -[VCPPnPSolver pose]
  -[VCPPnPSolver setPose:]
  -[VCPPnPSolver dealloc]
  -[VCPPnPSolver computeControlPointsCamera:Vt:]
  -[VCPPnPSolver computePoints3DCamera]
  -[VCPPnPSolver correctSigns]
  -[VCPPnPSolver computeRT:T:]
  -[VCPPnPSolver computeProjectionError:T:]
  -[VCPPnPSolver configureGaussNewton:R6x1:betas:jacobian:residual:]
  -[VCPPnPSolver getControlPoints]
  -[VCPPnPSolver computeBarycentricCoordinates]
  -[VCPPnPSolver computeSVDVt:Vt:]
  -[VCPPnPSolver computeL6x10:L6x10:]
  -[VCPPnPSolver computeR6x1:]
  -[VCPPnPSolver estimateBetasN1:R6x1:betas:]
  -[VCPPnPSolver estimateBetasN2:R6x1:betas:]
  -[VCPPnPSolver estimateBetasN3:R6x1:betas:]
  -[VCPPnPSolver optimizeBetas:R6x1:betas:]
  -[VCPPnPSolver estimateRT:betas:R:T:projectionError:]
  -[VCPPnPSolver estimatePose:]
  -[VCPPnPSolver initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:]
  -[VCPPnPSolver updateIntrinsic:vc:]
  -[VCPPnPSolver updateFocalLengthInPixels:]
  -[VCPPnPSolver estimateExtrinsicsWith:andPoints3D:andNumPoints:]


VCPSceneprintDescriptor : NSObject <VCPDistanceDescriptorProtocol>
  // class methods
  +[VCPSceneprintDescriptor preferredPixelFormat]
  +[VCPSceneprintDescriptor usePHAssetData]
  +[VCPSceneprintDescriptor descriptorWithImage:]
  +[VCPSceneprintDescriptor descriptorWithData:]

  // instance methods
  -[VCPSceneprintDescriptor initWithImage:]
  -[VCPSceneprintDescriptor .cxx_destruct]
  -[VCPSceneprintDescriptor serialize]
  -[VCPSceneprintDescriptor initWithData:]
  -[VCPSceneprintDescriptor computeDistance:toDescriptor:]


VCPSceneChangeAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPSceneChangeAnalyzer .cxx_construct]
  -[VCPSceneChangeAnalyzer results]
  -[VCPSceneChangeAnalyzer .cxx_destruct]
  -[VCPSceneChangeAnalyzer init]
  -[VCPSceneChangeAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPSceneChangeAnalyzer ComputeSceneDelta:]
  -[VCPSceneChangeAnalyzer decideLensSwitchPoint:]
  -[VCPSceneChangeAnalyzer PrintSegments]
  -[VCPSceneChangeAnalyzer finalizeAnalysisPass:]
  -[VCPSceneChangeAnalyzer isSegmentPoint]


VCPSceneChangeSegment : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames

  // instance methods
  -[VCPSceneChangeSegment timeRange]
  -[VCPSceneChangeSegment init]
  -[VCPSceneChangeSegment mergeSegment:]
  -[VCPSceneChangeSegment numOfFrames]
  -[VCPSceneChangeSegment updateSegment:]
  -[VCPSceneChangeSegment resetSegment:]
  -[VCPSceneChangeSegment finalizeAtTime:]


VCPVideoPixelStabilizer : VCPVideoStabilizer
  // instance methods
  -[VCPVideoPixelStabilizer init]
  -[VCPVideoPixelStabilizer dealloc]
  -[VCPVideoPixelStabilizer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoPixelStabilizer convertAnalysisResult]


VCPPhotosFace : NSObject <PFPhotosFaceRepresentation>
 @property  NSString *localIdentifier
 @property  NSString *personLocalIdentifier
 @property  long long sourceWidth
 @property  long long sourceHeight
 @property  short detectionType
 @property  double centerX
 @property  double centerY
 @property  double size
 @property  double bodyCenterX
 @property  double bodyCenterY
 @property  double bodyWidth
 @property  double bodyHeight
 @property  BOOL hidden
 @property  BOOL isInTrash
 @property  BOOL manual
 @property  BOOL isTooSmall
 @property  BOOL hasSmile
 @property  double blurScore
 @property  double exposureScore
 @property  BOOL isLeftEyeClosed
 @property  BOOL isRightEyeClosed
 @property  NSString *adjustmentVersion
 @property  long long nameSource
 @property  int trainingType
 @property  double poseYaw
 @property  unsigned long algorithmVersion
 @property  long long clusterSequenceNumber
 @property  long long qualityMeasure
 @property  unsigned short ageType
 @property  unsigned short sexType
 @property  unsigned short eyesState
 @property  unsigned short smileType
 @property  unsigned short facialHairType
 @property  unsigned short hairColorType
 @property  unsigned short glassesType
 @property  unsigned short expressionType
 @property  unsigned short headgearType
 @property  unsigned short hairType
 @property  unsigned short poseType
 @property  unsigned short skintoneType
 @property  unsigned short ethnicityType
 @property  BOOL hasFaceMask
 @property  unsigned short gazeType
 @property  double gazeCenterX
 @property  double gazeCenterY
 @property  NSString *groupingIdentifier
 @property  VCPVNImageprintWrapper *imageprintWrapper
 @property  double roll
 @property  double quality

  // class methods
  +[VCPPhotosFace faceWithLocalIdentifier:]

  // instance methods
  -[VCPPhotosFace manual]
  -[VCPPhotosFace bodyWidth]
  -[VCPPhotosFace algorithmVersion]
  -[VCPPhotosFace hidden]
  -[VCPPhotosFace hasSmile]
  -[VCPPhotosFace initWithLocalIdentifier:]
  -[VCPPhotosFace setExposureScore:]
  -[VCPPhotosFace poseYaw]
  -[VCPPhotosFace ageType]
  -[VCPPhotosFace centerX]
  -[VCPPhotosFace centerY]
  -[VCPPhotosFace .cxx_destruct]
  -[VCPPhotosFace sexType]
  -[VCPPhotosFace setCenterX:]
  -[VCPPhotosFace setCenterY:]
  -[VCPPhotosFace bodyCenterX]
  -[VCPPhotosFace setBodyCenterX:]
  -[VCPPhotosFace bodyCenterY]
  -[VCPPhotosFace setBodyCenterY:]
  -[VCPPhotosFace setBodyWidth:]
  -[VCPPhotosFace setQuality:]
  -[VCPPhotosFace isInTrash]
  -[VCPPhotosFace bodyHeight]
  -[VCPPhotosFace setBodyHeight:]
  -[VCPPhotosFace detectionType]
  -[VCPPhotosFace setDetectionType:]
  -[VCPPhotosFace sourceWidth]
  -[VCPPhotosFace setSourceWidth:]
  -[VCPPhotosFace sourceHeight]
  -[VCPPhotosFace setSourceHeight:]
  -[VCPPhotosFace setManual:]
  -[VCPPhotosFace setHasSmile:]
  -[VCPPhotosFace setBlurScore:]
  -[VCPPhotosFace isLeftEyeClosed]
  -[VCPPhotosFace expressionType]
  -[VCPPhotosFace quality]
  -[VCPPhotosFace isRightEyeClosed]
  -[VCPPhotosFace setNameSource:]
  -[VCPPhotosFace setPoseYaw:]
  -[VCPPhotosFace clusterSequenceNumber]
  -[VCPPhotosFace setClusterSequenceNumber:]
  -[VCPPhotosFace qualityMeasure]
  -[VCPPhotosFace setQualityMeasure:]
  -[VCPPhotosFace setAgeType:]
  -[VCPPhotosFace setSexType:]
  -[VCPPhotosFace setEyesState:]
  -[VCPPhotosFace setSmileType:]
  -[VCPPhotosFace facialHairType]
  -[VCPPhotosFace setFacialHairType:]
  -[VCPPhotosFace hairColorType]
  -[VCPPhotosFace glassesType]
  -[VCPPhotosFace personLocalIdentifier]
  -[VCPPhotosFace setHairColorType:]
  -[VCPPhotosFace setGlassesType:]
  -[VCPPhotosFace headgearType]
  -[VCPPhotosFace setHeadgearType:]
  -[VCPPhotosFace setHairType:]
  -[VCPPhotosFace setPoseType:]
  -[VCPPhotosFace skintoneType]
  -[VCPPhotosFace setSkintoneType:]
  -[VCPPhotosFace ethnicityType]
  -[VCPPhotosFace setEthnicityType:]
  -[VCPPhotosFace hasFaceMask]
  -[VCPPhotosFace setHasFaceMask:]
  -[VCPPhotosFace setGazeType:]
  -[VCPPhotosFace setSize:]
  -[VCPPhotosFace exposureScore]
  -[VCPPhotosFace gazeCenterX]
  -[VCPPhotosFace setGazeCenterX:]
  -[VCPPhotosFace gazeCenterY]
  -[VCPPhotosFace setGazeCenterY:]
  -[VCPPhotosFace groupingIdentifier]
  -[VCPPhotosFace setGroupingIdentifier:]
  -[VCPPhotosFace setAdjustmentVersion:]
  -[VCPPhotosFace adjustmentVersion]
  -[VCPPhotosFace localIdentifier]
  -[VCPPhotosFace hairType]
  -[VCPPhotosFace poseType]
  -[VCPPhotosFace gazeType]
  -[VCPPhotosFace normalizedFaceRect]
  -[VCPPhotosFace setAlgorithmVersion:]
  -[VCPPhotosFace photosFaceRepresentationSourceWidth]
  -[VCPPhotosFace photosFaceRepresentationSourceHeight]
  -[VCPPhotosFace photosFaceRepresentationCenterX]
  -[VCPPhotosFace photosFaceRepresentationCenterY]
  -[VCPPhotosFace photosFaceRepresentationSize]
  -[VCPPhotosFace photosFaceRepresentationBlurScore]
  -[VCPPhotosFace photosFaceRepresentationHasSmile]
  -[VCPPhotosFace photosFaceRepresentationIsLeftEyeClosed]
  -[VCPPhotosFace photosFaceRepresentationIsRightEyeClosed]
  -[VCPPhotosFace photosFaceRepresentationQualityMeasure]
  -[VCPPhotosFace photosFaceRepresentationClusterSequenceNumber]
  -[VCPPhotosFace size]
  -[VCPPhotosFace roll]
  -[VCPPhotosFace blurScore]
  -[VCPPhotosFace eyesState]
  -[VCPPhotosFace smileType]
  -[VCPPhotosFace photosFaceRepresentationLocalIdentifier]
  -[VCPPhotosFace photosFaceRepresentationRoll]
  -[VCPPhotosFace photosFaceRepresentationQuality]
  -[VCPPhotosFace nameSource]
  -[VCPPhotosFace setTrainingType:]
  -[VCPPhotosFace setRoll:]
  -[VCPPhotosFace setHidden:]
  -[VCPPhotosFace trainingType]
  -[VCPPhotosFace setPersonLocalIdentifier:]
  -[VCPPhotosFace setIsLeftEyeClosed:]
  -[VCPPhotosFace setIsRightEyeClosed:]
  -[VCPPhotosFace setIsInTrash:]
  -[VCPPhotosFace setIsTooSmall:]
  -[VCPPhotosFace isTooSmall]
  -[VCPPhotosFace setCenterAndSizeFromNormalizedFaceRect:]
  -[VCPPhotosFace setImageprintWrapper:]
  -[VCPPhotosFace setExpressionType:]
  -[VCPPhotosFace imageprintWrapper]
  -[VCPPhotosFace gistDescription]
  -[VCPPhotosFace replaceCoordinatesAndFeaturesFromDetectedFace:]


VCPFaceShapeModel : NSObject
 @property  int processingMode
 @property  * meshVertices
 @property  unsigned long vertexCount
 @property  int detectionModeCounterShapeModel

  // instance methods
  -[VCPFaceShapeModel .cxx_destruct]
  -[VCPFaceShapeModel initWithMode:]
  -[VCPFaceShapeModel vertexCount]
  -[VCPFaceShapeModel dealloc]
  -[VCPFaceShapeModel blendShapes]
  -[VCPFaceShapeModel setupModel:]
  -[VCPFaceShapeModel updateIntrinsic:vc:]
  -[VCPFaceShapeModel updateFocalLengthInPixels:]
  -[VCPFaceShapeModel getInternal3dLandmarksCoordinates:lm3dPos:]
  -[VCPFaceShapeModel getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:]
  -[VCPFaceShapeModel updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:]
  -[VCPFaceShapeModel project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:]
  -[VCPFaceShapeModel updateBoundaryLmForShapeOptimization]
  -[VCPFaceShapeModel updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:]
  -[VCPFaceShapeModel moveBoundaryLandmarks:output:isInput:]
  -[VCPFaceShapeModel projectAndUpdateBoundary]
  -[VCPFaceShapeModel optimizeProjectionMatrix:tracking:firstPass:]
  -[VCPFaceShapeModel updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:]
  -[VCPFaceShapeModel calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:]
  -[VCPFaceShapeModel updateMeshAndLm3dAfterExpressionChange]
  -[VCPFaceShapeModel calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:]
  -[VCPFaceShapeModel calculatePosePnpSolver:]
  -[VCPFaceShapeModel reestimateProjectionMatrixPnP]
  -[VCPFaceShapeModel updateIdentityShape:]
  -[VCPFaceShapeModel getPoseParam]
  -[VCPFaceShapeModel isIdentityInit]
  -[VCPFaceShapeModel setCameraIntrinsics:uc:vc:]
  -[VCPFaceShapeModel getEulerAngle:]
  -[VCPFaceShapeModel resetIdentityAndExpressions]
  -[VCPFaceShapeModel trackFaceMesh:]
  -[VCPFaceShapeModel fitOneImage:]
  -[VCPFaceShapeModel getPose]
  -[VCPFaceShapeModel updateMeshVertices]
  -[VCPFaceShapeModel processingMode]
  -[VCPFaceShapeModel setProcessingMode:]
  -[VCPFaceShapeModel meshVertices]
  -[VCPFaceShapeModel detectionModeCounterShapeModel]
  -[VCPFaceShapeModel setDetectionModeCounterShapeModel:]


VCPMADResource : NSObject
 @property  double activeCost
 @property  double inactiveCost

  // instance methods
  -[VCPMADResource purge]
  -[VCPMADResource inactiveCost]
  -[VCPMADResource activeCost]


VCPMotionFlowSubtleMotionAnalyzer : VCPVideoAnalyzer
 @property  float subtleMotionScore

  // class methods
  +[VCPMotionFlowSubtleMotionAnalyzer enableR2D2]

  // instance methods
  -[VCPMotionFlowSubtleMotionAnalyzer createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:]
  -[VCPMotionFlowSubtleMotionAnalyzer .cxx_construct]
  -[VCPMotionFlowSubtleMotionAnalyzer .cxx_destruct]
  -[VCPMotionFlowSubtleMotionAnalyzer init]
  -[VCPMotionFlowSubtleMotionAnalyzer dealloc]
  -[VCPMotionFlowSubtleMotionAnalyzer analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:]
  -[VCPMotionFlowSubtleMotionAnalyzer convertPixelBuffer:toPixelBuffer:withPixelFormat:]
  -[VCPMotionFlowSubtleMotionAnalyzer convertFlow:]
  -[VCPMotionFlowSubtleMotionAnalyzer prepareAnalyzerWithCVPixelBuffer:]
  -[VCPMotionFlowSubtleMotionAnalyzer preProcessing:]
  -[VCPMotionFlowSubtleMotionAnalyzer generateMotionFlow]
  -[VCPMotionFlowSubtleMotionAnalyzer generateSubleMotionScore:]
  -[VCPMotionFlowSubtleMotionAnalyzer subtleMotionScore]


VCPVideoProcessorNode : NSObject
 @property  VNRequest *request
 @property  {?=qiIq} timeInterval
 @property  unsigned long frameInterval

  // class methods
  +[VCPVideoProcessorNode validateConfiguration:withError:]
  +[VCPVideoProcessorNode nodeWithRequest:andConfiguration:]

  // instance methods
  -[VCPVideoProcessorNode timeInterval]
  -[VCPVideoProcessorNode frameInterval]
  -[VCPVideoProcessorNode .cxx_destruct]
  -[VCPVideoProcessorNode request]
  -[VCPVideoProcessorNode initWithRequest:andConfiguration:]


VCPFaceTensorModel : NSObject
 @property  int numVertices
 @property  ^f meanBlendshape
 @property  ^f tensorCoeff
 @property  ^f componentsBlendshape
 @property  ^i blendshapeComponentIndex

  // instance methods
  -[VCPFaceTensorModel dealloc]
  -[VCPFaceTensorModel numVertices]
  -[VCPFaceTensorModel initWithModelFile:]
  -[VCPFaceTensorModel meanBlendshape]
  -[VCPFaceTensorModel componentsBlendshape]
  -[VCPFaceTensorModel calculateMesh:numVertices:blendshapes:outputMesh:]
  -[VCPFaceTensorModel calculateModelBlendshapes:outputBlendshapes:]
  -[VCPFaceTensorModel tensorCoeff]
  -[VCPFaceTensorModel blendshapeComponentIndex]


VCPHumanPoseEspressoSession : NSObject
  // instance methods
  -[VCPHumanPoseEspressoSession initWithOptions:]
  -[VCPHumanPoseEspressoSession dealloc]
  -[VCPHumanPoseEspressoSession keypointsFromTensor:width:height:channels:withOptions:results:]
  -[VCPHumanPoseEspressoSession keypointsToObservation:]
  -[VCPHumanPoseEspressoSession keypointsFromTensor:withOptions:results:]
  -[VCPHumanPoseEspressoSession requiredInputFormat:height:format:]
  -[VCPHumanPoseEspressoSession processFrame:withOptions:results:]


VCPVanishingPointDetector : NSObject
  // instance methods
  -[VCPVanishingPointDetector initWithImage:]
  -[VCPVanishingPointDetector .cxx_destruct]
  -[VCPVanishingPointDetector dealloc]
  -[VCPVanishingPointDetector detect:withConfidence:dominantLine:]
  -[VCPVanishingPointDetector prepareImage:]
  -[VCPVanishingPointDetector calculateOrientationResponses]
  -[VCPVanishingPointDetector generateOrientationMap]
  -[VCPVanishingPointDetector generateLineWeightMap:weightMap:]
  -[VCPVanishingPointDetector voteVanishingPoint:]
  -[VCPVanishingPointDetector searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:]
  -[VCPVanishingPointDetector extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:]
  -[VCPVanishingPointDetector averageOrientationResponses:withCurrentMap:]
  -[VCPVanishingPointDetector smoothFiltering:width:height:]
  -[VCPVanishingPointDetector calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:]
  -[VCPVanishingPointDetector isVerticalOrHorizontal:]


VCPActionAnalyzer : NSObject
  // instance methods
  -[VCPActionAnalyzer segments]
  -[VCPActionAnalyzer .cxx_destruct]
  -[VCPActionAnalyzer init]
  -[VCPActionAnalyzer dealloc]
  -[VCPActionAnalyzer isActive:]
  -[VCPActionAnalyzer isScoreValid:]
  -[VCPActionAnalyzer decideSegmentPointUsingHinkleyDetector:]
  -[VCPActionAnalyzer updateActiveThreshold]
  -[VCPActionAnalyzer mergeSameTypeSegments]
  -[VCPActionAnalyzer printSegments:]
  -[VCPActionAnalyzer prepareTrimmingWithTrimStart:andTrimEnd:]
  -[VCPActionAnalyzer mergeConsecutiveShortSegments]
  -[VCPActionAnalyzer mergeSparseShortSegments]
  -[VCPActionAnalyzer analyzeFrameWithTimeRange:andActionScore:]
  -[VCPActionAnalyzer decideSegmentPointBasedOnActionScore:]
  -[VCPActionAnalyzer finalizeWithDestructiveTrimStart:trimEnd:]
  -[VCPActionAnalyzer postProcessSegmentsWithCaptureTime:trimStart:]
  -[VCPActionAnalyzer activeSegment]


VCPAsset : NSObject
 @property  BOOL isPano
 @property  BOOL isLivePhoto
 @property  BOOL isScreenshot
 @property  BOOL isHDR
 @property  BOOL isSDOF
 @property  NSDictionary *exif
 @property  BOOL hadFlash
 @property  float exposureTimeSeconds
 @property  float photoOffsetSeconds
 @property  float originalPhotoOffsetSeconds
 @property  BOOL isSlowmo
 @property  BOOL isTimelapse
 @property  double duration
 @property  float slowmoRate
 @property  float timelapseRate
 @property  {?={?=qiIq}{?=qiIq}} slomoRange
 @property  long long mediaType
 @property  unsigned long mediaSubtypes
 @property  unsigned long pixelWidth
 @property  unsigned long pixelHeight
 @property  NSDate *modificationDate
 @property  VCPFingerprint *fingerprint
 @property  BOOL isImage
 @property  BOOL isMovie
 @property  NSString *localIdentifier
 @property  NSURL *mainFileURL
 @property  NSArray *allScenes
 @property  NSDictionary *scenes
 @property  PHFetchResult *faces

  // class methods
  +[VCPAsset unimplementedExceptionForMethodName:]

  // instance methods
  -[VCPAsset modificationDate]
  -[VCPAsset movie]
  -[VCPAsset isMovie]
  -[VCPAsset fingerprint]
  -[VCPAsset mediaSubtypes]
  -[VCPAsset exif]
  -[VCPAsset allScenes]
  -[VCPAsset pixelWidth]
  -[VCPAsset faces]
  -[VCPAsset isSDOF]
  -[VCPAsset pixelHeight]
  -[VCPAsset isHDR]
  -[VCPAsset isScreenshot]
  -[VCPAsset isTimelapse]
  -[VCPAsset typeDescription]
  -[VCPAsset isLivePhoto]
  -[VCPAsset localIdentifier]
  -[VCPAsset scenes]
  -[VCPAsset mainFileURL]
  -[VCPAsset mediaType]
  -[VCPAsset isPano]
  -[VCPAsset duration]
  -[VCPAsset isImage]
  -[VCPAsset imageWithPreferredDimension:]
  -[VCPAsset hadFlash]
  -[VCPAsset exposureTimeSeconds]
  -[VCPAsset photoOffsetSeconds]
  -[VCPAsset originalPhotoOffsetSeconds]
  -[VCPAsset isSlowmo]
  -[VCPAsset slowmoRate]
  -[VCPAsset slomoRange]
  -[VCPAsset timelapseRate]
  -[VCPAsset streamedMovie]
  -[VCPAsset originalMovie]
  -[VCPAsset originalMovieSize]


VCPFaceGeometry : NSObject <NSSecureCoding>
 @property  unsigned long vertexCount
 @property  r^ vertices

  // class methods
  +[VCPFaceGeometry supportsSecureCoding]

  // instance methods
  -[VCPFaceGeometry initWithCoder:]
  -[VCPFaceGeometry vertices]
  -[VCPFaceGeometry vertexCount]
  -[VCPFaceGeometry dealloc]
  -[VCPFaceGeometry encodeWithCoder:]
  -[VCPFaceGeometry initWithVertices:vertexCount:]


VCPFaceAnchor : NSObject <NSSecureCoding>
 @property  {?=[4]} transform
 @property  NSDictionary *blendShapes
 @property  VCPFaceGeometry *geometry

  // class methods
  +[VCPFaceAnchor supportsSecureCoding]

  // instance methods
  -[VCPFaceAnchor geometry]
  -[VCPFaceAnchor initWithCoder:]
  -[VCPFaceAnchor .cxx_destruct]
  -[VCPFaceAnchor transform]
  -[VCPFaceAnchor encodeWithCoder:]
  -[VCPFaceAnchor blendShapes]
  -[VCPFaceAnchor initWithTransform:blendShapes:geometry:]


VCPCaptureAnalysisSession : NSObject
 @property  NSDictionary *aggregatedResults

  // class methods
  +[VCPCaptureAnalysisSession analyzerForAnalysisTypes:withPreferredTransform:properties:]
  +[VCPCaptureAnalysisSession aggregateAnalysisForTypes:withFramesMeta:properties:]

  // instance methods
  -[VCPCaptureAnalysisSession .cxx_destruct]
  -[VCPCaptureAnalysisSession init]
  -[VCPCaptureAnalysisSession dealloc]
  -[VCPCaptureAnalysisSession finalizeAnalysis]
  -[VCPCaptureAnalysisSession prewarmWithProperties:]
  -[VCPCaptureAnalysisSession analyzePixelBuffer:withTimestamp:andDuration:properties:error:]
  -[VCPCaptureAnalysisSession analyzePixelBuffer:withTimestamp:andDuration:properties:completion:]
  -[VCPCaptureAnalysisSession updatePreferredTransform:properties:]
  -[VCPCaptureAnalysisSession initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:]
  -[VCPCaptureAnalysisSession transformForAngle:pixelBuffer:]
  -[VCPCaptureAnalysisSession flipTransform:]
  -[VCPCaptureAnalysisSession rotateTransform:byAngle:]
  -[VCPCaptureAnalysisSession analyzeFrameWithTimeRange:analysisData:]
  -[VCPCaptureAnalysisSession shouldCutAt:stillPTS:withCut:]
  -[VCPCaptureAnalysisSession analyzeAudioBuffer:]
  -[VCPCaptureAnalysisSession aggregatedResults]


VCPClientDatabaseManager : NSObject
  // class methods
  +[VCPClientDatabaseManager sharedDatabaseForPhotoLibrary:]
  +[VCPClientDatabaseManager sharedDatabaseManager]

  // instance methods
  -[VCPClientDatabaseManager .cxx_destruct]
  -[VCPClientDatabaseManager init]
  -[VCPClientDatabaseManager sharedDatabaseForPhotoLibrary:]


VCPContentAnalysis : NSObject
  // class methods
  +[VCPContentAnalysis contentAnalysis]

  // instance methods
  -[VCPContentAnalysis .cxx_destruct]
  -[VCPContentAnalysis init]
  -[VCPContentAnalysis dealloc]
  -[VCPContentAnalysis copyBlock:withStride:toBlock:]
  -[VCPContentAnalysis blockContentDetection:]
  -[VCPContentAnalysis detectPixelBuffer:contentType:]


VCPDefaultPhotoLibraryManager : NSObject <PHPhotoLibraryAvailabilityObserver>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPDefaultPhotoLibraryManager sharedManager]

  // instance methods
  -[VCPDefaultPhotoLibraryManager photoLibraryDidBecomeUnavailable:]
  -[VCPDefaultPhotoLibraryManager .cxx_destruct]
  -[VCPDefaultPhotoLibraryManager init]
  -[VCPDefaultPhotoLibraryManager defaultPhotoLibrary]
  -[VCPDefaultPhotoLibraryManager closedefaultPhotoLibrary]


VCPDownloadManager : NSObject
 @property  @? cancel

  // class methods
  +[VCPDownloadManager sharedManager]
  +[VCPDownloadManager _reportDownload:]
  +[VCPDownloadManager maxSizeBytes]

  // instance methods
  -[VCPDownloadManager setCancel:]
  -[VCPDownloadManager .cxx_destruct]
  -[VCPDownloadManager init]
  -[VCPDownloadManager flush]
  -[VCPDownloadManager cancel]
  -[VCPDownloadManager requestDownloadOfResource:]


VCPFullAnalysisURLProcessingTask : NSObject <VCPMADTaskProtocol>
  // class methods
  +[VCPFullAnalysisURLProcessingTask taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:]

  // instance methods
  -[VCPFullAnalysisURLProcessingTask resourceRequirement]
  -[VCPFullAnalysisURLProcessingTask .cxx_destruct]
  -[VCPFullAnalysisURLProcessingTask cancel]
  -[VCPFullAnalysisURLProcessingTask autoCancellable]
  -[VCPFullAnalysisURLProcessingTask run]
  -[VCPFullAnalysisURLProcessingTask initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:]


VCPProcessingStatusEntry : NSObject
 @property  unsigned long taskID
 @property  NSString *localIdentifier
 @property  unsigned long status
 @property  unsigned long attempts
 @property  NSDate *lastRetryDate

  // class methods
  +[VCPProcessingStatusEntry entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:]

  // instance methods
  -[VCPProcessingStatusEntry .cxx_destruct]
  -[VCPProcessingStatusEntry lastRetryDate]
  -[VCPProcessingStatusEntry taskID]
  -[VCPProcessingStatusEntry localIdentifier]
  -[VCPProcessingStatusEntry attempts]
  -[VCPProcessingStatusEntry status]
  -[VCPProcessingStatusEntry initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andLastRetryDate:]


VCPCNNFastGestureRecognition : NSObject
  // class methods
  +[VCPCNNFastGestureRecognition detector]

  // instance methods
  -[VCPCNNFastGestureRecognition .cxx_destruct]
  -[VCPCNNFastGestureRecognition init]
  -[VCPCNNFastGestureRecognition dealloc]
  -[VCPCNNFastGestureRecognition getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:]
  -[VCPCNNFastGestureRecognition createInput:keypoints:]
  -[VCPCNNFastGestureRecognition getDetectionScore:]
  -[VCPCNNFastGestureRecognition planDestroy]
  -[VCPCNNFastGestureRecognition gestureDetection:score:]


VCPProtoMovieSceneprintResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTime *timestamp
 @property  NSData *sceneprintBlob

  // class methods
  +[VCPProtoMovieSceneprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSceneprintResult mergeFrom:]
  -[VCPProtoMovieSceneprintResult .cxx_destruct]
  -[VCPProtoMovieSceneprintResult dictionaryRepresentation]
  -[VCPProtoMovieSceneprintResult writeTo:]
  -[VCPProtoMovieSceneprintResult isEqual:]
  -[VCPProtoMovieSceneprintResult copyTo:]
  -[VCPProtoMovieSceneprintResult readFrom:]
  -[VCPProtoMovieSceneprintResult timestamp]
  -[VCPProtoMovieSceneprintResult copyWithZone:]
  -[VCPProtoMovieSceneprintResult setTimestamp:]
  -[VCPProtoMovieSceneprintResult setSceneprintBlob:]
  -[VCPProtoMovieSceneprintResult sceneprintBlob]
  -[VCPProtoMovieSceneprintResult exportToLegacyDictionary]


VCPMADServiceImagePixelBufferAsset : VCPMADServiceImageAsset
  // instance methods
  -[VCPMADServiceImagePixelBufferAsset hasCachedParseData]
  -[VCPMADServiceImagePixelBufferAsset .cxx_construct]
  -[VCPMADServiceImagePixelBufferAsset setCachedParseData:]
  -[VCPMADServiceImagePixelBufferAsset .cxx_destruct]
  -[VCPMADServiceImagePixelBufferAsset initWithPixelBuffer:orientation:andIdentifier:clientBundleID:clientTeamID:]
  -[VCPMADServiceImagePixelBufferAsset setDocumentObservations:]
  -[VCPMADServiceImagePixelBufferAsset identifier]
  -[VCPMADServiceImagePixelBufferAsset loadPixelBuffer:orientation:]
  -[VCPMADServiceImagePixelBufferAsset documentObservations]
  -[VCPMADServiceImagePixelBufferAsset cachedParseData]


VCPMADServiceImageURLAsset : VCPMADServiceImageAsset
  // instance methods
  -[VCPMADServiceImageURLAsset hasCachedParseData]
  -[VCPMADServiceImageURLAsset .cxx_construct]
  -[VCPMADServiceImageURLAsset setCachedParseData:]
  -[VCPMADServiceImageURLAsset .cxx_destruct]
  -[VCPMADServiceImageURLAsset setDocumentObservations:]
  -[VCPMADServiceImageURLAsset identifier]
  -[VCPMADServiceImageURLAsset loadPixelBuffer:orientation:]
  -[VCPMADServiceImageURLAsset documentObservations]
  -[VCPMADServiceImageURLAsset cachedParseData]
  -[VCPMADServiceImageURLAsset initWithURL:identifier:clientBundleID:clientTeamID:]


VCPMADServiceImagePhotosAsset : VCPMADServiceImageAsset
  // instance methods
  -[VCPMADServiceImagePhotosAsset resources]
  -[VCPMADServiceImagePhotosAsset hasCachedParseData]
  -[VCPMADServiceImagePhotosAsset .cxx_construct]
  -[VCPMADServiceImagePhotosAsset thumbnailResource]
  -[VCPMADServiceImagePhotosAsset setCachedParseData:]
  -[VCPMADServiceImagePhotosAsset .cxx_destruct]
  -[VCPMADServiceImagePhotosAsset faces]
  -[VCPMADServiceImagePhotosAsset barcodeObservations]
  -[VCPMADServiceImagePhotosAsset isScreenshot]
  -[VCPMADServiceImagePhotosAsset asset]
  -[VCPMADServiceImagePhotosAsset setDocumentObservations:]
  -[VCPMADServiceImagePhotosAsset initWithPhotosAsset:clientBundleID:clientTeamID:]
  -[VCPMADServiceImagePhotosAsset identifier]
  -[VCPMADServiceImagePhotosAsset location]
  -[VCPMADServiceImagePhotosAsset initWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:]
  -[VCPMADServiceImagePhotosAsset loadPixelBuffer:orientation:]
  -[VCPMADServiceImagePhotosAsset documentObservations]
  -[VCPMADServiceImagePhotosAsset persistOCRMRC]
  -[VCPMADServiceImagePhotosAsset nsfwClassifications]
  -[VCPMADServiceImagePhotosAsset setBarcodeObservations:]
  -[VCPMADServiceImagePhotosAsset cachedParseData]


VCPMADServiceImageAsset : NSObject
 @property  NSString *identifier
 @property  NSString *clientBundleID
 @property  NSString *clientTeamID
 @property  CLLocation *location
 @property  BOOL isScreenshot
 @property  NSArray *faces
 @property  NSArray *nsfwClassifications
 @property  NSArray *documentObservations
 @property  NSArray *barcodeObservations
 @property  BOOL hasCachedParseData
 @property  NSData *cachedParseData
 @property  NSString *signpostPayload

  // class methods
  +[VCPMADServiceImageAsset assetWithPixelBuffer:orientation:identifier:clientBundleID:clientTeamID:]
  +[VCPMADServiceImageAsset assetWithURL:identifier:clientBundleID:clientTeamID:]
  +[VCPMADServiceImageAsset assetWithPhotosAsset:clientBundleID:clientTeamID:]
  +[VCPMADServiceImageAsset assetWithPhotosAsset:pixelBuffer:orientation:clientBundleID:clientTeamID:]

  // instance methods
  -[VCPMADServiceImageAsset signpostPayload]
  -[VCPMADServiceImageAsset hasCachedParseData]
  -[VCPMADServiceImageAsset setCachedParseData:]
  -[VCPMADServiceImageAsset .cxx_destruct]
  -[VCPMADServiceImageAsset faces]
  -[VCPMADServiceImageAsset clientBundleID]
  -[VCPMADServiceImageAsset barcodeObservations]
  -[VCPMADServiceImageAsset isScreenshot]
  -[VCPMADServiceImageAsset setDocumentObservations:]
  -[VCPMADServiceImageAsset identifier]
  -[VCPMADServiceImageAsset location]
  -[VCPMADServiceImageAsset loadPixelBuffer:orientation:]
  -[VCPMADServiceImageAsset setSignpostPayload:]
  -[VCPMADServiceImageAsset documentObservations]
  -[VCPMADServiceImageAsset nsfwClassifications]
  -[VCPMADServiceImageAsset setBarcodeObservations:]
  -[VCPMADServiceImageAsset cachedParseData]
  -[VCPMADServiceImageAsset vcp_textAnnotation]
  -[VCPMADServiceImageAsset vcp_annotation:]
  -[VCPMADServiceImageAsset initWithClientBundleID:andClientTeamID:]
  -[VCPMADServiceImageAsset clientTeamID]


VCPProtoMoviePetsResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMoviePetsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePetsResult setTimeRange:]
  -[VCPProtoMoviePetsResult timeRange]
  -[VCPProtoMoviePetsResult setConfidence:]
  -[VCPProtoMoviePetsResult mergeFrom:]
  -[VCPProtoMoviePetsResult .cxx_destruct]
  -[VCPProtoMoviePetsResult confidence]
  -[VCPProtoMoviePetsResult dictionaryRepresentation]
  -[VCPProtoMoviePetsResult writeTo:]
  -[VCPProtoMoviePetsResult isEqual:]
  -[VCPProtoMoviePetsResult copyTo:]
  -[VCPProtoMoviePetsResult readFrom:]
  -[VCPProtoMoviePetsResult copyWithZone:]
  -[VCPProtoMoviePetsResult setBounds:]
  -[VCPProtoMoviePetsResult bounds]
  -[VCPProtoMoviePetsResult exportToLegacyDictionary]


VCPVideoCNNAutoplay : VCPVideoCNNTask
  // instance methods
  -[VCPVideoCNNAutoplay .cxx_construct]
  -[VCPVideoCNNAutoplay results]
  -[VCPVideoCNNAutoplay .cxx_destruct]
  -[VCPVideoCNNAutoplay init]
  -[VCPVideoCNNAutoplay run:]
  -[VCPVideoCNNAutoplay dealloc]
  -[VCPVideoCNNAutoplay finishAnalysisPass:]
  -[VCPVideoCNNAutoplay loadAnalysisResults:audioResults:]


VCPMotionFlowRequest : VCPRequest
  // instance methods
  -[VCPMotionFlowRequest .cxx_destruct]
  -[VCPMotionFlowRequest initWithOptions:]
  -[VCPMotionFlowRequest init]
  -[VCPMotionFlowRequest dealloc]
  -[VCPMotionFlowRequest updateWithOptions:error:]
  -[VCPMotionFlowRequest preferredInputSizeWithOptions:error:]
  -[VCPMotionFlowRequest preferredPixelFormat]
  -[VCPMotionFlowRequest cleanupWithOptions:error:]
  -[VCPMotionFlowRequest estimateMotionBetweenFirstImage:andSecondImage:error:]
  -[VCPMotionFlowRequest allocateInputAndOutputBuffers]
  -[VCPMotionFlowRequest copyImage:toBuffer:withChannels:]
  -[VCPMotionFlowRequest createInput:withImage:modelInputHeight:modelInputWidth:]
  -[VCPMotionFlowRequest releaseInputAndOutputBuffers]


VCPProtoLivePhotoHumanActionClassificationResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *classifications
 @property  VCPProtoBounds *bounds
 @property  BOOL hasFaceId
 @property  NSString *faceId

  // class methods
  +[VCPProtoLivePhotoHumanActionClassificationResult classificationType]
  +[VCPProtoLivePhotoHumanActionClassificationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoHumanActionClassificationResult setTimeRange:]
  -[VCPProtoLivePhotoHumanActionClassificationResult timeRange]
  -[VCPProtoLivePhotoHumanActionClassificationResult mergeFrom:]
  -[VCPProtoLivePhotoHumanActionClassificationResult faceId]
  -[VCPProtoLivePhotoHumanActionClassificationResult .cxx_destruct]
  -[VCPProtoLivePhotoHumanActionClassificationResult dictionaryRepresentation]
  -[VCPProtoLivePhotoHumanActionClassificationResult writeTo:]
  -[VCPProtoLivePhotoHumanActionClassificationResult isEqual:]
  -[VCPProtoLivePhotoHumanActionClassificationResult copyTo:]
  -[VCPProtoLivePhotoHumanActionClassificationResult addClassification:]
  -[VCPProtoLivePhotoHumanActionClassificationResult readFrom:]
  -[VCPProtoLivePhotoHumanActionClassificationResult copyWithZone:]
  -[VCPProtoLivePhotoHumanActionClassificationResult setBounds:]
  -[VCPProtoLivePhotoHumanActionClassificationResult setFaceId:]
  -[VCPProtoLivePhotoHumanActionClassificationResult bounds]
  -[VCPProtoLivePhotoHumanActionClassificationResult classifications]
  -[VCPProtoLivePhotoHumanActionClassificationResult setClassifications:]
  -[VCPProtoLivePhotoHumanActionClassificationResult hasFaceId]
  -[VCPProtoLivePhotoHumanActionClassificationResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoHumanActionClassificationResult classificationsCount]
  -[VCPProtoLivePhotoHumanActionClassificationResult clearClassifications]
  -[VCPProtoLivePhotoHumanActionClassificationResult classificationAtIndex:]


VCPFrameAnalysisStats : NSObject
 @property  BOOL frameProcessedByVideoAnalyzer
 @property  float cameraMotionScore
 @property  float subjectActionScore
 @property  float interestingnessScore
 @property  float obstructionScore
 @property  float exposureScore
 @property  float colorfulnessScore
 @property  BOOL subMbMotionAvailable
 @property  float frameExpressionScore
 @property  float faceArea
 @property  BOOL frameProcessedByHumanAnalyzer
 @property  float humanPoseScore
 @property  float humanActionScore
 @property  BOOL frameProcessedByFaceDetector
 @property  NSMutableArray *detectedFaces
 @property  VCPVideoActivityDescriptor *videoActivityDescriptor

  // instance methods
  -[VCPFrameAnalysisStats setExposureScore:]
  -[VCPFrameAnalysisStats .cxx_destruct]
  -[VCPFrameAnalysisStats init]
  -[VCPFrameAnalysisStats exposureScore]
  -[VCPFrameAnalysisStats reset]
  -[VCPFrameAnalysisStats setDetectedFaces:]
  -[VCPFrameAnalysisStats detectedFaces]
  -[VCPFrameAnalysisStats setVideoActivityDescriptor:]
  -[VCPFrameAnalysisStats videoActivityDescriptor]
  -[VCPFrameAnalysisStats frameExpressionScore]
  -[VCPFrameAnalysisStats setFrameExpressionScore:]
  -[VCPFrameAnalysisStats setCameraMotionScore:]
  -[VCPFrameAnalysisStats setSubjectActionScore:]
  -[VCPFrameAnalysisStats setInterestingnessScore:]
  -[VCPFrameAnalysisStats setColorfulnessScore:]
  -[VCPFrameAnalysisStats setFrameProcessedByVideoAnalyzer:]
  -[VCPFrameAnalysisStats setSubMbMotionAvailable:]
  -[VCPFrameAnalysisStats interestingnessScore]
  -[VCPFrameAnalysisStats obstructionScore]
  -[VCPFrameAnalysisStats setObstructionScore:]
  -[VCPFrameAnalysisStats setHumanActionScore:]
  -[VCPFrameAnalysisStats setHumanPoseScore:]
  -[VCPFrameAnalysisStats humanPoseScore]
  -[VCPFrameAnalysisStats humanActionScore]
  -[VCPFrameAnalysisStats frameProcessedByVideoAnalyzer]
  -[VCPFrameAnalysisStats cameraMotionScore]
  -[VCPFrameAnalysisStats subjectActionScore]
  -[VCPFrameAnalysisStats colorfulnessScore]
  -[VCPFrameAnalysisStats subMbMotionAvailable]
  -[VCPFrameAnalysisStats faceArea]
  -[VCPFrameAnalysisStats setFaceArea:]
  -[VCPFrameAnalysisStats frameProcessedByHumanAnalyzer]
  -[VCPFrameAnalysisStats setFrameProcessedByHumanAnalyzer:]
  -[VCPFrameAnalysisStats frameProcessedByFaceDetector]
  -[VCPFrameAnalysisStats setFrameProcessedByFaceDetector:]


VCPHomeKitAnalysisService : NSObject <VCPHomeKitAnalysisClientProtocol>
  // class methods
  +[VCPHomeKitAnalysisService analysisService]

  // instance methods
  -[VCPHomeKitAnalysisService .cxx_destruct]
  -[VCPHomeKitAnalysisService init]
  -[VCPHomeKitAnalysisService connection]
  -[VCPHomeKitAnalysisService cancelAllRequests]
  -[VCPHomeKitAnalysisService cancelRequest:]
  -[VCPHomeKitAnalysisService reportProgress:forRequest:]
  -[VCPHomeKitAnalysisService requestResidentMaintenanceWithOptions:andCompletionHandler:]
  -[VCPHomeKitAnalysisService requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:]
  -[VCPHomeKitAnalysisService requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:]
  -[VCPHomeKitAnalysisService requestIdentificationForFaceCrop:withOptions:andCompletionHandler:]


VCPColorNormalizationAnalyzer : NSObject
  // instance methods
  -[VCPColorNormalizationAnalyzer .cxx_destruct]
  -[VCPColorNormalizationAnalyzer init]
  -[VCPColorNormalizationAnalyzer _configureRequest:withRevision:]
  -[VCPColorNormalizationAnalyzer analyzeCGImage:results:]


VCPInMemoryAVAsset : AVURLAsset <AVAssetResourceLoaderDelegate>
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPInMemoryAVAsset assetWithData:]

  // instance methods
  -[VCPInMemoryAVAsset .cxx_destruct]
  -[VCPInMemoryAVAsset initWithData:]
  -[VCPInMemoryAVAsset resourceLoader:shouldWaitForLoadingOfRequestedResource:]


VCPInternetReachability : NSObject
 @property  BOOL hasWifiOrEthernetConnection

  // class methods
  +[VCPInternetReachability sharedInstance]

  // instance methods
  -[VCPInternetReachability .cxx_destruct]
  -[VCPInternetReachability init]
  -[VCPInternetReachability dealloc]
  -[VCPInternetReachability hasWifiOrEthernetConnection]
  -[VCPInternetReachability setReachabilityForFlags:update:]


VCPMADImageSafetyClassificationResource : VCPMADResource
  // class methods
  +[VCPMADImageSafetyClassificationResource sharedResource]

  // instance methods
  -[VCPMADImageSafetyClassificationResource purge]
  -[VCPMADImageSafetyClassificationResource .cxx_destruct]
  -[VCPMADImageSafetyClassificationResource init]
  -[VCPMADImageSafetyClassificationResource handler]


VCPMADImageSafetyClassificationTask : NSObject <VCPMADServiceImageProcessingSubtaskProtocol, VCPMADTaskProtocol>
  // class methods
  +[VCPMADImageSafetyClassificationTask dependencies]
  +[VCPMADImageSafetyClassificationTask taskWithRequest:imageAsset:andSignpostPayload:]

  // instance methods
  -[VCPMADImageSafetyClassificationTask resourceRequirement]
  -[VCPMADImageSafetyClassificationTask .cxx_destruct]
  -[VCPMADImageSafetyClassificationTask cancel]
  -[VCPMADImageSafetyClassificationTask initWithRequest:imageAsset:andSignpostPayload:]
  -[VCPMADImageSafetyClassificationTask autoCancellable]
  -[VCPMADImageSafetyClassificationTask run]


VCPGeneralCanceller : NSObject
 @property  BOOL canceled
 @property  @? updateBlock

  // class methods
  +[VCPGeneralCanceller cancelerWithUpdateBlock:]

  // instance methods
  -[VCPGeneralCanceller .cxx_destruct]
  -[VCPGeneralCanceller updateBlock]
  -[VCPGeneralCanceller setCanceled:]
  -[VCPGeneralCanceller canceled]
  -[VCPGeneralCanceller setUpdateBlock:]


VCPFaceCropSourceDescriptor : NSObject <NSCopying>
  // class methods
  +[VCPFaceCropSourceDescriptor descriptorForFace:image:]

  // instance methods
  -[VCPFaceCropSourceDescriptor face]
  -[VCPFaceCropSourceDescriptor image]
  -[VCPFaceCropSourceDescriptor .cxx_destruct]
  -[VCPFaceCropSourceDescriptor copyWithZone:]
  -[VCPFaceCropSourceDescriptor initWithFace:image:]


VCPFaceCropGenerator : NSObject
  // class methods
  +[VCPFaceCropGenerator _faceCropDataForImage:andNormalizedFaceRect:error:]
  +[VCPFaceCropGenerator _generateFaceCropWithDescriptor:andCancelBlock:error:]
  +[VCPFaceCropGenerator _reportCancellationOfRemainingFaceCropSourceDescriptors:withStartingIndex:andFailureBlock:]
  +[VCPFaceCropGenerator generateFaceCropsFromSourceDescriptors:withProgressBlock:andFailureBlock:andCancelBlock:]


VCPFaceCropManager : NSObject
  // class methods
  +[VCPFaceCropManager _allowANE]

  // instance methods
  -[VCPFaceCropManager .cxx_destruct]
  -[VCPFaceCropManager _bestFaceForFaceDetectionRequest:withRect:]
  -[VCPFaceCropManager _faceFromFaceCrop:error:]
  -[VCPFaceCropManager _clearDirtyStateOnFaceCrops:error:]
  -[VCPFaceCropManager _associateFace:withFaceCrop:error:]
  -[VCPFaceCropManager _updateFaceprint:withFace:error:]
  -[VCPFaceCropManager _faceAssociatedWithFaceCrop:]
  -[VCPFaceCropManager _generateAndAssociateFaceprintedFaceForFaceCrop:error:]
  -[VCPFaceCropManager _updateFace:withFaceCrop:error:]
  -[VCPFaceCropManager _recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
  -[VCPFaceCropManager _persistGeneratedFaceCrops:forAsset:error:]
  -[VCPFaceCropManager _vcpFaceCropFromPHFaceCrop:]
  -[VCPFaceCropManager _processDirtyFaceCrop:error:]
  -[VCPFaceCropManager initWithPhotoLibrary:andContext:]
  -[VCPFaceCropManager _persistFaceAnalysis:forPHAsset:]
  -[VCPFaceCropManager generateAndPersistFaceCropsForFaces:withAsset:andImage:error:]
  -[VCPFaceCropManager processDirtyFaceCrops:withCancelBlock:andExtendTimeoutBlock:]


VCPPhotosAsset : VCPAsset
 @property  NSArray *resources

  // class methods
  +[VCPPhotosAsset assetWithPHAsset:]

  // instance methods
  -[VCPPhotosAsset resources]
  -[VCPPhotosAsset modificationDate]
  -[VCPPhotosAsset movie]
  -[VCPPhotosAsset fingerprint]
  -[VCPPhotosAsset .cxx_destruct]
  -[VCPPhotosAsset mediaSubtypes]
  -[VCPPhotosAsset exif]
  -[VCPPhotosAsset allScenes]
  -[VCPPhotosAsset pixelWidth]
  -[VCPPhotosAsset faces]
  -[VCPPhotosAsset pixelHeight]
  -[VCPPhotosAsset localIdentifier]
  -[VCPPhotosAsset scenes]
  -[VCPPhotosAsset mainFileURL]
  -[VCPPhotosAsset mediaType]
  -[VCPPhotosAsset duration]
  -[VCPPhotosAsset initWithPHAsset:]
  -[VCPPhotosAsset imageWithPreferredDimension:]
  -[VCPPhotosAsset photoOffsetSeconds]
  -[VCPPhotosAsset originalPhotoOffsetSeconds]
  -[VCPPhotosAsset slowmoRate]
  -[VCPPhotosAsset slomoRange]
  -[VCPPhotosAsset streamedMovie]
  -[VCPPhotosAsset originalMovie]
  -[VCPPhotosAsset originalMovieSize]


VCPPriorityAnalysis : NSObject
  // class methods
  +[VCPPriorityAnalysis priorityAnalysis]

  // instance methods
  -[VCPPriorityAnalysis .cxx_construct]
  -[VCPPriorityAnalysis .cxx_destruct]
  -[VCPPriorityAnalysis init]
  -[VCPPriorityAnalysis dealloc]
  -[VCPPriorityAnalysis addKeypointsToNSArray:keypointConfidence:handBox:keypointsArray:]
  -[VCPPriorityAnalysis fastSignLanguageDetection:ofPixelBuffer:withMetadata:]
  -[VCPPriorityAnalysis calculatePriorityScore:ofPixelBuffer:withMetadata:]


VCPProtoAssetAnalysis : PBCodable <NSCopying>
 @property  unsigned int version
 @property  unsigned int types
 @property  unsigned int flags
 @property  double date
 @property  BOOL hasQuality
 @property  double quality
 @property  BOOL hasStatsFlags
 @property  unsigned long statsFlags
 @property  BOOL hasTypesWide
 @property  unsigned long typesWide
 @property  NSString *assetIdentifier
 @property  double assetModificationDate
 @property  NSString *assetMasterFingerprint
 @property  BOOL hasAssetAdjustedFingerprint
 @property  NSString *assetAdjustedFingerprint
 @property  NSMutableArray *imageBlurResults
 @property  NSMutableArray *imageCompositionResults
 @property  NSMutableArray *imageFaceResults
 @property  NSMutableArray *imageFeatureResults
 @property  NSMutableArray *imageJunkResults
 @property  NSMutableArray *imageSaliencyResults
 @property  NSMutableArray *imageShotTypeResults
 @property  NSMutableArray *imagePetsResults
 @property  NSMutableArray *imagePetsFaceResults
 @property  NSMutableArray *imageSceneprintResults
 @property  NSMutableArray *livePhotoEffectsResults
 @property  NSMutableArray *livePhotoRecommendationResults
 @property  NSMutableArray *livePhotoSharpnessResults
 @property  NSMutableArray *livePhotoKeyFrameResults
 @property  NSMutableArray *livePhotoKeyFrameStillResults
 @property  NSMutableArray *movieActivityLevelResults
 @property  NSMutableArray *movieCameraMotionResults
 @property  NSMutableArray *movieClassificationResults
 @property  NSMutableArray *movieFaceResults
 @property  NSMutableArray *movieFaceprintResults
 @property  NSMutableArray *movieFeatureResults
 @property  NSMutableArray *movieFineSubjectMotionResults
 @property  NSMutableArray *movieInterestingnessResults
 @property  NSMutableArray *movieMovingObjectResults
 @property  NSMutableArray *movieMusicResults
 @property  NSMutableArray *movieObstructionResults
 @property  NSMutableArray *movieOrientationResults
 @property  NSMutableArray *moviePreEncodeResults
 @property  NSMutableArray *movieQualityResults
 @property  NSMutableArray *movieSaliencyResults
 @property  NSMutableArray *movieSceneResults
 @property  NSMutableArray *movieSceneprintResults
 @property  NSMutableArray *movieSubjectMotionResults
 @property  NSMutableArray *movieSubtleMotionResults
 @property  NSMutableArray *movieUtteranceResults
 @property  NSMutableArray *movieVoiceResults
 @property  NSMutableArray *movieSummaryResults
 @property  NSMutableArray *movieHighlightResults
 @property  NSMutableArray *imageExposureResults
 @property  NSMutableArray *imageHumanPoseResults
 @property  NSMutableArray *movieHumanPoseResults
 @property  NSMutableArray *movieApplauseResults
 @property  NSMutableArray *movieBabbleResults
 @property  NSMutableArray *movieCheeringResults
 @property  NSMutableArray *movieLaughterResults
 @property  NSMutableArray *movieHumanActionResults
 @property  NSMutableArray *movieLoudnessResults
 @property  NSMutableArray *moviePetsResults
 @property  NSMutableArray *moviePetsFaceResults
 @property  NSMutableArray *movieStabilizationResults
 @property  NSMutableArray *movieHighlightScoreResults
 @property  NSMutableArray *livePhotoHumanActionClassificationResults

  // class methods
  +[VCPProtoAssetAnalysis imageBlurResultsType]
  +[VCPProtoAssetAnalysis imageCompositionResultsType]
  +[VCPProtoAssetAnalysis imageFaceResultsType]
  +[VCPProtoAssetAnalysis imageFeatureResultsType]
  +[VCPProtoAssetAnalysis imageJunkResultsType]
  +[VCPProtoAssetAnalysis imageSaliencyResultsType]
  +[VCPProtoAssetAnalysis imageShotTypeResultsType]
  +[VCPProtoAssetAnalysis imagePetsResultsType]
  +[VCPProtoAssetAnalysis imagePetsFaceResultsType]
  +[VCPProtoAssetAnalysis imageSceneprintResultsType]
  +[VCPProtoAssetAnalysis livePhotoEffectsResultsType]
  +[VCPProtoAssetAnalysis livePhotoRecommendationResultsType]
  +[VCPProtoAssetAnalysis livePhotoSharpnessResultsType]
  +[VCPProtoAssetAnalysis livePhotoKeyFrameResultsType]
  +[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsType]
  +[VCPProtoAssetAnalysis movieActivityLevelResultsType]
  +[VCPProtoAssetAnalysis movieCameraMotionResultsType]
  +[VCPProtoAssetAnalysis movieClassificationResultsType]
  +[VCPProtoAssetAnalysis movieFaceResultsType]
  +[VCPProtoAssetAnalysis movieFaceprintResultsType]
  +[VCPProtoAssetAnalysis movieFeatureResultsType]
  +[VCPProtoAssetAnalysis movieFineSubjectMotionResultsType]
  +[VCPProtoAssetAnalysis movieInterestingnessResultsType]
  +[VCPProtoAssetAnalysis movieMovingObjectResultsType]
  +[VCPProtoAssetAnalysis movieMusicResultsType]
  +[VCPProtoAssetAnalysis movieObstructionResultsType]
  +[VCPProtoAssetAnalysis movieOrientationResultsType]
  +[VCPProtoAssetAnalysis moviePreEncodeResultsType]
  +[VCPProtoAssetAnalysis movieQualityResultsType]
  +[VCPProtoAssetAnalysis movieSaliencyResultsType]
  +[VCPProtoAssetAnalysis movieSceneResultsType]
  +[VCPProtoAssetAnalysis movieSceneprintResultsType]
  +[VCPProtoAssetAnalysis movieSubjectMotionResultsType]
  +[VCPProtoAssetAnalysis movieSubtleMotionResultsType]
  +[VCPProtoAssetAnalysis movieUtteranceResultsType]
  +[VCPProtoAssetAnalysis movieVoiceResultsType]
  +[VCPProtoAssetAnalysis movieSummaryResultsType]
  +[VCPProtoAssetAnalysis movieHighlightResultsType]
  +[VCPProtoAssetAnalysis imageExposureResultsType]
  +[VCPProtoAssetAnalysis imageHumanPoseResultsType]
  +[VCPProtoAssetAnalysis movieHumanPoseResultsType]
  +[VCPProtoAssetAnalysis movieApplauseResultsType]
  +[VCPProtoAssetAnalysis movieBabbleResultsType]
  +[VCPProtoAssetAnalysis movieCheeringResultsType]
  +[VCPProtoAssetAnalysis movieLaughterResultsType]
  +[VCPProtoAssetAnalysis movieHumanActionResultsType]
  +[VCPProtoAssetAnalysis movieLoudnessResultsType]
  +[VCPProtoAssetAnalysis moviePetsResultsType]
  +[VCPProtoAssetAnalysis moviePetsFaceResultsType]
  +[VCPProtoAssetAnalysis movieStabilizationResultsType]
  +[VCPProtoAssetAnalysis movieHighlightScoreResultsType]
  +[VCPProtoAssetAnalysis livePhotoHumanActionClassificationResultsType]
  +[VCPProtoAssetAnalysis imageAnalysisFromLegacyDictionary:]
  +[VCPProtoAssetAnalysis movieAnalysisFromLegacyDictionary:]

  // instance methods
  -[VCPProtoAssetAnalysis setFlags:]
  -[VCPProtoAssetAnalysis mergeFrom:]
  -[VCPProtoAssetAnalysis types]
  -[VCPProtoAssetAnalysis .cxx_destruct]
  -[VCPProtoAssetAnalysis setTypes:]
  -[VCPProtoAssetAnalysis dictionaryRepresentation]
  -[VCPProtoAssetAnalysis setQuality:]
  -[VCPProtoAssetAnalysis writeTo:]
  -[VCPProtoAssetAnalysis quality]
  -[VCPProtoAssetAnalysis hasQuality]
  -[VCPProtoAssetAnalysis setVersion:]
  -[VCPProtoAssetAnalysis isEqual:]
  -[VCPProtoAssetAnalysis copyTo:]
  -[VCPProtoAssetAnalysis readFrom:]
  -[VCPProtoAssetAnalysis assetIdentifier]
  -[VCPProtoAssetAnalysis setAssetIdentifier:]
  -[VCPProtoAssetAnalysis flags]
  -[VCPProtoAssetAnalysis setDate:]
  -[VCPProtoAssetAnalysis version]
  -[VCPProtoAssetAnalysis copyWithZone:]
  -[VCPProtoAssetAnalysis date]
  -[VCPProtoAssetAnalysis movieHighlightScoreResults]
  -[VCPProtoAssetAnalysis movieSummaryResults]
  -[VCPProtoAssetAnalysis movieHighlightResults]
  -[VCPProtoAssetAnalysis setHasQuality:]
  -[VCPProtoAssetAnalysis exportToLegacyDictionary]
  -[VCPProtoAssetAnalysis addImageBlurResults:]
  -[VCPProtoAssetAnalysis addImageCompositionResults:]
  -[VCPProtoAssetAnalysis addImageFaceResults:]
  -[VCPProtoAssetAnalysis addImageFeatureResults:]
  -[VCPProtoAssetAnalysis addImageJunkResults:]
  -[VCPProtoAssetAnalysis addImageSaliencyResults:]
  -[VCPProtoAssetAnalysis addImageShotTypeResults:]
  -[VCPProtoAssetAnalysis addLivePhotoRecommendationResults:]
  -[VCPProtoAssetAnalysis addLivePhotoSharpnessResults:]
  -[VCPProtoAssetAnalysis addMovieActivityLevelResults:]
  -[VCPProtoAssetAnalysis addMovieCameraMotionResults:]
  -[VCPProtoAssetAnalysis addMovieClassificationResults:]
  -[VCPProtoAssetAnalysis addMovieFaceResults:]
  -[VCPProtoAssetAnalysis addMovieFaceprintResults:]
  -[VCPProtoAssetAnalysis addMovieFeatureResults:]
  -[VCPProtoAssetAnalysis addMovieFineSubjectMotionResults:]
  -[VCPProtoAssetAnalysis addMovieInterestingnessResults:]
  -[VCPProtoAssetAnalysis addMovieMovingObjectResults:]
  -[VCPProtoAssetAnalysis addMovieMusicResults:]
  -[VCPProtoAssetAnalysis addMovieObstructionResults:]
  -[VCPProtoAssetAnalysis addMovieOrientationResults:]
  -[VCPProtoAssetAnalysis addMoviePreEncodeResults:]
  -[VCPProtoAssetAnalysis addMovieQualityResults:]
  -[VCPProtoAssetAnalysis addMovieSaliencyResults:]
  -[VCPProtoAssetAnalysis addMovieSceneResults:]
  -[VCPProtoAssetAnalysis addMovieSubjectMotionResults:]
  -[VCPProtoAssetAnalysis addMovieUtteranceResults:]
  -[VCPProtoAssetAnalysis addMovieVoiceResults:]
  -[VCPProtoAssetAnalysis addImagePetsResults:]
  -[VCPProtoAssetAnalysis addMovieSummaryResults:]
  -[VCPProtoAssetAnalysis addMovieHighlightResults:]
  -[VCPProtoAssetAnalysis addImageExposureResults:]
  -[VCPProtoAssetAnalysis addLivePhotoEffectsResults:]
  -[VCPProtoAssetAnalysis addImagePetsFaceResults:]
  -[VCPProtoAssetAnalysis addImageSceneprintResults:]
  -[VCPProtoAssetAnalysis addMovieSceneprintResults:]
  -[VCPProtoAssetAnalysis addImageHumanPoseResults:]
  -[VCPProtoAssetAnalysis addMovieHumanPoseResults:]
  -[VCPProtoAssetAnalysis addMovieApplauseResults:]
  -[VCPProtoAssetAnalysis addMovieBabbleResults:]
  -[VCPProtoAssetAnalysis addMovieCheeringResults:]
  -[VCPProtoAssetAnalysis addMovieLaughterResults:]
  -[VCPProtoAssetAnalysis addLivePhotoKeyFrameResults:]
  -[VCPProtoAssetAnalysis addLivePhotoKeyFrameStillResults:]
  -[VCPProtoAssetAnalysis addMovieHumanActionResults:]
  -[VCPProtoAssetAnalysis addMovieSubtleMotionResults:]
  -[VCPProtoAssetAnalysis addMovieLoudnessResults:]
  -[VCPProtoAssetAnalysis addMoviePetsResults:]
  -[VCPProtoAssetAnalysis addMoviePetsFaceResults:]
  -[VCPProtoAssetAnalysis addMovieStabilizationResults:]
  -[VCPProtoAssetAnalysis addMovieHighlightScoreResults:]
  -[VCPProtoAssetAnalysis addLivePhotoHumanActionClassificationResults:]
  -[VCPProtoAssetAnalysis setAssetMasterFingerprint:]
  -[VCPProtoAssetAnalysis setAssetAdjustedFingerprint:]
  -[VCPProtoAssetAnalysis imageBlurResultsCount]
  -[VCPProtoAssetAnalysis clearImageBlurResults]
  -[VCPProtoAssetAnalysis imageBlurResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageCompositionResultsCount]
  -[VCPProtoAssetAnalysis clearImageCompositionResults]
  -[VCPProtoAssetAnalysis imageCompositionResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageFaceResultsCount]
  -[VCPProtoAssetAnalysis clearImageFaceResults]
  -[VCPProtoAssetAnalysis imageFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageFeatureResultsCount]
  -[VCPProtoAssetAnalysis clearImageFeatureResults]
  -[VCPProtoAssetAnalysis imageFeatureResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageJunkResultsCount]
  -[VCPProtoAssetAnalysis clearImageJunkResults]
  -[VCPProtoAssetAnalysis imageJunkResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageSaliencyResultsCount]
  -[VCPProtoAssetAnalysis clearImageSaliencyResults]
  -[VCPProtoAssetAnalysis imageSaliencyResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageShotTypeResultsCount]
  -[VCPProtoAssetAnalysis clearImageShotTypeResults]
  -[VCPProtoAssetAnalysis imageShotTypeResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoRecommendationResults]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoSharpnessResults]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieActivityLevelResultsCount]
  -[VCPProtoAssetAnalysis clearMovieActivityLevelResults]
  -[VCPProtoAssetAnalysis movieActivityLevelResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieCameraMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieCameraMotionResults]
  -[VCPProtoAssetAnalysis movieCameraMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieClassificationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieClassificationResults]
  -[VCPProtoAssetAnalysis movieClassificationResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFaceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFaceResults]
  -[VCPProtoAssetAnalysis movieFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFaceprintResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFaceprintResults]
  -[VCPProtoAssetAnalysis movieFaceprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFeatureResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFeatureResults]
  -[VCPProtoAssetAnalysis movieFeatureResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieFineSubjectMotionResults]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieInterestingnessResultsCount]
  -[VCPProtoAssetAnalysis clearMovieInterestingnessResults]
  -[VCPProtoAssetAnalysis movieInterestingnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieMovingObjectResultsCount]
  -[VCPProtoAssetAnalysis clearMovieMovingObjectResults]
  -[VCPProtoAssetAnalysis movieMovingObjectResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieMusicResultsCount]
  -[VCPProtoAssetAnalysis clearMovieMusicResults]
  -[VCPProtoAssetAnalysis movieMusicResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieObstructionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieObstructionResults]
  -[VCPProtoAssetAnalysis movieObstructionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieOrientationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieOrientationResults]
  -[VCPProtoAssetAnalysis movieOrientationResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePreEncodeResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePreEncodeResults]
  -[VCPProtoAssetAnalysis moviePreEncodeResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieQualityResultsCount]
  -[VCPProtoAssetAnalysis clearMovieQualityResults]
  -[VCPProtoAssetAnalysis movieQualityResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSaliencyResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSaliencyResults]
  -[VCPProtoAssetAnalysis movieSaliencyResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSceneResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSceneResults]
  -[VCPProtoAssetAnalysis movieSceneResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSubjectMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSubjectMotionResults]
  -[VCPProtoAssetAnalysis movieSubjectMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieUtteranceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieUtteranceResults]
  -[VCPProtoAssetAnalysis movieUtteranceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieVoiceResultsCount]
  -[VCPProtoAssetAnalysis clearMovieVoiceResults]
  -[VCPProtoAssetAnalysis movieVoiceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imagePetsResultsCount]
  -[VCPProtoAssetAnalysis clearImagePetsResults]
  -[VCPProtoAssetAnalysis imagePetsResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSummaryResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSummaryResults]
  -[VCPProtoAssetAnalysis movieSummaryResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHighlightResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHighlightResults]
  -[VCPProtoAssetAnalysis movieHighlightResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageExposureResultsCount]
  -[VCPProtoAssetAnalysis clearImageExposureResults]
  -[VCPProtoAssetAnalysis imageExposureResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoEffectsResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoEffectsResults]
  -[VCPProtoAssetAnalysis livePhotoEffectsResultsAtIndex:]
  -[VCPProtoAssetAnalysis imagePetsFaceResultsCount]
  -[VCPProtoAssetAnalysis clearImagePetsFaceResults]
  -[VCPProtoAssetAnalysis imagePetsFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageSceneprintResultsCount]
  -[VCPProtoAssetAnalysis clearImageSceneprintResults]
  -[VCPProtoAssetAnalysis imageSceneprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSceneprintResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSceneprintResults]
  -[VCPProtoAssetAnalysis movieSceneprintResultsAtIndex:]
  -[VCPProtoAssetAnalysis imageHumanPoseResultsCount]
  -[VCPProtoAssetAnalysis clearImageHumanPoseResults]
  -[VCPProtoAssetAnalysis imageHumanPoseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHumanPoseResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHumanPoseResults]
  -[VCPProtoAssetAnalysis movieHumanPoseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieApplauseResultsCount]
  -[VCPProtoAssetAnalysis clearMovieApplauseResults]
  -[VCPProtoAssetAnalysis movieApplauseResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieBabbleResultsCount]
  -[VCPProtoAssetAnalysis clearMovieBabbleResults]
  -[VCPProtoAssetAnalysis movieBabbleResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieCheeringResultsCount]
  -[VCPProtoAssetAnalysis clearMovieCheeringResults]
  -[VCPProtoAssetAnalysis movieCheeringResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieLaughterResultsCount]
  -[VCPProtoAssetAnalysis clearMovieLaughterResults]
  -[VCPProtoAssetAnalysis movieLaughterResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoKeyFrameResults]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoKeyFrameStillResults]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHumanActionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHumanActionResults]
  -[VCPProtoAssetAnalysis movieHumanActionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieSubtleMotionResultsCount]
  -[VCPProtoAssetAnalysis clearMovieSubtleMotionResults]
  -[VCPProtoAssetAnalysis movieSubtleMotionResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieLoudnessResultsCount]
  -[VCPProtoAssetAnalysis clearMovieLoudnessResults]
  -[VCPProtoAssetAnalysis movieLoudnessResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePetsResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePetsResults]
  -[VCPProtoAssetAnalysis moviePetsResultsAtIndex:]
  -[VCPProtoAssetAnalysis moviePetsFaceResultsCount]
  -[VCPProtoAssetAnalysis clearMoviePetsFaceResults]
  -[VCPProtoAssetAnalysis moviePetsFaceResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieStabilizationResultsCount]
  -[VCPProtoAssetAnalysis clearMovieStabilizationResults]
  -[VCPProtoAssetAnalysis movieStabilizationResultsAtIndex:]
  -[VCPProtoAssetAnalysis movieHighlightScoreResultsCount]
  -[VCPProtoAssetAnalysis clearMovieHighlightScoreResults]
  -[VCPProtoAssetAnalysis movieHighlightScoreResultsAtIndex:]
  -[VCPProtoAssetAnalysis livePhotoHumanActionClassificationResultsCount]
  -[VCPProtoAssetAnalysis clearLivePhotoHumanActionClassificationResults]
  -[VCPProtoAssetAnalysis livePhotoHumanActionClassificationResultsAtIndex:]
  -[VCPProtoAssetAnalysis setStatsFlags:]
  -[VCPProtoAssetAnalysis setHasStatsFlags:]
  -[VCPProtoAssetAnalysis hasStatsFlags]
  -[VCPProtoAssetAnalysis setTypesWide:]
  -[VCPProtoAssetAnalysis setHasTypesWide:]
  -[VCPProtoAssetAnalysis hasTypesWide]
  -[VCPProtoAssetAnalysis hasAssetAdjustedFingerprint]
  -[VCPProtoAssetAnalysis statsFlags]
  -[VCPProtoAssetAnalysis typesWide]
  -[VCPProtoAssetAnalysis assetModificationDate]
  -[VCPProtoAssetAnalysis setAssetModificationDate:]
  -[VCPProtoAssetAnalysis assetMasterFingerprint]
  -[VCPProtoAssetAnalysis assetAdjustedFingerprint]
  -[VCPProtoAssetAnalysis imageBlurResults]
  -[VCPProtoAssetAnalysis setImageBlurResults:]
  -[VCPProtoAssetAnalysis imageCompositionResults]
  -[VCPProtoAssetAnalysis setImageCompositionResults:]
  -[VCPProtoAssetAnalysis imageFaceResults]
  -[VCPProtoAssetAnalysis setImageFaceResults:]
  -[VCPProtoAssetAnalysis imageFeatureResults]
  -[VCPProtoAssetAnalysis setImageFeatureResults:]
  -[VCPProtoAssetAnalysis imageJunkResults]
  -[VCPProtoAssetAnalysis setImageJunkResults:]
  -[VCPProtoAssetAnalysis imageSaliencyResults]
  -[VCPProtoAssetAnalysis setImageSaliencyResults:]
  -[VCPProtoAssetAnalysis imageShotTypeResults]
  -[VCPProtoAssetAnalysis setImageShotTypeResults:]
  -[VCPProtoAssetAnalysis imagePetsResults]
  -[VCPProtoAssetAnalysis setImagePetsResults:]
  -[VCPProtoAssetAnalysis imagePetsFaceResults]
  -[VCPProtoAssetAnalysis setImagePetsFaceResults:]
  -[VCPProtoAssetAnalysis imageSceneprintResults]
  -[VCPProtoAssetAnalysis setImageSceneprintResults:]
  -[VCPProtoAssetAnalysis livePhotoEffectsResults]
  -[VCPProtoAssetAnalysis setLivePhotoEffectsResults:]
  -[VCPProtoAssetAnalysis livePhotoRecommendationResults]
  -[VCPProtoAssetAnalysis setLivePhotoRecommendationResults:]
  -[VCPProtoAssetAnalysis livePhotoSharpnessResults]
  -[VCPProtoAssetAnalysis setLivePhotoSharpnessResults:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameResults]
  -[VCPProtoAssetAnalysis setLivePhotoKeyFrameResults:]
  -[VCPProtoAssetAnalysis livePhotoKeyFrameStillResults]
  -[VCPProtoAssetAnalysis setLivePhotoKeyFrameStillResults:]
  -[VCPProtoAssetAnalysis movieActivityLevelResults]
  -[VCPProtoAssetAnalysis setMovieActivityLevelResults:]
  -[VCPProtoAssetAnalysis movieCameraMotionResults]
  -[VCPProtoAssetAnalysis setMovieCameraMotionResults:]
  -[VCPProtoAssetAnalysis movieClassificationResults]
  -[VCPProtoAssetAnalysis setMovieClassificationResults:]
  -[VCPProtoAssetAnalysis movieFaceResults]
  -[VCPProtoAssetAnalysis setMovieFaceResults:]
  -[VCPProtoAssetAnalysis movieFaceprintResults]
  -[VCPProtoAssetAnalysis setMovieFaceprintResults:]
  -[VCPProtoAssetAnalysis movieFeatureResults]
  -[VCPProtoAssetAnalysis setMovieFeatureResults:]
  -[VCPProtoAssetAnalysis movieFineSubjectMotionResults]
  -[VCPProtoAssetAnalysis setMovieFineSubjectMotionResults:]
  -[VCPProtoAssetAnalysis movieInterestingnessResults]
  -[VCPProtoAssetAnalysis setMovieInterestingnessResults:]
  -[VCPProtoAssetAnalysis movieMovingObjectResults]
  -[VCPProtoAssetAnalysis setMovieMovingObjectResults:]
  -[VCPProtoAssetAnalysis movieMusicResults]
  -[VCPProtoAssetAnalysis setMovieMusicResults:]
  -[VCPProtoAssetAnalysis movieObstructionResults]
  -[VCPProtoAssetAnalysis setMovieObstructionResults:]
  -[VCPProtoAssetAnalysis movieOrientationResults]
  -[VCPProtoAssetAnalysis setMovieOrientationResults:]
  -[VCPProtoAssetAnalysis moviePreEncodeResults]
  -[VCPProtoAssetAnalysis setMoviePreEncodeResults:]
  -[VCPProtoAssetAnalysis movieQualityResults]
  -[VCPProtoAssetAnalysis setMovieQualityResults:]
  -[VCPProtoAssetAnalysis movieSaliencyResults]
  -[VCPProtoAssetAnalysis setMovieSaliencyResults:]
  -[VCPProtoAssetAnalysis movieSceneResults]
  -[VCPProtoAssetAnalysis setMovieSceneResults:]
  -[VCPProtoAssetAnalysis movieSceneprintResults]
  -[VCPProtoAssetAnalysis setMovieSceneprintResults:]
  -[VCPProtoAssetAnalysis movieSubjectMotionResults]
  -[VCPProtoAssetAnalysis setMovieSubjectMotionResults:]
  -[VCPProtoAssetAnalysis movieSubtleMotionResults]
  -[VCPProtoAssetAnalysis setMovieSubtleMotionResults:]
  -[VCPProtoAssetAnalysis movieUtteranceResults]
  -[VCPProtoAssetAnalysis setMovieUtteranceResults:]
  -[VCPProtoAssetAnalysis movieVoiceResults]
  -[VCPProtoAssetAnalysis setMovieVoiceResults:]
  -[VCPProtoAssetAnalysis setMovieSummaryResults:]
  -[VCPProtoAssetAnalysis setMovieHighlightResults:]
  -[VCPProtoAssetAnalysis imageExposureResults]
  -[VCPProtoAssetAnalysis setImageExposureResults:]
  -[VCPProtoAssetAnalysis imageHumanPoseResults]
  -[VCPProtoAssetAnalysis setImageHumanPoseResults:]
  -[VCPProtoAssetAnalysis movieHumanPoseResults]
  -[VCPProtoAssetAnalysis setMovieHumanPoseResults:]
  -[VCPProtoAssetAnalysis movieApplauseResults]
  -[VCPProtoAssetAnalysis setMovieApplauseResults:]
  -[VCPProtoAssetAnalysis movieBabbleResults]
  -[VCPProtoAssetAnalysis setMovieBabbleResults:]
  -[VCPProtoAssetAnalysis movieCheeringResults]
  -[VCPProtoAssetAnalysis setMovieCheeringResults:]
  -[VCPProtoAssetAnalysis movieLaughterResults]
  -[VCPProtoAssetAnalysis setMovieLaughterResults:]
  -[VCPProtoAssetAnalysis movieHumanActionResults]
  -[VCPProtoAssetAnalysis setMovieHumanActionResults:]
  -[VCPProtoAssetAnalysis movieLoudnessResults]
  -[VCPProtoAssetAnalysis setMovieLoudnessResults:]
  -[VCPProtoAssetAnalysis moviePetsResults]
  -[VCPProtoAssetAnalysis setMoviePetsResults:]
  -[VCPProtoAssetAnalysis moviePetsFaceResults]
  -[VCPProtoAssetAnalysis setMoviePetsFaceResults:]
  -[VCPProtoAssetAnalysis movieStabilizationResults]
  -[VCPProtoAssetAnalysis setMovieStabilizationResults:]
  -[VCPProtoAssetAnalysis setMovieHighlightScoreResults:]
  -[VCPProtoAssetAnalysis livePhotoHumanActionClassificationResults]
  -[VCPProtoAssetAnalysis setLivePhotoHumanActionClassificationResults:]
  -[VCPProtoAssetAnalysis setAttributesFromLegacyDictionary:]
  -[VCPProtoAssetAnalysis setResults:withClass:forPropertyKey:]
  -[VCPProtoAssetAnalysis exportResultsWithPropertyKey:toLegacyDictionary:withKey:]


VCPProtoBounds : PBCodable <NSCopying>
 @property  double x0
 @property  double y0
 @property  double width
 @property  double height

  // class methods
  +[VCPProtoBounds boundsWithCGRect:]

  // instance methods
  -[VCPProtoBounds x0]
  -[VCPProtoBounds y0]
  -[VCPProtoBounds width]
  -[VCPProtoBounds mergeFrom:]
  -[VCPProtoBounds rectValue]
  -[VCPProtoBounds setWidth:]
  -[VCPProtoBounds dictionaryRepresentation]
  -[VCPProtoBounds writeTo:]
  -[VCPProtoBounds setHeight:]
  -[VCPProtoBounds height]
  -[VCPProtoBounds isEqual:]
  -[VCPProtoBounds copyTo:]
  -[VCPProtoBounds readFrom:]
  -[VCPProtoBounds copyWithZone:]
  -[VCPProtoBounds setX0:]
  -[VCPProtoBounds setY0:]


VCPImageMotionFlowAnalyzer : VCPImageAnalyzer
  // class methods
  +[VCPImageMotionFlowAnalyzer sharedModel:inputNames:]

  // instance methods
  -[VCPImageMotionFlowAnalyzer .cxx_construct]
  -[VCPImageMotionFlowAnalyzer .cxx_destruct]
  -[VCPImageMotionFlowAnalyzer init]
  -[VCPImageMotionFlowAnalyzer dealloc]
  -[VCPImageMotionFlowAnalyzer copyImage:toData:withChannels:]
  -[VCPImageMotionFlowAnalyzer prepareModelForSourceWidth:andSourceHeight:]
  -[VCPImageMotionFlowAnalyzer prepareModelWithAspectRatio:]
  -[VCPImageMotionFlowAnalyzer creatModel]
  -[VCPImageMotionFlowAnalyzer createInput:withBuffer:cnnInputHeight:cnnInputWidth:]
  -[VCPImageMotionFlowAnalyzer analyzeImages:secondImage:cancel:]
  -[VCPImageMotionFlowAnalyzer getFlowWithHeight:andWidth:]


VCPSongDetector : NSObject
  // instance methods
  -[VCPSongDetector results]
  -[VCPSongDetector .cxx_destruct]
  -[VCPSongDetector init]
  -[VCPSongDetector setupWithSample:andSampleBatchSize:]
  -[VCPSongDetector processAudioSamples:timestamp:]
  -[VCPSongDetector finalizeAnalysisAtTime:]


VCPProtoClassification : PBCodable <NSCopying>
 @property  unsigned int identifier
 @property  float confidence

  // instance methods
  -[VCPProtoClassification setConfidence:]
  -[VCPProtoClassification mergeFrom:]
  -[VCPProtoClassification confidence]
  -[VCPProtoClassification dictionaryRepresentation]
  -[VCPProtoClassification writeTo:]
  -[VCPProtoClassification isEqual:]
  -[VCPProtoClassification copyTo:]
  -[VCPProtoClassification readFrom:]
  -[VCPProtoClassification identifier]
  -[VCPProtoClassification setIdentifier:]
  -[VCPProtoClassification copyWithZone:]


VCPProtoImageBlurResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness
 @property  BOOL hasFaceSharpness
 @property  float faceSharpness

  // class methods
  +[VCPProtoImageBlurResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageBlurResult mergeFrom:]
  -[VCPProtoImageBlurResult dictionaryRepresentation]
  -[VCPProtoImageBlurResult writeTo:]
  -[VCPProtoImageBlurResult isEqual:]
  -[VCPProtoImageBlurResult sharpness]
  -[VCPProtoImageBlurResult copyTo:]
  -[VCPProtoImageBlurResult readFrom:]
  -[VCPProtoImageBlurResult copyWithZone:]
  -[VCPProtoImageBlurResult setSharpness:]
  -[VCPProtoImageBlurResult exportToLegacyDictionary]
  -[VCPProtoImageBlurResult setHasFaceSharpness:]
  -[VCPProtoImageBlurResult hasFaceSharpness]
  -[VCPProtoImageBlurResult faceSharpness]
  -[VCPProtoImageBlurResult setFaceSharpness:]


VCPProtoImageCompositionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoPoint *vanishingPoint
 @property  VCPProtoLine *dominantLine

  // class methods
  +[VCPProtoImageCompositionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageCompositionResult setConfidence:]
  -[VCPProtoImageCompositionResult mergeFrom:]
  -[VCPProtoImageCompositionResult .cxx_destruct]
  -[VCPProtoImageCompositionResult confidence]
  -[VCPProtoImageCompositionResult dictionaryRepresentation]
  -[VCPProtoImageCompositionResult writeTo:]
  -[VCPProtoImageCompositionResult isEqual:]
  -[VCPProtoImageCompositionResult copyTo:]
  -[VCPProtoImageCompositionResult readFrom:]
  -[VCPProtoImageCompositionResult copyWithZone:]
  -[VCPProtoImageCompositionResult setVanishingPoint:]
  -[VCPProtoImageCompositionResult vanishingPoint]
  -[VCPProtoImageCompositionResult exportToLegacyDictionary]
  -[VCPProtoImageCompositionResult setDominantLine:]
  -[VCPProtoImageCompositionResult dominantLine]


VCPProtoImageExposureResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float exposure
 @property  BOOL hasUnderExpose
 @property  float underExpose

  // class methods
  +[VCPProtoImageExposureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageExposureResult mergeFrom:]
  -[VCPProtoImageExposureResult dictionaryRepresentation]
  -[VCPProtoImageExposureResult writeTo:]
  -[VCPProtoImageExposureResult isEqual:]
  -[VCPProtoImageExposureResult copyTo:]
  -[VCPProtoImageExposureResult exposure]
  -[VCPProtoImageExposureResult readFrom:]
  -[VCPProtoImageExposureResult setExposure:]
  -[VCPProtoImageExposureResult copyWithZone:]
  -[VCPProtoImageExposureResult exportToLegacyDictionary]
  -[VCPProtoImageExposureResult setUnderExpose:]
  -[VCPProtoImageExposureResult setHasUnderExpose:]
  -[VCPProtoImageExposureResult hasUnderExpose]
  -[VCPProtoImageExposureResult underExpose]


VCPLoudnessAnalyzer : NSObject
  // instance methods
  -[VCPLoudnessAnalyzer .cxx_construct]
  -[VCPLoudnessAnalyzer results]
  -[VCPLoudnessAnalyzer .cxx_destruct]
  -[VCPLoudnessAnalyzer init]
  -[VCPLoudnessAnalyzer dealloc]
  -[VCPLoudnessAnalyzer setupWithSample:andSampleBatchSize:]
  -[VCPLoudnessAnalyzer processAudioSamples:timestamp:]
  -[VCPLoudnessAnalyzer finalizeAnalysisAtTime:]


VCPProtoImageFaceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int eyeExpression
 @property  int mouthExpression
 @property  int yaw
 @property  int position
 @property  VCPProtoBounds *bounds
 @property  BOOL isCloseup
 @property  BOOL hasFaceQuality
 @property  float faceQuality

  // class methods
  +[VCPProtoImageFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageFaceResult mergeFrom:]
  -[VCPProtoImageFaceResult setYaw:]
  -[VCPProtoImageFaceResult .cxx_destruct]
  -[VCPProtoImageFaceResult dictionaryRepresentation]
  -[VCPProtoImageFaceResult writeTo:]
  -[VCPProtoImageFaceResult isEqual:]
  -[VCPProtoImageFaceResult yaw]
  -[VCPProtoImageFaceResult copyTo:]
  -[VCPProtoImageFaceResult readFrom:]
  -[VCPProtoImageFaceResult copyWithZone:]
  -[VCPProtoImageFaceResult setBounds:]
  -[VCPProtoImageFaceResult setPosition:]
  -[VCPProtoImageFaceResult bounds]
  -[VCPProtoImageFaceResult position]
  -[VCPProtoImageFaceResult faceQuality]
  -[VCPProtoImageFaceResult setFaceQuality:]
  -[VCPProtoImageFaceResult exportToLegacyDictionary]
  -[VCPProtoImageFaceResult setHasFaceQuality:]
  -[VCPProtoImageFaceResult hasFaceQuality]
  -[VCPProtoImageFaceResult eyeExpression]
  -[VCPProtoImageFaceResult setEyeExpression:]
  -[VCPProtoImageFaceResult mouthExpression]
  -[VCPProtoImageFaceResult setMouthExpression:]
  -[VCPProtoImageFaceResult isCloseup]
  -[VCPProtoImageFaceResult setIsCloseup:]


VCPProtoImageFeatureResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *featureBlob

  // class methods
  +[VCPProtoImageFeatureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageFeatureResult mergeFrom:]
  -[VCPProtoImageFeatureResult .cxx_destruct]
  -[VCPProtoImageFeatureResult dictionaryRepresentation]
  -[VCPProtoImageFeatureResult writeTo:]
  -[VCPProtoImageFeatureResult isEqual:]
  -[VCPProtoImageFeatureResult copyTo:]
  -[VCPProtoImageFeatureResult readFrom:]
  -[VCPProtoImageFeatureResult copyWithZone:]
  -[VCPProtoImageFeatureResult exportToLegacyDictionary]
  -[VCPProtoImageFeatureResult setFeatureBlob:]
  -[VCPProtoImageFeatureResult featureBlob]


VCPProtoImageJunkResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence

  // class methods
  +[VCPProtoImageJunkResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageJunkResult setConfidence:]
  -[VCPProtoImageJunkResult mergeFrom:]
  -[VCPProtoImageJunkResult confidence]
  -[VCPProtoImageJunkResult dictionaryRepresentation]
  -[VCPProtoImageJunkResult writeTo:]
  -[VCPProtoImageJunkResult isEqual:]
  -[VCPProtoImageJunkResult copyTo:]
  -[VCPProtoImageJunkResult readFrom:]
  -[VCPProtoImageJunkResult copyWithZone:]
  -[VCPProtoImageJunkResult exportToLegacyDictionary]


VCPProtoImagePetsFaceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImagePetsFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImagePetsFaceResult setConfidence:]
  -[VCPProtoImagePetsFaceResult mergeFrom:]
  -[VCPProtoImagePetsFaceResult .cxx_destruct]
  -[VCPProtoImagePetsFaceResult confidence]
  -[VCPProtoImagePetsFaceResult dictionaryRepresentation]
  -[VCPProtoImagePetsFaceResult writeTo:]
  -[VCPProtoImagePetsFaceResult isEqual:]
  -[VCPProtoImagePetsFaceResult copyTo:]
  -[VCPProtoImagePetsFaceResult readFrom:]
  -[VCPProtoImagePetsFaceResult copyWithZone:]
  -[VCPProtoImagePetsFaceResult setBounds:]
  -[VCPProtoImagePetsFaceResult bounds]
  -[VCPProtoImagePetsFaceResult exportToLegacyDictionary]


VCPProtoMovieLaughterResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieLaughterResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieLaughterResult setTimeRange:]
  -[VCPProtoMovieLaughterResult timeRange]
  -[VCPProtoMovieLaughterResult setConfidence:]
  -[VCPProtoMovieLaughterResult mergeFrom:]
  -[VCPProtoMovieLaughterResult .cxx_destruct]
  -[VCPProtoMovieLaughterResult confidence]
  -[VCPProtoMovieLaughterResult dictionaryRepresentation]
  -[VCPProtoMovieLaughterResult writeTo:]
  -[VCPProtoMovieLaughterResult isEqual:]
  -[VCPProtoMovieLaughterResult copyTo:]
  -[VCPProtoMovieLaughterResult readFrom:]
  -[VCPProtoMovieLaughterResult copyWithZone:]
  -[VCPProtoMovieLaughterResult exportToLegacyDictionary]


VCPProtoImagePetsResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImagePetsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImagePetsResult setConfidence:]
  -[VCPProtoImagePetsResult mergeFrom:]
  -[VCPProtoImagePetsResult .cxx_destruct]
  -[VCPProtoImagePetsResult confidence]
  -[VCPProtoImagePetsResult dictionaryRepresentation]
  -[VCPProtoImagePetsResult writeTo:]
  -[VCPProtoImagePetsResult isEqual:]
  -[VCPProtoImagePetsResult copyTo:]
  -[VCPProtoImagePetsResult readFrom:]
  -[VCPProtoImagePetsResult copyWithZone:]
  -[VCPProtoImagePetsResult setBounds:]
  -[VCPProtoImagePetsResult bounds]
  -[VCPProtoImagePetsResult exportToLegacyDictionary]


VCPHandPoseVideoRequest : VCPRequest
  // instance methods
  -[VCPHandPoseVideoRequest .cxx_destruct]
  -[VCPHandPoseVideoRequest initWithOptions:]
  -[VCPHandPoseVideoRequest init]
  -[VCPHandPoseVideoRequest preferredInputSizeWithOptions:error:]
  -[VCPHandPoseVideoRequest preferredPixelFormat]
  -[VCPHandPoseVideoRequest processSampleBuffer:withOptions:error:]
  -[VCPHandPoseVideoRequest cleanupWithOptions:error:]
  -[VCPHandPoseVideoRequest associateHands:withExisingHands:]
  -[VCPHandPoseVideoRequest handDistance:withhandB:]


VCPMAEmbeddingAnalyzer : NSObject
  // instance methods
  -[VCPMAEmbeddingAnalyzer .cxx_destruct]
  -[VCPMAEmbeddingAnalyzer init]
  -[VCPMAEmbeddingAnalyzer _configureRequest:withRevision:preferANE:]
  -[VCPMAEmbeddingAnalyzer analyzeWithImageURL:requestTypes:reencode:completionHandler:]
  -[VCPMAEmbeddingAnalyzer _loadImageURL:withSession:reencodedImageData:andRequestHandler:]


VCPLoaned : NSObject
 @property  id object

  // instance methods
  -[VCPLoaned .cxx_destruct]
  -[VCPLoaned initWithObject:fromPool:]
  -[VCPLoaned object]
  -[VCPLoaned dealloc]


VCPObjectPool : NSObject
  // class methods
  +[VCPObjectPool objectPoolWithAllocator:]

  // instance methods
  -[VCPObjectPool getObject]
  -[VCPObjectPool .cxx_destruct]
  -[VCPObjectPool initWithAllocator:]
  -[VCPObjectPool returnObject:]


VCPProtoImageSaliencyResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float confidence
 @property  VCPProtoBounds *bounds

  // class methods
  +[VCPProtoImageSaliencyResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageSaliencyResult setConfidence:]
  -[VCPProtoImageSaliencyResult mergeFrom:]
  -[VCPProtoImageSaliencyResult .cxx_destruct]
  -[VCPProtoImageSaliencyResult confidence]
  -[VCPProtoImageSaliencyResult dictionaryRepresentation]
  -[VCPProtoImageSaliencyResult writeTo:]
  -[VCPProtoImageSaliencyResult isEqual:]
  -[VCPProtoImageSaliencyResult copyTo:]
  -[VCPProtoImageSaliencyResult readFrom:]
  -[VCPProtoImageSaliencyResult copyWithZone:]
  -[VCPProtoImageSaliencyResult setBounds:]
  -[VCPProtoImageSaliencyResult bounds]
  -[VCPProtoImageSaliencyResult exportToLegacyDictionary]


VCPProtoImageShotTypeResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int shotType

  // class methods
  +[VCPProtoImageShotTypeResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoImageShotTypeResult mergeFrom:]
  -[VCPProtoImageShotTypeResult dictionaryRepresentation]
  -[VCPProtoImageShotTypeResult writeTo:]
  -[VCPProtoImageShotTypeResult isEqual:]
  -[VCPProtoImageShotTypeResult copyTo:]
  -[VCPProtoImageShotTypeResult readFrom:]
  -[VCPProtoImageShotTypeResult copyWithZone:]
  -[VCPProtoImageShotTypeResult exportToLegacyDictionary]
  -[VCPProtoImageShotTypeResult shotType]
  -[VCPProtoImageShotTypeResult setShotType:]


VCPProtoLine : PBCodable <NSCopying>
 @property  VCPProtoPoint *start
 @property  VCPProtoPoint *end

  // class methods
  +[VCPProtoLine lineFromPoint:toPoint:]

  // instance methods
  -[VCPProtoLine setEnd:]
  -[VCPProtoLine mergeFrom:]
  -[VCPProtoLine .cxx_destruct]
  -[VCPProtoLine dictionaryRepresentation]
  -[VCPProtoLine setStart:]
  -[VCPProtoLine end]
  -[VCPProtoLine writeTo:]
  -[VCPProtoLine isEqual:]
  -[VCPProtoLine copyTo:]
  -[VCPProtoLine readFrom:]
  -[VCPProtoLine start]
  -[VCPProtoLine copyWithZone:]
  -[VCPProtoLine startPointValue]
  -[VCPProtoLine endPointValue]


VCPProtoMovieCheeringResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieCheeringResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieCheeringResult setTimeRange:]
  -[VCPProtoMovieCheeringResult timeRange]
  -[VCPProtoMovieCheeringResult setConfidence:]
  -[VCPProtoMovieCheeringResult mergeFrom:]
  -[VCPProtoMovieCheeringResult .cxx_destruct]
  -[VCPProtoMovieCheeringResult confidence]
  -[VCPProtoMovieCheeringResult dictionaryRepresentation]
  -[VCPProtoMovieCheeringResult writeTo:]
  -[VCPProtoMovieCheeringResult isEqual:]
  -[VCPProtoMovieCheeringResult copyTo:]
  -[VCPProtoMovieCheeringResult readFrom:]
  -[VCPProtoMovieCheeringResult copyWithZone:]
  -[VCPProtoMovieCheeringResult exportToLegacyDictionary]


VCPProtoLivePhotoEffectsRecipe : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int stabilizeResult
 @property  long long outputFrameDurValue
 @property  int cropRectX
 @property  int cropRectY
 @property  int cropRectHeight
 @property  int cropRectWidth
 @property  int timeScale
 @property  BOOL hasEpoch
 @property  long long epoch
 @property  BOOL hasFlags
 @property  int flags
 @property  NSMutableArray *frameInstructions
 @property  VCPProtoLivePhotoVariationParams *autoloop
 @property  VCPProtoLivePhotoVariationParams *bounce
 @property  VCPProtoLivePhotoVariationParams *longexposure
 @property  VCPProtoLivePhotoVariationParams *stabilize
 @property  int minVersion
 @property  int version

  // class methods
  +[VCPProtoLivePhotoEffectsRecipe resultFromLegacyDictionary:]
  +[VCPProtoLivePhotoEffectsRecipe frameInstructionsType]

  // instance methods
  -[VCPProtoLivePhotoEffectsRecipe epoch]
  -[VCPProtoLivePhotoEffectsRecipe bounce]
  -[VCPProtoLivePhotoEffectsRecipe setFlags:]
  -[VCPProtoLivePhotoEffectsRecipe mergeFrom:]
  -[VCPProtoLivePhotoEffectsRecipe timeScale]
  -[VCPProtoLivePhotoEffectsRecipe .cxx_destruct]
  -[VCPProtoLivePhotoEffectsRecipe dictionaryRepresentation]
  -[VCPProtoLivePhotoEffectsRecipe writeTo:]
  -[VCPProtoLivePhotoEffectsRecipe hasFlags]
  -[VCPProtoLivePhotoEffectsRecipe setEpoch:]
  -[VCPProtoLivePhotoEffectsRecipe setHasFlags:]
  -[VCPProtoLivePhotoEffectsRecipe setVersion:]
  -[VCPProtoLivePhotoEffectsRecipe isEqual:]
  -[VCPProtoLivePhotoEffectsRecipe copyTo:]
  -[VCPProtoLivePhotoEffectsRecipe setHasEpoch:]
  -[VCPProtoLivePhotoEffectsRecipe readFrom:]
  -[VCPProtoLivePhotoEffectsRecipe hasEpoch]
  -[VCPProtoLivePhotoEffectsRecipe setTimeScale:]
  -[VCPProtoLivePhotoEffectsRecipe minVersion]
  -[VCPProtoLivePhotoEffectsRecipe flags]
  -[VCPProtoLivePhotoEffectsRecipe version]
  -[VCPProtoLivePhotoEffectsRecipe copyWithZone:]
  -[VCPProtoLivePhotoEffectsRecipe setMinVersion:]
  -[VCPProtoLivePhotoEffectsRecipe autoloop]
  -[VCPProtoLivePhotoEffectsRecipe setAutoloop:]
  -[VCPProtoLivePhotoEffectsRecipe cropRectX]
  -[VCPProtoLivePhotoEffectsRecipe cropRectY]
  -[VCPProtoLivePhotoEffectsRecipe cropRectWidth]
  -[VCPProtoLivePhotoEffectsRecipe cropRectHeight]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionary]
  -[VCPProtoLivePhotoEffectsRecipe addFrameInstructions:]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructionsCount]
  -[VCPProtoLivePhotoEffectsRecipe clearFrameInstructions]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructionsAtIndex:]
  -[VCPProtoLivePhotoEffectsRecipe setBounce:]
  -[VCPProtoLivePhotoEffectsRecipe setLongexposure:]
  -[VCPProtoLivePhotoEffectsRecipe setStabilize:]
  -[VCPProtoLivePhotoEffectsRecipe stabilizeResult]
  -[VCPProtoLivePhotoEffectsRecipe setStabilizeResult:]
  -[VCPProtoLivePhotoEffectsRecipe outputFrameDurValue]
  -[VCPProtoLivePhotoEffectsRecipe setOutputFrameDurValue:]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectX:]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectY:]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectHeight:]
  -[VCPProtoLivePhotoEffectsRecipe setCropRectWidth:]
  -[VCPProtoLivePhotoEffectsRecipe frameInstructions]
  -[VCPProtoLivePhotoEffectsRecipe setFrameInstructions:]
  -[VCPProtoLivePhotoEffectsRecipe longexposure]
  -[VCPProtoLivePhotoEffectsRecipe stabilize]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionaryFromFrameInstruction:]
  -[VCPProtoLivePhotoEffectsRecipe exportToLegacyDictionaryFromParam:withLoopFlavor:]


VCPProtoLivePhotoEffectsResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  unsigned long loopSuggestionState
 @property  unsigned long longExposureSuggestionState
 @property  BOOL hasRecipeBlob
 @property  NSData *recipeBlob

  // class methods
  +[VCPProtoLivePhotoEffectsResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoEffectsResult mergeFrom:]
  -[VCPProtoLivePhotoEffectsResult .cxx_destruct]
  -[VCPProtoLivePhotoEffectsResult dictionaryRepresentation]
  -[VCPProtoLivePhotoEffectsResult writeTo:]
  -[VCPProtoLivePhotoEffectsResult isEqual:]
  -[VCPProtoLivePhotoEffectsResult copyTo:]
  -[VCPProtoLivePhotoEffectsResult readFrom:]
  -[VCPProtoLivePhotoEffectsResult copyWithZone:]
  -[VCPProtoLivePhotoEffectsResult exportToLegacyDictionary]
  -[VCPProtoLivePhotoEffectsResult setRecipeBlob:]
  -[VCPProtoLivePhotoEffectsResult hasRecipeBlob]
  -[VCPProtoLivePhotoEffectsResult loopSuggestionState]
  -[VCPProtoLivePhotoEffectsResult setLoopSuggestionState:]
  -[VCPProtoLivePhotoEffectsResult longExposureSuggestionState]
  -[VCPProtoLivePhotoEffectsResult setLongExposureSuggestionState:]
  -[VCPProtoLivePhotoEffectsResult recipeBlob]


VCPHumanPoseImageRequest : VCPRequest
  // class methods
  +[VCPHumanPoseImageRequest parseResults:observations:]

  // instance methods
  -[VCPHumanPoseImageRequest .cxx_destruct]
  -[VCPHumanPoseImageRequest initWithOptions:]
  -[VCPHumanPoseImageRequest init]
  -[VCPHumanPoseImageRequest updateWithOptions:error:]
  -[VCPHumanPoseImageRequest preferredInputSizeWithOptions:error:]
  -[VCPHumanPoseImageRequest preferredPixelFormat]
  -[VCPHumanPoseImageRequest processImage:withOptions:error:]
  -[VCPHumanPoseImageRequest cleanupWithOptions:error:]


VCPProtoLivePhotoFrameInstruction : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  long long timeValue
 @property  unsigned long homographyParamsCount
 @property  ^f homographyParams
 @property  int timeScale
 @property  long long epoch
 @property  int flags

  // class methods
  +[VCPProtoLivePhotoFrameInstruction resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoFrameInstruction epoch]
  -[VCPProtoLivePhotoFrameInstruction setFlags:]
  -[VCPProtoLivePhotoFrameInstruction mergeFrom:]
  -[VCPProtoLivePhotoFrameInstruction timeScale]
  -[VCPProtoLivePhotoFrameInstruction dictionaryRepresentation]
  -[VCPProtoLivePhotoFrameInstruction writeTo:]
  -[VCPProtoLivePhotoFrameInstruction setEpoch:]
  -[VCPProtoLivePhotoFrameInstruction isEqual:]
  -[VCPProtoLivePhotoFrameInstruction copyTo:]
  -[VCPProtoLivePhotoFrameInstruction readFrom:]
  -[VCPProtoLivePhotoFrameInstruction setTimeScale:]
  -[VCPProtoLivePhotoFrameInstruction flags]
  -[VCPProtoLivePhotoFrameInstruction timeValue]
  -[VCPProtoLivePhotoFrameInstruction dealloc]
  -[VCPProtoLivePhotoFrameInstruction setTimeValue:]
  -[VCPProtoLivePhotoFrameInstruction copyWithZone:]
  -[VCPProtoLivePhotoFrameInstruction exportToLegacyDictionary]
  -[VCPProtoLivePhotoFrameInstruction homographyParamsCount]
  -[VCPProtoLivePhotoFrameInstruction clearHomographyParams]
  -[VCPProtoLivePhotoFrameInstruction homographyParamAtIndex:]
  -[VCPProtoLivePhotoFrameInstruction addHomographyParam:]
  -[VCPProtoLivePhotoFrameInstruction homographyParams]
  -[VCPProtoLivePhotoFrameInstruction setHomographyParams:count:]


VCPProtoLivePhotoRecommendationResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore

  // class methods
  +[VCPProtoLivePhotoRecommendationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoRecommendationResult setTimeRange:]
  -[VCPProtoLivePhotoRecommendationResult timeRange]
  -[VCPProtoLivePhotoRecommendationResult mergeFrom:]
  -[VCPProtoLivePhotoRecommendationResult .cxx_destruct]
  -[VCPProtoLivePhotoRecommendationResult dictionaryRepresentation]
  -[VCPProtoLivePhotoRecommendationResult writeTo:]
  -[VCPProtoLivePhotoRecommendationResult isEqual:]
  -[VCPProtoLivePhotoRecommendationResult copyTo:]
  -[VCPProtoLivePhotoRecommendationResult readFrom:]
  -[VCPProtoLivePhotoRecommendationResult copyWithZone:]
  -[VCPProtoLivePhotoRecommendationResult qualityScore]
  -[VCPProtoLivePhotoRecommendationResult setQualityScore:]
  -[VCPProtoLivePhotoRecommendationResult exportToLegacyDictionary]


VCPProtoLivePhotoSharpnessResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float sharpness

  // class methods
  +[VCPProtoLivePhotoSharpnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoSharpnessResult mergeFrom:]
  -[VCPProtoLivePhotoSharpnessResult dictionaryRepresentation]
  -[VCPProtoLivePhotoSharpnessResult writeTo:]
  -[VCPProtoLivePhotoSharpnessResult isEqual:]
  -[VCPProtoLivePhotoSharpnessResult sharpness]
  -[VCPProtoLivePhotoSharpnessResult copyTo:]
  -[VCPProtoLivePhotoSharpnessResult readFrom:]
  -[VCPProtoLivePhotoSharpnessResult copyWithZone:]
  -[VCPProtoLivePhotoSharpnessResult setSharpness:]
  -[VCPProtoLivePhotoSharpnessResult exportToLegacyDictionary]


VCPImageHandsAnalyzer : VCPImageAnalyzer
  // instance methods
  -[VCPImageHandsAnalyzer .cxx_destruct]
  -[VCPImageHandsAnalyzer init]
  -[VCPImageHandsAnalyzer configForAspectRatio:]
  -[VCPImageHandsAnalyzer updateModelForAspectRatio:]
  -[VCPImageHandsAnalyzer preferredInputFormat:height:format:]
  -[VCPImageHandsAnalyzer analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageHandsAnalyzer initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:revision:]
  -[VCPImageHandsAnalyzer getClosestAspectRatio:]
  -[VCPImageHandsAnalyzer convertSingleResultToDict:keypointConfidence:box:results:]


VCPHomeResidentMaintenanceTask : NSObject <VCPMADTaskProtocol>
 @property  @? cancelBlock

  // class methods
  +[VCPHomeResidentMaintenanceTask taskWithOptions:andCompletionHandler:]

  // instance methods
  -[VCPHomeResidentMaintenanceTask isCanceled]
  -[VCPHomeResidentMaintenanceTask resourceRequirement]
  -[VCPHomeResidentMaintenanceTask .cxx_destruct]
  -[VCPHomeResidentMaintenanceTask cancelBlock]
  -[VCPHomeResidentMaintenanceTask setCancelBlock:]
  -[VCPHomeResidentMaintenanceTask cancel]
  -[VCPHomeResidentMaintenanceTask autoCancellable]
  -[VCPHomeResidentMaintenanceTask dealloc]
  -[VCPHomeResidentMaintenanceTask run]
  -[VCPHomeResidentMaintenanceTask initWithOptions:andCompletionHandler:]


VCPProtoLivePhotoVariationParams : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  int errorCode
 @property  BOOL hasLoopFadeLen
 @property  int loopFadeLen
 @property  BOOL hasLoopPeriod
 @property  int loopPeriod
 @property  BOOL hasLoopStart
 @property  int loopStart

  // class methods
  +[VCPProtoLivePhotoVariationParams resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoLivePhotoVariationParams errorCode]
  -[VCPProtoLivePhotoVariationParams mergeFrom:]
  -[VCPProtoLivePhotoVariationParams dictionaryRepresentation]
  -[VCPProtoLivePhotoVariationParams writeTo:]
  -[VCPProtoLivePhotoVariationParams isEqual:]
  -[VCPProtoLivePhotoVariationParams setErrorCode:]
  -[VCPProtoLivePhotoVariationParams copyTo:]
  -[VCPProtoLivePhotoVariationParams readFrom:]
  -[VCPProtoLivePhotoVariationParams copyWithZone:]
  -[VCPProtoLivePhotoVariationParams loopPeriod]
  -[VCPProtoLivePhotoVariationParams loopStart]
  -[VCPProtoLivePhotoVariationParams exportToLegacyDictionary]
  -[VCPProtoLivePhotoVariationParams setLoopFadeLen:]
  -[VCPProtoLivePhotoVariationParams setHasLoopFadeLen:]
  -[VCPProtoLivePhotoVariationParams hasLoopFadeLen]
  -[VCPProtoLivePhotoVariationParams setLoopPeriod:]
  -[VCPProtoLivePhotoVariationParams setHasLoopPeriod:]
  -[VCPProtoLivePhotoVariationParams hasLoopPeriod]
  -[VCPProtoLivePhotoVariationParams setLoopStart:]
  -[VCPProtoLivePhotoVariationParams setHasLoopStart:]
  -[VCPProtoLivePhotoVariationParams hasLoopStart]
  -[VCPProtoLivePhotoVariationParams loopFadeLen]


VCPProtoMovieActivityLevelResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float activityScore

  // class methods
  +[VCPProtoMovieActivityLevelResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieActivityLevelResult setTimeRange:]
  -[VCPProtoMovieActivityLevelResult timeRange]
  -[VCPProtoMovieActivityLevelResult mergeFrom:]
  -[VCPProtoMovieActivityLevelResult .cxx_destruct]
  -[VCPProtoMovieActivityLevelResult activityScore]
  -[VCPProtoMovieActivityLevelResult dictionaryRepresentation]
  -[VCPProtoMovieActivityLevelResult writeTo:]
  -[VCPProtoMovieActivityLevelResult setActivityScore:]
  -[VCPProtoMovieActivityLevelResult isEqual:]
  -[VCPProtoMovieActivityLevelResult copyTo:]
  -[VCPProtoMovieActivityLevelResult readFrom:]
  -[VCPProtoMovieActivityLevelResult copyWithZone:]
  -[VCPProtoMovieActivityLevelResult exportToLegacyDictionary]


VCPProtoMovieCameraMotionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int motionType
 @property  BOOL isFast

  // class methods
  +[VCPProtoMovieCameraMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieCameraMotionResult motionType]
  -[VCPProtoMovieCameraMotionResult setTimeRange:]
  -[VCPProtoMovieCameraMotionResult timeRange]
  -[VCPProtoMovieCameraMotionResult mergeFrom:]
  -[VCPProtoMovieCameraMotionResult setMotionType:]
  -[VCPProtoMovieCameraMotionResult .cxx_destruct]
  -[VCPProtoMovieCameraMotionResult dictionaryRepresentation]
  -[VCPProtoMovieCameraMotionResult writeTo:]
  -[VCPProtoMovieCameraMotionResult isEqual:]
  -[VCPProtoMovieCameraMotionResult copyTo:]
  -[VCPProtoMovieCameraMotionResult readFrom:]
  -[VCPProtoMovieCameraMotionResult copyWithZone:]
  -[VCPProtoMovieCameraMotionResult exportToLegacyDictionary]
  -[VCPProtoMovieCameraMotionResult isFast]
  -[VCPProtoMovieCameraMotionResult setIsFast:]


VCPHomeKitAnalysisSession : NSObject <VCPHomeKitAnalysisSessionClientProtocol>
  // class methods
  +[VCPHomeKitAnalysisSession sessionWithProperties:withResultsHandler:andInterruptionHandler:]
  +[VCPHomeKitAnalysisSession sessionWithProperties:andResultsHandler:]

  // instance methods
  -[VCPHomeKitAnalysisSession .cxx_construct]
  -[VCPHomeKitAnalysisSession .cxx_destruct]
  -[VCPHomeKitAnalysisSession connection]
  -[VCPHomeKitAnalysisSession invalidate]
  -[VCPHomeKitAnalysisSession processMessageWithOptions:andCompletionHandler:]
  -[VCPHomeKitAnalysisSession initWithProperties:withResultsHandler:andInterruptionHandler:]
  -[VCPHomeKitAnalysisSession processResults:withReply:]
  -[VCPHomeKitAnalysisSession processVideoFragmentAssetData:withOptions:andErrorHandler:]
  -[VCPHomeKitAnalysisSession processVideoFragmentAssetData:withOptions:andCompletionHandler:]


VCPHomeKitSessionExportedObject : NSObject <VCPHomeKitAnalysisSessionClientProtocol>
 @property  VCPHomeKitAnalysisSession *weakSession

  // instance methods
  -[VCPHomeKitSessionExportedObject .cxx_destruct]
  -[VCPHomeKitSessionExportedObject setWeakSession:]
  -[VCPHomeKitSessionExportedObject processResults:withReply:]
  -[VCPHomeKitSessionExportedObject weakSession]


VCPHomeKitMotionAnalyzer : VCPVideoAnalyzer
 @property  float actionScore

  // instance methods
  -[VCPHomeKitMotionAnalyzer .cxx_construct]
  -[VCPHomeKitMotionAnalyzer .cxx_destruct]
  -[VCPHomeKitMotionAnalyzer init]
  -[VCPHomeKitMotionAnalyzer actionScore]
  -[VCPHomeKitMotionAnalyzer dealloc]
  -[VCPHomeKitMotionAnalyzer setPixelBuffer:]
  -[VCPHomeKitMotionAnalyzer regionsOfInterest]
  -[VCPHomeKitMotionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPHomeKitMotionAnalyzer calculateFrameDifference:]
  -[VCPHomeKitMotionAnalyzer computeRegionsofInterest]


VCPProtoMovieClassificationResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *classifications

  // class methods
  +[VCPProtoMovieClassificationResult classificationType]
  +[VCPProtoMovieClassificationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieClassificationResult setTimeRange:]
  -[VCPProtoMovieClassificationResult timeRange]
  -[VCPProtoMovieClassificationResult mergeFrom:]
  -[VCPProtoMovieClassificationResult .cxx_destruct]
  -[VCPProtoMovieClassificationResult dictionaryRepresentation]
  -[VCPProtoMovieClassificationResult writeTo:]
  -[VCPProtoMovieClassificationResult isEqual:]
  -[VCPProtoMovieClassificationResult copyTo:]
  -[VCPProtoMovieClassificationResult addClassification:]
  -[VCPProtoMovieClassificationResult readFrom:]
  -[VCPProtoMovieClassificationResult copyWithZone:]
  -[VCPProtoMovieClassificationResult classifications]
  -[VCPProtoMovieClassificationResult setClassifications:]
  -[VCPProtoMovieClassificationResult exportToLegacyDictionary]
  -[VCPProtoMovieClassificationResult classificationsCount]
  -[VCPProtoMovieClassificationResult clearClassifications]
  -[VCPProtoMovieClassificationResult classificationAtIndex:]


VCPHandPoseImageRequest : VCPRequest
  // instance methods
  -[VCPHandPoseImageRequest .cxx_destruct]
  -[VCPHandPoseImageRequest initWithOptions:]
  -[VCPHandPoseImageRequest init]
  -[VCPHandPoseImageRequest updateWithOptions:error:]
  -[VCPHandPoseImageRequest preferredInputSizeWithOptions:error:]
  -[VCPHandPoseImageRequest preferredPixelFormat]
  -[VCPHandPoseImageRequest processImage:withOptions:error:]
  -[VCPHandPoseImageRequest parseResults:observations:]
  -[VCPHandPoseImageRequest cleanupWithOptions:error:]


VCPProtoMovieHighlightScoreResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float highlightScore

  // class methods
  +[VCPProtoMovieHighlightScoreResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHighlightScoreResult setTimeRange:]
  -[VCPProtoMovieHighlightScoreResult timeRange]
  -[VCPProtoMovieHighlightScoreResult mergeFrom:]
  -[VCPProtoMovieHighlightScoreResult .cxx_destruct]
  -[VCPProtoMovieHighlightScoreResult dictionaryRepresentation]
  -[VCPProtoMovieHighlightScoreResult writeTo:]
  -[VCPProtoMovieHighlightScoreResult isEqual:]
  -[VCPProtoMovieHighlightScoreResult copyTo:]
  -[VCPProtoMovieHighlightScoreResult readFrom:]
  -[VCPProtoMovieHighlightScoreResult copyWithZone:]
  -[VCPProtoMovieHighlightScoreResult exportToLegacyDictionary]
  -[VCPProtoMovieHighlightScoreResult highlightScore]
  -[VCPProtoMovieHighlightScoreResult setHighlightScore:]


VCPProtoMovieFaceprintResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  unsigned int faceID
 @property  NSData *faceprintBlob

  // class methods
  +[VCPProtoMovieFaceprintResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFaceprintResult mergeFrom:]
  -[VCPProtoMovieFaceprintResult .cxx_destruct]
  -[VCPProtoMovieFaceprintResult dictionaryRepresentation]
  -[VCPProtoMovieFaceprintResult faceID]
  -[VCPProtoMovieFaceprintResult writeTo:]
  -[VCPProtoMovieFaceprintResult isEqual:]
  -[VCPProtoMovieFaceprintResult copyTo:]
  -[VCPProtoMovieFaceprintResult readFrom:]
  -[VCPProtoMovieFaceprintResult copyWithZone:]
  -[VCPProtoMovieFaceprintResult setFaceID:]
  -[VCPProtoMovieFaceprintResult exportToLegacyDictionary]
  -[VCPProtoMovieFaceprintResult setFaceprintBlob:]
  -[VCPProtoMovieFaceprintResult faceprintBlob]


VCPRequest : NSObject
 @property  BOOL useCPUOnly
 @property  unsigned int revision

  // instance methods
  -[VCPRequest initWithOptions:]
  -[VCPRequest init]
  -[VCPRequest revision]
  -[VCPRequest updateWithOptions:error:]
  -[VCPRequest preferredInputSizeWithOptions:error:]
  -[VCPRequest preferredPixelFormat]
  -[VCPRequest cleanupWithOptions:error:]
  -[VCPRequest useCPUOnly]


VCPProtoMovieFaceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int mouthExpression
 @property  int position
 @property  VCPProtoBounds *bounds
 @property  BOOL isCloseup
 @property  int faceID

  // class methods
  +[VCPProtoMovieFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFaceResult setTimeRange:]
  -[VCPProtoMovieFaceResult timeRange]
  -[VCPProtoMovieFaceResult mergeFrom:]
  -[VCPProtoMovieFaceResult .cxx_destruct]
  -[VCPProtoMovieFaceResult dictionaryRepresentation]
  -[VCPProtoMovieFaceResult faceID]
  -[VCPProtoMovieFaceResult writeTo:]
  -[VCPProtoMovieFaceResult isEqual:]
  -[VCPProtoMovieFaceResult copyTo:]
  -[VCPProtoMovieFaceResult readFrom:]
  -[VCPProtoMovieFaceResult copyWithZone:]
  -[VCPProtoMovieFaceResult setBounds:]
  -[VCPProtoMovieFaceResult setPosition:]
  -[VCPProtoMovieFaceResult bounds]
  -[VCPProtoMovieFaceResult position]
  -[VCPProtoMovieFaceResult setFaceID:]
  -[VCPProtoMovieFaceResult exportToLegacyDictionary]
  -[VCPProtoMovieFaceResult mouthExpression]
  -[VCPProtoMovieFaceResult setMouthExpression:]
  -[VCPProtoMovieFaceResult isCloseup]
  -[VCPProtoMovieFaceResult setIsCloseup:]


VCPProtoMovieFeatureResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTime *timestamp
 @property  NSData *featureBlob

  // class methods
  +[VCPProtoMovieFeatureResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFeatureResult mergeFrom:]
  -[VCPProtoMovieFeatureResult .cxx_destruct]
  -[VCPProtoMovieFeatureResult dictionaryRepresentation]
  -[VCPProtoMovieFeatureResult writeTo:]
  -[VCPProtoMovieFeatureResult isEqual:]
  -[VCPProtoMovieFeatureResult copyTo:]
  -[VCPProtoMovieFeatureResult readFrom:]
  -[VCPProtoMovieFeatureResult timestamp]
  -[VCPProtoMovieFeatureResult copyWithZone:]
  -[VCPProtoMovieFeatureResult setTimestamp:]
  -[VCPProtoMovieFeatureResult exportToLegacyDictionary]
  -[VCPProtoMovieFeatureResult setFeatureBlob:]
  -[VCPProtoMovieFeatureResult featureBlob]


VCPProtoMovieFineSubjectMotionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float actionScore

  // class methods
  +[VCPProtoMovieFineSubjectMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieFineSubjectMotionResult setTimeRange:]
  -[VCPProtoMovieFineSubjectMotionResult timeRange]
  -[VCPProtoMovieFineSubjectMotionResult mergeFrom:]
  -[VCPProtoMovieFineSubjectMotionResult .cxx_destruct]
  -[VCPProtoMovieFineSubjectMotionResult dictionaryRepresentation]
  -[VCPProtoMovieFineSubjectMotionResult writeTo:]
  -[VCPProtoMovieFineSubjectMotionResult isEqual:]
  -[VCPProtoMovieFineSubjectMotionResult copyTo:]
  -[VCPProtoMovieFineSubjectMotionResult readFrom:]
  -[VCPProtoMovieFineSubjectMotionResult setActionScore:]
  -[VCPProtoMovieFineSubjectMotionResult actionScore]
  -[VCPProtoMovieFineSubjectMotionResult copyWithZone:]
  -[VCPProtoMovieFineSubjectMotionResult exportToLegacyDictionary]


VCPProtoMovieHighlightResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float curationScore
 @property  VCPProtoVideoKeyFrame *keyFrame
 @property  VCPProtoBounds *playbackCrop
 @property  BOOL hasColorNormalizationBlob
 @property  NSData *colorNormalizationBlob

  // class methods
  +[VCPProtoMovieHighlightResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieHighlightResult setTimeRange:]
  -[VCPProtoMovieHighlightResult timeRange]
  -[VCPProtoMovieHighlightResult mergeFrom:]
  -[VCPProtoMovieHighlightResult .cxx_destruct]
  -[VCPProtoMovieHighlightResult dictionaryRepresentation]
  -[VCPProtoMovieHighlightResult writeTo:]
  -[VCPProtoMovieHighlightResult curationScore]
  -[VCPProtoMovieHighlightResult isEqual:]
  -[VCPProtoMovieHighlightResult copyTo:]
  -[VCPProtoMovieHighlightResult readFrom:]
  -[VCPProtoMovieHighlightResult setCurationScore:]
  -[VCPProtoMovieHighlightResult copyWithZone:]
  -[VCPProtoMovieHighlightResult exportToLegacyDictionary]
  -[VCPProtoMovieHighlightResult keyFrame]
  -[VCPProtoMovieHighlightResult setKeyFrame:]
  -[VCPProtoMovieHighlightResult setColorNormalizationBlob:]
  -[VCPProtoMovieHighlightResult hasColorNormalizationBlob]
  -[VCPProtoMovieHighlightResult colorNormalizationBlob]
  -[VCPProtoMovieHighlightResult setPlaybackCrop:]
  -[VCPProtoMovieHighlightResult playbackCrop]


VCPSuggestionRequest : NSObject
 @property  unsigned long type
 @property  NSString *requestId
 @property  NSMutableDictionary *clusterFlagByClusterId
 @property  NSArray *csns
 @property  NSArray *cflags
 @property  @? updateHandler
 @property  VNCanceller *canceller

  // class methods
  +[VCPSuggestionRequest requestWithFaceClusterIds:clusterFlags:updateHandler:]

  // instance methods
  -[VCPSuggestionRequest setUpdateHandler:]
  -[VCPSuggestionRequest updateHandler]
  -[VCPSuggestionRequest .cxx_destruct]
  -[VCPSuggestionRequest csns]
  -[VCPSuggestionRequest type]
  -[VCPSuggestionRequest cflags]
  -[VCPSuggestionRequest requestId]
  -[VCPSuggestionRequest initWithFaceClusterIds:clusterFlags:updateHandler:]
  -[VCPSuggestionRequest clusterFlagByClusterId]
  -[VCPSuggestionRequest canceller]


VCPClusterer : NSObject <PVFaceClusteringProtocol>
 @property  BOOL needsFullSync
 @property  BOOL needsUpdate
 @property  BOOL ready
 @property  unsigned long clustererBringUpState
 @property  unsigned long clustererState
 @property  unsigned long hash
 @property  Class superclass
 @property  NSString *description
 @property  NSString *debugDescription

  // class methods
  +[VCPClusterer removeClusteringStateCacheWithURL:error:]

  // instance methods
  -[VCPClusterer needsFullSync]
  -[VCPClusterer isCanceled]
  -[VCPClusterer terminate]
  -[VCPClusterer differencesBetweenClustersInClusterCacheAndLibrary:]
  -[VCPClusterer .cxx_destruct]
  -[VCPClusterer isReady]
  -[VCPClusterer status]
  -[VCPClusterer needsUpdate]
  -[VCPClusterer level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:]
  -[VCPClusterer distancesFromClustersIdentifiedByFaceCSNs:toClustersIdentifiedByFaceCSNs:error:]
  -[VCPClusterer requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:]
  -[VCPClusterer cancelAllSuggestionRequests]
  -[VCPClusterer clustererState]
  -[VCPClusterer clusterCount]
  -[VCPClusterer restoreClusterCacheAndSyncWithLibrary:error:]
  -[VCPClusterer scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:]
  -[VCPClusterer numberOfAccumulatedClusterChanges]
  -[VCPClusterer clusterIfNecessaryAndWait]
  -[VCPClusterer clusterAndWait]
  -[VCPClusterer performClusteringWithCompletion:]
  -[VCPClusterer cancelClustering]
  -[VCPClusterer cancelSuggestionRequest:]
  -[VCPClusterer suggestedFaceClusterSequenceNumbersForFaceClusterSequenceNumbersRepresentingClusters:error:]
  -[VCPClusterer getClusters:threshold:utilizingGPU:error:]
  -[VCPClusterer isReadyToReturnSuggestions]
  -[VCPClusterer _readPropertyDictionary]
  -[VCPClusterer _cancelClusteringAndRestoreClusterCache:]
  -[VCPClusterer _recordIncrementCountOfPendingFacesToAdd:]
  -[VCPClusterer _processingQueueDetermineNextClusterTriggeringAccumulatedChangesCountIfNecessary]
  -[VCPClusterer _recordClusteringState:]
  -[VCPClusterer setClustererBringUpState:]
  -[VCPClusterer _recordCountOfPendingFacesToAdd:]
  -[VCPClusterer _processingQueueSaveClusterCache:]
  -[VCPClusterer _processingQueueGetVisionClusters:minimumClusterSize:returnClusterAsCountedSet:error:]
  -[VCPClusterer _removeEmptyGroups]
  -[VCPClusterer _setPropertyDictionaryValue:forKey:]
  -[VCPClusterer _processingQueueResetClusterCache:]
  -[VCPClusterer _recordCurrentStatus:]
  -[VCPClusterer clustererBringUpState]
  -[VCPClusterer _removeVisionClusterCacheFilesNotReferencedByVisionClusterState:]
  -[VCPClusterer _processingQueueGetFaceClusterSequenceNumbersInClusterCache:lastClusterSequenceNumber:error:]
  -[VCPClusterer _processingQueueRestoreClusteringCacheWithCacheDirectoryURL:clusterState:threshold:error:]
  -[VCPClusterer _visionClusterMemmapFileInCacheDirectoryURL:clusterState:error:]
  -[VCPClusterer _visionClusterStateDataBlobFromClusterSnapshotFileAtURL:error:]
  -[VCPClusterer _processingQueueRestoreFromClusterSnapshotFileAtURL:error:]
  -[VCPClusterer _processingQueueRestoreClusterCacheAndSyncWithLibrary:error:]
  -[VCPClusterer _recordClusterRebuildRequired:]
  -[VCPClusterer _propertyDictionaryFileURL]
  -[VCPClusterer distanceBetweenLevel0ClusterIdentifiedByFaceCSN:andLevel0ClusterIdentifiedByFaceCSN:error:]
  -[VCPClusterer clusteredFaceCount]
  -[VCPClusterer _faceTorsoprintsFromFaceCSNs:]
  -[VCPClusterer _performAndPersistClustersWithFaceTorsoprintsToAdd:groupingIdentifiersToAdd:faceTorsoprintsToRemove:updatedFaces:andError:]
  -[VCPClusterer _faceTorsoprintsFromFaceIdentifiers:assignClusterSeqNumberIfNeeded:updatedFaces:groupingIdentifiers:]
  -[VCPClusterer _processingQueueSyncClustererWithPhotoLibraryUsingFacesInClusterCache:]
  -[VCPClusterer _processingQueuePerformForcedFaceClustering:]
  -[VCPClusterer _faceTorsoprintsFromFaces:assignClusterSeqNumberIfNeeded:updatedFaces:]
  -[VCPClusterer _stringForVCPClustererBringUpState:]
  -[VCPClusterer _processingQueueQuickSyncClustererWithPhotoLibraryUsingFacesInClusterCache:visionClusters:]
  -[VCPClusterer initWithPhotoLibrary:context:extendTimeoutBlock:andCancelBlock:]


VCPProtoMovieInterestingnessResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float interestScore

  // class methods
  +[VCPProtoMovieInterestingnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieInterestingnessResult setTimeRange:]
  -[VCPProtoMovieInterestingnessResult timeRange]
  -[VCPProtoMovieInterestingnessResult mergeFrom:]
  -[VCPProtoMovieInterestingnessResult .cxx_destruct]
  -[VCPProtoMovieInterestingnessResult dictionaryRepresentation]
  -[VCPProtoMovieInterestingnessResult writeTo:]
  -[VCPProtoMovieInterestingnessResult isEqual:]
  -[VCPProtoMovieInterestingnessResult copyTo:]
  -[VCPProtoMovieInterestingnessResult readFrom:]
  -[VCPProtoMovieInterestingnessResult copyWithZone:]
  -[VCPProtoMovieInterestingnessResult exportToLegacyDictionary]
  -[VCPProtoMovieInterestingnessResult interestScore]
  -[VCPProtoMovieInterestingnessResult setInterestScore:]


VCPImageHumanPoseAnalyzerTopDown : VCPImageAnalyzer
  // instance methods
  -[VCPImageHumanPoseAnalyzerTopDown .cxx_destruct]
  -[VCPImageHumanPoseAnalyzerTopDown preferredInputFormat:height:format:]
  -[VCPImageHumanPoseAnalyzerTopDown analyzePixelBuffer:flags:results:cancel:]
  -[VCPImageHumanPoseAnalyzerTopDown initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:]


VCPProtoMovieLoudnessResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  double energy
 @property  double peak

  // class methods
  +[VCPProtoMovieLoudnessResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieLoudnessResult setTimeRange:]
  -[VCPProtoMovieLoudnessResult timeRange]
  -[VCPProtoMovieLoudnessResult mergeFrom:]
  -[VCPProtoMovieLoudnessResult .cxx_destruct]
  -[VCPProtoMovieLoudnessResult peak]
  -[VCPProtoMovieLoudnessResult dictionaryRepresentation]
  -[VCPProtoMovieLoudnessResult writeTo:]
  -[VCPProtoMovieLoudnessResult isEqual:]
  -[VCPProtoMovieLoudnessResult copyTo:]
  -[VCPProtoMovieLoudnessResult readFrom:]
  -[VCPProtoMovieLoudnessResult copyWithZone:]
  -[VCPProtoMovieLoudnessResult energy]
  -[VCPProtoMovieLoudnessResult setEnergy:]
  -[VCPProtoMovieLoudnessResult exportToLegacyDictionary]
  -[VCPProtoMovieLoudnessResult setPeak:]


VCPProtoMovieMovingObjectResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  NSMutableArray *bounds

  // class methods
  +[VCPProtoMovieMovingObjectResult resultFromLegacyDictionary:]
  +[VCPProtoMovieMovingObjectResult boundsType]

  // instance methods
  -[VCPProtoMovieMovingObjectResult setTimeRange:]
  -[VCPProtoMovieMovingObjectResult timeRange]
  -[VCPProtoMovieMovingObjectResult mergeFrom:]
  -[VCPProtoMovieMovingObjectResult .cxx_destruct]
  -[VCPProtoMovieMovingObjectResult dictionaryRepresentation]
  -[VCPProtoMovieMovingObjectResult writeTo:]
  -[VCPProtoMovieMovingObjectResult isEqual:]
  -[VCPProtoMovieMovingObjectResult copyTo:]
  -[VCPProtoMovieMovingObjectResult readFrom:]
  -[VCPProtoMovieMovingObjectResult copyWithZone:]
  -[VCPProtoMovieMovingObjectResult setBounds:]
  -[VCPProtoMovieMovingObjectResult bounds]
  -[VCPProtoMovieMovingObjectResult addBounds:]
  -[VCPProtoMovieMovingObjectResult exportToLegacyDictionary]
  -[VCPProtoMovieMovingObjectResult boundsCount]
  -[VCPProtoMovieMovingObjectResult clearBounds]
  -[VCPProtoMovieMovingObjectResult boundsAtIndex:]


VCPProtoMovieMusicResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieMusicResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieMusicResult setTimeRange:]
  -[VCPProtoMovieMusicResult timeRange]
  -[VCPProtoMovieMusicResult setConfidence:]
  -[VCPProtoMovieMusicResult mergeFrom:]
  -[VCPProtoMovieMusicResult .cxx_destruct]
  -[VCPProtoMovieMusicResult confidence]
  -[VCPProtoMovieMusicResult dictionaryRepresentation]
  -[VCPProtoMovieMusicResult writeTo:]
  -[VCPProtoMovieMusicResult isEqual:]
  -[VCPProtoMovieMusicResult copyTo:]
  -[VCPProtoMovieMusicResult readFrom:]
  -[VCPProtoMovieMusicResult copyWithZone:]
  -[VCPProtoMovieMusicResult exportToLegacyDictionary]


VCPProtoMovieObstructionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float obstructionScore

  // class methods
  +[VCPProtoMovieObstructionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieObstructionResult setTimeRange:]
  -[VCPProtoMovieObstructionResult timeRange]
  -[VCPProtoMovieObstructionResult mergeFrom:]
  -[VCPProtoMovieObstructionResult .cxx_destruct]
  -[VCPProtoMovieObstructionResult dictionaryRepresentation]
  -[VCPProtoMovieObstructionResult writeTo:]
  -[VCPProtoMovieObstructionResult isEqual:]
  -[VCPProtoMovieObstructionResult copyTo:]
  -[VCPProtoMovieObstructionResult readFrom:]
  -[VCPProtoMovieObstructionResult copyWithZone:]
  -[VCPProtoMovieObstructionResult obstructionScore]
  -[VCPProtoMovieObstructionResult setObstructionScore:]
  -[VCPProtoMovieObstructionResult exportToLegacyDictionary]


VCPCNNHandsDetector : NSObject
  // class methods
  +[VCPCNNHandsDetector detector:forceCPU:sharedModel:inputConfig:revision:]

  // instance methods
  -[VCPCNNHandsDetector .cxx_destruct]
  -[VCPCNNHandsDetector dealloc]
  -[VCPCNNHandsDetector copyImage:toData:]
  -[VCPCNNHandsDetector handsDetection:handsRegions:cancel:]
  -[VCPCNNHandsDetector updateModelWithResConfig:]
  -[VCPCNNHandsDetector initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:revision:]
  -[VCPCNNHandsDetector createModelWithResConfig:]
  -[VCPCNNHandsDetector generateHandsRegions:boxes:maxNumRegions:]
  -[VCPCNNHandsDetector retrieveBoxes:outHeight:outWidth:boxes:anchorBox:]
  -[VCPCNNHandsDetector nonMaxSuppression:]
  -[VCPCNNHandsDetector drawLine:width:height:stride:point0:point1:drawPoint:]
  -[VCPCNNHandsDetector createInput:withBuffer:]
  -[VCPCNNHandsDetector generateHandsBoxes:]
  -[VCPCNNHandsDetector drawRectangle:width:height:stride:keypoints:]


VCPFaceProcessingServiceWorker : NSObject
  // class methods
  +[VCPFaceProcessingServiceWorker newAllFacesFetchOptionsWithPhotoLibrary:]
  +[VCPFaceProcessingServiceWorker newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:]
  +[VCPFaceProcessingServiceWorker workerWithPhotoLibrary:andContext:]

  // instance methods
  -[VCPFaceProcessingServiceWorker updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:]
  -[VCPFaceProcessingServiceWorker _deleteAllVerifiedPersonsWithError:]
  -[VCPFaceProcessingServiceWorker _logFaceToSuggestionsLog:]
  -[VCPFaceProcessingServiceWorker .cxx_destruct]
  -[VCPFaceProcessingServiceWorker _closeSuggestionsLoggingSession]
  -[VCPFaceProcessingServiceWorker resetFaceClusteringStateWithContext:reply:]
  -[VCPFaceProcessingServiceWorker faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:]
  -[VCPFaceProcessingServiceWorker requestSuggestedMePersonIdentifierWithContext:reply:]
  -[VCPFaceProcessingServiceWorker _finalizeSuggestionsLog]
  -[VCPFaceProcessingServiceWorker validateClusterCacheWithContext:reply:]
  -[VCPFaceProcessingServiceWorker _openSuggestionsLoggingSession]
  -[VCPFaceProcessingServiceWorker personPromoterStatusWithContext:reply:]
  -[VCPFaceProcessingServiceWorker _appendToSuggestionsLog:]
  -[VCPFaceProcessingServiceWorker _copyImageAtURLToSuggestionsLoggingSession:]
  -[VCPFaceProcessingServiceWorker initWithPhotoLibrary:andContext:]
  -[VCPFaceProcessingServiceWorker _startAndSyncClusterCacheWithLibrary:reply:]
  -[VCPFaceProcessingServiceWorker _suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:]
  -[VCPFaceProcessingServiceWorker _suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:]
  -[VCPFaceProcessingServiceWorker suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:]
  -[VCPFaceProcessingServiceWorker resetPersonsModelWithReply:]
  -[VCPFaceProcessingServiceWorker resetPetsModelWithReply:]
  -[VCPFaceProcessingServiceWorker reclusterFacesWithContext:reply:extendTimeout:cancel:]
  -[VCPFaceProcessingServiceWorker rebuildPersonsWithContext:reply:extendTimeout:cancel:]


VCPMADServiceImageProcessingTask : VCPMABaseTask
 @property  NSString *signpostPayload

  // class methods
  +[VCPMADServiceImageProcessingTask taskWithRequests:forAsset:cancelBlock:andCompletionHandler:]

  // instance methods
  -[VCPMADServiceImageProcessingTask signpostPayload]
  -[VCPMADServiceImageProcessingTask .cxx_destruct]
  -[VCPMADServiceImageProcessingTask initWithRequests:forAsset:cancelBlock:andCompletionHandler:]
  -[VCPMADServiceImageProcessingTask cachesResources]
  -[VCPMADServiceImageProcessingTask run:]
  -[VCPMADServiceImageProcessingTask cancel]
  -[VCPMADServiceImageProcessingTask setSignpostPayload:]


VCPPhotosFaceProcessingContext : NSObject
 @property  float faceClusteringThreshold
 @property  float faceClusteringJunkThreshold
 @property  float faceClusteringAgeThreshold
 @property  float faceMergeFaceprintDistanceThreshold
 @property  float facePrimarySuggestionsThreshold
 @property  unsigned long minimumSuggestionSize
 @property  BOOL quarantineTwinsOnAssetEnabled
 @property  unsigned long minFaceCountToTriggerClustering
 @property  unsigned long maxFaceCountForClustering
 @property  BOOL suggestionsLogEnabled
 @property  BOOL faceClusteringDisabled
 @property  unsigned long minimumFaceGroupSizeForCreatingMergeCandidates
 @property  BOOL personBuildingDisabled
 @property  BOOL personBuilderMergeCandidatesDisabled
 @property  unsigned long advancedStatusMergeCandidateLimit
 @property  unsigned long advancedStatusVerifiedPersonLimit
 @property  BOOL clusterIncludeTorsoOnlyFaces
 @property  int processingVersion

  // class methods
  +[VCPPhotosFaceProcessingContext _includeTorsoOnlyFaces]
  +[VCPPhotosFaceProcessingContext contextWithPhotoLibrary:]

  // instance methods
  -[VCPPhotosFaceProcessingContext initWithPhotoLibrary:]
  -[VCPPhotosFaceProcessingContext minimumSuggestionSize]
  -[VCPPhotosFaceProcessingContext quarantineTwinsOnAssetEnabled]
  -[VCPPhotosFaceProcessingContext personBuildingDisabled]
  -[VCPPhotosFaceProcessingContext setFacePrimarySuggestionsThreshold:]
  -[VCPPhotosFaceProcessingContext minimumFaceGroupSizeForCreatingMergeCandidates]
  -[VCPPhotosFaceProcessingContext faceClusteringJunkThreshold]
  -[VCPPhotosFaceProcessingContext faceClusteringAgeThreshold]
  -[VCPPhotosFaceProcessingContext setMinimumSuggestionSize:]
  -[VCPPhotosFaceProcessingContext setFaceClusteringThreshold:]
  -[VCPPhotosFaceProcessingContext maxFaceCountForClustering]
  -[VCPPhotosFaceProcessingContext personBuilderMergeCandidatesDisabled]
  -[VCPPhotosFaceProcessingContext setPersonBuildingDisabled:]
  -[VCPPhotosFaceProcessingContext faceMergeFaceprintDistanceThreshold]
  -[VCPPhotosFaceProcessingContext setMinimumFaceGroupSizeForCreatingMergeCandidates:]
  -[VCPPhotosFaceProcessingContext setMinFaceCountToTriggerClustering:]
  -[VCPPhotosFaceProcessingContext setMaxFaceCountForClustering:]
  -[VCPPhotosFaceProcessingContext setPersonBuilderMergeCandidatesDisabled:]
  -[VCPPhotosFaceProcessingContext setFaceClusteringJunkThreshold:]
  -[VCPPhotosFaceProcessingContext setFaceClusteringDisabled:]
  -[VCPPhotosFaceProcessingContext advancedStatusVerifiedPersonLimit]
  -[VCPPhotosFaceProcessingContext setFaceMergeFaceprintDistanceThreshold:]
  -[VCPPhotosFaceProcessingContext setFaceClusteringAgeThreshold:]
  -[VCPPhotosFaceProcessingContext facePrimarySuggestionsThreshold]
  -[VCPPhotosFaceProcessingContext faceClusteringDisabled]
  -[VCPPhotosFaceProcessingContext faceClusteringThreshold]
  -[VCPPhotosFaceProcessingContext advancedStatusMergeCandidateLimit]
  -[VCPPhotosFaceProcessingContext suggestionsLogEnabled]
  -[VCPPhotosFaceProcessingContext setQuarantineTwinsOnAssetEnabled:]
  -[VCPPhotosFaceProcessingContext minFaceCountToTriggerClustering]
  -[VCPPhotosFaceProcessingContext processingVersion]
  -[VCPPhotosFaceProcessingContext setSuggestionsLogEnabled:]
  -[VCPPhotosFaceProcessingContext setAdvancedStatusMergeCandidateLimit:]
  -[VCPPhotosFaceProcessingContext setAdvancedStatusVerifiedPersonLimit:]
  -[VCPPhotosFaceProcessingContext clusterIncludeTorsoOnlyFaces]
  -[VCPPhotosFaceProcessingContext setClusterIncludeTorsoOnlyFaces:]
  -[VCPPhotosFaceProcessingContext setProcessingVersion:]


VCPFaceUtils : NSObject
  // class methods
  +[VCPFaceUtils configureVNRequest:withClass:andProcessingVersion:]
  +[VCPFaceUtils mad_PHValueFromVNAgeCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNSexCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNEyesCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNSmilingCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNFaceHairCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNHairColorCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNGlassesCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNExpressionCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNHeadgearCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNFaceHairCategoryV2Label:]
  +[VCPFaceUtils mad_PHValueFromVNPoseCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNSkintoneCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNEthnicityCategoryLabel:]
  +[VCPFaceUtils mad_PHValueFromVNFaceGazeDirection:]
  +[VCPFaceUtils mad_VNFaceGazeDirectionDescription:]
  +[VCPFaceUtils mad_PHFaceGazeTypeDescription:]
  +[VCPFaceUtils vcpPhotosFaceFromPHFace:copyPropertiesOption:]
  +[VCPFaceUtils resourceForFaceProcessingWithAsset:allowStreaming:]
  +[VCPFaceUtils imageCreationOptions]
  +[VCPFaceUtils phFacesFromVCPPhotosFaces:withFetchOptions:]
  +[VCPFaceUtils phFaceFromVCPPhotosFace:withFetchOptions:]
  +[VCPFaceUtils assignPropertiesOfVCPPhotosFace:toPHFaceChangeRequest:]
  +[VCPFaceUtils _vnFaceAttributeAgeToPHFaceAgeTypeMap]
  +[VCPFaceUtils _vnFaceAttributeSexToPHFaceSexTypeMap]
  +[VCPFaceUtils _vnFaceAttributeEyesToPHEyesStateMap]
  +[VCPFaceUtils _vnFaceAttributeSmileToPHFaceSmileTypeMap]
  +[VCPFaceUtils _vnFaceAttributeFacialHairToPHFacialHairTypeMap]
  +[VCPFaceUtils _vnFaceAttributeHairColorToPHFaceHairColorTypeMap]
  +[VCPFaceUtils _vnFaceAttributeGlassesToPHFaceGlassesTypeMap]
  +[VCPFaceUtils _vnFaceAttributeFacialHairToPHFaceExpressionType]
  +[VCPFaceUtils _vnFaceAttributeHeadGearToPHFaceHeadGearType]
  +[VCPFaceUtils _vnFaceAttributeHairTypeToPHFaceHairType]
  +[VCPFaceUtils _vnFaceAttributePoseToPHFacePoseType]
  +[VCPFaceUtils _vnFaceAttributeSkintoneToPHFaceSkintoneType]
  +[VCPFaceUtils _vnFaceAttributeEthnicityToPHFaceEthnicityType]
  +[VCPFaceUtils _vnFaceGazeDirectionToPHFaceGazeType]
  +[VCPFaceUtils _firstLocallyAvailableResourceFromResources:]
  +[VCPFaceUtils preferredResourcesForFaceProcessingWithAsset:]
  +[VCPFaceUtils resourceForFaceProcessing:allowStreaming:]

  // instance methods
  -[VCPFaceUtils _vcpFacesArrayFromPHFetchResult:copyPropertiesOption:]


VCPPersonBuilder : NSObject
  // instance methods
  -[VCPPersonBuilder .cxx_destruct]
  -[VCPPersonBuilder setPersonBuilderMergeCandidatesEnabled:]
  -[VCPPersonBuilder _setAllFaceGroupsNeedPersonBuilding]
  -[VCPPersonBuilder setLastMinimumFaceGroupSizeForCreatingMergeCandidate:]
  -[VCPPersonBuilder _readFaceAnalysisState]
  -[VCPPersonBuilder _setFaceAnalysisStateValue:forKey:]
  -[VCPPersonBuilder initWithPhotoLibrary:andFaceClusterer:andContext:]
  -[VCPPersonBuilder performPersonBuildingWithCancelOrExtendTimeoutBlock:error:]


VCPVideoHumanActionAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoHumanActionAnalyzer results]
  -[VCPVideoHumanActionAnalyzer .cxx_destruct]
  -[VCPVideoHumanActionAnalyzer normDistance:point2:]
  -[VCPVideoHumanActionAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoHumanActionAnalyzer finishAnalysisPass:]
  -[VCPVideoHumanActionAnalyzer privateResults]
  -[VCPVideoHumanActionAnalyzer initWithFrameStats:timeOfInterest:phFaces:]
  -[VCPVideoHumanActionAnalyzer computeVar:index2:interVar:intraVar:]
  -[VCPVideoHumanActionAnalyzer scaleRect:scaleX:scaleY:]
  -[VCPVideoHumanActionAnalyzer computeActionScore]
  -[VCPVideoHumanActionAnalyzer associatePerson:withPHFaces:]
  -[VCPVideoHumanActionAnalyzer intersectionOverUnion:rect:]
  -[VCPVideoHumanActionAnalyzer addActiveResults:]
  -[VCPVideoHumanActionAnalyzer processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:]


VCPPhotosSceneprintAssetProcessingTask : NSObject <VCPMADTaskProtocol>
  // class methods
  +[VCPPhotosSceneprintAssetProcessingTask taskWithAssets:options:andCompletionHandler:]
  +[VCPPhotosSceneprintAssetProcessingTask _panoVNRequestMethod]

  // instance methods
  -[VCPPhotosSceneprintAssetProcessingTask resourceRequirement]
  -[VCPPhotosSceneprintAssetProcessingTask .cxx_destruct]
  -[VCPPhotosSceneprintAssetProcessingTask run:]
  -[VCPPhotosSceneprintAssetProcessingTask cancel]
  -[VCPPhotosSceneprintAssetProcessingTask autoCancellable]
  -[VCPPhotosSceneprintAssetProcessingTask dealloc]
  -[VCPPhotosSceneprintAssetProcessingTask run]
  -[VCPPhotosSceneprintAssetProcessingTask initWithAssets:options:andCompletionHandler:]


VCPProtoMovieOrientationResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  int orientation

  // class methods
  +[VCPProtoMovieOrientationResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieOrientationResult setTimeRange:]
  -[VCPProtoMovieOrientationResult setOrientation:]
  -[VCPProtoMovieOrientationResult timeRange]
  -[VCPProtoMovieOrientationResult mergeFrom:]
  -[VCPProtoMovieOrientationResult .cxx_destruct]
  -[VCPProtoMovieOrientationResult dictionaryRepresentation]
  -[VCPProtoMovieOrientationResult writeTo:]
  -[VCPProtoMovieOrientationResult isEqual:]
  -[VCPProtoMovieOrientationResult copyTo:]
  -[VCPProtoMovieOrientationResult readFrom:]
  -[VCPProtoMovieOrientationResult orientation]
  -[VCPProtoMovieOrientationResult copyWithZone:]
  -[VCPProtoMovieOrientationResult exportToLegacyDictionary]


VCPVideoInterpolator : VCPVideoAnalyzer
 @property  BOOL processAborted
 @property  {?={?=qiIq}{?=qiIq}} adjustedTimeRange
 @property  BOOL cancelled

  // class methods
  +[VCPVideoInterpolator isEnabled]
  +[VCPVideoInterpolator isFRCFramworkAvailable]
  +[VCPVideoInterpolator getFRCQualityMode]
  +[VCPVideoInterpolator allowMultipleFormats]
  +[VCPVideoInterpolator sendPreGatedAnalytics]

  // instance methods
  -[VCPVideoInterpolator cancelled]
  -[VCPVideoInterpolator results]
  -[VCPVideoInterpolator .cxx_destruct]
  -[VCPVideoInterpolator setCancelled:]
  -[VCPVideoInterpolator dealloc]
  -[VCPVideoInterpolator analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoInterpolator finishAnalysisPass:]
  -[VCPVideoInterpolator getFrameSize:]
  -[VCPVideoInterpolator findIntraFrameList:]
  -[VCPVideoInterpolator isIntraFrame:]
  -[VCPVideoInterpolator setupLivePhotoInfoOutput:]
  -[VCPVideoInterpolator findLivePhotoInfoOutput:]
  -[VCPVideoInterpolator updateLivePhotoInfoSample:withTimestamp:withMetadata:isInterpolated:updatedSample:]
  -[VCPVideoInterpolator deserializeMetadata:]
  -[VCPVideoInterpolator combineVideoSegments]
  -[VCPVideoInterpolator appendOutput:toTrack:startTimeStamp:endTimeStamp:offset:duration:]
  -[VCPVideoInterpolator initWithTimestamps:andIdentifier:andTrack:]
  -[VCPVideoInterpolator processAborted]
  -[VCPVideoInterpolator adjustedTimeRange]


VCPProtoMoviePreEncodeResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  NSData *statisticsBlob

  // class methods
  +[VCPProtoMoviePreEncodeResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePreEncodeResult mergeFrom:]
  -[VCPProtoMoviePreEncodeResult .cxx_destruct]
  -[VCPProtoMoviePreEncodeResult dictionaryRepresentation]
  -[VCPProtoMoviePreEncodeResult writeTo:]
  -[VCPProtoMoviePreEncodeResult isEqual:]
  -[VCPProtoMoviePreEncodeResult copyTo:]
  -[VCPProtoMoviePreEncodeResult readFrom:]
  -[VCPProtoMoviePreEncodeResult copyWithZone:]
  -[VCPProtoMoviePreEncodeResult exportToLegacyDictionary]
  -[VCPProtoMoviePreEncodeResult setStatisticsBlob:]
  -[VCPProtoMoviePreEncodeResult statisticsBlob]


VCPProtoMovieQualityResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore

  // class methods
  +[VCPProtoMovieQualityResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieQualityResult setTimeRange:]
  -[VCPProtoMovieQualityResult timeRange]
  -[VCPProtoMovieQualityResult mergeFrom:]
  -[VCPProtoMovieQualityResult .cxx_destruct]
  -[VCPProtoMovieQualityResult dictionaryRepresentation]
  -[VCPProtoMovieQualityResult writeTo:]
  -[VCPProtoMovieQualityResult isEqual:]
  -[VCPProtoMovieQualityResult copyTo:]
  -[VCPProtoMovieQualityResult readFrom:]
  -[VCPProtoMovieQualityResult copyWithZone:]
  -[VCPProtoMovieQualityResult qualityScore]
  -[VCPProtoMovieQualityResult setQualityScore:]
  -[VCPProtoMovieQualityResult exportToLegacyDictionary]


VCPProtoMovieSaliencyResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMovieSaliencyResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSaliencyResult setTimeRange:]
  -[VCPProtoMovieSaliencyResult timeRange]
  -[VCPProtoMovieSaliencyResult setConfidence:]
  -[VCPProtoMovieSaliencyResult mergeFrom:]
  -[VCPProtoMovieSaliencyResult .cxx_destruct]
  -[VCPProtoMovieSaliencyResult confidence]
  -[VCPProtoMovieSaliencyResult dictionaryRepresentation]
  -[VCPProtoMovieSaliencyResult writeTo:]
  -[VCPProtoMovieSaliencyResult isEqual:]
  -[VCPProtoMovieSaliencyResult copyTo:]
  -[VCPProtoMovieSaliencyResult readFrom:]
  -[VCPProtoMovieSaliencyResult copyWithZone:]
  -[VCPProtoMovieSaliencyResult setBounds:]
  -[VCPProtoMovieSaliencyResult bounds]
  -[VCPProtoMovieSaliencyResult exportToLegacyDictionary]


VCPProtoMovieSceneResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float qualityScore
 @property  BOOL hasDistanceToPreviousScene
 @property  float distanceToPreviousScene
 @property  BOOL hasFlickerScore
 @property  float flickerScore
 @property  BOOL hasSceneprintDistanceToPreviousScene
 @property  float sceneprintDistanceToPreviousScene

  // class methods
  +[VCPProtoMovieSceneResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSceneResult setTimeRange:]
  -[VCPProtoMovieSceneResult timeRange]
  -[VCPProtoMovieSceneResult mergeFrom:]
  -[VCPProtoMovieSceneResult .cxx_destruct]
  -[VCPProtoMovieSceneResult dictionaryRepresentation]
  -[VCPProtoMovieSceneResult writeTo:]
  -[VCPProtoMovieSceneResult isEqual:]
  -[VCPProtoMovieSceneResult copyTo:]
  -[VCPProtoMovieSceneResult readFrom:]
  -[VCPProtoMovieSceneResult copyWithZone:]
  -[VCPProtoMovieSceneResult qualityScore]
  -[VCPProtoMovieSceneResult setQualityScore:]
  -[VCPProtoMovieSceneResult exportToLegacyDictionary]
  -[VCPProtoMovieSceneResult setDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult setHasDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult hasDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult setFlickerScore:]
  -[VCPProtoMovieSceneResult setHasFlickerScore:]
  -[VCPProtoMovieSceneResult hasFlickerScore]
  -[VCPProtoMovieSceneResult setSceneprintDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult setHasSceneprintDistanceToPreviousScene:]
  -[VCPProtoMovieSceneResult hasSceneprintDistanceToPreviousScene]
  -[VCPProtoMovieSceneResult distanceToPreviousScene]
  -[VCPProtoMovieSceneResult flickerScore]
  -[VCPProtoMovieSceneResult sceneprintDistanceToPreviousScene]


VCPProtoMovieSubjectMotionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  BOOL hasAction

  // class methods
  +[VCPProtoMovieSubjectMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSubjectMotionResult setTimeRange:]
  -[VCPProtoMovieSubjectMotionResult timeRange]
  -[VCPProtoMovieSubjectMotionResult mergeFrom:]
  -[VCPProtoMovieSubjectMotionResult .cxx_destruct]
  -[VCPProtoMovieSubjectMotionResult dictionaryRepresentation]
  -[VCPProtoMovieSubjectMotionResult writeTo:]
  -[VCPProtoMovieSubjectMotionResult hasAction]
  -[VCPProtoMovieSubjectMotionResult isEqual:]
  -[VCPProtoMovieSubjectMotionResult copyTo:]
  -[VCPProtoMovieSubjectMotionResult readFrom:]
  -[VCPProtoMovieSubjectMotionResult copyWithZone:]
  -[VCPProtoMovieSubjectMotionResult setHasAction:]
  -[VCPProtoMovieSubjectMotionResult exportToLegacyDictionary]


VCPFaceClusterer : NSObject
  // instance methods
  -[VCPFaceClusterer differencesBetweenClustersInClusterCacheAndLibrary:]
  -[VCPFaceClusterer .cxx_destruct]
  -[VCPFaceClusterer stop]
  -[VCPFaceClusterer resetFaceClusteringState:]
  -[VCPFaceClusterer _resetFaceClusteringStateWithContext:error:]
  -[VCPFaceClusterer startAndSyncClusterCacheWithLibrary:reply:]
  -[VCPFaceClusterer resetClusterer]
  -[VCPFaceClusterer cancelFaceClustering]
  -[VCPFaceClusterer scheduleClusteringOfFacesWithLocalIdentifiers:]
  -[VCPFaceClusterer clustererIsReadyToReturnSuggestions]
  -[VCPFaceClusterer performFaceClusteringWithCompletion:]
  -[VCPFaceClusterer scheduleUnclusteringOfFacesWithClusterSequenceNumbers:]
  -[VCPFaceClusterer clustererState]
  -[VCPFaceClusterer numberOfFacesPendingClustering]
  -[VCPFaceClusterer performFaceClusteringAndWait]
  -[VCPFaceClusterer getFaceClusters:clusteringThreshold:utilizingGPU:error:]
  -[VCPFaceClusterer clusterer]
  -[VCPFaceClusterer performFaceClusteringIfNecessaryAndWait]
  -[VCPFaceClusterer clusteringStatus]
  -[VCPFaceClusterer initWithPhotoLibrary:context:extendTimeoutBlock:andCancelBlock:]
  -[VCPFaceClusterer reclusterFacesWithThreshold:shouldRecluster:withContext:extendTimeout:cancel:error:]
  -[VCPFaceClusterer clusterFacesWithExtendTimeoutBlock:andCancelBlock:]
  -[VCPFaceClusterer reclusterFacesWithThreshold:shouldRecluster:error:]
  -[VCPFaceClusterer clusterFacesIfNecessaryWithExtendTimeoutBlock:andCancelBlock:]


VCPProtoMovieSummaryResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float curationScore
 @property  BOOL hasKeyFrame
 @property  VCPProtoVideoKeyFrame *keyFrame
 @property  BOOL autoPlayable
 @property  BOOL hasPlaybackCrop
 @property  VCPProtoBounds *playbackCrop

  // class methods
  +[VCPProtoMovieSummaryResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSummaryResult setTimeRange:]
  -[VCPProtoMovieSummaryResult timeRange]
  -[VCPProtoMovieSummaryResult mergeFrom:]
  -[VCPProtoMovieSummaryResult .cxx_destruct]
  -[VCPProtoMovieSummaryResult dictionaryRepresentation]
  -[VCPProtoMovieSummaryResult writeTo:]
  -[VCPProtoMovieSummaryResult curationScore]
  -[VCPProtoMovieSummaryResult isEqual:]
  -[VCPProtoMovieSummaryResult copyTo:]
  -[VCPProtoMovieSummaryResult readFrom:]
  -[VCPProtoMovieSummaryResult setCurationScore:]
  -[VCPProtoMovieSummaryResult copyWithZone:]
  -[VCPProtoMovieSummaryResult exportToLegacyDictionary]
  -[VCPProtoMovieSummaryResult keyFrame]
  -[VCPProtoMovieSummaryResult setKeyFrame:]
  -[VCPProtoMovieSummaryResult setPlaybackCrop:]
  -[VCPProtoMovieSummaryResult hasKeyFrame]
  -[VCPProtoMovieSummaryResult hasPlaybackCrop]
  -[VCPProtoMovieSummaryResult autoPlayable]
  -[VCPProtoMovieSummaryResult setAutoPlayable:]
  -[VCPProtoMovieSummaryResult playbackCrop]


VCPFaceCropUtils : NSObject
  // class methods
  +[VCPFaceCropUtils newDictionaryPopulatedWithFaceCropDataFromImageData:]
  +[VCPFaceCropUtils faceCropDimensionsFromFaceCrop:error:]
  +[VCPFaceCropUtils newDictionaryRepresentationOfFaceCropDataFromFaceBox:andCropRegion:andGroupingIdentifier:]
  +[VCPFaceCropUtils createOutputMetadataFromDictionary:]
  +[VCPFaceCropUtils newDictionaryWithCGImageSourceOptions]
  +[VCPFaceCropUtils newFaceCropFromCGImageSource:withFaceRect:groupingIdentifier:error:]
  +[VCPFaceCropUtils isValidFaceCrop:]
  +[VCPFaceCropUtils newFaceCropFromImageURL:withFaceRect:groupingIdentifier:error:]
  +[VCPFaceCropUtils newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:]
  +[VCPFaceCropUtils faceBoundsFromFaceCrop:error:]
  +[VCPFaceCropUtils cropBoundsInOriginalImageFromFaceCrop:error:]
  +[VCPFaceCropUtils groupingIdentifierFromFaceCrop:error:]


VCPProtoMovieUtteranceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange

  // class methods
  +[VCPProtoMovieUtteranceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieUtteranceResult setTimeRange:]
  -[VCPProtoMovieUtteranceResult timeRange]
  -[VCPProtoMovieUtteranceResult mergeFrom:]
  -[VCPProtoMovieUtteranceResult .cxx_destruct]
  -[VCPProtoMovieUtteranceResult dictionaryRepresentation]
  -[VCPProtoMovieUtteranceResult writeTo:]
  -[VCPProtoMovieUtteranceResult isEqual:]
  -[VCPProtoMovieUtteranceResult copyTo:]
  -[VCPProtoMovieUtteranceResult readFrom:]
  -[VCPProtoMovieUtteranceResult copyWithZone:]
  -[VCPProtoMovieUtteranceResult exportToLegacyDictionary]


VCPProtoMovieVoiceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float confidence

  // class methods
  +[VCPProtoMovieVoiceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieVoiceResult setTimeRange:]
  -[VCPProtoMovieVoiceResult timeRange]
  -[VCPProtoMovieVoiceResult setConfidence:]
  -[VCPProtoMovieVoiceResult mergeFrom:]
  -[VCPProtoMovieVoiceResult .cxx_destruct]
  -[VCPProtoMovieVoiceResult confidence]
  -[VCPProtoMovieVoiceResult dictionaryRepresentation]
  -[VCPProtoMovieVoiceResult writeTo:]
  -[VCPProtoMovieVoiceResult isEqual:]
  -[VCPProtoMovieVoiceResult copyTo:]
  -[VCPProtoMovieVoiceResult readFrom:]
  -[VCPProtoMovieVoiceResult copyWithZone:]
  -[VCPProtoMovieVoiceResult exportToLegacyDictionary]


VCPProtoPoint : PBCodable <NSCopying>
 @property  double x
 @property  double y

  // class methods
  +[VCPProtoPoint pointWithPoint:]

  // instance methods
  -[VCPProtoPoint y]
  -[VCPProtoPoint setX:]
  -[VCPProtoPoint setY:]
  -[VCPProtoPoint x]
  -[VCPProtoPoint mergeFrom:]
  -[VCPProtoPoint dictionaryRepresentation]
  -[VCPProtoPoint writeTo:]
  -[VCPProtoPoint isEqual:]
  -[VCPProtoPoint copyTo:]
  -[VCPProtoPoint readFrom:]
  -[VCPProtoPoint pointValue]
  -[VCPProtoPoint copyWithZone:]


VCPMADServiceImageProcessingTaskBatch : VCPMABaseTask
 @property  NSString *signpostPayload

  // class methods
  +[VCPMADServiceImageProcessingTaskBatch taskWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:]

  // instance methods
  -[VCPMADServiceImageProcessingTaskBatch signpostPayload]
  -[VCPMADServiceImageProcessingTaskBatch .cxx_destruct]
  -[VCPMADServiceImageProcessingTaskBatch cachesResources]
  -[VCPMADServiceImageProcessingTaskBatch run:]
  -[VCPMADServiceImageProcessingTaskBatch setSignpostPayload:]
  -[VCPMADServiceImageProcessingTaskBatch initWithCloudIdentifierRequests:photoLibrary:clientBundleID:clientTeamID:cancelBlock:andCompletionHandler:]
  -[VCPMADServiceImageProcessingTaskBatch assetWithIdentifier:isCloudIdentifier:error:]


VCPProtoMoviePetsFaceResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  VCPProtoBounds *bounds
 @property  float confidence

  // class methods
  +[VCPProtoMoviePetsFaceResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMoviePetsFaceResult setTimeRange:]
  -[VCPProtoMoviePetsFaceResult timeRange]
  -[VCPProtoMoviePetsFaceResult setConfidence:]
  -[VCPProtoMoviePetsFaceResult mergeFrom:]
  -[VCPProtoMoviePetsFaceResult .cxx_destruct]
  -[VCPProtoMoviePetsFaceResult confidence]
  -[VCPProtoMoviePetsFaceResult dictionaryRepresentation]
  -[VCPProtoMoviePetsFaceResult writeTo:]
  -[VCPProtoMoviePetsFaceResult isEqual:]
  -[VCPProtoMoviePetsFaceResult copyTo:]
  -[VCPProtoMoviePetsFaceResult readFrom:]
  -[VCPProtoMoviePetsFaceResult copyWithZone:]
  -[VCPProtoMoviePetsFaceResult setBounds:]
  -[VCPProtoMoviePetsFaceResult bounds]
  -[VCPProtoMoviePetsFaceResult exportToLegacyDictionary]


VCPProtoTime : PBCodable <NSCopying>
 @property  long long value
 @property  int timescale
 @property  unsigned int flags
 @property  long long epoch

  // class methods
  +[VCPProtoTime timeWithCMTime:]

  // instance methods
  -[VCPProtoTime epoch]
  -[VCPProtoTime setFlags:]
  -[VCPProtoTime mergeFrom:]
  -[VCPProtoTime dictionaryRepresentation]
  -[VCPProtoTime writeTo:]
  -[VCPProtoTime setEpoch:]
  -[VCPProtoTime isEqual:]
  -[VCPProtoTime copyTo:]
  -[VCPProtoTime readFrom:]
  -[VCPProtoTime setValue:]
  -[VCPProtoTime flags]
  -[VCPProtoTime value]
  -[VCPProtoTime timeValue]
  -[VCPProtoTime copyWithZone:]
  -[VCPProtoTime timescale]
  -[VCPProtoTime setTimescale:]


VCPProtoTimeRange : PBCodable <NSCopying>
 @property  VCPProtoTime *start
 @property  VCPProtoTime *duration

  // class methods
  +[VCPProtoTimeRange timeRangeWithCMTimeRange:]

  // instance methods
  -[VCPProtoTimeRange mergeFrom:]
  -[VCPProtoTimeRange .cxx_destruct]
  -[VCPProtoTimeRange setDuration:]
  -[VCPProtoTimeRange dictionaryRepresentation]
  -[VCPProtoTimeRange setStart:]
  -[VCPProtoTimeRange writeTo:]
  -[VCPProtoTimeRange isEqual:]
  -[VCPProtoTimeRange copyTo:]
  -[VCPProtoTimeRange readFrom:]
  -[VCPProtoTimeRange start]
  -[VCPProtoTimeRange copyWithZone:]
  -[VCPProtoTimeRange duration]
  -[VCPProtoTimeRange timeRangeValue]


VCPProtoVideoKeyFrame : PBCodable <NSCopying>
 @property  VCPProtoTime *timestamp
 @property  float curationScore

  // instance methods
  -[VCPProtoVideoKeyFrame mergeFrom:]
  -[VCPProtoVideoKeyFrame .cxx_destruct]
  -[VCPProtoVideoKeyFrame dictionaryRepresentation]
  -[VCPProtoVideoKeyFrame writeTo:]
  -[VCPProtoVideoKeyFrame curationScore]
  -[VCPProtoVideoKeyFrame isEqual:]
  -[VCPProtoVideoKeyFrame copyTo:]
  -[VCPProtoVideoKeyFrame readFrom:]
  -[VCPProtoVideoKeyFrame setCurationScore:]
  -[VCPProtoVideoKeyFrame timestamp]
  -[VCPProtoVideoKeyFrame copyWithZone:]
  -[VCPProtoVideoKeyFrame setTimestamp:]


VCPRealTimeAnalysisService : NSObject <VCPRealTimeAnalysisClientProtocol>
  // class methods
  +[VCPRealTimeAnalysisService analysisService]
  +[VCPRealTimeAnalysisService errorWithStatus:andDescription:]

  // instance methods
  -[VCPRealTimeAnalysisService .cxx_destruct]
  -[VCPRealTimeAnalysisService init]
  -[VCPRealTimeAnalysisService connection]
  -[VCPRealTimeAnalysisService dealloc]
  -[VCPRealTimeAnalysisService invalidate]
  -[VCPRealTimeAnalysisService requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:]


VCPRTLandmarkDetector : NSObject
  // instance methods
  -[VCPRTLandmarkDetector dealloc]
  -[VCPRTLandmarkDetector initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:]
  -[VCPRTLandmarkDetector detectLandmark:width:height:stride:facerect:prevResult:result:]
  -[VCPRTLandmarkDetector calculateFaceRectFromPrevLM:result:numOfLandmarks:]


VCPProtoMovieStabilizationRecipe : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  float cropRectX
 @property  float cropRectY
 @property  float cropRectHeight
 @property  float cropRectWidth
 @property  float inputBoundsX
 @property  float inputBoundsY
 @property  float inputBoundsHeight
 @property  float inputBoundsWidth
 @property  float sourceSizeHeight
 @property  float sourceSizeWidth
 @property  int timeScale
 @property  unsigned long timeValuesCount
 @property  ^q timeValues
 @property  unsigned long homographyParamsCount
 @property  ^f homographyParams

  // class methods
  +[VCPProtoMovieStabilizationRecipe resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieStabilizationRecipe mergeFrom:]
  -[VCPProtoMovieStabilizationRecipe timeScale]
  -[VCPProtoMovieStabilizationRecipe dictionaryRepresentation]
  -[VCPProtoMovieStabilizationRecipe writeTo:]
  -[VCPProtoMovieStabilizationRecipe isEqual:]
  -[VCPProtoMovieStabilizationRecipe copyTo:]
  -[VCPProtoMovieStabilizationRecipe readFrom:]
  -[VCPProtoMovieStabilizationRecipe setTimeScale:]
  -[VCPProtoMovieStabilizationRecipe dealloc]
  -[VCPProtoMovieStabilizationRecipe copyWithZone:]
  -[VCPProtoMovieStabilizationRecipe cropRectX]
  -[VCPProtoMovieStabilizationRecipe cropRectY]
  -[VCPProtoMovieStabilizationRecipe cropRectWidth]
  -[VCPProtoMovieStabilizationRecipe cropRectHeight]
  -[VCPProtoMovieStabilizationRecipe exportToLegacyDictionary]
  -[VCPProtoMovieStabilizationRecipe setCropRectX:]
  -[VCPProtoMovieStabilizationRecipe setCropRectY:]
  -[VCPProtoMovieStabilizationRecipe setCropRectHeight:]
  -[VCPProtoMovieStabilizationRecipe setCropRectWidth:]
  -[VCPProtoMovieStabilizationRecipe homographyParamsCount]
  -[VCPProtoMovieStabilizationRecipe clearHomographyParams]
  -[VCPProtoMovieStabilizationRecipe homographyParams]
  -[VCPProtoMovieStabilizationRecipe setHomographyParams:count:]
  -[VCPProtoMovieStabilizationRecipe timeValuesCount]
  -[VCPProtoMovieStabilizationRecipe clearTimeValues]
  -[VCPProtoMovieStabilizationRecipe timeValueAtIndex:]
  -[VCPProtoMovieStabilizationRecipe addTimeValue:]
  -[VCPProtoMovieStabilizationRecipe homographyParamsAtIndex:]
  -[VCPProtoMovieStabilizationRecipe addHomographyParams:]
  -[VCPProtoMovieStabilizationRecipe timeValues]
  -[VCPProtoMovieStabilizationRecipe setTimeValues:count:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsX]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsX:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsY]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsY:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsHeight]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsHeight:]
  -[VCPProtoMovieStabilizationRecipe inputBoundsWidth]
  -[VCPProtoMovieStabilizationRecipe setInputBoundsWidth:]
  -[VCPProtoMovieStabilizationRecipe sourceSizeHeight]
  -[VCPProtoMovieStabilizationRecipe setSourceSizeHeight:]
  -[VCPProtoMovieStabilizationRecipe sourceSizeWidth]
  -[VCPProtoMovieStabilizationRecipe setSourceSizeWidth:]


VCPSceneTaxonomy : NSObject
  // class methods
  +[VCPSceneTaxonomy sharedTaxonomy]

  // instance methods
  -[VCPSceneTaxonomy .cxx_destruct]
  -[VCPSceneTaxonomy init]
  -[VCPSceneTaxonomy sceneNameFromSceneId:]
  -[VCPSceneTaxonomy sceneIdFromSceneName:]


VCPSegment : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timeRange
 @property  unsigned long numOfFrames
 @property  unsigned long numOfValidFrames
 @property  float curationScore

  // instance methods
  -[VCPSegment setTimeRange:]
  -[VCPSegment timeRange]
  -[VCPSegment curationScore]
  -[VCPSegment init]
  -[VCPSegment score]
  -[VCPSegment setCurationScore:]
  -[VCPSegment updateDuration:]
  -[VCPSegment mergeSegment:]
  -[VCPSegment numOfFrames]
  -[VCPSegment copyFrom:]
  -[VCPSegment numOfValidFrames]
  -[VCPSegment sumOfScore]
  -[VCPSegment initWithTimestamp:score:valid:]
  -[VCPSegment updateWithFirstFrame:score:valid:]
  -[VCPSegment updateSegment:score:valid:]
  -[VCPSegment trimSegment:fromStart:]
  -[VCPSegment isContentTooShort]


VCPMovieAssetWriter : NSObject
 @property  long long status

  // class methods
  +[VCPMovieAssetWriter assetWriterWithURL:andTrack:andBitrate:]

  // instance methods
  -[VCPMovieAssetWriter .cxx_construct]
  -[VCPMovieAssetWriter .cxx_destruct]
  -[VCPMovieAssetWriter status]
  -[VCPMovieAssetWriter cancel]
  -[VCPMovieAssetWriter finish]
  -[VCPMovieAssetWriter dealloc]
  -[VCPMovieAssetWriter dispatchEncoding]
  -[VCPMovieAssetWriter updateStillPTS:]
  -[VCPMovieAssetWriter addPixelBuffer:withTime:withAttachment:]
  -[VCPMovieAssetWriter addLivePhotoInfoBuffer:]
  -[VCPMovieAssetWriter setupVideoTrack:]
  -[VCPMovieAssetWriter setupAudioTrack]
  -[VCPMovieAssetWriter setupMetadataTrack]
  -[VCPMovieAssetWriter initWithURL:andTrack:andBitrate:]
  -[VCPMovieAssetWriter popSample]
  -[VCPMovieAssetWriter processLivePhotoInfoMetadataTrack]
  -[VCPMovieAssetWriter copyPixelBuffer:toPixelBuffer:]
  -[VCPMovieAssetWriter pushSample:]
  -[VCPMovieAssetWriter pushLivePhotoInfoSample:]
  -[VCPMovieAssetWriter processStillImageMetadataTrack]
  -[VCPMovieAssetWriter passthroughMetadataTrackFrom:to:]
  -[VCPMovieAssetWriter popLivePhotoInfoSample]
  -[VCPMovieAssetWriter appendMetadataTrack]


VCPSharedInstanceManager : NSObject
  // class methods
  +[VCPSharedInstanceManager sharedManager]

  // instance methods
  -[VCPSharedInstanceManager .cxx_destruct]
  -[VCPSharedInstanceManager sharedInstanceWithIdentifier:andCreationBlock:]
  -[VCPSharedInstanceManager init]
  -[VCPSharedInstanceManager resetSharedInstanceWithIdentifier:]
  -[VCPSharedInstanceManager reset]


VCPTrimAnalyzer : NSObject
  // instance methods
  -[VCPTrimAnalyzer .cxx_destruct]
  -[VCPTrimAnalyzer isReady]
  -[VCPTrimAnalyzer init]
  -[VCPTrimAnalyzer printSegments:]
  -[VCPTrimAnalyzer prepareTrimmingWithTrimStart:andTrimEnd:]
  -[VCPTrimAnalyzer analyzeFrameWithTimeRange:analysisData:]
  -[VCPTrimAnalyzer shouldCutAt:stillPTS:withCut:]
  -[VCPTrimAnalyzer generateCurationSegment]
  -[VCPTrimAnalyzer generateInterestingTrimBasedOnCaptureTime:]
  -[VCPTrimAnalyzer updateCurationThreshold]
  -[VCPTrimAnalyzer calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:]
  -[VCPTrimAnalyzer isCurated:]
  -[VCPTrimAnalyzer isTimestampSkipable:]
  -[VCPTrimAnalyzer checkTrimAt:captureTime:]
  -[VCPTrimAnalyzer finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:]
  -[VCPTrimAnalyzer bestTrimTimeRange]


VCPURLAsset : VCPAsset
  // class methods
  +[VCPURLAsset movieAssetWithURL:]
  +[VCPURLAsset livePhotoAssetWithImageURL:andMovieURL:]
  +[VCPURLAsset imageAssetWithURL:]
  +[VCPURLAsset sdofImageAssetWithURL:]

  // instance methods
  -[VCPURLAsset modificationDate]
  -[VCPURLAsset movie]
  -[VCPURLAsset .cxx_destruct]
  -[VCPURLAsset mediaSubtypes]
  -[VCPURLAsset exif]
  -[VCPURLAsset pixelWidth]
  -[VCPURLAsset pixelHeight]
  -[VCPURLAsset scenes]
  -[VCPURLAsset mainFileURL]
  -[VCPURLAsset mediaType]
  -[VCPURLAsset duration]
  -[VCPURLAsset imageWithPreferredDimension:]
  -[VCPURLAsset photoOffsetSeconds]
  -[VCPURLAsset originalPhotoOffsetSeconds]
  -[VCPURLAsset slowmoRate]
  -[VCPURLAsset slomoRange]
  -[VCPURLAsset originalMovie]
  -[VCPURLAsset initWithImageURL:isSDOF:]
  -[VCPURLAsset initWithImageURL:andMovieURL:]
  -[VCPURLAsset initWithMovieURL:]


VCPVideoActivityAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoActivityAnalyzer results]
  -[VCPVideoActivityAnalyzer .cxx_destruct]
  -[VCPVideoActivityAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoActivityAnalyzer normalizeActivityDescriptor]
  -[VCPVideoActivityAnalyzer prepareActivityStats]
  -[VCPVideoActivityAnalyzer generateActivityDescriptor]
  -[VCPVideoActivityAnalyzer computeActivityScoreAtTime:]
  -[VCPVideoActivityAnalyzer resetActivityStatsAtTime:]
  -[VCPVideoActivityAnalyzer extractRequiredInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer extractRequiredClassificationInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer extractRequiredFaceInfoFrom:toArray:]
  -[VCPVideoActivityAnalyzer validationScoreOfTimeRange:fromResult:startIdx:]
  -[VCPVideoActivityAnalyzer actionScoreInTimeRange:]
  -[VCPVideoActivityAnalyzer validateActivityScores]
  -[VCPVideoActivityAnalyzer scaleBasedOnFaceForTimeRange:]
  -[VCPVideoActivityAnalyzer addSceneSwitchFrequencyConstributionToActivityLevel:]
  -[VCPVideoActivityAnalyzer addSceneClassificationContributionToActivityLevel:]
  -[VCPVideoActivityAnalyzer initWithFrameStats:]
  -[VCPVideoActivityAnalyzer preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:]
  -[VCPVideoActivityAnalyzer finishAnalysisPass:fpsRate:]


VCPCompactResult : NSObject
 @property  {?={?=qiIq}{?=qiIq}} timerange
 @property  float score

  // instance methods
  -[VCPCompactResult setScore:]
  -[VCPCompactResult score]
  -[VCPCompactResult timerange]
  -[VCPCompactResult setTimerange:]
  -[VCPCompactResult initWithTimerange:andScore:]


VCPMADMachineReadableCodeResource : VCPMADVisionResource
  // class methods
  +[VCPMADMachineReadableCodeResource sharedResource]

  // instance methods
  -[VCPMADMachineReadableCodeResource inactiveCost]
  -[VCPMADMachineReadableCodeResource activeCost]


VCPMADVIMachineReadableCodeDetectionTask : NSObject <VCPMADServiceImageProcessingSubtaskProtocol, VCPMADTaskProtocol>
  // class methods
  +[VCPMADVIMachineReadableCodeDetectionTask dependencies]
  +[VCPMADVIMachineReadableCodeDetectionTask taskWithRequest:imageAsset:andSignpostPayload:]
  +[VCPMADVIMachineReadableCodeDetectionTask enableGating]

  // instance methods
  -[VCPMADVIMachineReadableCodeDetectionTask resourceRequirement]
  -[VCPMADVIMachineReadableCodeDetectionTask .cxx_destruct]
  -[VCPMADVIMachineReadableCodeDetectionTask cancel]
  -[VCPMADVIMachineReadableCodeDetectionTask initWithRequest:imageAsset:andSignpostPayload:]
  -[VCPMADVIMachineReadableCodeDetectionTask autoCancellable]
  -[VCPMADVIMachineReadableCodeDetectionTask canReuseResultsForRequest]
  -[VCPMADVIMachineReadableCodeDetectionTask run]


VCPVideoActivityDescriptor : NSObject
 @property  ^f descriptors

  // instance methods
  -[VCPVideoActivityDescriptor descriptors]
  -[VCPVideoActivityDescriptor reset]
  -[VCPVideoActivityDescriptor dealloc]
  -[VCPVideoActivityDescriptor initWithFrameWidthInMb:heightInMb:]
  -[VCPVideoActivityDescriptor ExtractActivityDescriptorFromStats:]
  -[VCPVideoActivityDescriptor spatialDescriptorWithMvMagnitudeMean:]


VCPVideoHumanActionClassifier : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoHumanActionClassifier results]
  -[VCPVideoHumanActionClassifier .cxx_destruct]
  -[VCPVideoHumanActionClassifier init]
  -[VCPVideoHumanActionClassifier createModel]
  -[VCPVideoHumanActionClassifier dealloc]
  -[VCPVideoHumanActionClassifier analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoHumanActionClassifier finishAnalysisPass:]
  -[VCPVideoHumanActionClassifier privateResults]
  -[VCPVideoHumanActionClassifier prepareData:]
  -[VCPVideoHumanActionClassifier detect]
  -[VCPVideoHumanActionClassifier keypointsFromObservations:]
  -[VCPVideoHumanActionClassifier analyzeBodyArray:]


VCPProtoMovieSubtleMotionResult : PBCodable <VCPProtoResultLegacyConversionProtocol, NSCopying>
 @property  VCPProtoTimeRange *timeRange
 @property  float actionScore

  // class methods
  +[VCPProtoMovieSubtleMotionResult resultFromLegacyDictionary:]

  // instance methods
  -[VCPProtoMovieSubtleMotionResult setTimeRange:]
  -[VCPProtoMovieSubtleMotionResult timeRange]
  -[VCPProtoMovieSubtleMotionResult mergeFrom:]
  -[VCPProtoMovieSubtleMotionResult .cxx_destruct]
  -[VCPProtoMovieSubtleMotionResult dictionaryRepresentation]
  -[VCPProtoMovieSubtleMotionResult writeTo:]
  -[VCPProtoMovieSubtleMotionResult isEqual:]
  -[VCPProtoMovieSubtleMotionResult copyTo:]
  -[VCPProtoMovieSubtleMotionResult readFrom:]
  -[VCPProtoMovieSubtleMotionResult setActionScore:]
  -[VCPProtoMovieSubtleMotionResult actionScore]
  -[VCPProtoMovieSubtleMotionResult copyWithZone:]
  -[VCPProtoMovieSubtleMotionResult exportToLegacyDictionary]


VCPVideoAnalyzer : NSObject
  // class methods
  +[VCPVideoAnalyzer dependencies]

  // instance methods
  -[VCPVideoAnalyzer results]
  -[VCPVideoAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoAnalyzer finishAnalysisPass:]


VCPVideoFaceDetector : VCPVideoAnalyzer
  // class methods
  +[VCPVideoFaceDetector faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:]

  // instance methods
  -[VCPVideoFaceDetector results]
  -[VCPVideoFaceDetector .cxx_destruct]
  -[VCPVideoFaceDetector faceRanges]


VCPVideoFaceMeshAnalyzer : NSObject
 @property  {?=[4]} pose
 @property  NSDictionary *blendShapes
 @property  unsigned long vertexCount
 @property  r^ vertices
 @property  r^f landmarks
 @property  BOOL bufferRotated

  // instance methods
  -[VCPVideoFaceMeshAnalyzer pose]
  -[VCPVideoFaceMeshAnalyzer .cxx_destruct]
  -[VCPVideoFaceMeshAnalyzer setFrame:]
  -[VCPVideoFaceMeshAnalyzer vertices]
  -[VCPVideoFaceMeshAnalyzer landmarks]
  -[VCPVideoFaceMeshAnalyzer vertexCount]
  -[VCPVideoFaceMeshAnalyzer dealloc]
  -[VCPVideoFaceMeshAnalyzer isTracked]
  -[VCPVideoFaceMeshAnalyzer blendShapes]
  -[VCPVideoFaceMeshAnalyzer updateFocalLengthInPixels:]
  -[VCPVideoFaceMeshAnalyzer initWithFocalLengthInPixels:offline:isFastMode:]
  -[VCPVideoFaceMeshAnalyzer analyzeFrame:withFaceRect:withRotation:withTimestamp:]
  -[VCPVideoFaceMeshAnalyzer makeValidationDecision]
  -[VCPVideoFaceMeshAnalyzer updateIntrinsicWhenRotated]
  -[VCPVideoFaceMeshAnalyzer checkResolutionChange:withRotation:]
  -[VCPVideoFaceMeshAnalyzer validateFace:eulerAngles:]
  -[VCPVideoFaceMeshAnalyzer rotateLandmarks:width:height:landmarks:numLandmarks:]
  -[VCPVideoFaceMeshAnalyzer mapToCameraNegativeZ]
  -[VCPVideoFaceMeshAnalyzer bufferRotated]


VCPPhotosFacePair : NSObject
 @property  VCPPhotosFace *face1
 @property  VCPPhotosFace *face2
 @property  double score

  // class methods
  +[VCPPhotosFacePair pairWithFace:andFace:andScore:]

  // instance methods
  -[VCPPhotosFacePair .cxx_destruct]
  -[VCPPhotosFacePair face1]
  -[VCPPhotosFacePair face2]
  -[VCPPhotosFacePair score]
  -[VCPPhotosFacePair initWithFace:andFace:andScore:]


VCPFaceMerger : NSObject
  // class methods
  +[VCPFaceMerger _allowANE]

  // instance methods
  -[VCPFaceMerger .cxx_destruct]
  -[VCPFaceMerger initWithContext:]
  -[VCPFaceMerger mergeExistingFaces:withDetectedFaces:forImage:]
  -[VCPFaceMerger _bboxAlignedFaceObservationsFromFaceObservations:inImage:withError:]
  -[VCPFaceMerger _sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:]
  -[VCPFaceMerger _configureRequest:withRevision:]
  -[VCPFaceMerger _faceObservationsWithBBoxFromVCPPhotosFaces:mapping:]
  -[VCPFaceMerger _alignBBoxForVCPPhotosFaces:forImage:]


VCPPetsRegion : NSObject
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bound
 @property  float confidence

  // instance methods
  -[VCPPetsRegion setConfidence:]
  -[VCPPetsRegion confidence]
  -[VCPPetsRegion bound]
  -[VCPPetsRegion setBound:]
  -[VCPPetsRegion initWith:confidence:]


VCPVideoPetsAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoPetsAnalyzer results]
  -[VCPVideoPetsAnalyzer .cxx_destruct]
  -[VCPVideoPetsAnalyzer initWithTransform:]
  -[VCPVideoPetsAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoPetsAnalyzer finishAnalysisPass:]
  -[VCPVideoPetsAnalyzer parseResults:toDetections:atTime:fromTime:addActiveRegions:]
  -[VCPVideoPetsAnalyzer addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:]


VCPVideoFacePoseAnalyzer : NSObject
 @property  {?=[4]} pose

  // instance methods
  -[VCPVideoFacePoseAnalyzer pose]
  -[VCPVideoFacePoseAnalyzer setPose:]
  -[VCPVideoFacePoseAnalyzer .cxx_destruct]
  -[VCPVideoFacePoseAnalyzer init]
  -[VCPVideoFacePoseAnalyzer updateFocalLengthInPixels:]
  -[VCPVideoFacePoseAnalyzer initWithFocalLengthInPixels:]
  -[VCPVideoFacePoseAnalyzer analyzeFrameForPose:withFaceRect:withTimestamp:]


VCPVideoFacePoseFilter : NSObject
  // instance methods
  -[VCPVideoFacePoseFilter .cxx_construct]
  -[VCPVideoFacePoseFilter reset]
  -[VCPVideoFacePoseFilter rotationToEulerAngles:angles:]
  -[VCPVideoFacePoseFilter kalmanFiltering:T:]
  -[VCPVideoFacePoseFilter eulerAnglesToRotation:R:]
  -[VCPVideoFacePoseFilter filteringPose:]


VCPVideoFullFaceDetector : VCPVideoFaceDetector
  // instance methods
  -[VCPVideoFullFaceDetector .cxx_destruct]
  -[VCPVideoFullFaceDetector initWithTransform:]
  -[VCPVideoFullFaceDetector dealloc]
  -[VCPVideoFullFaceDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoFullFaceDetector finishAnalysisPass:]
  -[VCPVideoFullFaceDetector frameFaceResults]
  -[VCPVideoFullFaceDetector initWithTransform:withExistingFaceprints:frameStats:]
  -[VCPVideoFullFaceDetector faceRanges]
  -[VCPVideoFullFaceDetector minProcessTimeIntervalInSecs]
  -[VCPVideoFullFaceDetector detectFaces:faces:]
  -[VCPVideoFullFaceDetector compareFace:withFace:]
  -[VCPVideoFullFaceDetector removeSmallestKeyFace]
  -[VCPVideoFullFaceDetector detectTrackFacesInFrame:withTimestamp:faces:]
  -[VCPVideoFullFaceDetector clusterFaces]
  -[VCPVideoFullFaceDetector updateWithExistingFaces]
  -[VCPVideoFullFaceDetector locationChange:relativeTo:landscape:]


VCPCNNHandKeypointsDetectorEspresso : VCPCNNHandKeypointsDetector
  // instance methods
  -[VCPCNNHandKeypointsDetectorEspresso .cxx_destruct]
  -[VCPCNNHandKeypointsDetectorEspresso dealloc]
  -[VCPCNNHandKeypointsDetectorEspresso init:sharedModel:modelName:]
  -[VCPCNNHandKeypointsDetectorEspresso getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:]
  -[VCPCNNHandKeypointsDetectorEspresso generateHandKeypoints:keypointConfidence:offset:]


VCPVideoGlobalAnalyzer : NSObject
  // instance methods
  -[VCPVideoGlobalAnalyzer setActivityLevel:]
  -[VCPVideoGlobalAnalyzer analyzeOverallQuality:withFpsRate:]
  -[VCPVideoGlobalAnalyzer generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:]
  -[VCPVideoGlobalAnalyzer hasMeaningfulSceneSegment:withFpsRate:]
  -[VCPVideoGlobalAnalyzer assetQualityScoreFromAnalysis:withFpsRate:]
  -[VCPVideoGlobalAnalyzer assetActionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetExpressionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetVoiceScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetJunkScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer assetCameraMotionScoreFromAnalysis:]
  -[VCPVideoGlobalAnalyzer checkCameraZoom:cameraMotionResults:]
  -[VCPVideoGlobalAnalyzer scaleForTimeRange:basedOnFace:]
  -[VCPVideoGlobalAnalyzer isJunkTimeRange:basedOnResults:]
  -[VCPVideoGlobalAnalyzer subjectActivityInTimeRange:fromResults:]
  -[VCPVideoGlobalAnalyzer cameraActivityfromQuality:]
  -[VCPVideoGlobalAnalyzer assetActivityLevelFromAnalysisResults:]


VCPVideoKeyFrame : NSObject
 @property  {?=qiIq} timestamp
 @property  float score
 @property  float semanticScore
 @property  float sharpness
 @property  float faceSharpness
 @property  float exposureScore
 @property  BOOL isHeadingFrame
 @property  float textureScore
 @property  float expressionChangeScore
 @property  unsigned long statsFlags
 @property  NSMutableArray *detectedFaces
 @property  NSMutableArray *faceQualityScores
 @property  NSMutableDictionary *frameResults
 @property  float overallFaceQualityScore
 @property  float qualityScoreForLivePhoto
 @property  float globalQualityScore
 @property  float visualPleasingScore
 @property  float penaltyScore
 @property  float contentScore
 @property  float humanPoseScore
 @property  float humanActionScore

  // instance methods
  -[VCPVideoKeyFrame setScore:]
  -[VCPVideoKeyFrame setExposureScore:]
  -[VCPVideoKeyFrame .cxx_destruct]
  -[VCPVideoKeyFrame initWithLivePhoto:]
  -[VCPVideoKeyFrame sharpness]
  -[VCPVideoKeyFrame exposureScore]
  -[VCPVideoKeyFrame semanticScore]
  -[VCPVideoKeyFrame score]
  -[VCPVideoKeyFrame timestamp]
  -[VCPVideoKeyFrame setDetectedFaces:]
  -[VCPVideoKeyFrame detectedFaces]
  -[VCPVideoKeyFrame setSharpness:]
  -[VCPVideoKeyFrame setTimestamp:]
  -[VCPVideoKeyFrame setContentScore:]
  -[VCPVideoKeyFrame contentScore]
  -[VCPVideoKeyFrame frameResults]
  -[VCPVideoKeyFrame printStats]
  -[VCPVideoKeyFrame setGlobalQualityScore:]
  -[VCPVideoKeyFrame qualityScoreForLivePhoto]
  -[VCPVideoKeyFrame setQualityScoreForLivePhoto:]
  -[VCPVideoKeyFrame visualPleasingScore]
  -[VCPVideoKeyFrame setVisualPleasingScore:]
  -[VCPVideoKeyFrame overallFaceQualityScore]
  -[VCPVideoKeyFrame setOverallFaceQualityScore:]
  -[VCPVideoKeyFrame penaltyScore]
  -[VCPVideoKeyFrame setPenaltyScore:]
  -[VCPVideoKeyFrame textureScore]
  -[VCPVideoKeyFrame setTextureScore:]
  -[VCPVideoKeyFrame globalQualityScore]
  -[VCPVideoKeyFrame expressionChangeScore]
  -[VCPVideoKeyFrame setExpressionChangeScore:]
  -[VCPVideoKeyFrame faceQualityScores]
  -[VCPVideoKeyFrame setFaceQualityScores:]
  -[VCPVideoKeyFrame setHumanActionScore:]
  -[VCPVideoKeyFrame setHumanPoseScore:]
  -[VCPVideoKeyFrame humanPoseScore]
  -[VCPVideoKeyFrame humanActionScore]
  -[VCPVideoKeyFrame setSemanticScore:]
  -[VCPVideoKeyFrame copyFrom:]
  -[VCPVideoKeyFrame setStatsFlags:]
  -[VCPVideoKeyFrame statsFlags]
  -[VCPVideoKeyFrame faceSharpness]
  -[VCPVideoKeyFrame isHeadingFrame]
  -[VCPVideoKeyFrame computeGlobalQuality]
  -[VCPVideoKeyFrame computeScoreFromColorfulness]
  -[VCPVideoKeyFrame computeScoreFromExposure]
  -[VCPVideoKeyFrame computeExpressionScore]
  -[VCPVideoKeyFrame computeScoreFromAction]
  -[VCPVideoKeyFrame computeGlobalQualityForLivePhoto]
  -[VCPVideoKeyFrame computeVisualPleasingScore]
  -[VCPVideoKeyFrame computePenaltyScore]
  -[VCPVideoKeyFrame computeContentScore]
  -[VCPVideoKeyFrame computeCurationScoreComponents]
  -[VCPVideoKeyFrame storeFrameResults]
  -[VCPVideoKeyFrame setFrameResults:]
  -[VCPVideoKeyFrame loadKeyFrameResult:timestamp:]
  -[VCPVideoKeyFrame setFaceSharpness:]
  -[VCPVideoKeyFrame computeCurationScore]
  -[VCPVideoKeyFrame hasGoodSubjectAction]
  -[VCPVideoKeyFrame setIsHeadingFrame:]
  -[VCPVideoKeyFrame resetStatsFlag]
  -[VCPVideoKeyFrame setFaceStatsFlag:detectedFaces:]
  -[VCPVideoKeyFrame setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:]


VCPVideoKeyFrameAnalyzer : NSObject
  // instance methods
  -[VCPVideoKeyFrameAnalyzer .cxx_destruct]
  -[VCPVideoKeyFrameAnalyzer initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:]
  -[VCPVideoKeyFrameAnalyzer analyzeFrame:withTimestamp:]
  -[VCPVideoKeyFrameAnalyzer preparePostProcessingStatsFromFaceRange:junkResults:]
  -[VCPVideoKeyFrameAnalyzer postProcess]
  -[VCPVideoKeyFrameAnalyzer keyFrames]
  -[VCPVideoKeyFrameAnalyzer keyFrameScores]
  -[VCPVideoKeyFrameAnalyzer setKeyFrameTime:isHeadingFrame:]
  -[VCPVideoKeyFrameAnalyzer prepareFrameStats:]
  -[VCPVideoKeyFrameAnalyzer computeSharpnessOfFrame:]
  -[VCPVideoKeyFrameAnalyzer computeFaceQualityOfFrame:]
  -[VCPVideoKeyFrameAnalyzer finalizeKeyFrame]
  -[VCPVideoKeyFrameAnalyzer adjustScoreByFace]
  -[VCPVideoKeyFrameAnalyzer modulateByJunk]
  -[VCPVideoKeyFrameAnalyzer modulateByTimeRange]
  -[VCPVideoKeyFrameAnalyzer setBlurAnalyzerFaceResults:]
  -[VCPVideoKeyFrameAnalyzer loadKeyFrameResults:]
  -[VCPVideoKeyFrameAnalyzer modulateByExposure]
  -[VCPVideoKeyFrameAnalyzer computeMinDistanceBetween:withSet:]


VCPVideoLightFaceDetector : VCPVideoFaceDetector
  // instance methods
  -[VCPVideoLightFaceDetector .cxx_destruct]
  -[VCPVideoLightFaceDetector dealloc]
  -[VCPVideoLightFaceDetector analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoLightFaceDetector finishAnalysisPass:]
  -[VCPVideoLightFaceDetector initWithTransform:frameStats:faceDominated:]
  -[VCPVideoLightFaceDetector minProcessTimeIntervalInSecs]
  -[VCPVideoLightFaceDetector detectFaces:faces:]


VCPVideoMetaAnalyzer : NSObject
 @property  NSDictionary *publicResults
 @property  NSDictionary *privateResults

  // class methods
  +[VCPVideoMetaAnalyzer analyzerForTrackType:withTransform:requestAnalyses:formatDescription:]

  // instance methods
  -[VCPVideoMetaAnalyzer finalizeAnalysis]
  -[VCPVideoMetaAnalyzer privateResults]
  -[VCPVideoMetaAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaAnalyzer publicResults]


VCPVideoMetaFaceAnalyzer : VCPVideoMetaAnalyzer
  // instance methods
  -[VCPVideoMetaFaceAnalyzer .cxx_destruct]
  -[VCPVideoMetaFaceAnalyzer initWithTransform:]
  -[VCPVideoMetaFaceAnalyzer finalizeAnalysis]
  -[VCPVideoMetaFaceAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaFaceAnalyzer publicResults]
  -[VCPVideoMetaFaceAnalyzer flipTransform:]


VCPVideoMetaFocusAnalyzer : NSObject
 @property  NSArray *results

  // instance methods
  -[VCPVideoMetaFocusAnalyzer results]
  -[VCPVideoMetaFocusAnalyzer .cxx_destruct]
  -[VCPVideoMetaFocusAnalyzer init]
  -[VCPVideoMetaFocusAnalyzer finalizeAnalysis]
  -[VCPVideoMetaFocusAnalyzer addSegmentToResults]
  -[VCPVideoMetaFocusAnalyzer processFrameMetadata:]


VCPVideoMetaFocusSegment : VCPMetaSegment
 @property  long long focusStatus

  // instance methods
  -[VCPVideoMetaFocusSegment setFocusStatus:]
  -[VCPVideoMetaFocusSegment focusStatus]
  -[VCPVideoMetaFocusSegment resetSegment:atTime:]
  -[VCPVideoMetaFocusSegment initWithFocusStatus:atTime:]
  -[VCPVideoMetaFocusSegment updateSegment:atTime:]


VCPVideoMetaLensSwitchAnalyzer : NSObject
 @property  BOOL hadZoom
 @property  float minZoom
 @property  float maxZoom

  // instance methods
  -[VCPVideoMetaLensSwitchAnalyzer results]
  -[VCPVideoMetaLensSwitchAnalyzer maxZoom]
  -[VCPVideoMetaLensSwitchAnalyzer init]
  -[VCPVideoMetaLensSwitchAnalyzer setMaxZoom:]
  -[VCPVideoMetaLensSwitchAnalyzer minZoom]
  -[VCPVideoMetaLensSwitchAnalyzer setMinZoom:]
  -[VCPVideoMetaLensSwitchAnalyzer hadZoom]
  -[VCPVideoMetaLensSwitchAnalyzer setHadZoom:]


VCPVideoMetaLivePhotoMetaAnalyzer : VCPVideoMetaAnalyzer
  // class methods
  +[VCPVideoMetaLivePhotoMetaAnalyzer defaultDesiredKeys]
  +[VCPVideoMetaLivePhotoMetaAnalyzer referenceSoftwareStackVersion]

  // instance methods
  -[VCPVideoMetaLivePhotoMetaAnalyzer .cxx_destruct]
  -[VCPVideoMetaLivePhotoMetaAnalyzer init]
  -[VCPVideoMetaLivePhotoMetaAnalyzer finalizeAnalysis]
  -[VCPVideoMetaLivePhotoMetaAnalyzer privateResults]
  -[VCPVideoMetaLivePhotoMetaAnalyzer processMetadataGroup:flags:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer initWithRequestAnalyses:formatDescription:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer readGyroHomographyDimension:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer gyroHomographyVersionIsValid:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer readSoftwareStackVersion:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer compareSoftwareStackVersion:withReferenceVersion:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer getSetupDataFrom:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer getFirstAtomWithFourCharCode:fromSetupData:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer compareNumericVersion:withReferenceVersion:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer convertLivePhotoStruct:toDictionary:]
  -[VCPVideoMetaLivePhotoMetaAnalyzer convertLivePhotoBinary:toDictionary:]


VCPVideoMetaMotionAnalyzer : NSObject
 @property  NSArray *results

  // instance methods
  -[VCPVideoMetaMotionAnalyzer .cxx_construct]
  -[VCPVideoMetaMotionAnalyzer results]
  -[VCPVideoMetaMotionAnalyzer .cxx_destruct]
  -[VCPVideoMetaMotionAnalyzer init]
  -[VCPVideoMetaMotionAnalyzer finalizeAnalysis]
  -[VCPVideoMetaMotionAnalyzer processFrameMetadata:]
  -[VCPVideoMetaMotionAnalyzer decideSegmentPointBasedOn:]
  -[VCPVideoMetaMotionAnalyzer mergeSimilarSegments]


VCPVideoMetaMotionSegment : VCPMetaSegment
 @property  float absMotion
 @property  float stabilityScore

  // instance methods
  -[VCPVideoMetaMotionSegment mergeSegment:]
  -[VCPVideoMetaMotionSegment finalizeAtTime:]
  -[VCPVideoMetaMotionSegment resetSegment:atTime:]
  -[VCPVideoMetaMotionSegment updateSegment:atTime:]
  -[VCPVideoMetaMotionSegment stabilityScore]
  -[VCPVideoMetaMotionSegment initWithAbsMotion:atTime:]
  -[VCPVideoMetaMotionSegment absMotion]
  -[VCPVideoMetaMotionSegment setAbsMotion:]
  -[VCPVideoMetaMotionSegment setStabilityScore:]


VCPVideMetaOrientationAnalyzer : VCPVideoMetaAnalyzer
  // instance methods
  -[VCPVideMetaOrientationAnalyzer .cxx_destruct]
  -[VCPVideMetaOrientationAnalyzer init]
  -[VCPVideMetaOrientationAnalyzer privateResults]
  -[VCPVideMetaOrientationAnalyzer processMetadataGroup:flags:]


VCPVideoObjectTracker : NSObject
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} objectBoundsInitial
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} objectBounds
 @property  float confidence
 @property  {?=qiIq} start
 @property  int lostCount

  // instance methods
  -[VCPVideoObjectTracker .cxx_destruct]
  -[VCPVideoObjectTracker confidence]
  -[VCPVideoObjectTracker start]
  -[VCPVideoObjectTracker objectBounds]
  -[VCPVideoObjectTracker initWithObjectBounds:inFrame:timestamp:]
  -[VCPVideoObjectTracker trackObjectInFrame:]
  -[VCPVideoObjectTracker objectBoundsInitial]
  -[VCPVideoObjectTracker lostCount]


VCPSaliencyRegion : NSObject
 @property  {CGRect={CGPoint=dd}{CGSize=dd}} bound
 @property  float confidence

  // class methods
  +[VCPSaliencyRegion salientRegionsFromPixelBuffer:]
  +[VCPSaliencyRegion attachSalientRegions:toPixelBuffer:]

  // instance methods
  -[VCPSaliencyRegion setConfidence:]
  -[VCPSaliencyRegion confidence]
  -[VCPSaliencyRegion bound]
  -[VCPSaliencyRegion plistRepresentation]
  -[VCPSaliencyRegion initWithPlistRepresentation:]
  -[VCPSaliencyRegion setBound:]
  -[VCPSaliencyRegion initWith:confidence:]


VCPVideoSaliencyAnalyzer : VCPVideoAnalyzer
  // instance methods
  -[VCPVideoSaliencyAnalyzer results]
  -[VCPVideoSaliencyAnalyzer .cxx_destruct]
  -[VCPVideoSaliencyAnalyzer initWithTransform:]
  -[VCPVideoSaliencyAnalyzer analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoSaliencyAnalyzer finishAnalysisPass:]
  -[VCPVideoSaliencyAnalyzer isOutOfBoundary:]
  -[VCPVideoSaliencyAnalyzer updateConfidence:prevBound:newBound:width:height:]
  -[VCPVideoSaliencyAnalyzer pruneRegions:withOverlapRatio:]
  -[VCPVideoSaliencyAnalyzer boundDistance:relativeTo:landscape:]


VCPClassification : NSObject
 @property  NSString *sceneId
 @property  float duration
 @property  float sumConfidence

  // instance methods
  -[VCPClassification .cxx_destruct]
  -[VCPClassification setDuration:]
  -[VCPClassification sceneId]
  -[VCPClassification duration]
  -[VCPClassification setSceneId:]
  -[VCPClassification initWithSceneId:withDuration:withConfidence:]
  -[VCPClassification sumConfidence]
  -[VCPClassification setSumConfidence:]


VCPVideoSceneClassifier : VCPVideoAnalyzer
 @property  NSDictionary *frameScenes
 @property  NSArray *sceneResults

  // instance methods
  -[VCPVideoSceneClassifier results]
  -[VCPVideoSceneClassifier .cxx_destruct]
  -[VCPVideoSceneClassifier init]
  -[VCPVideoSceneClassifier dealloc]
  -[VCPVideoSceneClassifier analyzeFrame:withTimestamp:andDuration:flags:]
  -[VCPVideoSceneClassifier finishAnalysisPass:]
  -[VCPVideoSceneClassifier addResult:start:duration:keyIsName:]
  -[VCPVideoSceneClassifier compareObjectsOfInterest:withScenes:]
  -[VCPVideoSceneClassifier addAggregatedScenes:timerange:]
  -[VCPVideoSceneClassifier frameScenes]
  -[VCPVideoSceneClassifier sceneResults]
  -[VCPVideoSceneClassifier setSceneResults:]


VCPVideoTrackDecoder : NSObject
  // class methods
  +[VCPVideoTrackDecoder decodeDimensionsForTrack:]

  // instance methods
  -[VCPVideoTrackDecoder .cxx_destruct]
  -[VCPVideoTrackDecoder initWithTrack:]
  -[VCPVideoTrackDecoder init]
  -[VCPVideoTrackDecoder status]
  -[VCPVideoTrackDecoder copyNextSampleBuffer]
  -[VCPVideoTrackDecoder settings]
  -[VCPVideoTrackDecoder validateDecodedFrame:withSettings:]
  -[VCPVideoTrackDecoder getNextCaptureSampleBuffer]


VCPVideoTrackStandardDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackStandardDecoder .cxx_destruct]
  -[VCPVideoTrackStandardDecoder status]
  -[VCPVideoTrackStandardDecoder dealloc]
  -[VCPVideoTrackStandardDecoder copyNextSampleBuffer]
  -[VCPVideoTrackStandardDecoder initWithTrack:timerange:withSettings:applyTransform:]
  -[VCPVideoTrackStandardDecoder initWithTrack:timerange:]


VCPVideoTrackSubsamplingDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackSubsamplingDecoder .cxx_destruct]
  -[VCPVideoTrackSubsamplingDecoder status]
  -[VCPVideoTrackSubsamplingDecoder dealloc]
  -[VCPVideoTrackSubsamplingDecoder copyNextSampleBuffer]
  -[VCPVideoTrackSubsamplingDecoder getNextCaptureSampleBuffer]
  -[VCPVideoTrackSubsamplingDecoder initWithTrack:timerange:atInterval:]


VCPVideoTrackSyncDecoder : VCPVideoTrackDecoder
  // instance methods
  -[VCPVideoTrackSyncDecoder .cxx_destruct]
  -[VCPVideoTrackSyncDecoder status]
  -[VCPVideoTrackSyncDecoder dealloc]
  -[VCPVideoTrackSyncDecoder copyNextSampleBuffer]
  -[VCPVideoTrackSyncDecoder findNextSample:timerange:]
  -[VCPVideoTrackSyncDecoder decodeSample:sample:]
  -[VCPVideoTrackSyncDecoder decodeTask]
  -[VCPVideoTrackSyncDecoder initWithTrack:timerange:]


VCPVoiceDetector : NSObject
 @property  NSMutableArray *voiceDetections

  // class methods
  +[VCPVoiceDetector detector]

  // instance methods
  -[VCPVoiceDetector results]
  -[VCPVoiceDetector .cxx_destruct]
  -[VCPVoiceDetector loadModel]
  -[VCPVoiceDetector init]
  -[VCPVoiceDetector setupWithSample:andSampleBatchSize:]
  -[VCPVoiceDetector processAudioSamples:timestamp:]
  -[VCPVoiceDetector finalizeAnalysisAtTime:]
  -[VCPVoiceDetector audioFormatRequirements]
  -[VCPVoiceDetector voiceDetections]
  -[VCPVoiceDetector setVoiceDetections:]
  -[VCPVoiceDetector addDetectionFromTime:toTime:result:]
  -[VCPVoiceDetector setupWithAudioStream:]


VCPVoiceDetectorV2 : VCPVoiceDetector
  // instance methods
  -[VCPVoiceDetectorV2 results]
  -[VCPVoiceDetectorV2 loadModel]
  -[VCPVoiceDetectorV2 init]
  -[VCPVoiceDetectorV2 dealloc]
  -[VCPVoiceDetectorV2 processAudioSamples:timestamp:]
  -[VCPVoiceDetectorV2 finalizeAnalysisAtTime:]
  -[VCPVoiceDetectorV2 setupWithAudioStream:]


VCPCtrTracker : NSObject <VCPBaseTracker>
 @property  ^{CGPoint=dd} box
 @property  BOOL stableInd
 @property  BOOL lostTrackInd
 @property  float confidence

  // instance methods
  -[VCPCtrTracker box]
  -[VCPCtrTracker setConfidence:]
  -[VCPCtrTracker confidence]
  -[VCPCtrTracker init]
  -[VCPCtrTracker setBox:]
  -[VCPCtrTracker dealloc]
  -[VCPCtrTracker setupTrackerWithReferenceFrame:withROI:]
  -[VCPCtrTracker trackInFrame:]
  -[VCPCtrTracker lostTrackInd]
  -[VCPCtrTracker stableInd]
  -[VCPCtrTracker setStableInd:]
  -[VCPCtrTracker setLostTrackInd:]


MADRequest(MediaAnalysis)
	// instance methods
	-[MADRequest(MediaAnalysis) vcp_taskWithImageAsset:andSignpostPayload:]

AVAsset(MediaAnalysis)
	// instance methods
	-[AVAsset(MediaAnalysis) vcp_enabledTracksWithMediaType:]
	-[AVAsset(MediaAnalysis) vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:]
	-[AVAsset(MediaAnalysis) vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:]
	-[AVAsset(MediaAnalysis) vcp_firstEnabledTrackWithMediaType:]
	-[AVAsset(MediaAnalysis) vcp_isShortMovie]
	-[AVAsset(MediaAnalysis) vcp_isMontage]
	-[AVAsset(MediaAnalysis) vcp_assetWithoutAdjustments:duration:]
	-[AVAsset(MediaAnalysis) vcp_livePhotoStillDisplayTime]

PFVideoAVObjectBuilder(CMTimerange)
	// instance methods
	-[PFVideoAVObjectBuilder(CMTimerange) vcp_convertToOriginalTimerangeFromScaledTimerange:]

AVAssetTrack(MediaAnalysis)
	// instance methods
	-[AVAssetTrack(MediaAnalysis) vcp_imageOrientation]
	-[AVAssetTrack(MediaAnalysis) vcp_orientation]
	-[AVAssetTrack(MediaAnalysis) vcp_endTime]
	-[AVAssetTrack(MediaAnalysis) vcp_fullFrameSize]
	-[AVAssetTrack(MediaAnalysis) vcp_cleanApertureRect]
	-[AVAssetTrack(MediaAnalysis) vcp_startTime]

PHPerson(PVPersonProtocol)
	// instance methods
	-[PHPerson(PVPersonProtocol) hidden]
	-[PHPerson(PVPersonProtocol) favorite]
	-[PHPerson(PVPersonProtocol) keyFace]
	-[PHPerson(PVPersonProtocol) setKeyFace:]
	-[PHPerson(PVPersonProtocol) setManualOrder:]
	-[PHPerson(PVPersonProtocol) setIsVerified:]
	-[PHPerson(PVPersonProtocol) personLocalIdentifiers]
	-[PHPerson(PVPersonProtocol) anonymizedName]
	-[PHPerson(PVPersonProtocol) pv_addMergeCandidatePersons:]

PHFace(MediaAnalysis)
	// instance methods
	-[PHFace(MediaAnalysis) faceprintData]
	-[PHFace(MediaAnalysis) setQualityMeasure:]
	-[PHFace(MediaAnalysis) photosFaceRepresentationSourceWidth]
	-[PHFace(MediaAnalysis) photosFaceRepresentationSourceHeight]
	-[PHFace(MediaAnalysis) photosFaceRepresentationCenterX]
	-[PHFace(MediaAnalysis) photosFaceRepresentationCenterY]
	-[PHFace(MediaAnalysis) photosFaceRepresentationSize]
	-[PHFace(MediaAnalysis) photosFaceRepresentationBlurScore]
	-[PHFace(MediaAnalysis) photosFaceRepresentationHasSmile]
	-[PHFace(MediaAnalysis) photosFaceRepresentationIsLeftEyeClosed]
	-[PHFace(MediaAnalysis) photosFaceRepresentationIsRightEyeClosed]
	-[PHFace(MediaAnalysis) photosFaceRepresentationQualityMeasure]
	-[PHFace(MediaAnalysis) photosFaceRepresentationClusterSequenceNumber]
	-[PHFace(MediaAnalysis) photosFaceRepresentationLocalIdentifier]
	-[PHFace(MediaAnalysis) photosFaceRepresentationRoll]
	-[PHFace(MediaAnalysis) photosFaceRepresentationQuality]
	-[PHFace(MediaAnalysis) vcp_hasFace]
	-[PHFace(MediaAnalysis) vcp_normalizedFaceBounds]
	-[PHFace(MediaAnalysis) vcp_hasBody]
	-[PHFace(MediaAnalysis) vcp_normalizedBodyBounds]

PHPhotoLibrary(PVPhotoLibraryProtocol)
	// class methods
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultAssetPropertySets]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _phPeopleSortDescriptors]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultFacePropertySets]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _phFaceSortDescriptors]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_defaultMediaAnalysisDatabaseFilepath]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) _includeTorsoOnlyFaces]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_defaultURL]
	+[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_defaultPhotoLibrary]

	// instance methods
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMoments]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMomentsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsWithType:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_persistentStorageDirectoryURL]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_performChangesAndWait:error:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsInMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchCandidatePersonsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchInvalidCandidatePersonsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_numberOfFacesWithFaceprints]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForPerson:inMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForPersonLocalIdentifiers:inMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFacesForFaceGroup:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsForFaceLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMomentsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchMomentsForAssetsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsWithLocalIdentifiers:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsInMoment:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchAssetsForFaceGroup:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFaceGroups]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchFaceGroupsForPerson:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_fetchInvalidAssetIdentifiersForCommonComparison]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_faceProcessingProgress]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) pv_lastAssetDate]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultFetchOptions]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _defaultAssetFetchOptions]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _progressFromWorkerStatesDictionary:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_mediaAnalysisDatabaseFilepath]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_vipModelLastGenerationDateForVIPType:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_vipModelFilepathForVIPType:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_assetCountForTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_assetCountWithInternalPredicate:forTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_visionCacheStorageDirectoryURL]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) mad_countOfUnclusteredFaces]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) mad_unclusteredFacesFetchOptions]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_eligibleForStreaming:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_analysisPreferences]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_mediaAnalysisDirectory]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isCPLEnabled]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isCPLDownloadComplete]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_supportsInMemoryDownload]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_assetCountWithMediaType:forTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _analysisPreferencesURL]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) _updateAnalysisPreferencesWithEntries:keysToRemove:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_anyAssetsForTaskID:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isCPLSyncComplete]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_allowInMemoryDownload]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_libraryScaleShortDescription]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_requiresProcessingForTask:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_requiredFaceLibraryProcessingSubTasks]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_setAnalysisPreferencesValue:forKey:]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_isSyndicationLibrary]
	-[PHPhotoLibrary(PVPhotoLibraryProtocol) vcp_faceAnalysisStateFilepath]

PHAsset(FullAnalysis)
	// class methods
	+[PHAsset(FullAnalysis) vcp_fullAnalysisTypesForAssetType:]
	+[PHAsset(FullAnalysis) vcp_fetchOptionsForLibrary:forTaskID:]
	+[PHAsset(FullAnalysis) vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:]
	+[PHAsset(FullAnalysis) vcp_ocrGatingThreshold]
	+[PHAsset(FullAnalysis) vcp_usePHFace]
	+[PHAsset(FullAnalysis) vcp_usePHFaceExpression]

	// instance methods
	-[PHAsset(FullAnalysis) vcp_fingerprint:]
	-[PHAsset(FullAnalysis) vcp_typeDescription]
	-[PHAsset(FullAnalysis) vcp_isLivePhoto]
	-[PHAsset(FullAnalysis) vcp_fullAnalysisTypes]
	-[PHAsset(FullAnalysis) vcp_modificationDate]
	-[PHAsset(FullAnalysis) vcp_needSceneProcessing]
	-[PHAsset(FullAnalysis) vcp_needsOCRProcessing]
	-[PHAsset(FullAnalysis) vcp_needsVisualSearchProcessing]
	-[PHAsset(FullAnalysis) vcp_isVideoSlowmo]
	-[PHAsset(FullAnalysis) vcp_fullAnalysisTypesForResources:]
	-[PHAsset(FullAnalysis) vcp_eligibleForVideoDownload:]
	-[PHAsset(FullAnalysis) vcp_isShortMovie]
	-[PHAsset(FullAnalysis) vcp_hasAdjustments:]
	-[PHAsset(FullAnalysis) vcp_faceRectFrom:]
	-[PHAsset(FullAnalysis) vcp_flagsForPHFace:withFaceRect:]
	-[PHAsset(FullAnalysis) vcp_PHFaces]
	-[PHAsset(FullAnalysis) vcp_isMontageWithTaskID:]
	-[PHAsset(FullAnalysis) vcp_isPano]
	-[PHAsset(FullAnalysis) vcp_isSdofPhoto]
	-[PHAsset(FullAnalysis) vcp_isVideoTimelapse]
	-[PHAsset(FullAnalysis) vcp_confidenceForSceneIdentifier:]
	-[PHAsset(FullAnalysis) vcp_passedOCRGating]
	-[PHAsset(FullAnalysis) vcp_originalSize]
	-[PHAsset(FullAnalysis) vcp_queryPHFaces:results:]
	-[PHAsset(FullAnalysis) vcp_quickFaceClassificationDone]
	-[PHAsset(FullAnalysis) vcp_needFaceProcessing]
	-[PHAsset(FullAnalysis) vcp_ocrMajorDimensionForResource:]
	-[PHAsset(FullAnalysis) clsDistanceIdentity]
	-[PHAsset(FullAnalysis) vcp_abnormalDimension]

(VCPPhotosPersistenceDelegateAdditions)
	// instance methods
	-[(VCPPhotosPersistenceDelegateAdditions) persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalMovie:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_thumbnailResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_avAsset:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_localPhotoResourcesSorted:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalPhoto:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalSlowmo:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_isOriginalLocal]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_hasLocalAdjustments]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_resourceWithType:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_smallResourceMeetingCriteria:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_localMovieResourcesSorted:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_photoResourcesSorted:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_highResImageResourcesForAsset:]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_originalResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_originalVideoResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_getFpsRate]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_adjustmentsResource]
	-[(VCPPhotosPersistenceDelegateAdditions) vcp_smallMovieDerivativeResource]

PHFetchResult(MediaAnalysis)
	// instance methods
	-[PHFetchResult(MediaAnalysis) allObjects]
	-[PHFetchResult(MediaAnalysis) resultsAsArray]
	-[PHFetchResult(MediaAnalysis) resultsAsSet]

<DEREK BUG Categories!>(PHAssetResource)
	// instance methods
	-[<DEREK BUG Categories!>(PHAssetResource) vcp_sortBySize]

NSBundle(VCPMediaAnalysis)
	// class methods
	+[NSBundle(VCPMediaAnalysis) vcp_mediaAnalysisBundle]

(Exif)
	// class methods
	+[(Exif) vcp_exifFromImageURL:]

	// instance methods
	-[(Exif) vcp_dateModified]
	-[(Exif) vcp_version]
	-[(Exif) vcp_results]
	-[(Exif) vcp_quality]
	-[(Exif) vcp_types]
	-[(Exif) vcp_fingerprint]
	-[(Exif) vcp_degraded]
	-[(Exif) vcp_flags]
	-[(Exif) vcp_statsFlags]
	-[(Exif) vcp_syncPoint]
	-[(Exif) vcp_captureDeviceMake]
	-[(Exif) vcp_captureDeviceModel]
	-[(Exif) vcp_isAppleCapture]
	-[(Exif) vcp_dateAnalyzed]
	-[(Exif) vcp_streamedVideo]
	-[(Exif) vcp_time]
	-[(Exif) vcp_timerange]
	-[(Exif) vcp_flashFired]
	-[(Exif) vcp_scaledExposureTime]

<DEREK BUG Categories!>(MediaAnalysis)
	// instance methods
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setVersion:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setDateModified:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setDateAnalyzed:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setFlags:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setFingerprint:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setResult:forKey:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_addTypes:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setStatsFlags:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setTypes:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_addEntriesFromResults:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setSyncPoint:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_addFlags:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_appendResults:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setQuality:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_removeSyncPoint]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_addStatsFlags:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_appendResult:forKey:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_mutableResults]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setResults:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_setTimerange:]
	-[<DEREK BUG Categories!>(MediaAnalysis) vcp_removeResultForKey:]

NSPredicate(MediaAnalysis)
	// class methods
	+[NSPredicate(MediaAnalysis) mad_prioritizedAssetsForFaceDetectionInternalPredicate]
	+[NSPredicate(MediaAnalysis) _peopleThreshold]
	+[NSPredicate(MediaAnalysis) vcp_imagesPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_stillImagesPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_livePhotosPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_nonPanoImagesPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_moviesPredicate:]
	+[NSPredicate(MediaAnalysis) vcp_fullAnalysisPredatesVersionInternalPredicate:]
	+[NSPredicate(MediaAnalysis) mad_nonPrioritizedAssetsForFaceDetectionInternalPredicate]

PHAssetResource(MediaAnalysis)
	// class methods
	+[PHAssetResource(MediaAnalysis) vcp_allAcceptableResourcesForAsset:]
	+[PHAssetResource(MediaAnalysis) vcp_ascendingSizeComparator]
	+[PHAssetResource(MediaAnalysis) vcp_allResourcesForAsset:]
	+[PHAssetResource(MediaAnalysis) vcp_descendingSizeComparator]

	// instance methods
	-[PHAssetResource(MediaAnalysis) vcp_isLocallyAvailable]
	-[PHAssetResource(MediaAnalysis) vcp_uniformTypeIdentifier]
	-[PHAssetResource(MediaAnalysis) vcp_size]
	-[PHAssetResource(MediaAnalysis) vcp_isPhotoResourceUsable:]
	-[PHAssetResource(MediaAnalysis) vcp_isMovie]
	-[PHAssetResource(MediaAnalysis) vcp_isVideoResourceUsable:]
	-[PHAssetResource(MediaAnalysis) vcp_isPhoto]
	-[PHAssetResource(MediaAnalysis) vcp_fileSize]
	-[PHAssetResource(MediaAnalysis) vcp_isDecodable]
	-[PHAssetResource(MediaAnalysis) vcp_avAsset]

(MercuryBase64)
	// instance methods
	-[(MercuryBase64) vcp_isMercuryBase64]
	-[(MercuryBase64) vcp_mercuryBase64ToLocalIdentifier]

PHAssetCollection(PVMomentProtocol)
	// instance methods
	-[PHAssetCollection(PVMomentProtocol) isCoarse]
	-[PHAssetCollection(PVMomentProtocol) approximateCoordinate]

PHAssetResourceManager(MediaAnalysis)
	// class methods
	+[PHAssetResourceManager(MediaAnalysis) vcp_reportDownload:withTaskID:]
	+[PHAssetResourceManager(MediaAnalysis) vcp_inMemoryDownload:withTaskID:toData:cancel:]
	+[PHAssetResourceManager(MediaAnalysis) vcp_requestFileURLForAssetResource:withTaskID:toResourceURL:cancel:]
	+[PHAssetResourceManager(MediaAnalysis) vcp_requestFileURLForAssetResource:withTaskID:timeoutHandler:urlHandler:andCompletionHandler:]

PHFaceGroup(PVFaceGroupProtocol)
	// instance methods
	-[PHFaceGroup(PVFaceGroupProtocol) isDirty]
	-[PHFaceGroup(PVFaceGroupProtocol) faceCountInFaceGroup]

NSProgress(MediaAnalysis)
	// instance methods
	-[NSProgress(MediaAnalysis) vcp_childWithPendingUnitCount:]

VNClustererBuilder(BackwardCompatability)
	// instance methods
	-[VNClustererBuilder(BackwardCompatability) vcp_updateModelByAddingFaces:]

01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAsset 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetImageGenerator 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReader 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderOutputMetadataAdaptor 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderSampleReferenceOutput 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetReaderTrackOutput 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetTrack 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetWriter 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVAssetWriterInput 
01 00 2900 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVAudioFormat 
01 00 2900 /System/Library/Frameworks/AVFAudio.framework/AVFAudio: AVAudioPCMBuffer 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMediaDataStorage 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMetadataItem 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMutableComposition 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVMutableMovie 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVTimedMetadataGroup 
01 00 1f00 /System/Library/Frameworks/AVFoundation.framework/AVFoundation: AVURLAsset 
01 00 0700 /System/Library/PrivateFrameworks/CVNLP.framework/CVNLP: CVNLPCommSafetyHandler 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADEmbeddingGenerationRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADImageSafetyClassificationRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADImageSafetyClassificationResult 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIDocumentRecognitionRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIDocumentRecognitionResult 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIMachineReadableCodeDetectionRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIMachineReadableCodeDetectionResult 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchGatingDomainInfo 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchGatingRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchGatingResult 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchGatingResultItem 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchRegionAttributes 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchRequest 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchResult 
01 00 0900 /System/Library/PrivateFrameworks/MediaAnalysisServices.framework/MediaAnalysisServices: MADVIVisualSearchResultItem 
01 00 0800 /System/Library/Frameworks/CoreML.framework/CoreML: MLArrayBatchProvider 
01 00 0800 /System/Library/Frameworks/CoreML.framework/CoreML: MLFeatureValue 
01 00 0800 /System/Library/Frameworks/CoreML.framework/CoreML: MLModel 
01 00 0800 /System/Library/Frameworks/CoreML.framework/CoreML: MLPredictionOptions 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNBinaryConvolution 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNConvolution 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNConvolutionDescriptor 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNDepthWiseConvolutionDescriptor 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNFullyConnected 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSCNNPoolingMax 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImage 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImageBilinearScale 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSImageDescriptor 
01 00 1c00 /System/Library/Frameworks/MetalPerformanceShaders.framework/MetalPerformanceShaders: MPSTemporaryImage 
01 00 0d00 /System/Library/Frameworks/Metal.framework/Metal: MTLTextureDescriptor 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSArray 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSBundle 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSCharacterSet 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSCompoundPredicate 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSConstantArray 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantDoubleNumber 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantFloatNumber 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSConstantIntegerNumber 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSCountedSet 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSData 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDate 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSDateFormatter 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSDictionary 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSError 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSException 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSFileManager 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSIndexSet 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSJSONSerialization 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedArchiver 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSKeyedUnarchiver 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSLocale 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSLock 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSMapTable 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableArray 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableData 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableDictionary 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSMutableSet 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSMutableString 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSNull 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumber 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSNumberFormatter 
01 00 2600 /usr/lib/libobjc.A.dylib: NSObject 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSPredicate 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSProcessInfo 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSProgress 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSPropertyListSerialization 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSSet 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSSortDescriptor 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSString 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSURL 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSUUID 
01 00 2a00 /System/Library/Frameworks/CoreFoundation.framework/CoreFoundation: NSUserDefaults 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSValue 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSXPCConnection 
01 00 2100 /System/Library/Frameworks/Foundation.framework/Foundation: NSXPCInterface 
01 00 1d00 /System/Library/PrivateFrameworks/ProtocolBuffer.framework/ProtocolBuffer: PBCodable 
01 00 1400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFPhotosFaceUtilities 
01 00 1400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFSlowMotionConfiguration 
01 00 1400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFSlowMotionUtilities 
01 00 1400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFVideoAVObjectBuilder 
01 00 1400 /System/Library/PrivateFrameworks/PhotosFormats.framework/PhotosFormats: PFVideoAdjustments 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHAsset 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHAssetChangeRequest 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHAssetCollection 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResource 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResourceManager 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHAssetResourceRequestOptions 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHCollection 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFace 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFaceChangeRequest 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFaceCrop 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFaceCropChangeRequest 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFaceGroup 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFaceGroupChangeRequest 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFaceprint 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFetchOptions 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHFetchResult 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHMoment 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHObject 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHPerson 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHPersonChangeRequest 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHPhotoLibrary 
01 00 1a00 /System/Library/Frameworks/Photos.framework/Photos: PHSceneClassification 
01 00 1100 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNAudioStreamAnalyzer 
01 00 1100 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectSoundRequest 
01 00 1100 /System/Library/Frameworks/SoundAnalysis.framework/SoundAnalysis: SNDetectionResult 
01 00 0600 /System/Library/Frameworks/UniformTypeIdentifiers.framework/UniformTypeIdentifiers: UTType 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIAnnotation 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIImageRegion 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIParsedVisualQuery 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIQueryContext 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIRegionalAnnotation 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIService 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VITextBlockAnnotation 
01 00 0500 /System/Library/PrivateFrameworks/VisualIntelligence.framework/VisualIntelligence: VIVisualQuery 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VN1JC7R3k4455fKQz0dY1VhQ 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VN5kJNH3eYuyaLxNpZr5Z7zi 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VN6Mb1ME89lyW3HpahkEygIG 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VN6kBnCOr2mZlSV6yV1dLwB 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNAlignFaceRectangleRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNAnimalObservation 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNAnimalprint 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNBarcodeObservation 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCanceller 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyFaceAttributesRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyImageAestheticsRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyJunkImageRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyMemeImageRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClassifyPotentialLandmarkRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClustererBuilder 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClustererBuilderOptions 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNClustererQuery 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateAnimalprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateFaceTorsoprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateFaceprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateImageprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateNeuralHashprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateSceneprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNCreateTorsoprintRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectBarcodesRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceCaptureQualityRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceExpressionsRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceGazeRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceLandmarksRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFacePoseRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectFaceRectanglesRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDetectHumanRectanglesRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNDocumentObservation 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNEntityIdentificationModel 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNEntityIdentificationModelConfiguration 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNEntityIdentificationModelReadOptions 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNEntityIdentificationModelWriteOptions 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNFaceObservation 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNFaceTorsoprint 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNFaceprint 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNGenerateAttentionBasedSaliencyImageRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNGenerateObjectnessBasedSaliencyImageRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNIdentifyJunkRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNImageBlurScoreRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNImageExposureScoreRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNImageRequestHandler 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNImageprint 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNMutableEntityIdentificationModel 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNMutablePersonsModel 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNPersonsModel 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNPersonsModelConfiguration 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNPersonsModelReadOptions 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNPersonsModelWriteOptions 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNProcessingDevice 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNRecognizeAnimalsRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNRecognizeDocumentElementsRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNRecognizeDocumentsRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNRecognizeObjectsRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNSceneClassificationRequest 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNSceneObservation 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNSceneprint 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNSession 
01 00 1300 /System/Library/Frameworks/Vision.framework/Vision: VNVYvzEtX1JlUdu8xx5qhDI 
